{"meta":{"title":"llllz_liu","subtitle":"llllzの博客","description":"计算机 | 软件工程","author":"llllz.","url":"https://gitee.com/yunyd","root":"/yunyd/"},"pages":[{"title":"404","date":"2019-08-10T08:41:10.000Z","updated":"2023-08-01T03:34:54.609Z","comments":true,"path":"404.html","permalink":"https://gitee.com/yunyd/404.html","excerpt":"","text":""},{"title":"","date":"2023-08-01T03:34:54.752Z","updated":"2023-08-01T03:34:54.752Z","comments":true,"path":"baidu_verify_xxxxxxx.html","permalink":"https://gitee.com/yunyd/baidu_verify_xxxxxxx.html","excerpt":"","text":"wvlc3L96QK"},{"title":"放松一下","date":"2019-08-10T08:41:10.000Z","updated":"2023-08-01T03:34:54.629Z","comments":true,"path":"List/index.html","permalink":"https://gitee.com/yunyd/List/index.html","excerpt":"","text":"影音资源共享"},{"title":"","date":"2023-08-01T03:34:54.756Z","updated":"2023-08-01T03:34:54.756Z","comments":true,"path":"google1xxxxxxx0.html","permalink":"https://gitee.com/yunyd/google1xxxxxxx0.html","excerpt":"","text":"google-site-verification: google110e5e5e14c8dcf0.html"},{"title":"archives","date":"2019-10-24T16:00:00.000Z","updated":"2023-08-01T03:34:54.751Z","comments":true,"path":"archives/index.html","permalink":"https://gitee.com/yunyd/archives/index.html","excerpt":"","text":""},{"title":"留言板","date":"2023-07-19T16:00:00.000Z","updated":"2023-08-10T23:19:38.396Z","comments":true,"path":"contact/index.html","permalink":"https://gitee.com/yunyd/contact/index.html","excerpt":"","text":"畅所欲言 在这里可以留下你的足迹，欢迎在下方留言，欢迎交换友链，一起交流学习！ 友链 llllzの友链信息 博客名称: llllzの博客 博客网址: http://yunyd.gitee.io 博客介绍: The harder you work, the luckier you will be"},{"title":"友链","date":"2019-07-19T08:42:10.000Z","updated":"2023-08-01T09:40:55.431Z","comments":true,"path":"friends/index.html","permalink":"https://gitee.com/yunyd/friends/index.html","excerpt":"","text":""},{"title":"about","date":"2019-10-24T16:00:00.000Z","updated":"2023-08-01T03:34:54.750Z","comments":true,"path":"about/index.html","permalink":"https://gitee.com/yunyd/about/index.html","excerpt":"","text":""},{"title":"资源分享","date":"2019-07-19T08:40:27.000Z","updated":"2023-08-01T03:34:54.757Z","comments":true,"path":"resource/index.html","permalink":"https://gitee.com/yunyd/resource/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-07-19T08:40:27.000Z","updated":"2023-08-01T03:34:54.758Z","comments":true,"path":"tags/index.html","permalink":"https://gitee.com/yunyd/tags/index.html","excerpt":"","text":""},{"title":"视频","date":"2019-08-10T08:41:10.000Z","updated":"2023-08-01T03:34:54.630Z","comments":true,"path":"List/movies/index.html","permalink":"https://gitee.com/yunyd/List/movies/index.html","excerpt":"","text":""},{"title":"听听音乐","date":"2019-07-19T08:40:27.000Z","updated":"2023-08-01T03:34:54.632Z","comments":true,"path":"List/tools/index.html","permalink":"https://gitee.com/yunyd/List/tools/index.html","excerpt":"","text":""},{"title":"听听音乐","date":"2019-07-19T08:40:27.000Z","updated":"2023-08-01T03:34:54.631Z","comments":true,"path":"List/music/index.html","permalink":"https://gitee.com/yunyd/List/music/index.html","excerpt":"","text":""},{"title":"相册","date":"2023-08-01T03:34:54.619Z","updated":"2023-08-01T03:34:54.619Z","comments":true,"path":"List/galleries/index.html","permalink":"https://gitee.com/yunyd/List/galleries/index.html","excerpt":"","text":""},{"title":"乖巧小狗","date":"2023-08-01T03:34:54.620Z","updated":"2023-08-01T03:34:54.620Z","comments":true,"path":"List/galleries/乖巧小狗/index.html","permalink":"https://gitee.com/yunyd/List/galleries/%E4%B9%96%E5%B7%A7%E5%B0%8F%E7%8B%97/index.html","excerpt":"","text":""},{"title":"二次元风","date":"2023-08-01T03:34:54.620Z","updated":"2023-08-01T03:34:54.620Z","comments":true,"path":"List/galleries/二次元风/index.html","permalink":"https://gitee.com/yunyd/List/galleries/%E4%BA%8C%E6%AC%A1%E5%85%83%E9%A3%8E/index.html","excerpt":"","text":""},{"title":"动漫人物","date":"2023-08-01T03:34:54.621Z","updated":"2023-08-01T03:34:54.621Z","comments":true,"path":"List/galleries/动漫人物/index.html","permalink":"https://gitee.com/yunyd/List/galleries/%E5%8A%A8%E6%BC%AB%E4%BA%BA%E7%89%A9/index.html","excerpt":"","text":""},{"title":"动漫插画","date":"2023-08-01T03:34:54.622Z","updated":"2023-08-01T03:34:54.622Z","comments":true,"path":"List/galleries/动漫插画/index.html","permalink":"https://gitee.com/yunyd/List/galleries/%E5%8A%A8%E6%BC%AB%E6%8F%92%E7%94%BB/index.html","excerpt":"","text":""},{"title":"动漫风景","date":"2023-08-01T03:34:54.623Z","updated":"2023-08-01T03:34:54.623Z","comments":true,"path":"List/galleries/动漫风景/index.html","permalink":"https://gitee.com/yunyd/List/galleries/%E5%8A%A8%E6%BC%AB%E9%A3%8E%E6%99%AF/index.html","excerpt":"","text":""},{"title":"清新花卉","date":"2023-08-01T03:34:54.625Z","updated":"2023-08-01T03:34:54.625Z","comments":true,"path":"List/galleries/清新花卉/index.html","permalink":"https://gitee.com/yunyd/List/galleries/%E6%B8%85%E6%96%B0%E8%8A%B1%E5%8D%89/index.html","excerpt":"","text":""},{"title":"城市风光","date":"2023-08-01T03:34:54.625Z","updated":"2023-08-01T03:34:54.625Z","comments":true,"path":"List/galleries/城市风光/index.html","permalink":"https://gitee.com/yunyd/List/galleries/%E5%9F%8E%E5%B8%82%E9%A3%8E%E5%85%89/index.html","excerpt":"","text":""},{"title":"呆萌猫咪","date":"2023-08-01T03:34:54.624Z","updated":"2023-08-01T03:34:54.624Z","comments":true,"path":"List/galleries/呆萌猫咪/index.html","permalink":"https://gitee.com/yunyd/List/galleries/%E5%91%86%E8%90%8C%E7%8C%AB%E5%92%AA/index.html","excerpt":"","text":""},{"title":"炫酷跑车","date":"2023-08-01T03:34:54.626Z","updated":"2023-08-01T03:34:54.626Z","comments":true,"path":"List/galleries/炫酷跑车/index.html","permalink":"https://gitee.com/yunyd/List/galleries/%E7%82%AB%E9%85%B7%E8%B7%91%E8%BD%A6/index.html","excerpt":"","text":""},{"title":"甜美食品","date":"2023-08-01T03:34:54.628Z","updated":"2023-08-01T03:34:54.628Z","comments":true,"path":"List/galleries/甜美食品/index.html","permalink":"https://gitee.com/yunyd/List/galleries/%E7%94%9C%E7%BE%8E%E9%A3%9F%E5%93%81/index.html","excerpt":"","text":""},{"title":"自然风景","date":"2023-08-01T03:34:54.629Z","updated":"2023-08-01T03:34:54.629Z","comments":true,"path":"List/galleries/自然风景/index.html","permalink":"https://gitee.com/yunyd/List/galleries/%E8%87%AA%E7%84%B6%E9%A3%8E%E6%99%AF/index.html","excerpt":"","text":""},{"title":"璀璨星空","date":"2023-08-01T03:34:54.627Z","updated":"2023-08-01T03:34:54.627Z","comments":true,"path":"List/galleries/璀璨星空/index.html","permalink":"https://gitee.com/yunyd/List/galleries/%E7%92%80%E7%92%A8%E6%98%9F%E7%A9%BA/index.html","excerpt":"","text":""}],"posts":[{"title":"Docker","slug":"Docker","date":"2023-08-28T01:02:17.000Z","updated":"2023-08-28T01:09:51.104Z","comments":true,"path":"posts/f5f9fa9b.html","link":"","permalink":"https://gitee.com/yunyd/posts/f5f9fa9b.html","excerpt":"","text":"Docker回顾1.初识Docker1.1.什么是Docker微服务虽然具备各种各样的优势，但服务的拆分通用给部署带来了很大的麻烦。 分布式系统中，依赖的组件非常多，不同组件之间部署时往往会产生一些冲突。 在数百上千台服务中重复部署，环境不一定一致，会遇到各种问题 1.1.1.应用部署的环境问题大型项目组件较多，运行环境也较为复杂，部署时会碰到一些问题： 依赖关系复杂，容易出现兼容性问题 开发、测试、生产环境有差异 例如一个项目中，部署时需要依赖于node.js、Redis、RabbitMQ、MySQL等，这些服务部署时所需要的函数库、依赖项各不相同，甚至会有冲突。给部署带来了极大的困难。 1.1.2.Docker解决依赖兼容问题而Docker确巧妙的解决了这些问题，Docker是如何实现的呢？ Docker为了解决依赖的兼容问题的，采用了两个手段： 将应用的Libs（函数库）、Deps（依赖）、配置与应用一起打包 将每个应用放到一个隔离容器去运行，避免互相干扰 这样打包好的应用包中，既包含应用本身，也保护应用所需要的Libs、Deps，无需再操作系统上安装这些，自然就不存在不同应用之间的兼容问题了。 虽然解决了不同应用的兼容问题，但是开发、测试等环境会存在差异，操作系统版本也会有差异，怎么解决这些问题呢？ 1.1.3.Docker解决操作系统环境差异要解决不同操作系统环境差异问题，必须先了解操作系统结构。以一个Ubuntu操作系统为例，结构如下： 结构包括： 计算机硬件：例如CPU、内存、磁盘等 系统内核：所有Linux发行版的内核都是Linux，例如CentOS、Ubuntu、Fedora等。内核可以与计算机硬件交互，对外提供内核指令，用于操作计算机硬件。 系统应用：操作系统本身提供的应用、函数库。这些函数库是对内核指令的封装，使用更加方便。 应用于计算机交互的流程如下： 1）应用调用操作系统应用（函数库），实现各种功能 2）系统函数库是对内核指令集的封装，会调用内核指令 3）内核指令操作计算机硬件 Ubuntu和CentOSpringBoot都是基于Linux内核，无非是系统应用不同，提供的函数库有差异： 此时，如果将一个Ubuntu版本的MySQL应用安装到CentOS系统，MySQL在调用Ubuntu函数库时，会发现找不到或者不匹配，就会报错了： Docker如何解决不同系统环境的问题？ Docker将用户程序与所需要调用的系统(比如Ubuntu)函数库一起打包 Docker运行到不同操作系统时，直接基于打包的函数库，借助于操作系统的Linux内核来运行 如图： 1.1.4.小结Docker如何解决大型项目依赖关系复杂，不同组件依赖的兼容性问题？ Docker允许开发中将应用、依赖、函数库、配置一起打包，形成可移植镜像 Docker应用运行在容器中，使用沙箱机制，相互隔离 Docker如何解决开发、测试、生产环境有差异的问题？ Docker镜像中包含完整运行环境，包括系统函数库，仅依赖系统的Linux内核，因此可以在任意Linux操作系统上运行 Docker是一个快速交付应用、运行应用的技术，具备下列优势： 可以将程序及其依赖、运行环境一起打包为一个镜像，可以迁移到任意Linux操作系统 运行时利用沙箱机制形成隔离容器，各个应用互不干扰 启动、移除都可以通过一行命令完成，方便快捷 1.2.Docker和虚拟机的区别Docker可以让一个应用在任何操作系统中非常方便的运行。而以前我们接触的虚拟机，也能在一个操作系统中，运行另外一个操作系统，保护系统中的任何应用。 两者有什么差异呢？ 虚拟机（virtual machine）是在操作系统中模拟硬件设备，然后运行另一个操作系统，比如在 Windows 系统里面运行 Ubuntu 系统，这样就可以运行任意的Ubuntu应用了。 Docker仅仅是封装函数库，并没有模拟完整的操作系统，如图： 对比来看： 小结： Docker和虚拟机的差异： docker是一个系统进程；虚拟机是在操作系统中的操作系统 docker体积小、启动速度快、性能好；虚拟机体积大、启动速度慢、性能一般 1.3.Docker架构1.3.1.镜像和容器Docker中有几个重要的概念： 镜像（Image）：Docker将应用程序及其所需的依赖、函数库、环境、配置等文件打包在一起，称为镜像。 容器（Container）：镜像中的应用程序运行后形成的进程就是容器，只是Docker会给容器进程做隔离，对外不可见。 一切应用最终都是代码组成，都是硬盘中的一个个的字节形成的文件。只有运行时，才会加载到内存，形成进程。 而镜像，就是把一个应用在硬盘上的文件、及其运行环境、部分系统函数库文件一起打包形成的文件包。这个文件包是只读的。 容器呢，就是将这些文件中编写的程序、函数加载到内存中允许，形成进程，只不过要隔离起来。因此一个镜像可以启动多次，形成多个容器进程。 例如你下载了一个QQ，如果我们将QQ在磁盘上的运行文件及其运行的操作系统依赖打包，形成QQ镜像。然后你可以启动多次，双开、甚至三开QQ，跟多个妹子聊天。 1.3.2.DockerHub开源应用程序非常多，打包这些应用往往是重复的劳动。为了避免这些重复劳动，人们就会将自己打包的应用镜像，例如Redis、MySQL镜像放到网络上，共享使用，就像GitHub的代码共享一样。 DockerHub：DockerHub是一个官方的Docker镜像的托管平台。这样的平台称为Docker Registry。 国内也有类似于DockerHub 的公开服务，比如 网易云镜像服务、阿里云镜像库等。 我们一方面可以将自己的镜像共享到DockerHub，另一方面也可以从DockerHub拉取镜像： 1.3.3.Docker架构我们要使用Docker来操作镜像、容器，就必须要安装Docker。 Docker是一个CS架构的程序，由两部分组成： 服务端(server)：Docker守护进程，负责处理Docker指令，管理镜像、容器等 客户端(client)：通过命令或RestAPI向Docker服务端发送指令。可以在本地或远程向服务端发送指令。 如图： 1.3.4.小结镜像： 将应用程序及其依赖、环境、配置打包在一起 容器： 镜像运行起来就是容器，一个镜像可以运行多个容器 Docker结构： 服务端：接收命令或远程请求，操作镜像或容器 客户端：发送命令或者请求到Docker服务端 DockerHub： 一个镜像托管的服务器，类似的还有阿里云镜像服务，统称为DockerRegistry 1.4.安装Docker企业部署一般都是采用Linux操作系统，而其中又数CentOS发行版占比最多，因此我们在CentOS下安装Docker。 2.Docker的基本操作2.1.镜像操作2.1.1.镜像名称首先来看下镜像的名称组成： 镜名称一般分两部分组成：[repository]:[tag]。 在没有指定tag时，默认是latest，代表最新版本的镜像 如图： 这里的mysql就是repository，5.7就是tag，合一起就是镜像名称，代表5.7版本的MySQL镜像。 2.1.2.镜像命令常见的镜像操作命令如图： 2.1.3.案例1-拉取、查看镜像需求：从DockerHub中拉取一个nginx镜像并查看 1）首先去镜像仓库搜索nginx镜像，比如DockerHub: 2）根据查看到的镜像名称，拉取自己需要的镜像，通过命令：docker pull nginx 3）通过命令：docker images 查看拉取到的镜像 2.1.4.案例2-保存、导入镜像需求：利用docker save将nginx镜像导出磁盘，然后再通过load加载回来 1）利用docker xx –help命令查看docker save和docker load的语法 例如，查看save命令用法，可以输入命令： docker save --help 结果： 命令格式： docker save -o [保存的目标文件名称] [镜像名称] 2）使用docker save导出镜像到磁盘 运行命令： docker save -o nginx.tar nginx:latest 结果如图： 3）使用docker load加载镜像 先删除本地的nginx镜像： docker rmi nginx:latest 然后运行命令，加载本地文件： docker load -i nginx.tar 结果： 2.1.5.练习需求：去DockerHub搜索并拉取一个Redis镜像 目标： 1）去DockerHub搜索Redis镜像 2）查看Redis镜像的名称和版本 3）利用docker pull命令拉取镜像 4）利用docker save命令将 redis:latest打包为一个redis.tar包 5）利用docker rmi 删除本地的redis:latest 6）利用docker load 重新加载 redis.tar文件 2.2.容器操作2.2.1.容器相关命令容器操作的命令如图： 容器保护三个状态： 运行：进程正常运行 暂停：进程暂停，CPU不再运行，并不释放内存 停止：进程终止，回收进程占用的内存、CPU等资源 其中： docker run：创建并运行一个容器，处于运行状态 docker pause：让一个运行的容器暂停 docker unpause：让一个容器从暂停状态恢复运行 docker stop：停止一个运行的容器 docker start：让一个停止的容器再次运行 docker rm：删除一个容器 2.2.2.案例-创建并运行一个容器创建并运行nginx容器的命令： docker run --name containerName -p 80:80 -d nginx 命令解读： docker run ：创建并运行一个容器 –name : 给容器起一个名字，比如叫做mn -p ：将宿主机端口与容器端口映射，冒号左侧是宿主机端口，右侧是容器端口 -d：后台运行容器 nginx：镜像名称，例如nginx 这里的-p参数，是将容器端口映射到宿主机端口。 默认情况下，容器是隔离环境，我们直接访问宿主机的80端口，肯定访问不到容器中的nginx。 现在，将容器的80与宿主机的80关联起来，当我们访问宿主机的80端口时，就会被映射到容器的80，这样就能访问到nginx了： 2.2.3.案例-进入容器，修改文件需求：进入Nginx容器，修改HTML文件内容，添加“传智教育欢迎您” 提示：进入容器要用到docker exec命令。 步骤： 1）进入容器。进入我们刚刚创建的nginx容器的命令为： docker exec -it mn bash 命令解读： docker exec ：进入容器内部，执行一个命令 -it : 给当前进入的容器创建一个标准输入、输出终端，允许我们与容器交互 mn ：要进入的容器的名称 bash：进入容器后执行的命令，bash是一个linux终端交互命令 2）进入nginx的HTML所在目录 /usr/share/nginx/html 容器内部会模拟一个独立的Linux文件系统，看起来如同一个linux服务器一样： nginx的环境、配置、运行文件全部都在这个文件系统中，包括我们要修改的html文件。 查看DockerHub网站中的nginx页面，可以知道nginx的html目录位置在/usr/share/nginx/html 我们执行命令，进入该目录： cd /usr/share/nginx/html 查看目录下文件： 3）修改index.html的内容 容器内没有vi命令，无法直接修改，我们用下面的命令来修改： sed -i -e 's#Welcome to nginx#传智教育欢迎您#g' -e 's#&lt;head&gt;#&lt;head&gt;&lt;meta charset=\"utf-8\"&gt;#g' index.html 在浏览器访问自己的虚拟机地址，例如我的是：http://192.168.150.101，即可看到结果： 2.2.4.小结docker run命令的常见参数有哪些？ –name：指定容器名称 -p：指定端口映射 -d：让容器后台运行 查看容器日志的命令： docker logs 添加 -f 参数可以持续查看日志 查看容器状态： docker ps docker ps -a 查看所有容器，包括已经停止的 2.3.数据卷（容器数据管理）在之前的nginx案例中，修改nginx的html页面时，需要进入nginx内部。并且因为没有编辑器，修改文件也很麻烦。 这就是因为容器与数据（容器内文件）耦合带来的后果。 要解决这个问题，必须将数据与容器解耦，这就要用到数据卷了。 2.3.1.什么是数据卷数据卷（volume）是一个虚拟目录，指向宿主机文件系统中的某个目录。 一旦完成数据卷挂载，对容器的一切操作都会作用在数据卷对应的宿主机目录了。 这样，我们操作宿主机的/var/lib/docker/volumes/html目录，就等于操作容器内的/usr/share/nginx/html目录了 2.3.2.数据集操作命令数据卷操作的基本语法如下： docker volume [COMMAND] docker volume命令是数据卷操作，根据命令后跟随的command来确定下一步的操作： create 创建一个volume inspect 显示一个或多个volume的信息 ls 列出所有的volume prune 删除未使用的volume rm 删除一个或多个指定的volume 2.3.3.创建和查看数据卷需求：创建一个数据卷，并查看数据卷在宿主机的目录位置 ① 创建数据卷 docker volume create html ② 查看所有数据 docker volume ls 结果： ③ 查看数据卷详细信息卷 docker volume inspect html 结果： 可以看到，我们创建的html这个数据卷关联的宿主机目录为/var/lib/docker/volumes/html/_data目录。 小结： 数据卷的作用： 将容器与数据分离，解耦合，方便操作容器内数据，保证数据安全 数据卷操作： docker volume create：创建数据卷 docker volume ls：查看所有数据卷 docker volume inspect：查看数据卷详细信息，包括关联的宿主机目录位置 docker volume rm：删除指定数据卷 docker volume prune：删除所有未使用的数据卷 2.3.4.挂载数据卷我们在创建容器时，可以通过 -v 参数来挂载一个数据卷到某个容器内目录，命令格式如下： docker run \\ --name mn \\ -v html:/root/html \\ -p 8080:80 nginx \\ 这里的-v就是挂载数据卷的命令： -v html:/root/htm ：把html数据卷挂载到容器内的/root/html这个目录中 2.3.5.案例-给nginx挂载数据卷需求：创建一个nginx容器，修改容器内的html目录内的index.html内容 分析：上个案例中，我们进入nginx容器内部，已经知道nginx的html目录所在位置/usr/share/nginx/html ，我们需要把这个目录挂载到html这个数据卷上，方便操作其中的内容。 提示：运行容器时使用 -v 参数挂载数据卷 步骤： ① 创建容器并挂载数据卷到容器内的HTML目录 docker run --name mn -v html:/usr/share/nginx/html -p 80:80 -d nginx ② 进入html数据卷所在位置，并修改HTML内容 # 查看html数据卷的位置 docker volume inspect html # 进入该目录 cd /var/lib/docker/volumes/html/_data # 修改文件 vi index.html 2.3.6.案例-给MySQL挂载本地目录容器不仅仅可以挂载数据卷，也可以直接挂载到宿主机目录上。关联关系如下： 带数据卷模式：宿主机目录 –&gt; 数据卷 —&gt; 容器内目录 直接挂载模式：宿主机目录 —&gt; 容器内目录 如图： 语法： 目录挂载与数据卷挂载的语法是类似的： -v [宿主机目录]:[容器内目录] -v [宿主机文件]:[容器内文件] 需求：创建并运行一个MySQL容器，将宿主机目录直接挂载到容器 实现思路如下： 1）在将mysql.tar文件上传到虚拟机，通过load命令加载为镜像 2）创建目录/tmp/mysql/data 3）创建目录/tmp/mysql/conf，将资料提供的hmy.cnf文件上传到/tmp/mysql/conf 4）去DockerHub查阅资料，创建并运行MySQL容器，要求： ① 挂载/tmp/mysql/data到mysql容器内数据存储目录 ② 挂载/tmp/mysql/conf/hmy.cnf到mysql容器的配置文件 ③ 设置MySQL密码 2.3.7.小结docker run的命令中通过 -v 参数挂载文件或目录到容器中： -v volume名称:容器内目录 -v 宿主机文件:容器内文 -v 宿主机目录:容器内目录 数据卷挂载与目录直接挂载的 数据卷挂载耦合度低，由docker来管理目录，但是目录较深，不好找 目录挂载耦合度高，需要我们自己管理目录，不过目录容易寻找查看 3.Dockerfile自定义镜像常见的镜像在DockerHub就能找到，但是我们自己写的项目就必须自己构建镜像了。 而要自定义镜像，就必须先了解镜像的结构才行。 3.1.镜像结构镜像是将应用程序及其需要的系统函数库、环境、配置、依赖打包而成。 我们以MySQL为例，来看看镜像的组成结构： 简单来说，镜像就是在系统函数库、运行环境基础上，添加应用程序文件、配置文件、依赖文件等组合，然后编写好启动脚本打包在一起形成的文件。 我们要构建镜像，其实就是实现上述打包的过程。 3.2.Dockerfile语法构建自定义的镜像时，并不需要一个个文件去拷贝，打包。 我们只需要告诉Docker，我们的镜像的组成，需要哪些BaseImage、需要拷贝什么文件、需要安装什么依赖、启动脚本是什么，将来Docker会帮助我们构建镜像。 而描述上述信息的文件就是Dockerfile文件。 Dockerfile就是一个文本文件，其中包含一个个的**指令(Instruction)**，用指令来说明要执行什么操作来构建镜像。每一个指令都会形成一层Layer。 更新详细语法说明，请参考官网文档： https://docs.docker.com/engine/reference/builder 3.3.构建Java项目3.3.1.基于Ubuntu构建Java项目需求：基于Ubuntu镜像构建一个新镜像，运行一个java项目 步骤1：新建一个空文件夹docker-demo 步骤2：拷贝资料中的docker-demo.jar文件到docker-demo这个目录 步骤3：拷贝jdk8.tar.gz文件到docker-demo这个目录 步骤4：拷贝Dockerfile到docker-demo这个目录 其中的内容如下： # 指定基础镜像 FROM ubuntu:16.04 # 配置环境变量，JDK的安装目录 ENV JAVA_DIR=/usr/local # 拷贝jdk和java项目的包 COPY ./jdk8.tar.gz $JAVA_DIR/ COPY ./docker-demo.jar /tmp/app.jar # 安装JDK RUN cd $JAVA_DIR \\ &amp;&amp; tar -xf ./jdk8.tar.gz \\ &amp;&amp; mv ./jdk1.8.0_144 ./java8 # 配置环境变量 ENV JAVA_HOME=$JAVA_DIR/java8 ENV PATH=$PATH:$JAVA_HOME/bin # 暴露端口 EXPOSE 8090 # 入口，java项目的启动命令 ENTRYPOINT java -jar /tmp/app.jar 步骤5：进入docker-demo 将准备好的docker-demo上传到虚拟机任意目录，然后进入docker-demo目录下 步骤6：运行命令： docker build -t javaweb:1.0 . 最后访问 http://192.168.150.101:8090/hello/count，其中的ip改成你的虚拟机ip 3.3.2.基于java8构建Java项目虽然我们可以基于Ubuntu基础镜像，添加任意自己需要的安装包，构建镜像，但是却比较麻烦。所以大多数情况下，我们都可以在一些安装了部分软件的基础镜像上做改造。 例如，构建java项目的镜像，可以在已经准备了JDK的基础镜像基础上构建。 需求：基于java:8-alpine镜像，将一个Java项目构建为镜像 实现思路如下： ① 新建一个空的目录，然后在目录中新建一个文件，命名为Dockerfile ② 拷贝docker-demo.jar到这个目录中 ③ 编写Dockerfile文件： a ）基于java:8-alpine作为基础镜像 b ）将app.jar拷贝到镜像中 c ）暴露端口 d ）编写入口ENTRYPOINT 内容如下： FROM java:8-alpine COPY ./app.jar /tmp/app.jar EXPOSE 8090 ENTRYPOINT java -jar /tmp/app.jar ④ 使用docker build命令构建镜像 ⑤ 使用docker run创建容器并运行 3.4.小结小结： Dockerfile的本质是一个文件，通过指令描述镜像的构建过程 Dockerfile的第一行必须是FROM，从一个基础镜像来构建 基础镜像可以是基本操作系统，如Ubuntu。也可以是其他人制作好的镜像，例如：java:8-alpine 4.Docker-ComposeDocker Compose可以基于Compose文件帮我们快速的部署分布式应用，而无需手动一个个创建和运行容器！ 4.1.初识DockerComposeCompose文件是一个文本文件，通过指令定义集群中的每个容器如何运行。格式如下： version: \"3.8\" services: mysql: image: mysql:5.7.25 environment: MYSQL_ROOT_PASSWORD: 123 volumes: - \"/tmp/mysql/data:/var/lib/mysql\" - \"/tmp/mysql/conf/hmy.cnf:/etc/mysql/conf.d/hmy.cnf\" web: build: . ports: - \"8090:8090\" 上面的Compose文件就描述一个项目，其中包含两个容器： mysql：一个基于mysql:5.7.25镜像构建的容器，并且挂载了两个目录 web：一个基于docker build临时构建的镜像容器，映射端口时8090 DockerCompose的详细语法参考官网：https://docs.docker.com/compose/compose-file/ 其实DockerCompose文件可以看做是将多个docker run命令写到一个文件，只是语法稍有差异。 4.2.安装DockerCompose参考网上资料 4.3.部署微服务集群需求：将之前学习的cloud-demo微服务集群利用DockerCompose部署 实现思路： ① 查看资料提供的cloud-demo文件夹，里面已经编写好了docker-compose文件 ② 修改自己的cloud-demo项目，将数据库、nacos地址都命名为docker-compose中的服务名 ③ 使用maven打包工具，将项目中的每个微服务都打包为app.jar ④ 将打包好的app.jar拷贝到cloud-demo中的每一个对应的子目录中 ⑤ 将cloud-demo上传至虚拟机，利用 docker-compose up -d 来部署 4.3.1.compose文件查看cloud-demo文件夹，里面已经编写好了docker-compose文件，而且每个微服务都准备了一个独立的目录： 内容如下： version: \"3.2\" services: nacos: image: nacos/nacos-server environment: MODE: standalone ports: - \"8848:8848\" mysql: image: mysql:5.7.25 environment: MYSQL_ROOT_PASSWORD: 123 volumes: - \"$PWD/mysql/data:/var/lib/mysql\" - \"$PWD/mysql/conf:/etc/mysql/conf.d/\" userservice: build: ./user-service orderservice: build: ./order-service gateway: build: ./gateway ports: - \"10010:10010\" 可以看到，其中包含5个service服务： nacos：作为注册中心和配置中心 image: nacos/nacos-server： 基于nacos/nacos-server镜像构建 environment：环境变量 MODE: standalone：单点模式启动 ports：端口映射，这里暴露了8848端口 mysql：数据库 image: mysql:5.7.25：镜像版本是mysql:5.7.25 environment：环境变量 MYSQL_ROOT_PASSWORD: 123：设置数据库root账户的密码为123 volumes：数据卷挂载，这里挂载了mysql的data、conf目录，其中有我提前准备好的数据 userservice、orderservice、gateway：都是基于Dockerfile临时构建的 查看mysql目录，可以看到其中已经准备好了cloud_order、cloud_user表： 查看微服务目录，可以看到都包含Dockerfile文件： 内容如下： FROM java:8-alpine COPY ./app.jar /tmp/app.jar ENTRYPOINT java -jar /tmp/app.jar 4.3.2.修改微服务配置因为微服务将来要部署为docker容器，而容器之间互联不是通过IP地址，而是通过容器名。这里我们将order-service、user-service、gateway服务的mysql、nacos地址都修改为基于容器名的访问。 如下所示： spring: datasource: url: jdbc:mysql://mysql:3306/cloud_order?useSSL=false username: root password: 123 driver-class-name: com.mysql.jdbc.Driver application: name: orderservice cloud: nacos: server-addr: nacos:8848 # nacos服务地址 4.3.3.打包接下来需要将我们的每个微服务都打包。因为之前查看到Dockerfile中的jar包名称都是app.jar，因此我们的每个微服务都需要用这个名称。 可以通过修改pom.xml中的打包名称来实现，每个微服务都需要修改： &lt;build&gt; &lt;!-- 服务打包的最终名称 --&gt; &lt;finalName&gt;app&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 打包后： 4.3.4.拷贝jar包到部署目录编译打包好的app.jar文件，需要放到Dockerfile的同级目录中。注意：每个微服务的app.jar放到与服务名称对应的目录，别搞错了。 user-service： order-service： gateway： 4.3.5.部署最后，我们需要将文件整个cloud-demo文件夹上传到虚拟机中，理由DockerCompose部署。 上传到任意目录： 部署： 进入cloud-demo目录，然后运行下面的命令： docker-compose up -d 5.Docker镜像仓库5.1.搭建私有镜像仓库参考网上资料《CentOS7安装Docker》 5.2.推送、拉取镜像推送镜像到私有镜像服务必须先tag，步骤如下： ① 重新tag本地镜像，名称前缀为私有仓库的地址：192.168.150.101:8080/ docker tag nginx:latest 192.168.150.101:8080/nginx:1.0 ② 推送镜像 docker push 192.168.150.101:8080/nginx:1.0 ③ 拉取镜像 docker pull 192.168.150.101:8080/nginx:1.0","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://gitee.com/yunyd/tags/Docker/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://gitee.com/yunyd/tags/SpringCloud/"}],"author":"llllz."},{"title":"Gateway服务网关","slug":"Gateway网关","date":"2023-08-27T02:08:14.000Z","updated":"2023-08-27T02:08:49.168Z","comments":true,"path":"posts/596a9b7e.html","link":"","permalink":"https://gitee.com/yunyd/posts/596a9b7e.html","excerpt":"","text":"Gateway服务网关Spring Cloud Gateway 是 Spring Cloud 的一个全新项目，该项目是基于 Spring 5.0，Spring Boot 2.0 和 Project Reactor 等响应式编程和事件流技术开发的网关，它旨在为微服务架构提供一种简单有效的统一的 API 路由管理方式。 1.为什么需要网关Gateway网关是我们服务的守门神，所有微服务的统一入口。 网关的核心功能特性： 请求路由 权限控制 限流 架构图： 权限控制：网关作为微服务入口，需要校验用户是是否有请求资格，如果没有则进行拦截。 路由和负载均衡：一切请求都必须先经过gateway，但网关不处理业务，而是根据某种规则，把请求转发到某个微服务，这个过程叫做路由。当然路由的目标服务有多个时，还需要做负载均衡。 限流：当请求流量过高时，在网关中按照下流的微服务能够接受的速度来放行请求，避免服务压力过大。 在SpringCloud中网关的实现包括两种： gateway zuul Zuul是基于Servlet的实现，属于阻塞式编程。而SpringCloudGateway则是基于Spring5中提供的WebFlux，属于响应式编程的实现，具备更好的性能。 2.gateway快速入门下面，我们就演示下网关的基本路由功能。基本步骤如下： 创建SpringBoot工程gateway，引入网关依赖 编写启动类 编写基础配置和路由规则 启动网关服务进行测试 1）创建gateway服务，引入依赖创建服务： 引入依赖： &lt;!--网关--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--nacos服务发现依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; 2）编写启动类package cn.itcast.gateway; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); } } 3）编写基础配置和路由规则创建application.yml文件，内容如下： server: port: 10010 # 网关端口 spring: application: name: gateway # 服务名称 cloud: nacos: server-addr: localhost:8848 # nacos地址 gateway: routes: # 网关路由配置 - id: user-service # 路由id，自定义，只要唯一即可 # uri: http://127.0.0.1:8081 # 路由的目标地址 http就是固定地址 uri: lb://userservice # 路由的目标地址 lb就是负载均衡，后面跟服务名称 predicates: # 路由断言，也就是判断请求是否符合路由规则的条件 - Path=/user/** # 这个是按照路径匹配，只要以/user/开头就符合要求 我们将符合Path 规则的一切请求，都代理到 uri参数指定的地址。 本例中，我们将 /user/**开头的请求，代理到lb://userservice，lb是负载均衡，根据服务名拉取服务列表，实现负载均衡。 4）重启测试重启网关，访问http://localhost:10010/user/1时，符合`/user/**`规则，请求转发到uri：http://userservice/user/1，得到了结果： 5）网关路由的流程图整个访问的流程如下： 总结： 网关搭建步骤： 创建项目，引入nacos服务发现和gateway依赖 配置application.yml，包括服务基本信息、nacos地址、路由 路由配置包括： 路由id：路由的唯一标示 路由目标（uri）：路由的目标地址，http代表固定地址，lb代表根据服务名负载均衡 路由断言（predicates）：判断路由的规则， 路由过滤器（filters）：对请求或响应做处理 接下来，就重点来学习路由断言和路由过滤器的详细知识 3.断言工厂我们在配置文件中写的断言规则只是字符串，这些字符串会被Predicate Factory读取并处理，转变为路由判断的条件 例如Path=/user/**是按照路径匹配，这个规则是由 org.springframework.cloud.gateway.handler.predicate.PathRoutePredicateFactory类来 处理的，像这样的断言工厂在SpringCloudGateway还有十几个: 名称 说明 示例 After 是某个时间点后的请求 - After=2037-01-20T17:42:47.789-07:00[America/Denver] Before 是某个时间点之前的请求 - Before=2031-04-13T15:14:47.433+08:00[Asia/Shanghai] Between 是某两个时间点之前的请求 - Between=2037-01-20T17:42:47.789-07:00[America/Denver], 2037-01-21T17:42:47.789-07:00[America/Denver] Cookie 请求必须包含某些cookie - Cookie=chocolate, ch.p Header 请求必须包含某些header - Header=X-Request-Id, \\d+ Host 请求必须是访问某个host（域名） - Host=.somehost.org,.anotherhost.org Method 请求方式必须是指定方式 - Method=GET,POST Path 请求路径必须符合指定规则 - Path=/red/{segment},/blue/** Query 请求参数必须包含指定参数 - Query=name, Jack或者- Query=name RemoteAddr 请求者的ip必须是指定范围 - RemoteAddr=192.168.1.1/24 Weight 权重处理 我们只需要掌握Path这种路由工程就可以了。 4.过滤器工厂GatewayFilter是网关中提供的一种过滤器，可以对进入网关的请求和微服务返回的响应做处理： 4.1.路由过滤器的种类Spring提供了31种不同的路由过滤器工厂。例如： 名称 说明 AddRequestHeader 给当前请求添加一个请求头 RemoveRequestHeader 移除请求中的一个请求头 AddResponseHeader 给响应结果中添加一个响应头 RemoveResponseHeader 从响应结果中移除有一个响应头 RequestRateLimiter 限制请求的流量 4.2.请求头过滤器下面我们以AddRequestHeader 为例来讲解。 需求：给所有进入userservice的请求添加一个请求头：Truth=itcast is freaking awesome! 只需要修改gateway服务的application.yml文件，添加路由过滤即可： spring: cloud: gateway: routes: - id: user-service uri: lb://userservice predicates: - Path=/user/** filters: # 过滤器 - AddRequestHeader=Truth, Itcast is freaking awesome! # 添加请求头 当前过滤器写在userservice路由下，因此仅仅对访问userservice的请求有效。 4.3.默认过滤器如果要对所有的路由都生效，则可以将过滤器工厂写到default下。格式如下： spring: cloud: gateway: routes: - id: user-service uri: lb://userservice predicates: - Path=/user/** default-filters: # 默认过滤项 - AddRequestHeader=Truth, Itcast is freaking awesome! 4.4.总结过滤器的作用是什么？ ① 对路由的请求或响应做加工处理，比如添加请求头 ② 配置在路由下的过滤器只对当前路由的请求生效 defaultFilters的作用是什么？ ① 对所有路由都生效的过滤器 5.全局过滤器上一节学习的过滤器，网关提供了31种，但每一种过滤器的作用都是固定的。如果我们希望拦截请求，做自己的业务逻辑则没办法实现。 5.1.全局过滤器作用全局过滤器的作用也是处理一切进入网关的请求和微服务响应，与GatewayFilter的作用一样。区别在于GatewayFilter通过配置定义，处理逻辑是固定的；而GlobalFilter的逻辑需要自己写代码实现。 定义方式是实现GlobalFilter接口。 public interface GlobalFilter { /** * 处理当前请求，有必要的话通过{@link GatewayFilterChain}将请求交给下一个过滤器处理 * * @param exchange 请求上下文，里面可以获取Request、Response等信息 * @param chain 用来把请求委托给下一个过滤器 * @return {@code Mono&lt;Void&gt;} 返回标示当前过滤器业务结束 */ Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain); } 在filter中编写自定义逻辑，可以实现下列功能： 登录状态判断 权限校验 请求限流等 5.2.自定义全局过滤器需求：定义全局过滤器，拦截请求，判断请求的参数是否满足下面条件： 参数中是否有authorization， authorization参数值是否为admin 如果同时满足则放行，否则拦截 实现： 在gateway中定义一个过滤器： package cn.itcast.gateway.filters; import org.springframework.cloud.gateway.filter.GatewayFilterChain; import org.springframework.cloud.gateway.filter.GlobalFilter; import org.springframework.core.annotation.Order; import org.springframework.http.HttpStatus; import org.springframework.stereotype.Component; import org.springframework.web.server.ServerWebExchange; import reactor.core.publisher.Mono; @Order(-1) @Component public class AuthorizeFilter implements GlobalFilter { @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { // 1.获取请求参数 MultiValueMap&lt;String, String&gt; params = exchange.getRequest().getQueryParams(); // 2.获取authorization参数 String auth = params.getFirst(\"authorization\"); // 3.校验 if (\"admin\".equals(auth)) { // 放行 return chain.filter(exchange); } // 4.拦截 // 4.1.禁止访问，设置状态码 exchange.getResponse().setStatusCode(HttpStatus.FORBIDDEN); // 4.2.结束处理 return exchange.getResponse().setComplete(); } } 5.3.过滤器执行顺序请求进入网关会碰到三类过滤器：当前路由的过滤器、DefaultFilter、GlobalFilter 请求路由后，会将当前路由过滤器和DefaultFilter、GlobalFilter，合并到一个过滤器链（集合）中，排序后依次执行每个过滤器： 排序的规则是什么呢？ 每一个过滤器都必须指定一个int类型的order值，order值越小，优先级越高，执行顺序越靠前。 GlobalFilter通过实现Ordered接口，或者添加@Order注解来指定order值，由我们自己指定 路由过滤器和defaultFilter的order由Spring指定，默认是按照声明顺序从1递增。 当过滤器的order值一样时，会按照 defaultFilter &gt; 路由过滤器 &gt; GlobalFilter的顺序执行。 详细内容，可以查看源码： org.springframework.cloud.gateway.route.RouteDefinitionRouteLocator#getFilters()方法是先加载defaultFilters，然后再加载某个route的filters，然后合并。 org.springframework.cloud.gateway.handler.FilteringWebHandler#handle()方法会加载全局过滤器，与前面的过滤器合并后根据order排序，组织过滤器链 6.跨域问题6.1.什么是跨域问题跨域：域名不一致就是跨域，主要包括： 域名不同： www.taobao.com 和 www.taobao.org 和 www.jd.com 和 miaosha.jd.com 域名相同，端口不同：localhost:8080和localhost8081 跨域问题：浏览器禁止请求的发起者与服务端发生跨域ajax请求，请求被浏览器拦截的问题 解决方案：CORS，这个以前应该学习过，这里不再赘述了。不知道的小伙伴可以查看https://www.ruanyifeng.com/blog/2016/04/cors.html 6.2.模拟跨域问题找到页面文件： 放入tomcat或者nginx这样的web服务器中，启动并访问。 可以在浏览器控制台看到下面的错误： 从localhost:8090访问localhost:10010，端口不同，显然是跨域的请求。 6.3.解决跨域问题在gateway服务的application.yml文件中，添加下面的配置： spring: cloud: gateway: # 。。。 globalcors: # 全局的跨域处理 add-to-simple-url-handler-mapping: true # 解决options请求被拦截问题 corsConfigurations: '[/**]': allowedOrigins: # 允许哪些网站的跨域请求 - \"http://localhost:8090\" allowedMethods: # 允许的跨域ajax的请求方式 - \"GET\" - \"POST\" - \"DELETE\" - \"PUT\" - \"OPTIONS\" allowedHeaders: \"*\" # 允许在请求中携带的头信息 allowCredentials: true # 是否允许携带cookie maxAge: 360000 # 这次跨域检测的有效期","categories":[],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://gitee.com/yunyd/tags/SpringCloud/"},{"name":"Gateway","slug":"Gateway","permalink":"https://gitee.com/yunyd/tags/Gateway/"}],"author":"llllz."},{"title":"Feign远程调用复习","slug":"Feign","date":"2023-08-27T02:01:57.000Z","updated":"2023-08-27T02:08:49.165Z","comments":true,"path":"posts/dc362a43.html","link":"","permalink":"https://gitee.com/yunyd/posts/dc362a43.html","excerpt":"","text":"1.Feign远程调用复习先来看我们以前利用RestTemplate发起远程调用的代码： 存在下面的问题： 代码可读性差，编程体验不统一 参数复杂URL难以维护 Feign是一个声明式的http客户端，官方地址：https://github.com/OpenFeign/feign 其作用就是帮助我们优雅的实现http请求的发送，解决上面提到的问题。 1.1.Feign替代RestTemplateFegin的使用步骤如下： 1）引入依赖我们在order-service服务的pom文件中引入feign的依赖： &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; 2）添加注解在order-service的启动类添加注解开启Feign的功能： 3）编写Feign的客户端在order-service中新建一个接口，内容如下： package cn.itcast.order.client; import cn.itcast.order.pojo.User; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; @FeignClient(\"userservice\") public interface UserClient { @GetMapping(\"/user/{id}\") User findById(@PathVariable(\"id\") Long id); } 这个客户端主要是基于SpringMVC的注解来声明远程调用的信息，比如： 服务名称：userservice 请求方式：GET 请求路径：/user/{id} 请求参数：Long id 返回值类型：User 这样，Feign就可以帮助我们发送http请求，无需自己使用RestTemplate来发送了。 4）测试修改order-service中的OrderService类中的queryOrderById方法，使用Feign客户端代替RestTemplate： 是不是看起来优雅多了。 5）总结使用Feign的步骤： ① 引入依赖 ② 添加@EnableFeignClients注解 ③ 编写FeignClient接口 ④ 使用FeignClient中定义的方法代替RestTemplate 1.2.自定义配置Feign可以支持很多的自定义配置，如下表所示： 类型 作用 说明 feign.Logger.Level 修改日志级别 包含四种不同的级别：NONE、BASIC、HEADERS、FULL feign.codec.Decoder 响应结果的解析器 http远程调用的结果做解析，例如解析json字符串为java对象 feign.codec.Encoder 请求参数编码 将请求参数编码，便于通过http请求发送 feign. Contract 支持的注解格式 默认是SpringMVC的注解 feign. Retryer 失败重试机制 请求失败的重试机制，默认是没有，不过会使用Ribbon的重试 一般情况下，默认值就能满足我们使用，如果要自定义时，只需要创建自定义的@Bean覆盖默认Bean即可。 下面以日志为例来演示如何自定义配置。 1.2.1.配置文件方式基于配置文件修改feign的日志级别可以针对单个服务： feign: client: config: userservice: # 针对某个微服务的配置 loggerLevel: FULL # 日志级别 也可以针对所有服务： feign: client: config: default: # 这里用default就是全局配置，如果是写服务名称，则是针对某个微服务的配置 loggerLevel: FULL # 日志级别 而日志的级别分为四种： NONE：不记录任何日志信息，这是默认值。 BASIC：仅记录请求的方法，URL以及响应状态码和执行时间 HEADERS：在BASIC的基础上，额外记录了请求和响应的头信息 FULL：记录所有请求和响应的明细，包括头信息、请求体、元数据。 1.2.2.Java代码方式也可以基于Java代码来修改日志级别，先声明一个类，然后声明一个Logger.Level的对象： public class DefaultFeignConfiguration { @Bean public Logger.Level feignLogLevel(){ return Logger.Level.BASIC; // 日志级别为BASIC } } 如果要全局生效，将其放到启动类的@EnableFeignClients这个注解中： @EnableFeignClients(defaultConfiguration = DefaultFeignConfiguration .class) 如果是局部生效，则把它放到对应的@FeignClient这个注解中： @FeignClient(value = \"userservice\", configuration = DefaultFeignConfiguration .class) 1.3.Feign使用优化Feign底层发起http请求，依赖于其它的框架。其底层客户端实现包括： •URLConnection：默认实现，不支持连接池 •Apache HttpClient ：支持连接池 •OKHttp：支持连接池 因此提高Feign的性能主要手段就是使用连接池代替默认的URLConnection。 这里我们用Apache的HttpClient来演示。 1）引入依赖 在order-service的pom文件中引入Apache的HttpClient依赖： &lt;!--httpClient的依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt; &lt;/dependency&gt; 2）配置连接池 在order-service的application.yml中添加配置： feign: client: config: default: # default全局的配置 loggerLevel: BASIC # 日志级别，BASIC就是基本的请求和响应信息 httpclient: enabled: true # 开启feign对HttpClient的支持 max-connections: 200 # 最大的连接数 max-connections-per-route: 50 # 每个路径的最大连接数 接下来，在FeignClientFactoryBean中的loadBalance方法中打断点： Debug方式启动order-service服务，可以看到这里的client，底层就是Apache HttpClient： 总结，Feign的优化： 1.日志级别尽量用basic 2.使用HttpClient或OKHttp代替URLConnection ① 引入feign-httpClient依赖 ② 配置文件开启httpClient功能，设置连接池参数 1.4.最佳实践所谓最近实践，就是使用过程中总结的经验，最好的一种使用方式。 自习观察可以发现，Feign的客户端与服务提供者的controller代码非常相似： feign客户端： UserController： 有没有一种办法简化这种重复的代码编写呢？ 1.4.1.继承方式一样的代码可以通过继承来共享： 1）定义一个API接口，利用定义方法，并基于SpringMVC注解做声明。 2）Feign客户端和Controller都集成改接口 优点： 简单 实现了代码共享 缺点： 服务提供方、服务消费方紧耦合 参数列表中的注解映射并不会继承，因此Controller中必须再次声明方法、参数列表、注解 1.4.2.抽取方式将Feign的Client抽取为独立模块，并且把接口有关的POJO、默认的Feign配置都放到这个模块中，提供给所有消费者使用。 例如，将UserClient、User、Feign的默认配置都抽取到一个feign-api包中，所有微服务引用该依赖包，即可直接使用。 1.4.3.实现基于抽取的最佳实践1）抽取首先创建一个module，命名为feign-api： 项目结构： 在feign-api中然后引入feign的starter依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; 然后，order-service中编写的UserClient、User、DefaultFeignConfiguration都复制到feign-api项目中 2）在order-service中使用feign-api首先，删除order-service中的UserClient、User、DefaultFeignConfiguration等类或接口。 在order-service的pom文件中中引入feign-api的依赖： &lt;dependency&gt; &lt;groupId&gt;cn.itcast.demo&lt;/groupId&gt; &lt;artifactId&gt;feign-api&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/dependency&gt; 修改order-service中的所有与上述三个组件有关的导包部分，改成导入feign-api中的包 3）重启测试重启后，发现服务报错了： 这是因为UserClient现在在cn.itcast.feign.clients包下， 而order-service的@EnableFeignClients注解是在cn.itcast.order包下，不在同一个包，无法扫描到UserClient。 4）解决扫描包问题方式一： 指定Feign应该扫描的包： @EnableFeignClients(basePackages = \"cn.itcast.feign.clients\") 方式二： 指定需要加载的Client接口： @EnableFeignClients(clients = {UserClient.class})","categories":[],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://gitee.com/yunyd/tags/SpringCloud/"},{"name":"Feign","slug":"Feign","permalink":"https://gitee.com/yunyd/tags/Feign/"}],"author":"llllz."},{"title":"Nacos复习回顾","slug":"Nacos","date":"2023-08-26T04:35:26.000Z","updated":"2023-08-26T04:40:56.460Z","comments":true,"path":"posts/270777eb.html","link":"","permalink":"https://gitee.com/yunyd/posts/270777eb.html","excerpt":"","text":"Nacos复习回顾1.Nacos注册中心国内公司一般都推崇阿里巴巴的技术，比如注册中心，SpringCloudAlibaba也推出了一个名为Nacos的注册中心。 1.1.认识和安装NacosNacos是阿里巴巴的产品，现在是SpringCloud中的一个组件。相比Eureka功能更加丰富，在国内受欢迎程度较高。 1.2.服务注册到nacosNacos是SpringCloudAlibaba的组件，而SpringCloudAlibaba也遵循SpringCloud中定义的服务注册、服务发现规范。因此使用Nacos和使用Eureka对于微服务来说，并没有太大区别。 主要差异在于： 依赖不同 服务地址不同 1）引入依赖在cloud-demo父工程的pom文件中的&lt;dependencyManagement&gt;中引入SpringCloudAlibaba的依赖： &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.6.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; 然后在user-service和order-service中的pom文件中引入nacos-discovery依赖： &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; 注意：不要忘了注释掉eureka的依赖。 2）配置nacos地址在user-service和order-service的application.yml中添加nacos地址： spring: cloud: nacos: server-addr: localhost:8848 注意：不要忘了注释掉eureka的地址 3）重启重启微服务后，登录nacos管理页面，可以看到微服务信息： 1.3.服务分级存储模型一个服务可以有多个实例，例如我们的user-service，可以有: 127.0.0.1:8081 127.0.0.1:8082 127.0.0.1:8083 假如这些实例分布于全国各地的不同机房，例如： 127.0.0.1:8081，在上海机房 127.0.0.1:8082，在上海机房 127.0.0.1:8083，在杭州机房 Nacos就将同一机房内的实例 划分为一个集群。 也就是说，user-service是服务，一个服务可以包含多个集群，如杭州、上海，每个集群下可以有多个实例，形成分级模型，如图： 微服务互相访问时，应该尽可能访问同集群实例，因为本地访问速度更快。当本集群内不可用时，才访问其它集群。例如： 杭州机房内的order-service应该优先访问同机房的user-service。 1.3.1.给user-service配置集群修改user-service的application.yml文件，添加集群配置： spring: cloud: nacos: server-addr: localhost:8848 discovery: cluster-name: HZ # 集群名称 重启两个user-service实例后，我们可以在nacos控制台看到下面结果： 我们再次复制一个user-service启动配置，添加属性： -Dserver.port=8083 -Dspring.cloud.nacos.discovery.cluster-name=SH 配置如图所示： 启动UserApplication3后再次查看nacos控制台： 1.3.2.同集群优先的负载均衡默认的ZoneAvoidanceRule并不能实现根据同集群优先来实现负载均衡。 因此Nacos中提供了一个NacosRule的实现，可以优先从同集群中挑选实例。 1）给order-service配置集群信息 修改order-service的application.yml文件，添加集群配置： spring: cloud: nacos: server-addr: localhost:8848 discovery: cluster-name: HZ # 集群名称 2）修改负载均衡规则 修改order-service的application.yml文件，修改负载均衡规则： userservice: ribbon: NFLoadBalancerRuleClassName: com.alibaba.cloud.nacos.ribbon.NacosRule # 负载均衡规则 1.4.权重配置实际部署中会出现这样的场景： 服务器设备性能有差异，部分实例所在机器性能较好，另一些较差，我们希望性能好的机器承担更多的用户请求。 但默认情况下NacosRule是同集群内随机挑选，不会考虑机器的性能问题。 因此，Nacos提供了权重配置来控制访问频率，权重越大则访问频率越高。 在nacos控制台，找到user-service的实例列表，点击编辑，即可修改权重： 在弹出的编辑窗口，修改权重： 注意：如果权重修改为0，则该实例永远不会被访问 1.5.环境隔离Nacos提供了namespace来实现环境隔离功能。 nacos中可以有多个namespace namespace下可以有group、service等 不同namespace之间相互隔离，例如不同namespace的服务互相不可见 1.5.1.创建namespace默认情况下，所有service、data、group都在同一个namespace，名为public： 我们可以点击页面新增按钮，添加一个namespace： 然后，填写表单： 就能在页面看到一个新的namespace： 1.5.2.给微服务配置namespace给微服务配置namespace只能通过修改配置来实现。 例如，修改order-service的application.yml文件： spring: cloud: nacos: server-addr: localhost:8848 discovery: cluster-name: HZ namespace: 492a7d5d-237b-46a1-a99a-fa8e98e4b0f9 # 命名空间，填ID 重启order-service后，访问控制台，可以看到下面的结果： 此时访问order-service，因为namespace不同，会导致找不到userservice，控制台会报错： 1.6.Nacos与Eureka的区别Nacos的服务实例分为两种l类型： 临时实例：如果实例宕机超过一定时间，会从服务列表剔除，默认的类型。 非临时实例：如果实例宕机，不会从服务列表剔除，也可以叫永久实例。 配置一个服务实例为永久实例： spring: cloud: nacos: discovery: ephemeral: false # 设置为非临时实例 Nacos和Eureka整体结构类似，服务注册、服务拉取、心跳等待，但是也存在一些差异： Nacos与eureka的共同点 都支持服务注册和服务拉取 都支持服务提供者心跳方式做健康检测 Nacos与Eureka的区别 Nacos支持服务端主动检测提供者状态：临时实例采用心跳模式，非临时实例采用主动检测模式 临时实例心跳不正常会被剔除，非临时实例则不会被剔除 Nacos支持服务列表变更的消息推送模式，服务列表更新更及时 Nacos集群默认采用AP方式，当集群中存在非临时实例时，采用CP模式；Eureka采用AP方式 2.Nacos配置管理Nacos除了可以做注册中心，同样可以做配置管理来使用。 2.1.统一配置管理当微服务部署的实例越来越多，达到数十、数百时，逐个修改微服务配置就会让人抓狂，而且很容易出错。我们需要一种统一配置管理方案，可以集中管理所有实例的配置。 Nacos一方面可以将配置集中管理，另一方可以在配置变更时，及时通知微服务，实现配置的热更新。 2.1.1.在nacos中添加配置文件如何在nacos中管理配置呢？ 然后在弹出的表单中，填写配置信息： 注意：项目的核心配置，需要热更新的配置才有放到nacos管理的必要。基本不会变更的一些配置还是保存在微服务本地比较好。 2.1.2.从微服务拉取配置微服务要拉取nacos中管理的配置，并且与本地的application.yml配置合并，才能完成项目启动。 但如果尚未读取application.yml，又如何得知nacos地址呢？ 因此spring引入了一种新的配置文件：bootstrap.yaml文件，会在application.yml之前被读取，流程如下： 1）引入nacos-config依赖 首先，在user-service服务中，引入nacos-config的客户端依赖： &lt;!--nacos配置管理依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; 2）添加bootstrap.yaml 然后，在user-service中添加一个bootstrap.yaml文件，内容如下： spring: application: name: userservice # 服务名称 profiles: active: dev #开发环境，这里是dev cloud: nacos: server-addr: localhost:8848 # Nacos地址 config: file-extension: yaml # 文件后缀名 这里会根据spring.cloud.nacos.server-addr获取nacos地址，再根据 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension}作为文件id，来读取配置。 本例中，就是去读取userservice-dev.yaml： 3）读取nacos配置 在user-service中的UserController中添加业务逻辑，读取pattern.dateformat配置： 完整代码： package cn.itcast.user.web; import cn.itcast.user.pojo.User; import cn.itcast.user.service.UserService; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.*; import java.time.LocalDateTime; import java.time.format.DateTimeFormatter; @Slf4j @RestController @RequestMapping(\"/user\") public class UserController { @Autowired private UserService userService; @Value(\"${pattern.dateformat}\") private String dateformat; @GetMapping(\"now\") public String now(){ return LocalDateTime.now().format(DateTimeFormatter.ofPattern(dateformat)); } // ...略 } 在页面访问，可以看到效果： 2.2.配置热更新我们最终的目的，是修改nacos中的配置后，微服务中无需重启即可让配置生效，也就是配置热更新。 要实现配置热更新，可以使用两种方式： 2.2.1.方式一在@Value注入的变量所在类上添加注解@RefreshScope： 2.2.2.方式二使用@ConfigurationProperties注解代替@Value注解。 在user-service服务中，添加一个类，读取patterrn.dateformat属性： package cn.itcast.user.config; import lombok.Data; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.stereotype.Component; @Component @Data @ConfigurationProperties(prefix = \"pattern\") public class PatternProperties { private String dateformat; } 在UserController中使用这个类代替@Value： 完整代码： package cn.itcast.user.web; import cn.itcast.user.config.PatternProperties; import cn.itcast.user.pojo.User; import cn.itcast.user.service.UserService; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import java.time.LocalDateTime; import java.time.format.DateTimeFormatter; @Slf4j @RestController @RequestMapping(\"/user\") public class UserController { @Autowired private UserService userService; @Autowired private PatternProperties patternProperties; @GetMapping(\"now\") public String now(){ return LocalDateTime.now().format(DateTimeFormatter.ofPattern(patternProperties.getDateformat())); } // 略 } 2.3.配置共享其实微服务启动时，会去nacos读取多个配置文件，例如： [spring.application.name]-[spring.profiles.active].yaml，例如：userservice-dev.yaml [spring.application.name].yaml，例如：userservice.yaml 而[spring.application.name].yaml不包含环境，因此可以被多个环境共享。 下面我们通过案例来测试配置共享 1）添加一个环境共享配置我们在nacos中添加一个userservice.yaml文件： 2）在user-service中读取共享配置在user-service服务中，修改PatternProperties类，读取新添加的属性： 在user-service服务中，修改UserController，添加一个方法： 3）运行两个UserApplication，使用不同的profile修改UserApplication2这个启动项，改变其profile值： 这样，UserApplication(8081)使用的profile是dev，UserApplication2(8082)使用的profile是test。 启动UserApplication和UserApplication2 访问http://localhost:8081/user/prop，结果： 访问http://localhost:8082/user/prop，结果： 可以看出来，不管是dev，还是test环境，都读取到了envSharedValue这个属性的值。 4）配置共享的优先级当nacos、服务本地同时出现相同属性时，优先级有高低之分：","categories":[],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://gitee.com/yunyd/tags/SpringCloud/"},{"name":"Nacos","slug":"Nacos","permalink":"https://gitee.com/yunyd/tags/Nacos/"}],"author":"llllz."},{"title":"Eureka复习回顾","slug":"Eureka","date":"2023-08-26T00:41:40.000Z","updated":"2023-08-26T00:48:45.166Z","comments":true,"path":"posts/7b1e2515.html","link":"","permalink":"https://gitee.com/yunyd/posts/7b1e2515.html","excerpt":"","text":"Eureka复习回顾1.微服务1.1.单体架构单体架构：将业务的所有功能集中在一个项目中开发，打成一个包部署。 单体架构的优缺点如下： 优点： 架构简单 部署成本低 缺点： 耦合度高（维护困难、升级困难） 1.2.分布式架构分布式架构：根据业务功能对系统做拆分，每个业务功能模块作为独立项目开发，称为一个服务。 分布式架构的优缺点： 优点： 降低服务耦合 有利于服务升级和拓展 缺点： 服务调用关系错综复杂 分布式架构虽然降低了服务耦合，但是服务拆分时也有很多问题需要思考： 服务拆分的粒度如何界定？ 服务之间如何调用？ 服务的调用关系如何管理？ 人们需要制定一套行之有效的标准来约束分布式架构。 1.3.微服务微服务的架构特征： 单一职责：微服务拆分粒度更小，每一个服务都对应唯一的业务能力，做到单一职责 自治：团队独立、技术独立、数据独立，独立部署和交付 面向服务：服务提供统一标准的接口，与语言和技术无关 隔离性强：服务调用做好隔离、容错、降级，避免出现级联问题 微服务的上述特性其实是在给分布式架构制定一个标准，进一步降低服务之间的耦合度，提供服务的独立性和灵活性。做到高内聚，低耦合。 因此，可以认为微服务是一种经过良好架构设计的分布式架构方案 。 但方案该怎么落地？选用什么样的技术栈？全球的互联网公司都在积极尝试自己的微服务落地方案。 其中在Java领域最引人注目的就是SpringCloud提供的方案了。 1.4.SpringCloudSpringCloud是目前国内使用最广泛的微服务框架。官网地址：https://spring.io/projects/spring-cloud。 SpringCloud集成了各种微服务功能组件，并基于SpringBoot实现了这些组件的自动装配，从而提供了良好的开箱即用体验。 其中常见的组件包括： 另外，SpringCloud底层是依赖于SpringBoot的，并且有版本的兼容关系，如下： 我们课堂学习的版本是 Hoxton.SR10，因此对应的SpringBoot版本是2.3.x版本。 1.5.总结 单体架构：简单方便，高度耦合，扩展性差，适合小型项目。例如：学生管理系统 分布式架构：松耦合，扩展性好，但架构复杂，难度大。适合大型互联网项目，例如：京东、淘宝 微服务：一种良好的分布式架构方案 ①优点：拆分粒度更小、服务更独立、耦合度更低 ②缺点：架构非常复杂，运维、监控、部署难度提高 SpringCloud是微服务架构的一站式解决方案，集成了各种优秀微服务功能组件 2.服务拆分和远程调用任何分布式架构都离不开服务的拆分，微服务也是一样。 2.1.服务拆分原则这里我总结了微服务拆分时的几个原则： 不同微服务，不要重复开发相同业务 微服务数据独立，不要访问其它微服务的数据库 微服务可以将自己的业务暴露为接口，供其它微服务调用 2.2.服务拆分示例以cloud-demo为例，其结构如下： cloud-demo：父工程，管理依赖 order-service：订单微服务，负责订单相关业务 user-service：用户微服务，负责用户相关业务 要求： 订单微服务和用户微服务都必须有各自的数据库，相互独立 订单服务和用户服务都对外暴露Restful的接口 订单服务如果需要查询用户信息，只能调用用户服务的Restful接口，不能查询用户数据库 2.2.1.导入Sql语句首先，将cloud-order.sql和cloud-user.sql导入到mysql中： cloud-user表中初始数据如下： cloud-order表中初始数据如下： cloud-order表中持有cloud-user表中的id字段。 2.2.2.导入demo工程用IDEA导入Demo： 项目结构如下： 导入后，会在IDEA右下角出现弹窗： 点击弹窗，然后按下图选择： 会出现这样的菜单： 配置下项目使用的JDK： 2.3.实现远程调用案例在order-service服务中，有一个根据id查询订单的接口： 根据id查询订单，返回值是Order对象，如图： 其中的user为null 在user-service中有一个根据id查询用户的接口： 查询的结果如图： 2.3.1.案例需求：修改order-service中的根据id查询订单业务，要求在查询订单的同时，根据订单中包含的userId查询出用户信息，一起返回。 因此，我们需要在order-service中 向user-service发起一个http的请求，调用http://localhost:8081/user/{userId}这个接口。 大概的步骤是这样的： 注册一个RestTemplate的实例到Spring容器 修改order-service服务中的OrderService类中的queryOrderById方法，根据Order对象中的userId查询User 将查询的User填充到Order对象，一起返回 2.3.2.注册RestTemplate首先，我们在order-service服务中的OrderApplication启动类中，注册RestTemplate实例： package cn.itcast.order; import org.mybatis.spring.annotation.MapperScan; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.context.annotation.Bean; import org.springframework.web.client.RestTemplate; @MapperScan(\"cn.itcast.order.mapper\") @SpringBootApplication public class OrderApplication { public static void main(String[] args) { SpringApplication.run(OrderApplication.class, args); } @Bean public RestTemplate restTemplate() { return new RestTemplate(); } } 2.3.3.实现远程调用修改order-service服务中的cn.itcast.order.service包下的OrderService类中的queryOrderById方法： 2.4.提供者与消费者在服务调用关系中，会有两个不同的角色： 服务提供者：一次业务中，被其它微服务调用的服务。（提供接口给其它微服务） 服务消费者：一次业务中，调用其它微服务的服务。（调用其它微服务提供的接口） 但是，服务提供者与服务消费者的角色并不是绝对的，而是相对于业务而言。 如果服务A调用了服务B，而服务B又调用了服务C，服务B的角色是什么？ 对于A调用B的业务而言：A是服务消费者，B是服务提供者 对于B调用C的业务而言：B是服务消费者，C是服务提供者 因此，服务B既可以是服务提供者，也可以是服务消费者。 3.Eureka注册中心假如我们的服务提供者user-service部署了多个实例，如图： 大家思考几个问题： order-service在发起远程调用的时候，该如何得知user-service实例的ip地址和端口？ 有多个user-service实例地址，order-service调用时该如何选择？ order-service如何得知某个user-service实例是否依然健康，是不是已经宕机？ 3.1.Eureka的结构和作用这些问题都需要利用SpringCloud中的注册中心来解决，其中最广为人知的注册中心就是Eureka，其结构如下： 回答之前的各个问题。 问题1：order-service如何得知user-service实例地址？ 获取地址信息的流程如下： user-service服务实例启动后，将自己的信息注册到eureka-server（Eureka服务端）。这个叫服务注册 eureka-server保存服务名称到服务实例地址列表的映射关系 order-service根据服务名称，拉取实例地址列表。这个叫服务发现或服务拉取 问题2：order-service如何从多个user-service实例中选择具体的实例？ order-service从实例列表中利用负载均衡算法选中一个实例地址 向该实例地址发起远程调用 问题3：order-service如何得知某个user-service实例是否依然健康，是不是已经宕机？ user-service会每隔一段时间（默认30秒）向eureka-server发起请求，报告自己状态，称为心跳 当超过一定时间没有发送心跳时，eureka-server会认为微服务实例故障，将该实例从服务列表中剔除 order-service拉取服务时，就能将故障实例排除了 注意：一个微服务，既可以是服务提供者，又可以是服务消费者，因此eureka将服务注册、服务发现等功能统一封装到了eureka-client端 因此，接下来我们动手实践的步骤包括： 3.2.搭建eureka-server首先大家注册中心服务端：eureka-server，这必须是一个独立的微服务 3.2.1.创建eureka-server服务在cloud-demo父工程下，创建一个子模块： 填写模块信息： 然后填写服务信息： 3.2.2.引入eureka依赖引入SpringCloud为eureka提供的starter依赖： &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; 3.2.3.编写启动类给eureka-server服务编写一个启动类，一定要添加一个@EnableEurekaServer注解，开启eureka的注册中心功能： package cn.itcast.eureka; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer; @SpringBootApplication @EnableEurekaServer public class EurekaApplication { public static void main(String[] args) { SpringApplication.run(EurekaApplication.class, args); } } 3.2.4.编写配置文件编写一个application.yml文件，内容如下： server: port: 10086 spring: application: name: eureka-server eureka: client: service-url: defaultZone: http://127.0.0.1:10086/eureka 3.2.5.启动服务启动微服务，然后在浏览器访问：http://127.0.0.1:10086 看到下面结果应该是成功了： 3.3.服务注册下面，我们将user-service注册到eureka-server中去。 1）引入依赖在user-service的pom文件中，引入下面的eureka-client依赖： &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; 2）配置文件在user-service中，修改application.yml文件，添加服务名称、eureka地址： spring: application: name: userservice eureka: client: service-url: defaultZone: http://127.0.0.1:10086/eureka 3）启动多个user-service实例为了演示一个服务有多个实例的场景，我们添加一个SpringBoot的启动配置，再启动一个user-service。 首先，复制原来的user-service启动配置： 然后，在弹出的窗口中，填写信息： 现在，SpringBoot窗口会出现两个user-service启动配置： 不过，第一个是8081端口，第二个是8082端口。 启动两个user-service实例： 查看eureka-server管理页面： 3.4.服务发现下面，我们将order-service的逻辑修改：向eureka-server拉取user-service的信息，实现服务发现。 1）引入依赖之前说过，服务发现、服务注册统一都封装在eureka-client依赖，因此这一步与服务注册时一致。 在order-service的pom文件中，引入下面的eureka-client依赖： &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; 2）配置文件服务发现也需要知道eureka地址，因此第二步与服务注册一致，都是配置eureka信息： 在order-service中，修改application.yml文件，添加服务名称、eureka地址： spring: application: name: orderservice eureka: client: service-url: defaultZone: http://127.0.0.1:10086/eureka 3）服务拉取和负载均衡最后，我们要去eureka-server中拉取user-service服务的实例列表，并且实现负载均衡。 不过这些动作不用我们去做，只需要添加一些注解即可。 在order-service的OrderApplication中，给RestTemplate这个Bean添加一个@LoadBalanced注解： 修改order-service服务中的cn.itcast.order.service包下的OrderService类中的queryOrderById方法。修改访问的url路径，用服务名代替ip、端口： spring会自动帮助我们从eureka-server端，根据userservice这个服务名称，获取实例列表，而后完成负载均衡。 4.Ribbon负载均衡上一节中，我们添加了@LoadBalanced注解，即可实现负载均衡功能，这是什么原理呢？ 4.1.负载均衡原理SpringCloud底层其实是利用了一个名为Ribbon的组件，来实现负载均衡功能的。 那么我们发出的请求明明是http://userservice/user/1，怎么变成了http://localhost:8081的呢？ 4.2.源码跟踪为什么我们只输入了service名称就可以访问了呢？之前还要获取ip和端口。 显然有人帮我们根据service名称，获取到了服务实例的ip和端口。它就是LoadBalancerInterceptor，这个类会在对RestTemplate的请求进行拦截，然后从Eureka根据服务id获取服务列表，随后利用负载均衡算法得到真实的服务地址信息，替换服务id。 我们进行源码跟踪： 1）LoadBalancerIntercepor 可以看到这里的intercept方法，拦截了用户的HttpRequest请求，然后做了几件事： request.getURI()：获取请求uri，本例中就是 http://user-service/user/8 originalUri.getHost()：获取uri路径的主机名，其实就是服务id，user-service this.loadBalancer.execute()：处理服务id，和用户请求。 这里的this.loadBalancer是LoadBalancerClient类型，我们继续跟入。 2）LoadBalancerClient继续跟入execute方法： 代码是这样的： getLoadBalancer(serviceId)：根据服务id获取ILoadBalancer，而ILoadBalancer会拿着服务id去eureka中获取服务列表并保存起来。 getServer(loadBalancer)：利用内置的负载均衡算法，从服务列表中选择一个。本例中，可以看到获取了8082端口的服务 放行后，再次访问并跟踪，发现获取的是8081： 果然实现了负载均衡。 3）负载均衡策略IRule在刚才的代码中，可以看到获取服务使通过一个getServer方法来做负载均衡: 我们继续跟入： 继续跟踪源码chooseServer方法，发现这么一段代码： 我们看看这个rule是谁： 这里的rule默认值是一个RoundRobinRule，看类的介绍： 这不就是轮询的意思嘛。 到这里，整个负载均衡的流程我们就清楚了。 4）总结SpringCloudRibbon的底层采用了一个拦截器，拦截了RestTemplate发出的请求，对地址做了修改。用一幅图来总结一下： 基本流程如下： 拦截我们的RestTemplate请求http://userservice/user/1 RibbonLoadBalancerClient会从请求url中获取服务名称，也就是user-service DynamicServerListLoadBalancer根据user-service到eureka拉取服务列表 eureka返回列表，localhost:8081、localhost:8082 IRule利用内置负载均衡规则，从列表中选择一个，例如localhost:8081 RibbonLoadBalancerClient修改请求地址，用localhost:8081替代userservice，得到http://localhost:8081/user/1，发起真实请求 4.3.负载均衡策略4.3.1.负载均衡策略负载均衡的规则都定义在IRule接口中，而IRule有很多不同的实现类： 不同规则的含义如下： 内置负载均衡规则类 规则描述 RoundRobinRule 简单轮询服务列表来选择服务器。它是Ribbon默认的负载均衡规则。 AvailabilityFilteringRule 对以下两种服务器进行忽略： （1）在默认情况下，这台服务器如果3次连接失败，这台服务器就会被设置为“短路”状态。短路状态将持续30秒，如果再次连接失败，短路的持续时间就会几何级地增加。 （2）并发数过高的服务器。如果一个服务器的并发连接数过高，配置了AvailabilityFilteringRule规则的客户端也会将其忽略。并发连接数的上限，可以由客户端的..ActiveConnectionsLimit属性进行配置。 WeightedResponseTimeRule 为每一个服务器赋予一个权重值。服务器响应时间越长，这个服务器的权重就越小。这个规则会随机选择服务器，这个权重值会影响服务器的选择。 ZoneAvoidanceRule 以区域可用的服务器为基础进行服务器的选择。使用Zone对服务器进行分类，这个Zone可以理解为一个机房、一个机架等。而后再对Zone内的多个服务做轮询。 BestAvailableRule 忽略那些短路的服务器，并选择并发数较低的服务器。 RandomRule 随机选择一个可用的服务器。 RetryRule 重试机制的选择逻辑 默认的实现就是ZoneAvoidanceRule，是一种轮询方案 4.3.2.自定义负载均衡策略通过定义IRule实现可以修改负载均衡规则，有两种方式： 代码方式：在order-service中的OrderApplication类中，定义一个新的IRule： @Bean public IRule randomRule(){ return new RandomRule(); } 配置文件方式：在order-service的application.yml文件中，添加新的配置也可以修改规则： userservice: # 给某个微服务配置负载均衡规则，这里是userservice服务 ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule # 负载均衡规则 注意，一般用默认的负载均衡规则，不做修改。 4.4.饥饿加载Ribbon默认是采用懒加载，即第一次访问时才会去创建LoadBalanceClient，请求时间会很长。 而饥饿加载则会在项目启动时创建，降低第一次访问的耗时，通过下面配置开启饥饿加载： ribbon: eager-load: enabled: true clients: userservice","categories":[],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://gitee.com/yunyd/tags/SpringCloud/"},{"name":"Eureka","slug":"Eureka","permalink":"https://gitee.com/yunyd/tags/Eureka/"}],"author":"llllz."},{"title":"Dubbo复习","slug":"Dubbo复习","date":"2023-08-24T03:21:15.000Z","updated":"2023-08-25T00:18:51.566Z","comments":true,"path":"posts/11f4b451.html","link":"","permalink":"https://gitee.com/yunyd/posts/11f4b451.html","excerpt":"","text":"Dubbo复习一、基础知识1、分布式基础理论1.1 什么是分布式系统？《分布式系统原理与范型》定义： “分布式系统是若干独立计算机的集合，这些计算机对于用户来说就像单个相关系统” 分布式系统（distributed system）是建立在网络之上的软件系统。 随着互联网的发展，网站应用的规模不断扩大，常规的垂直应用架构已无法应对，分布式服务架构以及流动计算架构势在必行，亟需一个治理系统确保架构有条不紊的演进。 1.2 发展演变 单一应用架构当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。此时，用于简化增删改查工作量的数据访问框架(ORM)是关键。 适用于小型网站，小型管理系统，将所有功能都部署到一个功能里，简单易用。 缺点： 1、性能扩展比较难 ​ 2、协同开发问题 ​ 3、不利于升级维护 垂直应用架构当访问量逐渐增大，单一应用增加机器带来的加速度越来越小，将应用拆成互不相干的几个应用，以提升效率。此时，用于加速前端页面开发的Web框架(MVC)是关键。 通过切分业务来实现各个模块独立部署，降低了维护和部署的难度，团队各司其职更易管理，性能扩展也更方便，更有针对性。 缺点： 公用模块无法重复利用，开发性的浪费 分布式服务架构当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。此时，用于提高业务复用及整合的**分布式服务框架(RPC)**是关键。 流动计算架构当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。此时，用于提高机器利用率的资源调度和治理中心(SOA)**[ Service Oriented Architecture]**是关键。 1.3 RPC什么叫RPCRPC【Remote Procedure Call】是指远程过程调用，是一种进程间通信方式，他是一种技术的思想，而不是规范。它允许程序调用另一个地址空间（通常是共享网络的另一台机器上）的过程或函数，而不用程序员显式编码这个远程调用的细节。即程序员无论是调用本地的还是远程的函数，本质上编写的调用代码基本相同。 RPC基本原理 RPC两个核心模块：通讯，序列化。 2、dubbo核心概念2.1 简介Apache Dubbo (incubating) |ˈdʌbəʊ| 是一款高性能、轻量级的开源Java RPC框架，它提供了三大核心能力：面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。 官网： http://dubbo.apache.org/ 2.2 基本概念 服务提供者（Provider）：暴露服务的服务提供方，服务提供者在启动时，向注册中心注册自己提供的服务。 ​ 服务消费者（Consumer）: 调用远程服务的服务消费方，服务消费者在启动时，向注册中心订阅自己所需的服务，服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。 ​ 注册中心（Registry）：注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者 ​ 监控中心（Monitor）：服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心 Ø 调用关系说明 l 服务容器负责启动，加载，运行服务提供者。 l 服务提供者在启动时，向注册中心注册自己提供的服务。 l 服务消费者在启动时，向注册中心订阅自己所需的服务。 l 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。 l 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。 l 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 3、dubbo环境搭建3.1 【windows】-安装zookeeper 1、下载zookeeper网址 https://archive.apache.org/dist/zookeeper/zookeeper-3.4.13/ 2、解压zookeeper解压运行zkServer.cmd ，初次运行会报错，没有zoo.cfg配置文件 3、修改zoo.cfg配置文件将conf下的zoo_sample.cfg复制一份改名为zoo.cfg即可。注意几个重要位置：dataDir=./ 临时数据存储的目录（可写相对路径）clientPort=2181 zookeeper的端口号修改完成后再次启动zookeeper 4、使用zkCli.cmd测试ls /：列出zookeeper根下保存的所有节点create –e /atguigu 123：创建一个atguigu节点，值为123get /atguigu：获取/atguigu节点的值 3.2 【windows】-安装dubbo-admin管理控制台dubbo本身并不是一个服务软件。它其实就是一个jar包能够帮你的java程序连接到zookeeper，并利用zookeeper消费、提供服务。所以你不用在Linux上启动什么dubbo服务。 但是为了让用户更好的管理监控众多的dubbo服务，官方提供了一个可视化的监控程序，不过这个监控即使不装也不影响使用。 1、下载dubbo-adminhttps://github.com/apache/incubator-dubbo-ops 2、进入目录，修改dubbo-admin配置修改 src\\main\\resources\\application.properties 指定zookeeper地址 3、打包dubbo-adminmvn clean package -Dmaven.test.skip=true 4、运行dubbo-adminjava -jar dubbo-admin-0.0.1-SNAPSHOT.jar注意：【有可能控制台看着启动了，但是网页打不开，需要在控制台按下ctrl+c即可】默认使用root/root 登陆 3.3 【linux】-安装zookeeper1、安装jdk 1、下载jdkhttp://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html![](https://llllz-1319101047.cos.ap-beijing.myqcloud.com/Dubbo/12.jpg) 不要使用wget命令获取jdk链接，这是默认不同意，导致下载来的jdk压缩内容错误 2、上传到服务器并解压 3、设置环境变量/usr/local/java/jdk1.8.0_171 文件末尾加入下面配置 export JAVA_HOME=/usr/local/java/jdk1.8.0_171export JRE_HOME=${JAVA_HOME}/jreexport CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/libexport PATH=${JAVA_HOME}/bin:$PATH 4、使环境变量生效&amp;测试JDK 2、安装zookeeper 1、下载zookeeper网址 https://archive.apache.org/dist/zookeeper/zookeeper-3.4.11/ wget https://archive.apache.org/dist/zookeeper/zookeeper-3.4.11/zookeeper-3.4.11.tar.gz 2、解压 3、移动到指定位置并改名为zookeeper 2、安装dubbo-admindubbo本身并不是一个服务软件。它其实就是一个jar包能够帮你的java程序连接到zookeeper，并利用zookeeper消费、提供服务。所以你不用在Linux上启动什么dubbo服务。 但是为了让用户更好的管理监控众多的dubbo服务，官方提供了一个可视化的监控程序，不过这个监控即使不装也不影响使用。 1、下载dubbo-adminhttps://github.com/apache/incubator-dubbo-ops 2、进入目录，修改dubbo-admin配置修改 src\\main\\resources\\application.properties 指定zookeeper地址 3、打包dubbo-adminmvn clean package -Dmaven.test.skip=true 4、运行dubbo-adminjava -jar dubbo-admin-0.0.1-SNAPSHOT.jar默认使用root/root 登陆 4、dubbo-helloworld4.1 提出需求某个电商系统，订单服务需要调用用户服务获取某个用户的所有地址； 我们现在 需要创建两个服务模块进行测试 模块 功能 订单服务web模块 创建订单等 用户服务service模块 查询用户地址等 测试预期结果： ​ 订单服务web模块在A服务器，用户服务模块在B服务器，A可以远程调用B的功能。 4.2 工程架构根据 dubbo《服务化最佳实践》 1、分包建议将服务接口，服务模型，服务异常等均放在 API 包中，因为服务模型及异常也是 API 的一部分，同时，这样做也符合分包原则：重用发布等价原则(REP)，共同重用原则(CRP)。 如果需要，也可以考虑在 API 包中放置一份 spring 的引用配置，这样使用方，只需在 spring 加载过程中引用此配置即可，配置建议放在模块的包目录下，以免冲突，如：com/alibaba/china/xxx/dubbo-reference.xml。 2、粒度服务接口尽可能大粒度，每个服务方法应代表一个功能，而不是某功能的一个步骤，否则将面临分布式事务问题，Dubbo 暂未提供分布式事务支持。 服务接口建议以业务场景为单位划分，并对相近业务做抽象，防止接口数量爆炸。 不建议使用过于抽象的通用接口，如：Map query(Map)，这样的接口没有明确语义，会给后期维护带来不便。 4.3 创建模块1、gmall-interface：公共接口层（model，service，exception…）作用：定义公共接口，也可以导入公共依赖 Bean模型 Bean模型 public class UserAddress implements Serializable{ private Integer id; private String userAddress; private String userId; private String consignee; private String phoneNum; private String isDefault; } 2. ##### Service接口 - ```java UserService public List&lt;UserAddress&gt; getUserAddressList(String userId) 2、gmall-user：用户模块（对用户接口的实现） pom.xml &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.atguigu.dubbo&lt;/groupId&gt; &lt;artifactId&gt;gmall-interface&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 2. Service - ```java public class UserServiceImpl implements UserService { @Override public List&lt;UserAddress&gt; getUserAddressList(String userId) { // TODO Auto-generated method stub return userAddressDao.getUserAddressById(userId); } } gmall-order-web：订单模块（调用用户模块） &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.atguigu.dubbo&lt;/groupId&gt; &lt;artifactId&gt;gmall-interface&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; - ##### 测试 - ```java public class OrderService { UserService userService; /** * 初始化订单，查询用户的所有地址并返回 * @param userId * @return */ public List&lt;UserAddress&gt; initOrder(String userId){ return userService.getUserAddressList(userId); } } 现在这样是无法进行调用的。我们gmall-order-web引入了gmall-interface，但是interface的实现是gmall-user，我们并没有引入，而且实际他可能还在别的服务器中。 4.4 使用dubbo改造1、改造gmall-user作为服务提供者 &lt;!-- 引入dubbo --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.6.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 由于我们使用zookeeper作为注册中心，所以需要操作zookeeper dubbo 2.6以前的版本引入zkclient操作zookeeper dubbo 2.6及以后的版本引入curator操作zookeeper 下面两个zk客户端根据dubbo版本2选1即可 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.10&lt;/version&gt; &lt;/dependency&gt; &lt;!-- curator-framework --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;2.12.0&lt;/version&gt; &lt;/dependency&gt; - 配置提供者 - ```配置 &lt;!--当前应用的名字 --&gt; &lt;dubbo:application name=\"gmall-user\"&gt;&lt;/dubbo:application&gt; &lt;!--指定注册中心的地址 --&gt; &lt;dubbo:registry address=\"zookeeper://118.24.44.169:2181\" /&gt; &lt;!--使用dubbo协议，将服务暴露在20880端口 --&gt; &lt;dubbo:protocol name=\"dubbo\" port=\"20880\" /&gt; &lt;!-- 指定需要暴露的服务 --&gt; &lt;dubbo:service interface=\"com.atguigu.gmall.service.UserService\" ref=\"userServiceImpl\" /&gt; 启动服务 public static void main(String[] args) throws IOException { ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"classpath:spring-beans.xml\"); System.in.read(); } #### **2、改造g**mall-order-web作为服务消费者 - ```xml &lt;!-- 引入dubbo --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.6.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 由于我们使用zookeeper作为注册中心，所以需要引入zkclient和curator操作zookeeper --&gt; &lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.10&lt;/version&gt; &lt;/dependency&gt; &lt;!-- curator-framework --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;2.12.0&lt;/version&gt; &lt;/dependency&gt; 配置消费者信息 &lt;!-- 应用名 --&gt; &lt;dubbo:application name=\"gmall-order-web\"&gt;&lt;/dubbo:application&gt; &lt;!-- 指定注册中心地址 --&gt; &lt;dubbo:registry address=\"zookeeper://118.24.44.169:2181\" /&gt; &lt;!-- 生成远程服务代理，可以和本地bean一样使用demoService --&gt; &lt;dubbo:reference id=\"userService\" interface=\"com.atguigu.gmall.service.UserService\"&gt;&lt;/dubbo:reference&gt; #### **3、测试调用** 访问gmall-order-web的initOrder请求，会调用UserService获取用户地址； 调用成功。说明我们order已经可以调用远程的UserService了； #### **4、注解版** - ```java 1、服务提供方 &lt;dubbo:application name=\"gmall-user\"&gt;&lt;/dubbo:application&gt; &lt;dubbo:registry address=\"zookeeper://118.24.44.169:2181\" /&gt; &lt;dubbo:protocol name=\"dubbo\" port=\"20880\" /&gt; &lt;dubbo:annotation package=\"com.atguigu.gmall.user.impl\"/&gt; import com.alibaba.dubbo.config.annotation.Service; import com.atguigu.gmall.bean.UserAddress; import com.atguigu.gmall.service.UserService; import com.atguigu.gmall.user.mapper.UserAddressMapper; @Service //使用dubbo提供的service注解，注册暴露服务 public class UserServiceImpl implements UserService { @Autowired UserAddressMapper userAddressMapper; 2、服务消费方 &lt;dubbo:application name=\"gmall-order-web\"&gt;&lt;/dubbo:application&gt; &lt;dubbo:registry address=\"zookeeper://118.24.44.169:2181\" /&gt; &lt;dubbo:annotation package=\"com.atguigu.gmall.order.controller\"/&gt; @Controller public class OrderController { @Reference //使用dubbo提供的reference注解引用远程服务 UserService userService; ## 5、监控中心 ### 5.1 dubbo-admin 图形化的服务管理页面；安装时需要指定注册中心地址，即可从注册中心中获取到所有的提供者/消费者进行配置管理 ### 5.2 dubbo-monitor-simple 简单的监控中心； #### **1、安装** | 1、下载 dubbo-opshttps://github.com/apache/incubator-dubbo-ops | | ------------------------------------------------------------ | | 2、修改配置指定注册中心地址进入 dubbo-monitor-simple\\src\\main\\resources\\conf修改 dubbo.properties文件![](https://llllz-1319101047.cos.ap-beijing.myqcloud.com/Dubbo/34.jpg) | | 3、打包dubbo-monitor-simplemvn clean package -Dmaven.test.skip=true | | 4、解压 tar.gz 文件，并运行start.bat![](https://llllz-1319101047.cos.ap-beijing.myqcloud.com/Dubbo/35.jpg) 如果缺少servlet-api，自行导入servlet-api再访问监控中心 | | 5、启动访问8080![](https://llllz-1319101047.cos.ap-beijing.myqcloud.com/Dubbo/36.jpg) | #### **2、监控中心配置** 所有服务配置连接监控中心，进行监控统计 &lt;!-- 监控中心协议，如果为protocol=\"registry\"，表示从注册中心发现监控中心地址，否则直连监控中心 --&gt; &lt;dubbo:monitor protocol=**\"registry\"**&gt;&lt;/dubbo:monitor&gt; Simple Monitor 挂掉不会影响到 Consumer 和 Provider 之间的调用，所以用于生产环境不会有风险。 Simple Monitor 采用磁盘存储统计信息，请注意安装机器的磁盘限制，如果要集群，建议用mount共享磁盘。 ## 6、整合SpringBoot | 1、引入spring-boot-starter以及dubbo和curator的依赖&lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.2.0&lt;/version&gt;&lt;/dependency&gt;注意starter版本适配：![](https://llllz-1319101047.cos.ap-beijing.myqcloud.com/Dubbo/37.jpg) | | ------------------------------------------------------------ | - ```java 2、配置application.properties 提供者配置： dubbo.application.name=gmall-user dubbo.registry.protocol=zookeeper dubbo.registry.address=192.168.67.159:2181 dubbo.scan.base-package=com.atguigu.gmall dubbo.protocol.name=dubbo application.name就是服务名，不能跟别的dubbo提供端重复 registry.protocol 是指定注册中心协议 registry.address 是注册中心的地址加端口号 protocol.name 是分布式固定是dubbo,不要改。 base-package 注解方式要扫描的包 消费者配置： dubbo.application.name=gmall-order-web dubbo.registry.protocol=zookeeper dubbo.registry.address=192.168.67.159:2181 dubbo.scan.base-package=com.atguigu.gmall dubbo.protocol.name=dubbo 3、dubbo注解 @Service、@Reference 【如果没有在配置中写dubbo.scan.base-package,还需要使用@EnableDubbo注解】 # 二、dubbo配置 ## 1、配置原则 ![](https://llllz-1319101047.cos.ap-beijing.myqcloud.com/Dubbo/38.jpg) JVM 启动 -D 参数优先，这样可以使用户在部署和启动时进行参数重写，比如在启动时需改变协议的端口。 XML 次之，如果在 XML 中有配置，则 dubbo.properties 中的相应配置项无效。 Properties 最后，相当于缺省值，只有 XML 没有配置时，dubbo.properties 的相应配置项才会生效，通常用于共享公共配置，比如应用名。 ## 2、重试次数 失败自动切换，当出现失败，重试其它服务器，但重试会带来更长延迟。可通过 retries=\"2\" 来设置重试次数(不含第一次)。 重试次数配置如下： &gt; &lt;dubbo:service retries=\"2\" /&gt; &gt; &gt; 或 &gt; &gt; &lt;dubbo:reference retries=\"2\" /&gt; &gt; &gt; 或 &gt; &gt; &lt;dubbo:reference&gt; &gt; &gt; ​ &lt;dubbo:method name=\"findFoo\" retries=\"2\" /&gt; &gt; &gt; &lt;/dubbo:reference&gt; ## 3、超时时间 由于网络或服务端不可靠，会导致调用出现一种不确定的中间状态（超时）。为了避免超时导致客户端资源（线程）挂起耗尽，必须设置超时时间。 ### 1、Dubbo消费端 全局超时配置&lt;dubbo:consumer timeout=\"5000\" /&gt; 指定接口以及特定方法超时配置&lt;dubbo:reference interface=\"com.foo.BarService\" timeout=\"2000\"&gt; &lt;dubbo:method name=\"sayHello\" timeout=\"3000\" /&gt;&lt;/dubbo:reference&gt; ### 2、Dubbo服务端 全局超时配置&lt;dubbo:provider timeout=\"5000\" /&gt; 指定接口以及特定方法超时配置&lt;dubbo:provider interface=\"com.foo.BarService\" timeout=\"2000\"&gt; &lt;dubbo:method name=\"sayHello\" timeout=\"3000\" /&gt;&lt;/dubbo:provider&gt; ### 3、配置原则 dubbo推荐在Provider上尽量多配置Consumer端属性： 作服务的提供者，比服务使用方更清楚服务性能参数，如调用的超时时间，合理的重试次数，等等2、在Provider配置后，Consumer不配置则会使用Provider的配置值，即Provider配置可以作为Consumer的缺省值。否则，Consumer会使用Consumer端的全局设置，这对于Provider不可控的，并且往往是不合理的 配置的覆盖规则： 1. 方法级配置别优于接口级别，即小Scope优先 2. Consumer端配置 优于 Provider配置 优于 全局配置 3. 最后是Dubbo Hard Code的配置值（见配置文档） ![](https://llllz-1319101047.cos.ap-beijing.myqcloud.com/Dubbo/39.jpg) ## 4、版本号 当一个接口实现，出现不兼容升级时，可以用版本号过渡，版本号不同的服务相互间不引用。 可以按照以下的步骤进行版本迁移： 在低压力时间段，先升级一半提供者为新版本 再将所有消费者升级为新版本 然后将剩下的一半提供者升级为新版本 - 老版本服务提供者配置：&lt;dubbo:service interface=\"com.foo.BarService\" version=\"1.0.0\" /&gt; - 新版本服务提供者配置：&lt;dubbo:service interface=\"com.foo.BarService\" version=\"2.0.0\" /&gt; - 老版本服务消费者配置：&lt;dubbo:reference id=\"barService\" interface=\"com.foo.BarService\" version=\"1.0.0\" /&gt; - 新版本服务消费者配置：&lt;dubbo:reference id=\"barService\" interface=\"com.foo.BarService\" version=\"2.0.0\" /&gt; - 如果不需要区分版本，可以按照以下的方式配置：&lt;dubbo:reference id=\"barService\" interface=\"com.foo.BarService\" version=\"*\" /&gt; # 三、高可用 ## 1、zookeeper宕机与dubbo直连 现象：zookeeper注册中心宕机，还可以消费dubbo暴露的服务。 原因： 健壮性l 监控中心宕掉不影响使用，只是丢失部分采样数据l 数据库宕掉后，注册中心仍能通过缓存提供服务列表查询，但不能注册新服务l 注册中心对等集群，任意一台宕掉后，将自动切换到另一台l **注册中心全部宕掉后，服务提供者和服务消费者仍能通过本地缓存通讯**l 服务提供者无状态，任意一台宕掉后，不影响使用l 服务提供者全部宕掉后，服务消费者应用将无法使用，并无限次重连等待服务提供者恢复 高可用：通过设计，减少系统不能提供服务的时间； ## 2、集群下dubbo负载均衡配置 在集群负载均衡时，Dubbo 提供了多种均衡策略，缺省为 random 随机调用。 负载均衡策略 - **Random LoadBalance** 随机，按权重设置随机概率。在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。 - **RoundRobin LoadBalance** 轮循，按公约后的权重设置轮循比率。存在慢的提供者累积请求的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。 - **LeastActive LoadBalance** 最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。 - **ConsistentHash LoadBalance** 一致性 Hash，相同参数的请求总是发到同一提供者。当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。算法参见：http://en.wikipedia.org/wiki/Consistent_hashing缺省只对第一个参数 Hash，如果要修改，请配置 &lt;dubbo:parameter key=\"hash.arguments\" value=\"0,1\" /&gt;缺省用 160 份虚拟节点，如果要修改，请配置 &lt;dubbo:parameter key=\"hash.nodes\" value=\"320\" /&gt; ## 3、整合hystrix，服务熔断与降级处理 ### 1、服务降级 **什么是服务降级？** **当服务器压力剧增的情况下，根据实际业务情况及流量，对一些服务和页面有策略的不处理或换种简单的方式处理，从而释放服务器资源以保证核心交易正常运作或高效运作。** 可以通过服务降级功能临时屏蔽某个出错的非关键服务，并定义降级后的返回策略。 向注册中心写入动态配置覆盖规则： ```配置 RegistryFactory registryFactory = ExtensionLoader.getExtensionLoader(RegistryFactory.class).getAdaptiveExtension();Registry registry = registryFactory.getRegistry(URL.valueOf(\"zookeeper://10.20.153.10:2181\"));registry.register(URL.valueOf(\"override://0.0.0.0/com.foo.BarService?category=configurators&amp;dynamic=false&amp;application=foo&amp;mock=force:return+null\")); 其中： mock=force:return+null 表示消费方对该服务的方法调用都直接返回 null 值，不发起远程调用。用来屏蔽不重要服务不可用时对调用方的影响。 还可以改为 mock=fail:return+null 表示消费方对该服务的方法调用在失败后，再返回 null 值，不抛异常。用来容忍不重要服务不稳定时对调用方的影响。 2、集群容错在集群调用失败时，Dubbo 提供了多种容错方案，缺省为 failover 重试。 集群容错模式 Failover Cluster失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。可通过 retries=”2” 来设置重试次数(不含第一次)。 重试次数配置如下： &lt;dubbo:service retries=”2” /&gt; 或 &lt;dubbo:reference retries=”2” /&gt; 或 dubbo:reference ​ &lt;dubbo:method name=”findFoo” retries=”2” /&gt; Failfast Cluster 快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。 Failsafe Cluster 失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。 Failback Cluster 失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 Forking Cluster 并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=”2” 来设置最大并行数。 Broadcast Cluster 广播调用所有提供者，逐个调用，任意一台报错则报错 [2]。通常用于通知所有提供者更新缓存或日志等本地资源信息。 集群模式配置 按照以下示例在服务提供方和消费方配置集群模式 &lt;dubbo:service cluster=”failsafe” /&gt; 或 &lt;dubbo:reference cluster=”failsafe” /&gt; 3、整合hystrixHystrix 旨在通过控制那些访问远程系统、服务和第三方库的节点，从而对延迟和故障提供更强大的容错能力。Hystrix具备拥有回退机制和断路器功能的线程和信号隔离，请求缓存和请求打包，以及监控和配置等功能 1、配置spring-cloud-starter-netflix-hystrixspring boot官方提供了对hystrix的集成，直接在pom.xml里加入依赖： &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;version&gt;1.4.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; 然后在Application类上增加@EnableHystrix来启用hystrix starter： @SpringBootApplication @EnableHystrix public class ProviderApplication { 2、配置Provider端在Dubbo的Provider上增加@HystrixCommand配置，这样子调用就会经过Hystrix代理。 @Service(version = \"1.0.0\") public class HelloServiceImpl implements HelloService { @HystrixCommand(commandProperties = { @HystrixProperty(name = \"circuitBreaker.requestVolumeThreshold\", value = \"10\"), @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\", value = \"2000\") }) @Override public String sayHello(String name) { // System.out.println(\"async provider received: \" + name); // return \"annotation: hello, \" + name; throw new RuntimeException(\"Exception to show hystrix enabled.\"); } } 3、配置Consumer端对于Consumer端，则可以增加一层method调用，并在method上配置@HystrixCommand。当调用出错时，会走到fallbackMethod = “reliable”的调用里。 @Reference(version = \"1.0.0\") private HelloService demoService; @HystrixCommand(fallbackMethod = \"reliable\") public String doSayHello(String name) { return demoService.sayHello(name); } public String reliable(String name) { return \"hystrix fallback value\"; } 四、dubbo原理1、RPC原理 一次完整的RPC调用流程（同步调用，异步另说）如下： 1）服务消费方（client）调用以本地调用方式调用服务； 2）client stub接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体； 3）client stub找到服务地址，并将消息发送到服务端； 4）server stub收到消息后进行解码； 5）server stub根据解码结果调用本地的服务； 6）本地服务执行并将结果返回给server stub； 7）server stub将返回结果打包成消息并发送至消费方； 8）client stub接收到消息，并进行解码； 9）服务消费方得到最终结果。 RPC框架的目标就是要2~8这些步骤都封装起来，这些细节对用户来说是透明的，不可见的。 2、netty通信原理Netty是一个异步事件驱动的网络应用程序框架， 用于快速开发可维护的高性能协议服务器和客户端。它极大地简化并简化了TCP和UDP套接字服务器等网络编程。 BIO：(Blocking IO) NIO (Non-Blocking IO) Selector 一般称 为选择器 ，也可以翻译为 多路复用器， Connect（连接就绪）、Accept（接受就绪）、Read（读就绪）、Write（写就绪） Netty基本原理： 3、dubbo原理1、dubbo原理 -框架设计 config 配置层：对外配置接口，以 ServiceConfig, ReferenceConfig 为中心，可以直接初始化配置类，也可以通过 spring 解析配置生成配置类 proxy 服务代理层：服务接口透明代理，生成服务的客户端 Stub 和服务器端 Skeleton, 以 ServiceProxy 为中心，扩展接口为 ProxyFactory registry 注册中心层：封装服务地址的注册与发现，以服务 URL 为中心，扩展接口为 RegistryFactory, Registry, RegistryService cluster 路由层：封装多个提供者的路由及负载均衡，并桥接注册中心，以 Invoker 为中心，扩展接口为 Cluster, Directory, Router, LoadBalance monitor 监控层：RPC 调用次数和调用时间监控，以 Statistics 为中心，扩展接口为 MonitorFactory, Monitor, MonitorService protocol 远程调用层：封装 RPC 调用，以 Invocation, Result 为中心，扩展接口为 Protocol, Invoker, Exporter exchange 信息交换层：封装请求响应模式，同步转异步，以 Request, Response 为中心，扩展接口为 Exchanger, ExchangeChannel, ExchangeClient, ExchangeServer transport 网络传输层：抽象 mina 和 netty 为统一接口，以 Message 为中心，扩展接口为 Channel, Transporter, Client, Server, Codec serialize 数据序列化层：可复用的一些工具，扩展接口为 Serialization, ObjectInput, ObjectOutput, ThreadPool 2、dubbo原理 -启动解析、加载配置信息 3、dubbo原理 -服务暴露 4、dubbo原理 -服务引用 5、dubbo原理 -服务调用","categories":[],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gitee.com/yunyd/tags/Dubbo/"}],"author":"llllz."},{"title":"Redis复习 -Ⅱ","slug":"Redis复习  -2","date":"2023-08-22T02:08:42.000Z","updated":"2023-08-25T00:22:01.612Z","comments":true,"path":"posts/89420fb3.html","link":"","permalink":"https://gitee.com/yunyd/posts/89420fb3.html","excerpt":"","text":"Redis复习目录： 短信登录 这一块我们会使用redis共享session来实现 商户查询缓存 通过本章节，我们会理解缓存击穿，缓存穿透，缓存雪崩等问题，让小伙伴的对于这些概念的理解不仅仅是停留在概念上，更是能在代码中看到对应的内容 优惠卷秒杀 通过本章节，我们可以学会Redis的计数器功能， 结合Lua完成高性能的redis操作，同时学会Redis分布式锁的原理，包括Redis的三种消息队列 1、短信登录1.1 、基于Session实现登录流程发送验证码： 用户在提交手机号后，会校验手机号是否合法，如果不合法，则要求用户重新输入手机号 如果手机号合法，后台此时生成对应的验证码，同时将验证码进行保存，然后再通过短信的方式将验证码发送给用户 短信验证码登录、注册： 用户将验证码和手机号进行输入，后台从session中拿到当前验证码，然后和用户输入的验证码进行校验，如果不一致，则无法通过校验，如果一致，则后台根据手机号查询用户，如果用户不存在，则为用户创建账号信息，保存到数据库，无论是否存在，都会将用户信息保存到session中，方便后续获得当前登录信息 校验登录状态: 用户在请求时候，会从cookie中携带着JsessionId到后台，后台通过JsessionId从session中拿到用户信息，如果没有session信息，则进行拦截，如果有session信息，则将用户信息保存到threadLocal中，并且放行 1.2 、实现发送短信验证码功能页面流程 具体代码如下 贴心小提示： 具体逻辑上文已经分析，我们仅仅只需要按照提示的逻辑写出代码即可。 发送验证码 @Override public Result sendCode(String phone, HttpSession session) { // 1.校验手机号 if (RegexUtils.isPhoneInvalid(phone)) { // 2.如果不符合，返回错误信息 return Result.fail(\"手机号格式错误！\"); } // 3.符合，生成验证码 String code = RandomUtil.randomNumbers(6); // 4.保存验证码到 session session.setAttribute(\"code\",code); // 5.发送验证码 log.debug(\"发送短信验证码成功，验证码：{}\", code); // 返回ok return Result.ok(); } 登录 @Override public Result login(LoginFormDTO loginForm, HttpSession session) { // 1.校验手机号 String phone = loginForm.getPhone(); if (RegexUtils.isPhoneInvalid(phone)) { // 2.如果不符合，返回错误信息 return Result.fail(\"手机号格式错误！\"); } // 3.校验验证码 Object cacheCode = session.getAttribute(\"code\"); String code = loginForm.getCode(); if(cacheCode == null || !cacheCode.toString().equals(code)){ //3.不一致，报错 return Result.fail(\"验证码错误\"); } //一致，根据手机号查询用户 User user = query().eq(\"phone\", phone).one(); //5.判断用户是否存在 if(user == null){ //不存在，则创建 user = createUserWithPhone(phone); } //7.保存用户信息到session中 session.setAttribute(\"user\",user); return Result.ok(); } 1.3、实现登录拦截功能温馨小贴士：tomcat的运行原理 当用户发起请求时，会访问我们像tomcat注册的端口，任何程序想要运行，都需要有一个线程对当前端口号进行监听，tomcat也不例外，当监听线程知道用户想要和tomcat连接连接时，那会由监听线程创建socket连接，socket都是成对出现的，用户通过socket像互相传递数据，当tomcat端的socket接受到数据后，此时监听线程会从tomcat的线程池中取出一个线程执行用户请求，在我们的服务部署到tomcat后，线程会找到用户想要访问的工程，然后用这个线程转发到工程中的controller，service，dao中，并且访问对应的DB，在用户执行完请求后，再统一返回，再找到tomcat端的socket，再将数据写回到用户端的socket，完成请求和响应 通过以上讲解，我们可以得知 每个用户其实对应都是去找tomcat线程池中的一个线程来完成工作的， 使用完成后再进行回收，既然每个请求都是独立的，所以在每个用户去访问我们的工程时，我们可以使用threadlocal来做到线程隔离，每个线程操作自己的一份数据 温馨小贴士：关于threadlocal 如果小伙伴们看过threadLocal的源码，你会发现在threadLocal中，无论是他的put方法和他的get方法， 都是先从获得当前用户的线程，然后从线程中取出线程的成员变量map，只要线程不一样，map就不一样，所以可以通过这种方式来做到线程隔离 拦截器代码 public class LoginInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { //1.获取session HttpSession session = request.getSession(); //2.获取session中的用户 Object user = session.getAttribute(\"user\"); //3.判断用户是否存在 if(user == null){ //4.不存在，拦截，返回401状态码 response.setStatus(401); return false; } //5.存在，保存用户信息到Threadlocal UserHolder.saveUser((User)user); //6.放行 return true; } } 让拦截器生效 @Configuration public class MvcConfig implements WebMvcConfigurer { @Resource private StringRedisTemplate stringRedisTemplate; @Override public void addInterceptors(InterceptorRegistry registry) { // 登录拦截器 registry.addInterceptor(new LoginInterceptor()) .excludePathPatterns( \"/shop/**\", \"/voucher/**\", \"/shop-type/**\", \"/upload/**\", \"/blog/hot\", \"/user/code\", \"/user/login\" ).order(1); // token刷新的拦截器 registry.addInterceptor(new RefreshTokenInterceptor(stringRedisTemplate)).addPathPatterns(\"/**\").order(0); } } 1.4、隐藏用户敏感信息我们通过浏览器观察到此时用户的全部信息都在，这样极为不靠谱，所以我们应当在返回用户信息之前，将用户的敏感信息进行隐藏，采用的核心思路就是书写一个UserDto对象，这个UserDto对象就没有敏感信息了，我们在返回前，将有用户敏感信息的User对象转化成没有敏感信息的UserDto对象，那么就能够避免这个尴尬的问题了 在登录方法处修改 //7.保存用户信息到session中 session.setAttribute(\"user\", BeanUtils.copyProperties(user,UserDTO.class)); 在拦截器处： //5.存在，保存用户信息到Threadlocal UserHolder.saveUser((UserDTO) user); 在UserHolder处：将user对象换成UserDTO public class UserHolder { private static final ThreadLocal&lt;UserDTO&gt; tl = new ThreadLocal&lt;&gt;(); public static void saveUser(UserDTO user){ tl.set(user); } public static UserDTO getUser(){ return tl.get(); } public static void removeUser(){ tl.remove(); } } 1.5、session共享问题核心思路分析： 每个tomcat中都有一份属于自己的session,假设用户第一次访问第一台tomcat，并且把自己的信息存放到第一台服务器的session中，但是第二次这个用户访问到了第二台tomcat，那么在第二台服务器上，肯定没有第一台服务器存放的session，所以此时 整个登录拦截功能就会出现问题，我们能如何解决这个问题呢？早期的方案是session拷贝，就是说虽然每个tomcat上都有不同的session，但是每当任意一台服务器的session修改时，都会同步给其他的Tomcat服务器的session，这样的话，就可以实现session的共享了 但是这种方案具有两个大问题 1、每台服务器中都有完整的一份session数据，服务器压力过大。 2、session拷贝数据时，可能会出现延迟 所以咱们后来采用的方案都是基于redis来完成，我们把session换成redis，redis数据本身就是共享的，就可以避免session共享的问题了 1.6 Redis代替session的业务流程1.6.1、设计key的结构首先我们要思考一下利用redis来存储数据，那么到底使用哪种结构呢？由于存入的数据比较简单，我们可以考虑使用String，或者是使用哈希，如下图，如果使用String，同学们注意他的value，用多占用一点空间，如果使用哈希，则他的value中只会存储他数据本身，如果不是特别在意内存，其实使用String就可以啦。 1.6.2、设计key的具体细节所以我们可以使用String结构，就是一个简单的key，value键值对的方式，但是关于key的处理，session他是每个用户都有自己的session，但是redis的key是共享的，咱们就不能使用code了 在设计这个key的时候，我们之前讲过需要满足两点 1、key要具有唯一性 2、key要方便携带 如果我们采用phone：手机号这个的数据来存储当然是可以的，但是如果把这样的敏感数据存储到redis中并且从页面中带过来毕竟不太合适，所以我们在后台生成一个随机串token，然后让前端带来这个token就能完成我们的整体逻辑了 1.6.3、整体访问流程当注册完成后，用户去登录会去校验用户提交的手机号和验证码，是否一致，如果一致，则根据手机号查询用户信息，不存在则新建，最后将用户数据保存到redis，并且生成token作为redis的key，当我们校验用户是否登录时，会去携带着token进行访问，从redis中取出token对应的value，判断是否存在这个数据，如果没有则拦截，如果存在则将其保存到threadLocal中，并且放行。 1.7 基于Redis实现短信登录这里具体逻辑就不分析了，之前咱们已经重点分析过这个逻辑啦。 UserServiceImpl代码 @Override public Result login(LoginFormDTO loginForm, HttpSession session) { // 1.校验手机号 String phone = loginForm.getPhone(); if (RegexUtils.isPhoneInvalid(phone)) { // 2.如果不符合，返回错误信息 return Result.fail(\"手机号格式错误！\"); } // 3.从redis获取验证码并校验 String cacheCode = stringRedisTemplate.opsForValue().get(LOGIN_CODE_KEY + phone); String code = loginForm.getCode(); if (cacheCode == null || !cacheCode.equals(code)) { // 不一致，报错 return Result.fail(\"验证码错误\"); } // 4.一致，根据手机号查询用户 select * from tb_user where phone = ? User user = query().eq(\"phone\", phone).one(); // 5.判断用户是否存在 if (user == null) { // 6.不存在，创建新用户并保存 user = createUserWithPhone(phone); } // 7.保存用户信息到 redis中 // 7.1.随机生成token，作为登录令牌 String token = UUID.randomUUID().toString(true); // 7.2.将User对象转为HashMap存储 UserDTO userDTO = BeanUtil.copyProperties(user, UserDTO.class); Map&lt;String, Object&gt; userMap = BeanUtil.beanToMap(userDTO, new HashMap&lt;&gt;(), CopyOptions.create() .setIgnoreNullValue(true) .setFieldValueEditor((fieldName, fieldValue) -&gt; fieldValue.toString())); // 7.3.存储 String tokenKey = LOGIN_USER_KEY + token; stringRedisTemplate.opsForHash().putAll(tokenKey, userMap); // 7.4.设置token有效期 stringRedisTemplate.expire(tokenKey, LOGIN_USER_TTL, TimeUnit.MINUTES); // 8.返回token return Result.ok(token); } 1.8 解决状态登录刷新问题1.8.1 初始方案思路总结：在这个方案中，他确实可以使用对应路径的拦截，同时刷新登录token令牌的存活时间，但是现在这个拦截器他只是拦截需要被拦截的路径，假设当前用户访问了一些不需要拦截的路径，那么这个拦截器就不会生效，所以此时令牌刷新的动作实际上就不会执行，所以这个方案他是存在问题的 1.8.2 优化方案既然之前的拦截器无法对不需要拦截的路径生效，那么我们可以添加一个拦截器，在第一个拦截器中拦截所有的路径，把第二个拦截器做的事情放入到第一个拦截器中，同时刷新令牌，因为第一个拦截器有了threadLocal的数据，所以此时第二个拦截器只需要判断拦截器中的user对象是否存在即可，完成整体刷新功能。 1.8.3 代码RefreshTokenInterceptor public class RefreshTokenInterceptor implements HandlerInterceptor { private StringRedisTemplate stringRedisTemplate; public RefreshTokenInterceptor(StringRedisTemplate stringRedisTemplate) { this.stringRedisTemplate = stringRedisTemplate; } @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { // 1.获取请求头中的token String token = request.getHeader(\"authorization\"); if (StrUtil.isBlank(token)) { return true; } // 2.基于TOKEN获取redis中的用户 String key = LOGIN_USER_KEY + token; Map&lt;Object, Object&gt; userMap = stringRedisTemplate.opsForHash().entries(key); // 3.判断用户是否存在 if (userMap.isEmpty()) { return true; } // 5.将查询到的hash数据转为UserDTO UserDTO userDTO = BeanUtil.fillBeanWithMap(userMap, new UserDTO(), false); // 6.存在，保存用户信息到 ThreadLocal UserHolder.saveUser(userDTO); // 7.刷新token有效期 stringRedisTemplate.expire(key, LOGIN_USER_TTL, TimeUnit.MINUTES); // 8.放行 return true; } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { // 移除用户 UserHolder.removeUser(); } } LoginInterceptor public class LoginInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { // 1.判断是否需要拦截（ThreadLocal中是否有用户） if (UserHolder.getUser() == null) { // 没有，需要拦截，设置状态码 response.setStatus(401); // 拦截 return false; } // 有用户，则放行 return true; } } 2、商户查询缓存2.1 什么是缓存?前言:什么是缓存? 就像自行车,越野车的避震器 举个例子:越野车,山地自行车,都拥有”避震器”,防止车体加速后因惯性,在酷似”U”字母的地形上飞跃,硬着陆导致的损害,像个弹簧一样; 同样,实际开发中,系统也需要”避震器”,防止过高的数据访问猛冲系统,导致其操作线程无法及时处理信息而瘫痪; 这在实际开发中对企业讲,对产品口碑,用户评价都是致命的;所以企业非常重视缓存技术; 缓存(**Cache),就是数据交换的缓冲区**,俗称的缓存就是缓冲区内的数据,一般从数据库中获取,存储于本地代码(例如: 例1:Static final ConcurrentHashMap&lt;K,V&gt; map = new ConcurrentHashMap&lt;&gt;(); 本地用于高并发 例2:static final Cache&lt;K,V&gt; USER_CACHE = CacheBuilder.newBuilder().build(); 用于redis等缓存 例3:Static final Map&lt;K,V&gt; map = new HashMap(); 本地缓存 由于其被Static修饰,所以随着类的加载而被加载到内存之中,作为本地缓存,由于其又被final修饰,所以其引用(例3:map)和对象(例3:new HashMap())之间的关系是固定的,不能改变,因此不用担心赋值(=)导致缓存失效; 2.1.1 为什么要使用缓存一句话:因为速度快,好用 缓存数据存储于代码中,而代码运行在内存中,内存的读写性能远高于磁盘,缓存可以大大降低用户访问并发量带来的服务器读写压力 实际开发过程中,企业的数据量,少则几十万,多则几千万,这么大数据量,如果没有缓存来作为”避震器”,系统是几乎撑不住的,所以企业会大量运用到缓存技术; 但是缓存也会增加代码复杂度和运营的成本: 2.1.2 如何使用缓存实际开发中,会构筑多级缓存来使系统运行速度进一步提升,例如:本地缓存与redis中的缓存并发使用 浏览器缓存：主要是存在于浏览器端的缓存 应用层缓存：可以分为tomcat本地缓存，比如之前提到的map，或者是使用redis作为缓存 数据库缓存：在数据库中有一片空间是 buffer pool，增改查数据都会先加载到mysql的缓存中 CPU缓存：当代计算机最大的问题是 cpu性能提升了，但内存读写速度没有跟上，所以为了适应当下的情况，增加了cpu的L1，L2，L3级的缓存 2.2 添加商户缓存在我们查询商户信息时，我们是直接操作从数据库中去进行查询的，大致逻辑是这样，直接查询数据库那肯定慢咯，所以我们需要增加缓存 @GetMapping(\"/{id}\") public Result queryShopById(@PathVariable(\"id\") Long id) { //这里是直接查询数据库 return shopService.queryById(id); } 2.2.1 、缓存模型和思路标准的操作方式就是查询数据库之前先查询缓存，如果缓存数据存在，则直接从缓存中返回，如果缓存数据不存在，再查询数据库，然后将数据存入redis。 2.1.2、代码如下代码思路：如果缓存有，则直接返回，如果缓存不存在，则查询数据库，然后存入redis。 2.3 缓存更新策略缓存更新是redis为了节约内存而设计出来的一个东西，主要是因为内存数据宝贵，当我们向redis插入太多数据，此时就可能会导致缓存中的数据过多，所以redis会对部分数据进行更新，或者把他叫为淘汰更合适。 内存淘汰：redis自动进行，当redis内存达到咱们设定的max-memery的时候，会自动触发淘汰机制，淘汰掉一些不重要的数据(可以自己设置策略方式) 超时剔除：当我们给redis设置了过期时间ttl之后，redis会将超时的数据进行删除，方便咱们继续使用缓存 主动更新：我们可以手动调用方法把缓存删掉，通常用于解决缓存和数据库不一致问题 2.3.1 、数据库缓存不一致解决方案：由于我们的缓存的数据源来自于数据库,而数据库的数据是会发生变化的,因此,如果当数据库中数据发生变化,而缓存却没有同步,此时就会有一致性问题存在,其后果是: 用户使用缓存中的过时数据,就会产生类似多线程数据安全问题,从而影响业务,产品口碑等;怎么解决呢？有如下几种方案 Cache Aside Pattern 人工编码方式：缓存调用者在更新完数据库后再去更新缓存，也称之为双写方案 Read/Write Through Pattern : 由系统本身完成，数据库与缓存的问题交由系统本身去处理 Write Behind Caching Pattern ：调用者只操作缓存，其他线程去异步处理数据库，实现最终一致 2.3.2 、数据库和缓存不一致采用什么方案综合考虑使用方案一，但是方案一调用者如何处理呢？这里有几个问题 操作缓存和数据库时有三个问题需要考虑： 如果采用第一个方案，那么假设我们每次操作数据库后，都操作缓存，但是中间如果没有人查询，那么这个更新动作实际上只有最后一次生效，中间的更新动作意义并不大，我们可以把缓存删除，等待再次查询时，将缓存中的数据加载出来 删除缓存还是更新缓存？ 更新缓存：每次更新数据库都更新缓存，无效写操作较多 删除缓存：更新数据库时让缓存失效，查询时再更新缓存 如何保证缓存与数据库的操作的同时成功或失败？ 单体系统，将缓存与数据库操作放在一个事务 分布式系统，利用TCC等分布式事务方案 应该具体操作缓存还是操作数据库，我们应当是先操作数据库，再删除缓存，原因在于，如果你选择第一种方案，在两个线程并发来访问时，假设线程1先来，他先把缓存删了，此时线程2过来，他查询缓存数据并不存在，此时他写入缓存，当他写入缓存后，线程1再执行更新动作时，实际上写入的就是旧的数据，新的数据被旧数据覆盖了。 先操作缓存还是先操作数据库？ 先删除缓存，再操作数据库 先操作数据库，再删除缓存 2.4 实现商铺和缓存与数据库双写一致核心思路如下： 修改ShopController中的业务逻辑，满足下面的需求： 根据id查询店铺时，如果缓存未命中，则查询数据库，将数据库结果写入缓存，并设置超时时间 根据id修改店铺时，先修改数据库，再删除缓存 修改重点代码1：修改ShopServiceImpl的queryById方法 设置redis缓存时添加过期时间 修改重点代码2 代码分析：通过之前的淘汰，我们确定了采用删除策略，来解决双写问题，当我们修改了数据之后，然后把缓存中的数据进行删除，查询时发现缓存中没有数据，则会从mysql中加载最新的数据，从而避免数据库和缓存不一致的问题 2.5 缓存穿透问题的解决思路缓存穿透 ：缓存穿透是指客户端请求的数据在缓存中和数据库中都不存在，这样缓存永远不会生效，这些请求都会打到数据库。 常见的解决方案有两种： 缓存空对象 优点：实现简单，维护方便 缺点： 额外的内存消耗 可能造成短期的不一致 布隆过滤 优点：内存占用较少，没有多余key 缺点： 实现复杂 存在误判可能 缓存空对象思路分析：当我们客户端访问不存在的数据时，先请求redis，但是此时redis中没有数据，此时会访问到数据库，但是数据库中也没有数据，这个数据穿透了缓存，直击数据库，我们都知道数据库能够承载的并发不如redis这么高，如果大量的请求同时过来访问这种不存在的数据，这些请求就都会访问到数据库，简单的解决方案就是哪怕这个数据在数据库中也不存在，我们也把这个数据存入到redis中去，这样，下次用户过来访问这个不存在的数据，那么在redis中也能找到这个数据就不会进入到缓存了 布隆过滤：布隆过滤器其实采用的是哈希思想来解决这个问题，通过一个庞大的二进制数组，走哈希思想去判断当前这个要查询的这个数据是否存在，如果布隆过滤器判断存在，则放行，这个请求会去访问redis，哪怕此时redis中的数据过期了，但是数据库中一定存在这个数据，在数据库中查询出来这个数据后，再将其放入到redis中， 假设布隆过滤器判断这个数据不存在，则直接返回 这种方式优点在于节约内存空间，存在误判，误判原因在于：布隆过滤器走的是哈希思想，只要哈希思想，就可能存在哈希冲突 2.6 编码解决商品查询的缓存穿透问题：核心思路如下： 在原来的逻辑中，我们如果发现这个数据在mysql中不存在，直接就返回404了，这样是会存在缓存穿透问题的 现在的逻辑中：如果这个数据不存在，我们不会返回404 ，还是会把这个数据写入到Redis中，并且将value设置为空，欧当再次发起查询时，我们如果发现命中之后，判断这个value是否是null，如果是null，则是之前写入的数据，证明是缓存穿透数据，如果不是，则直接返回数据。 小总结： 缓存穿透产生的原因是什么？ 用户请求的数据在缓存中和数据库中都不存在，不断发起这样的请求，给数据库带来巨大压力 缓存穿透的解决方案有哪些？ 缓存null值 布隆过滤 增强id的复杂度，避免被猜测id规律 做好数据的基础格式校验 加强用户权限校验 做好热点参数的限流 2.7 缓存雪崩问题及解决思路缓存雪崩是指在同一时段大量的缓存key同时失效或者Redis服务宕机，导致大量请求到达数据库，带来巨大压力。 解决方案： 给不同的Key的TTL添加随机值 利用Redis集群提高服务的可用性 给缓存业务添加降级限流策略 给业务添加多级缓存 2.8 缓存击穿问题及解决思路缓存击穿问题也叫热点Key问题，就是一个被高并发访问并且缓存重建业务较复杂的key突然失效了，无数的请求访问会在瞬间给数据库带来巨大的冲击。 常见的解决方案有两种： 互斥锁 逻辑过期 逻辑分析：假设线程1在查询缓存之后，本来应该去查询数据库，然后把这个数据重新加载到缓存的，此时只要线程1走完这个逻辑，其他线程就都能从缓存中加载这些数据了，但是假设在线程1没有走完的时候，后续的线程2，线程3，线程4同时过来访问当前这个方法， 那么这些线程都不能从缓存中查询到数据，那么他们就会同一时刻来访问查询缓存，都没查到，接着同一时间去访问数据库，同时的去执行数据库代码，对数据库访问压力过大 解决方案一、使用锁来解决： 因为锁能实现互斥性。假设线程过来，只能一个人一个人的来访问数据库，从而避免对于数据库访问压力过大，但这也会影响查询的性能，因为此时会让查询的性能从并行变成了串行，我们可以采用tryLock方法 + double check来解决这样的问题。 假设现在线程1过来访问，他查询缓存没有命中，但是此时他获得到了锁的资源，那么线程1就会一个人去执行逻辑，假设现在线程2过来，线程2在执行过程中，并没有获得到锁，那么线程2就可以进行到休眠，直到线程1把锁释放后，线程2获得到锁，然后再来执行逻辑，此时就能够从缓存中拿到数据了。 解决方案二、逻辑过期方案 方案分析：我们之所以会出现这个缓存击穿问题，主要原因是在于我们对key设置了过期时间，假设我们不设置过期时间，其实就不会有缓存击穿的问题，但是不设置过期时间，这样数据不就一直占用我们内存了吗，我们可以采用逻辑过期方案。 我们把过期时间设置在 redis的value中，注意：这个过期时间并不会直接作用于redis，而是我们后续通过逻辑去处理。假设线程1去查询缓存，然后从value中判断出来当前的数据已经过期了，此时线程1去获得互斥锁，那么其他线程会进行阻塞，获得了锁的线程他会开启一个 线程去进行 以前的重构数据的逻辑，直到新开的线程完成这个逻辑后，才释放锁， 而线程1直接进行返回，假设现在线程3过来访问，由于线程线程2持有着锁，所以线程3无法获得锁，线程3也直接返回数据，只有等到新开的线程2把重建数据构建完后，其他线程才能走返回正确的数据。 这种方案巧妙在于，异步的构建缓存，缺点在于在构建完缓存之前，返回的都是脏数据。 进行对比 互斥锁方案：由于保证了互斥性，所以数据一致，且实现简单，因为仅仅只需要加一把锁而已，也没其他的事情需要操心，所以没有额外的内存消耗，缺点在于有锁就有死锁问题的发生，且只能串行执行性能肯定受到影响 逻辑过期方案： 线程读取过程中不需要等待，性能好，有一个额外的线程持有锁去进行重构数据，但是在重构数据完成前，其他的线程只能返回之前的数据，且实现起来麻烦 2.9 利用互斥锁解决缓存击穿问题核心思路：相较于原来从缓存中查询不到数据后直接查询数据库而言，现在的方案是 进行查询之后，如果从缓存没有查询到数据，则进行互斥锁的获取，获取互斥锁后，判断是否获得到了锁，如果没有获得到，则休眠，过一会再进行尝试，直到获取到锁为止，才能进行查询 如果获取到了锁的线程，再去进行查询，查询后将数据写入redis，再释放锁，返回数据，利用互斥锁就能保证只有一个线程去执行操作数据库的逻辑，防止缓存击穿 操作锁的代码： 核心思路就是利用redis的setnx方法来表示获取锁，该方法含义是redis中如果没有这个key，则插入成功，返回1，在stringRedisTemplate中返回true， 如果有这个key则插入失败，则返回0，在stringRedisTemplate返回false，我们可以通过true，或者是false，来表示是否有线程成功插入key，成功插入的key的线程我们认为他就是获得到锁的线程。 private boolean tryLock(String key) { Boolean flag = stringRedisTemplate.opsForValue().setIfAbsent(key, \"1\", 10, TimeUnit.SECONDS); return BooleanUtil.isTrue(flag); } private void unlock(String key) { stringRedisTemplate.delete(key); } 操作代码： public Shop queryWithMutex(Long id) { String key = CACHE_SHOP_KEY + id; // 1、从redis中查询商铺缓存 String shopJson = stringRedisTemplate.opsForValue().get(\"key\"); // 2、判断是否存在 if (StrUtil.isNotBlank(shopJson)) { // 存在,直接返回 return JSONUtil.toBean(shopJson, Shop.class); } //判断命中的值是否是空值 if (shopJson != null) { //返回一个错误信息 return null; } // 4.实现缓存重构 //4.1 获取互斥锁 String lockKey = \"lock:shop:\" + id; Shop shop = null; try { boolean isLock = tryLock(lockKey); // 4.2 判断否获取成功 if(!isLock){ //4.3 失败，则休眠重试 Thread.sleep(50); return queryWithMutex(id); } //4.4 成功，根据id查询数据库 shop = getById(id); // 5.不存在，返回错误 if(shop == null){ //将空值写入redis stringRedisTemplate.opsForValue().set(key,\"\",CACHE_NULL_TTL,TimeUnit.MINUTES); //返回错误信息 return null; } //6.写入redis stringRedisTemplate.opsForValue().set(key,JSONUtil.toJsonStr(shop),CACHE_NULL_TTL,TimeUnit.MINUTES); }catch (Exception e){ throw new RuntimeException(e); } finally { //7.释放互斥锁 unlock(lockKey); } return shop; } 3.0 、利用逻辑过期解决缓存击穿问题需求：修改根据id查询商铺的业务，基于逻辑过期方式来解决缓存击穿问题 思路分析：当用户开始查询redis时，判断是否命中，如果没有命中则直接返回空数据，不查询数据库，而一旦命中后，将value取出，判断value中的过期时间是否满足，如果没有过期，则直接返回redis中的数据，如果过期，则在开启独立线程后直接返回之前的数据，独立线程去重构数据，重构完成后释放互斥锁。 如果封装数据：因为现在redis中存储的数据的value需要带上过期时间，此时要么你去修改原来的实体类，要么你 步骤一、 新建一个实体类，我们采用第二个方案，这个方案，对原来代码没有侵入性。 @Data public class RedisData { private LocalDateTime expireTime; private Object data; } 步骤二、 在ShopServiceImpl 新增此方法，利用单元测试进行缓存预热 在测试类中 步骤三：正式代码 ShopServiceImpl private static final ExecutorService CACHE_REBUILD_EXECUTOR = Executors.newFixedThreadPool(10); public Shop queryWithLogicalExpire( Long id ) { String key = CACHE_SHOP_KEY + id; // 1.从redis查询商铺缓存 String json = stringRedisTemplate.opsForValue().get(key); // 2.判断是否存在 if (StrUtil.isBlank(json)) { // 3.存在，直接返回 return null; } // 4.命中，需要先把json反序列化为对象 RedisData redisData = JSONUtil.toBean(json, RedisData.class); Shop shop = JSONUtil.toBean((JSONObject) redisData.getData(), Shop.class); LocalDateTime expireTime = redisData.getExpireTime(); // 5.判断是否过期 if(expireTime.isAfter(LocalDateTime.now())) { // 5.1.未过期，直接返回店铺信息 return shop; } // 5.2.已过期，需要缓存重建 // 6.缓存重建 // 6.1.获取互斥锁 String lockKey = LOCK_SHOP_KEY + id; boolean isLock = tryLock(lockKey); // 6.2.判断是否获取锁成功 if (isLock){ CACHE_REBUILD_EXECUTOR.submit( ()-&gt;{ try{ //重建缓存 this.saveShop2Redis(id,20L); }catch (Exception e){ throw new RuntimeException(e); }finally { unlock(lockKey); } }); } // 6.4.返回过期的商铺信息 return shop; } 3.1、封装Redis工具类基于StringRedisTemplate封装一个缓存工具类，满足下列需求： 方法1：将任意Java对象序列化为json并存储在string类型的key中，并且可以设置TTL过期时间 方法2：将任意Java对象序列化为json并存储在string类型的key中，并且可以设置逻辑过期时间，用于处理缓 存击穿问题 方法3：根据指定的key查询缓存，并反序列化为指定类型，利用缓存空值的方式解决缓存穿透问题 方法4：根据指定的key查询缓存，并反序列化为指定类型，需要利用逻辑过期解决缓存击穿问题 将逻辑进行封装 @Slf4j @Component public class CacheClient { private final StringRedisTemplate stringRedisTemplate; private static final ExecutorService CACHE_REBUILD_EXECUTOR = Executors.newFixedThreadPool(10); public CacheClient(StringRedisTemplate stringRedisTemplate) { this.stringRedisTemplate = stringRedisTemplate; } public void set(String key, Object value, Long time, TimeUnit unit) { stringRedisTemplate.opsForValue().set(key, JSONUtil.toJsonStr(value), time, unit); } public void setWithLogicalExpire(String key, Object value, Long time, TimeUnit unit) { // 设置逻辑过期 RedisData redisData = new RedisData(); redisData.setData(value); redisData.setExpireTime(LocalDateTime.now().plusSeconds(unit.toSeconds(time))); // 写入Redis stringRedisTemplate.opsForValue().set(key, JSONUtil.toJsonStr(redisData)); } public &lt;R,ID&gt; R queryWithPassThrough( String keyPrefix, ID id, Class&lt;R&gt; type, Function&lt;ID, R&gt; dbFallback, Long time, TimeUnit unit){ String key = keyPrefix + id; // 1.从redis查询商铺缓存 String json = stringRedisTemplate.opsForValue().get(key); // 2.判断是否存在 if (StrUtil.isNotBlank(json)) { // 3.存在，直接返回 return JSONUtil.toBean(json, type); } // 判断命中的是否是空值 if (json != null) { // 返回一个错误信息 return null; } // 4.不存在，根据id查询数据库 R r = dbFallback.apply(id); // 5.不存在，返回错误 if (r == null) { // 将空值写入redis stringRedisTemplate.opsForValue().set(key, \"\", CACHE_NULL_TTL, TimeUnit.MINUTES); // 返回错误信息 return null; } // 6.存在，写入redis this.set(key, r, time, unit); return r; } public &lt;R, ID&gt; R queryWithLogicalExpire( String keyPrefix, ID id, Class&lt;R&gt; type, Function&lt;ID, R&gt; dbFallback, Long time, TimeUnit unit) { String key = keyPrefix + id; // 1.从redis查询商铺缓存 String json = stringRedisTemplate.opsForValue().get(key); // 2.判断是否存在 if (StrUtil.isBlank(json)) { // 3.存在，直接返回 return null; } // 4.命中，需要先把json反序列化为对象 RedisData redisData = JSONUtil.toBean(json, RedisData.class); R r = JSONUtil.toBean((JSONObject) redisData.getData(), type); LocalDateTime expireTime = redisData.getExpireTime(); // 5.判断是否过期 if(expireTime.isAfter(LocalDateTime.now())) { // 5.1.未过期，直接返回店铺信息 return r; } // 5.2.已过期，需要缓存重建 // 6.缓存重建 // 6.1.获取互斥锁 String lockKey = LOCK_SHOP_KEY + id; boolean isLock = tryLock(lockKey); // 6.2.判断是否获取锁成功 if (isLock){ // 6.3.成功，开启独立线程，实现缓存重建 CACHE_REBUILD_EXECUTOR.submit(() -&gt; { try { // 查询数据库 R newR = dbFallback.apply(id); // 重建缓存 this.setWithLogicalExpire(key, newR, time, unit); } catch (Exception e) { throw new RuntimeException(e); }finally { // 释放锁 unlock(lockKey); } }); } // 6.4.返回过期的商铺信息 return r; } public &lt;R, ID&gt; R queryWithMutex( String keyPrefix, ID id, Class&lt;R&gt; type, Function&lt;ID, R&gt; dbFallback, Long time, TimeUnit unit) { String key = keyPrefix + id; // 1.从redis查询商铺缓存 String shopJson = stringRedisTemplate.opsForValue().get(key); // 2.判断是否存在 if (StrUtil.isNotBlank(shopJson)) { // 3.存在，直接返回 return JSONUtil.toBean(shopJson, type); } // 判断命中的是否是空值 if (shopJson != null) { // 返回一个错误信息 return null; } // 4.实现缓存重建 // 4.1.获取互斥锁 String lockKey = LOCK_SHOP_KEY + id; R r = null; try { boolean isLock = tryLock(lockKey); // 4.2.判断是否获取成功 if (!isLock) { // 4.3.获取锁失败，休眠并重试 Thread.sleep(50); return queryWithMutex(keyPrefix, id, type, dbFallback, time, unit); } // 4.4.获取锁成功，根据id查询数据库 r = dbFallback.apply(id); // 5.不存在，返回错误 if (r == null) { // 将空值写入redis stringRedisTemplate.opsForValue().set(key, \"\", CACHE_NULL_TTL, TimeUnit.MINUTES); // 返回错误信息 return null; } // 6.存在，写入redis this.set(key, r, time, unit); } catch (InterruptedException e) { throw new RuntimeException(e); }finally { // 7.释放锁 unlock(lockKey); } // 8.返回 return r; } private boolean tryLock(String key) { Boolean flag = stringRedisTemplate.opsForValue().setIfAbsent(key, \"1\", 10, TimeUnit.SECONDS); return BooleanUtil.isTrue(flag); } private void unlock(String key) { stringRedisTemplate.delete(key); } } 在ShopServiceImpl 中 @Resource private CacheClient cacheClient; @Override public Result queryById(Long id) { // 解决缓存穿透 Shop shop = cacheClient .queryWithPassThrough(CACHE_SHOP_KEY, id, Shop.class, this::getById, CACHE_SHOP_TTL, TimeUnit.MINUTES); // 互斥锁解决缓存击穿 // Shop shop = cacheClient // .queryWithMutex(CACHE_SHOP_KEY, id, Shop.class, this::getById, CACHE_SHOP_TTL, TimeUnit.MINUTES); // 逻辑过期解决缓存击穿 // Shop shop = cacheClient // .queryWithLogicalExpire(CACHE_SHOP_KEY, id, Shop.class, this::getById, 20L, TimeUnit.SECONDS); if (shop == null) { return Result.fail(\"店铺不存在！\"); } // 7.返回 return Result.ok(shop); } 3、优惠卷秒杀3.1 -全局唯一ID每个店铺都可以发布优惠券： 当用户抢购时，就会生成订单并保存到tb_voucher_order这张表中，而订单表如果使用数据库自增ID就存在一些问题： id的规律性太明显 受单表数据量的限制 场景分析：如果我们的id具有太明显的规则，用户或者说商业对手很容易猜测出来我们的一些敏感信息，比如商城在一天时间内，卖出了多少单，这明显不合适。 场景分析二：随着我们商城规模越来越大，mysql的单表的容量不宜超过500W，数据量过大之后，我们要进行拆库拆表，但拆分表了之后，他们从逻辑上讲他们是同一张表，所以他们的id是不能一样的， 于是乎我们需要保证id的唯一性。 全局ID生成器，是一种在分布式系统下用来生成全局唯一ID的工具，一般要满足下列特性： 为了增加ID的安全性，我们可以不直接使用Redis自增的数值，而是拼接一些其它信息： ID的组成部分：符号位：1bit，永远为0 时间戳：31bit，以秒为单位，可以使用69年 序列号：32bit，秒内的计数器，支持每秒产生2^32个不同ID 3.2 -Redis实现全局唯一Id@Component public class RedisIdWorker { /** * 开始时间戳 */ private static final long BEGIN_TIMESTAMP = 1640995200L; /** * 序列号的位数 */ private static final int COUNT_BITS = 32; private StringRedisTemplate stringRedisTemplate; public RedisIdWorker(StringRedisTemplate stringRedisTemplate) { this.stringRedisTemplate = stringRedisTemplate; } public long nextId(String keyPrefix) { // 1.生成时间戳 LocalDateTime now = LocalDateTime.now(); long nowSecond = now.toEpochSecond(ZoneOffset.UTC); long timestamp = nowSecond - BEGIN_TIMESTAMP; // 2.生成序列号 // 2.1.获取当前日期，精确到天 String date = now.format(DateTimeFormatter.ofPattern(\"yyyy:MM:dd\")); // 2.2.自增长 long count = stringRedisTemplate.opsForValue().increment(\"icr:\" + keyPrefix + \":\" + date); // 3.拼接并返回 return timestamp &lt;&lt; COUNT_BITS | count; } } 测试类 知识小贴士：关于countdownlatch countdownlatch名为信号枪：主要的作用是同步协调在多线程的等待于唤醒问题 我们如果没有CountDownLatch ，那么由于程序是异步的，当异步程序没有执行完时，主线程就已经执行完了，然后我们期望的是分线程全部走完之后，主线程再走，所以我们此时需要使用到CountDownLatch CountDownLatch 中有两个最重要的方法 1、countDown 2、await await 方法 是阻塞方法，我们担心分线程没有执行完时，main线程就先执行，所以使用await可以让main线程阻塞，那么什么时候main线程不再阻塞呢？当CountDownLatch 内部维护的 变量变为0时，就不再阻塞，直接放行，那么什么时候CountDownLatch 维护的变量变为0 呢，我们只需要调用一次countDown ，内部变量就减少1，我们让分线程和变量绑定， 执行完一个分线程就减少一个变量，当分线程全部走完，CountDownLatch 维护的变量就是0，此时await就不再阻塞，统计出来的时间也就是所有分线程执行完后的时间。 @Test void testIdWorker() throws InterruptedException { CountDownLatch latch = new CountDownLatch(300); Runnable task = () -&gt; { for (int i = 0; i &lt; 100; i++) { long id = redisIdWorker.nextId(\"order\"); System.out.println(\"id = \" + id); } latch.countDown(); }; long begin = System.currentTimeMillis(); for (int i = 0; i &lt; 300; i++) { es.submit(task); } latch.await(); long end = System.currentTimeMillis(); System.out.println(\"time = \" + (end - begin)); } 3.3 添加优惠卷每个店铺都可以发布优惠券，分为平价券和特价券。平价券可以任意购买，而特价券需要秒杀抢购： tb_voucher：优惠券的基本信息，优惠金额、使用规则等tb_seckill_voucher：优惠券的库存、开始抢购时间，结束抢购时间。特价优惠券才需要填写这些信息 平价卷由于优惠力度并不是很大，所以是可以任意领取 而代金券由于优惠力度大，所以像第二种卷，就得限制数量，从表结构上也能看出，特价卷除了具有优惠卷的基本信息以外，还具有库存，抢购时间，结束时间等等字段 **新增普通卷代码： **VoucherController @PostMapping public Result addVoucher(@RequestBody Voucher voucher) { voucherService.save(voucher); return Result.ok(voucher.getId()); } 新增秒杀卷代码： VoucherController @PostMapping(\"seckill\") public Result addSeckillVoucher(@RequestBody Voucher voucher) { voucherService.addSeckillVoucher(voucher); return Result.ok(voucher.getId()); } VoucherServiceImpl @Override @Transactional public void addSeckillVoucher(Voucher voucher) { // 保存优惠券 save(voucher); // 保存秒杀信息 SeckillVoucher seckillVoucher = new SeckillVoucher(); seckillVoucher.setVoucherId(voucher.getId()); seckillVoucher.setStock(voucher.getStock()); seckillVoucher.setBeginTime(voucher.getBeginTime()); seckillVoucher.setEndTime(voucher.getEndTime()); seckillVoucherService.save(seckillVoucher); // 保存秒杀库存到Redis中 stringRedisTemplate.opsForValue().set(SECKILL_STOCK_KEY + voucher.getId(), voucher.getStock().toString()); } 3.4 实现秒杀下单下单核心思路：当我们点击抢购时，会触发右侧的请求，我们只需要编写对应的controller即可 秒杀下单应该思考的内容： 下单时需要判断两点： 秒杀是否开始或结束，如果尚未开始或已经结束则无法下单 库存是否充足，不足则无法下单 下单核心逻辑分析： 当用户开始进行下单，我们应当去查询优惠卷信息，查询到优惠卷信息，判断是否满足秒杀条件 比如时间是否充足，如果时间充足，则进一步判断库存是否足够，如果两者都满足，则扣减库存，创建订单，然后返回订单id，如果有一个条件不满足则直接结束。 VoucherOrderServiceImpl @Override public Result seckillVoucher(Long voucherId) { // 1.查询优惠券 SeckillVoucher voucher = seckillVoucherService.getById(voucherId); // 2.判断秒杀是否开始 if (voucher.getBeginTime().isAfter(LocalDateTime.now())) { // 尚未开始 return Result.fail(\"秒杀尚未开始！\"); } // 3.判断秒杀是否已经结束 if (voucher.getEndTime().isBefore(LocalDateTime.now())) { // 尚未开始 return Result.fail(\"秒杀已经结束！\"); } // 4.判断库存是否充足 if (voucher.getStock() &lt; 1) { // 库存不足 return Result.fail(\"库存不足！\"); } //5，扣减库存 boolean success = seckillVoucherService.update() .setSql(\"stock= stock -1\") .eq(\"voucher_id\", voucherId).update(); if (!success) { //扣减库存 return Result.fail(\"库存不足！\"); } //6.创建订单 VoucherOrder voucherOrder = new VoucherOrder(); // 6.1.订单id long orderId = redisIdWorker.nextId(\"order\"); voucherOrder.setId(orderId); // 6.2.用户id Long userId = UserHolder.getUser().getId(); voucherOrder.setUserId(userId); // 6.3.代金券id voucherOrder.setVoucherId(voucherId); save(voucherOrder); return Result.ok(orderId); } 3.5 库存超卖问题分析有关超卖问题分析：在我们原有代码中是这么写的 if (voucher.getStock() &lt; 1) { // 库存不足 return Result.fail(\"库存不足！\"); } //5，扣减库存 boolean success = seckillVoucherService.update() .setSql(\"stock= stock -1\") .eq(\"voucher_id\", voucherId).update(); if (!success) { //扣减库存 return Result.fail(\"库存不足！\"); } 假设线程1过来查询库存，判断出来库存大于1，正准备去扣减库存，但是还没有来得及去扣减，此时线程2过来，线程2也去查询库存，发现这个数量一定也大于1，那么这两个线程都会去扣减库存，最终多个线程相当于一起去扣减库存，此时就会出现库存的超卖问题。 超卖问题是典型的多线程安全问题，针对这一问题的常见解决方案就是加锁：而对于加锁，我们通常有两种解决方案：见下图： 悲观锁： 悲观锁可以实现对于数据的串行化执行，比如syn，和lock都是悲观锁的代表，同时，悲观锁中又可以再细分为公平锁，非公平锁，可重入锁，等等 乐观锁： 乐观锁：会有一个版本号，每次操作数据会对版本号+1，再提交回数据时，会去校验是否比之前的版本大1 ，如果大1 ，则进行操作成功，这套机制的核心逻辑在于，如果在操作过程中，版本号只比原来大1 ，那么就意味着操作过程中没有人对他进行过修改，他的操作就是安全的，如果不大1，则数据被修改过，当然乐观锁还有一些变种的处理方式比如cas 乐观锁的典型代表：就是cas，利用cas进行无锁化机制加锁，var5 是操作前读取的内存值，while中的var1+var2 是预估值，如果预估值 == 内存值，则代表中间没有被人修改过，此时就将新值去替换 内存值 其中do while 是为了在操作失败时，再次进行自旋操作，即把之前的逻辑再操作一次。 int var5; do { var5 = this.getIntVolatile(var1, var2); } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; 课程中的使用方式： 课程中的使用方式是没有像cas一样带自旋的操作，也没有对version的版本号+1 ，他的操作逻辑是在操作时，对版本号进行+1 操作，然后要求version 如果是1 的情况下，才能操作，那么第一个线程在操作后，数据库中的version变成了2，但是他自己满足version=1 ，所以没有问题，此时线程2执行，线程2 最后也需要加上条件version =1 ，但是现在由于线程1已经操作过了，所以线程2，操作时就不满足version=1 的条件了，所以线程2无法执行成功 3.6 乐观锁解决超卖问题修改代码方案一、 VoucherOrderServiceImpl 在扣减库存时，改为： boolean success = seckillVoucherService.update() .setSql(\"stock= stock -1\") //set stock = stock -1 .eq(\"voucher_id\", voucherId).eq(\"stock\",voucher.getStock()).update(); //where id = ？ and stock = ? 以上逻辑的核心含义是：只要我扣减库存时的库存和之前我查询到的库存是一样的，就意味着没有人在中间修改过库存，那么此时就是安全的，但是以上这种方式通过测试发现会有很多失败的情况，失败的原因在于：在使用乐观锁过程中假设100个线程同时都拿到了100的库存，然后大家一起去进行扣减，但是100个人中只有1个人能扣减成功，其他的人在处理时，他们在扣减时，库存已经被修改过了，所以此时其他线程都会失败 修改代码方案二、 之前的方式要修改前后都保持一致，但是这样我们分析过，成功的概率太低，所以我们的乐观锁需要变一下，改成stock大于0 即可 boolean success = seckillVoucherService.update() .setSql(\"stock= stock -1\") .eq(\"voucher_id\", voucherId).update().gt(\"stock\",0); //where id = ? and stock &gt; 0 知识小扩展： 针对cas中的自旋压力过大，我们可以使用Longaddr这个类去解决 Java8 提供的一个对AtomicLong改进后的一个类，LongAdder 大量线程并发更新一个原子性的时候，天然的问题就是自旋，会导致并发性问题，当然这也比我们直接使用syn来的好 所以利用这么一个类，LongAdder来进行优化 如果获取某个值，则会对cell和base的值进行递增，最后返回一个完整的值 3.6 优惠券秒杀-一人一单需求：修改秒杀业务，要求同一个优惠券，一个用户只能下一单 现在的问题在于： 优惠卷是为了引流，但是目前的情况是，一个人可以无限制的抢这个优惠卷，所以我们应当增加一层逻辑，让一个用户只能下一个单，而不是让一个用户下多个单 具体操作逻辑如下：比如时间是否充足，如果时间充足，则进一步判断库存是否足够，然后再根据优惠卷id和用户id查询是否已经下过这个订单，如果下过这个订单，则不再下单，否则进行下单 VoucherOrderServiceImpl 初步代码：增加一人一单逻辑 @Override public Result seckillVoucher(Long voucherId) { // 1.查询优惠券 SeckillVoucher voucher = seckillVoucherService.getById(voucherId); // 2.判断秒杀是否开始 if (voucher.getBeginTime().isAfter(LocalDateTime.now())) { // 尚未开始 return Result.fail(\"秒杀尚未开始！\"); } // 3.判断秒杀是否已经结束 if (voucher.getEndTime().isBefore(LocalDateTime.now())) { // 尚未开始 return Result.fail(\"秒杀已经结束！\"); } // 4.判断库存是否充足 if (voucher.getStock() &lt; 1) { // 库存不足 return Result.fail(\"库存不足！\"); } // 5.一人一单逻辑 // 5.1.用户id Long userId = UserHolder.getUser().getId(); int count = query().eq(\"user_id\", userId).eq(\"voucher_id\", voucherId).count(); // 5.2.判断是否存在 if (count &gt; 0) { // 用户已经购买过了 return Result.fail(\"用户已经购买过一次！\"); } //6，扣减库存 boolean success = seckillVoucherService.update() .setSql(\"stock= stock -1\") .eq(\"voucher_id\", voucherId).update(); if (!success) { //扣减库存 return Result.fail(\"库存不足！\"); } //7.创建订单 VoucherOrder voucherOrder = new VoucherOrder(); // 7.1.订单id long orderId = redisIdWorker.nextId(\"order\"); voucherOrder.setId(orderId); voucherOrder.setUserId(userId); // 7.3.代金券id voucherOrder.setVoucherId(voucherId); save(voucherOrder); return Result.ok(orderId); } 存在问题：现在的问题还是和之前一样，并发过来，查询数据库，都不存在订单，所以我们还是需要加锁，但是乐观锁比较适合更新数据，而现在是插入数据，所以我们需要使用悲观锁操作 注意：在这里提到了非常多的问题，我们需要慢慢的来思考，首先我们的初始方案是封装了一个createVoucherOrder方法，同时为了确保他线程安全，在方法上添加了一把synchronized 锁 @Transactional public synchronized Result createVoucherOrder(Long voucherId) { Long userId = UserHolder.getUser().getId(); // 5.1.查询订单 int count = query().eq(\"user_id\", userId).eq(\"voucher_id\", voucherId).count(); // 5.2.判断是否存在 if (count &gt; 0) { // 用户已经购买过了 return Result.fail(\"用户已经购买过一次！\"); } // 6.扣减库存 boolean success = seckillVoucherService.update() .setSql(\"stock = stock - 1\") // set stock = stock - 1 .eq(\"voucher_id\", voucherId).gt(\"stock\", 0) // where id = ? and stock &gt; 0 .update(); if (!success) { // 扣减失败 return Result.fail(\"库存不足！\"); } // 7.创建订单 VoucherOrder voucherOrder = new VoucherOrder(); // 7.1.订单id long orderId = redisIdWorker.nextId(\"order\"); voucherOrder.setId(orderId); // 7.2.用户id voucherOrder.setUserId(userId); // 7.3.代金券id voucherOrder.setVoucherId(voucherId); save(voucherOrder); // 7.返回订单id return Result.ok(orderId); } ，但是这样添加锁，锁的粒度太粗了，在使用锁过程中，控制锁粒度 是一个非常重要的事情，因为如果锁的粒度太大，会导致每个线程进来都会锁住，所以我们需要去控制锁的粒度，以下这段代码需要修改为：intern() 这个方法是从常量池中拿到数据，如果我们直接使用userId.toString() 他拿到的对象实际上是不同的对象，new出来的对象，我们使用锁必须保证锁必须是同一把，所以我们需要使用intern()方法 @Transactional public Result createVoucherOrder(Long voucherId) { Long userId = UserHolder.getUser().getId(); synchronized(userId.toString().intern()){ // 5.1.查询订单 int count = query().eq(\"user_id\", userId).eq(\"voucher_id\", voucherId).count(); // 5.2.判断是否存在 if (count &gt; 0) { // 用户已经购买过了 return Result.fail(\"用户已经购买过一次！\"); } // 6.扣减库存 boolean success = seckillVoucherService.update() .setSql(\"stock = stock - 1\") // set stock = stock - 1 .eq(\"voucher_id\", voucherId).gt(\"stock\", 0) // where id = ? and stock &gt; 0 .update(); if (!success) { // 扣减失败 return Result.fail(\"库存不足！\"); } // 7.创建订单 VoucherOrder voucherOrder = new VoucherOrder(); // 7.1.订单id long orderId = redisIdWorker.nextId(\"order\"); voucherOrder.setId(orderId); // 7.2.用户id voucherOrder.setUserId(userId); // 7.3.代金券id voucherOrder.setVoucherId(voucherId); save(voucherOrder); // 7.返回订单id return Result.ok(orderId); } } 但是以上代码还是存在问题，问题的原因在于当前方法被spring的事务控制，如果你在方法内部加锁，可能会导致当前方法事务还没有提交，但是锁已经释放也会导致问题，所以我们选择将当前方法整体包裹起来，确保事务不会出现问题：如下： 在seckillVoucher 方法中，添加以下逻辑，这样就能保证事务的特性，同时也控制了锁的粒度 但是以上做法依然有问题，因为你调用的方法，其实是this.的方式调用的，事务想要生效，还得利用代理来生效，所以这个地方，我们需要获得原始的事务对象， 来操作事务 3.7 集群环境下的并发问题通过加锁可以解决在单机情况下的一人一单安全问题，但是在集群模式下就不行了。 1、我们将服务启动两份，端口分别为8081和8082： 2、然后修改nginx的conf目录下的nginx.conf文件，配置反向代理和负载均衡： 具体操作(略) 有关锁失效原因分析 由于现在我们部署了多个tomcat，每个tomcat都有一个属于自己的jvm，那么假设在服务器A的tomcat内部，有两个线程，这两个线程由于使用的是同一份代码，那么他们的锁对象是同一个，是可以实现互斥的，但是如果现在是服务器B的tomcat内部，又有两个线程，但是他们的锁对象写的虽然和服务器A一样，但是锁对象却不是同一个，所以线程3和线程4可以实现互斥，但是却无法和线程1和线程2实现互斥，这就是 集群环境下，syn锁失效的原因，在这种情况下，我们就需要使用分布式锁来解决这个问题。 4、分布式锁4.1 、基本原理和实现方式对比分布式锁：满足分布式系统或集群模式下多进程可见并且互斥的锁。 分布式锁的核心思想就是让大家都使用同一把锁，只要大家使用的是同一把锁，那么我们就能锁住线程，不让线程进行，让程序串行执行，这就是分布式锁的核心思路 那么分布式锁他应该满足一些什么样的条件呢？ 可见性：多个线程都能看到相同的结果，注意：这个地方说的可见性并不是并发编程中指的内存可见性，只是说多个进程之间都能感知到变化的意思 互斥：互斥是分布式锁的最基本的条件，使得程序串行执行 高可用：程序不易崩溃，时时刻刻都保证较高的可用性 高性能：由于加锁本身就让性能降低，所有对于分布式锁本身需要他就较高的加锁性能和释放锁性能 安全性：安全也是程序中必不可少的一环 常见的分布式锁有三种 Mysql：mysql本身就带有锁机制，但是由于mysql性能本身一般，所以采用分布式锁的情况下，其实使用mysql作为分布式锁比较少见 Redis：redis作为分布式锁是非常常见的一种使用方式，现在企业级开发中基本都使用redis或者zookeeper作为分布式锁，利用setnx这个方法，如果插入key成功，则表示获得到了锁，如果有人插入成功，其他人插入失败则表示无法获得到锁，利用这套逻辑来实现分布式锁 Zookeeper：zookeeper也是企业级开发中较好的一个实现分布式锁的方案，由于本套视频并不讲解zookeeper的原理和分布式锁的实现，所以不过多阐述 4.2 、Redis分布式锁的实现核心思路实现分布式锁时需要实现的两个基本方法： 获取锁： 互斥：确保只能有一个线程获取锁 非阻塞：尝试一次，成功返回true，失败返回false 释放锁： 手动释放 超时释放：获取锁时添加一个超时时间 核心思路： 我们利用redis 的setNx 方法，当有多个线程进入时，我们就利用该方法，第一个线程进入时，redis 中就有这个key 了，返回了1，如果结果是1，则表示他抢到了锁，那么他去执行业务，然后再删除锁，退出锁逻辑，没有抢到锁的哥们，等待一定时间后重试即可 4.3 实现分布式锁版本一 加锁逻辑 锁的基本接口 SimpleRedisLock 利用setnx方法进行加锁，同时增加过期时间，防止死锁，此方法可以保证加锁和增加过期时间具有原子性 private static final String KEY_PREFIX=\"lock:\" @Override public boolean tryLock(long timeoutSec) { // 获取线程标示 String threadId = Thread.currentThread().getId() // 获取锁 Boolean success = stringRedisTemplate.opsForValue() .setIfAbsent(KEY_PREFIX + name, threadId + \"\", timeoutSec, TimeUnit.SECONDS); return Boolean.TRUE.equals(success); } 释放锁逻辑 SimpleRedisLock 释放锁，防止删除别人的锁 public void unlock() { //通过del删除锁 stringRedisTemplate.delete(KEY_PREFIX + name); } 修改业务代码 @Override public Result seckillVoucher(Long voucherId) { // 1.查询优惠券 SeckillVoucher voucher = seckillVoucherService.getById(voucherId); // 2.判断秒杀是否开始 if (voucher.getBeginTime().isAfter(LocalDateTime.now())) { // 尚未开始 return Result.fail(\"秒杀尚未开始！\"); } // 3.判断秒杀是否已经结束 if (voucher.getEndTime().isBefore(LocalDateTime.now())) { // 尚未开始 return Result.fail(\"秒杀已经结束！\"); } // 4.判断库存是否充足 if (voucher.getStock() &lt; 1) { // 库存不足 return Result.fail(\"库存不足！\"); } Long userId = UserHolder.getUser().getId(); //创建锁对象(新增代码) SimpleRedisLock lock = new SimpleRedisLock(\"order:\" + userId, stringRedisTemplate); //获取锁对象 boolean isLock = lock.tryLock(1200); //加锁失败 if (!isLock) { return Result.fail(\"不允许重复下单\"); } try { //获取代理对象(事务) IVoucherOrderService proxy = (IVoucherOrderService) AopContext.currentProxy(); return proxy.createVoucherOrder(voucherId); } finally { //释放锁 lock.unlock(); } } 4.4 Redis分布式锁误删情况说明逻辑说明： 持有锁的线程在锁的内部出现了阻塞，导致他的锁自动释放，这时其他线程，线程2来尝试获得锁，就拿到了这把锁，然后线程2在持有锁执行过程中，线程1反应过来，继续执行，而线程1执行过程中，走到了删除锁逻辑，此时就会把本应该属于线程2的锁进行删除，这就是误删别人锁的情况说明 解决方案：解决方案就是在每个线程释放锁的时候，去判断一下当前这把锁是否属于自己，如果属于自己，则不进行锁的删除，假设还是上边的情况，线程1卡顿，锁自动释放，线程2进入到锁的内部执行逻辑，此时线程1反应过来，然后删除锁，但是线程1，一看当前这把锁不是属于自己，于是不进行删除锁逻辑，当线程2走到删除锁逻辑时，如果没有卡过自动释放锁的时间点，则判断当前这把锁是属于自己的，于是删除这把锁。 4.5 解决Redis分布式锁误删问题需求：修改之前的分布式锁实现，满足：在获取锁时存入线程标示（可以用UUID表示）在释放锁时先获取锁中的线程标示，判断是否与当前线程标示一致 如果一致则释放锁 如果不一致则不释放锁 核心逻辑：在存入锁时，放入自己线程的标识，在删除锁时，判断当前这把锁的标识是不是自己存入的，如果是，则进行删除，如果不是，则不进行删除。 具体代码如下：加锁 private static final String ID_PREFIX = UUID.randomUUID().toString(true) + \"-\"; @Override public boolean tryLock(long timeoutSec) { // 获取线程标示 String threadId = ID_PREFIX + Thread.currentThread().getId(); // 获取锁 Boolean success = stringRedisTemplate.opsForValue() .setIfAbsent(KEY_PREFIX + name, threadId, timeoutSec, TimeUnit.SECONDS); return Boolean.TRUE.equals(success); } 释放锁 public void unlock() { // 获取线程标示 String threadId = ID_PREFIX + Thread.currentThread().getId(); // 获取锁中的标示 String id = stringRedisTemplate.opsForValue().get(KEY_PREFIX + name); // 判断标示是否一致 if(threadId.equals(id)) { // 释放锁 stringRedisTemplate.delete(KEY_PREFIX + name); } } 有关代码实操说明： 在我们修改完此处代码后，我们重启工程，然后启动两个线程，第一个线程持有锁后，手动释放锁，第二个线程 此时进入到锁内部，再放行第一个线程，此时第一个线程由于锁的value值并非是自己，所以不能释放锁，也就无法删除别人的锁，此时第二个线程能够正确释放锁，通过这个案例初步说明我们解决了锁误删的问题。 4.6 分布式锁的原子性问题更为极端的误删逻辑说明： 线程1现在持有锁之后，在执行业务逻辑过程中，他正准备删除锁，而且已经走到了条件判断的过程中，比如他已经拿到了当前这把锁确实是属于他自己的，正准备删除锁，但是此时他的锁到期了，那么此时线程2进来，但是线程1他会接着往后执行，当他卡顿结束后，他直接就会执行删除锁那行代码，相当于条件判断并没有起到作用，这就是删锁时的原子性问题，之所以有这个问题，是因为线程1的拿锁，比锁，删锁，实际上并不是原子性的，我们要防止刚才的情况发生， 4.7 Lua脚本解决多条命令原子性问题Redis提供了Lua脚本功能，在一个脚本中编写多条Redis命令，确保多条命令执行时的原子性。Lua是一种编程语言，它的基本语法大家可以参考网站：https://www.runoob.com/lua/lua-tutorial.html，这里重点介绍Redis提供的调用函数，我们可以使用lua去操作redis，又能保证他的原子性，这样就可以实现拿锁比锁删锁是一个原子性动作了，作为Java程序员这一块并不作一个简单要求，并不需要大家过于精通，只需要知道他有什么作用即可。 这里重点介绍Redis提供的调用函数，语法如下： redis.call('命令名称', 'key', '其它参数', ...) 例如，我们要执行set name jack，则脚本是这样： # 执行 set name jack redis.call('set', 'name', 'jack') 例如，我们要先执行set name Rose，再执行get name，则脚本如下： # 先执行 set name jack redis.call('set', 'name', 'Rose') # 再执行 get name local name = redis.call('get', 'name') # 返回 return name 写好脚本以后，需要用Redis命令来调用脚本，调用脚本的常见命令如下： 例如，我们要执行 redis.call(‘set’, ‘name’, ‘jack’) 这个脚本，语法如下： 如果脚本中的key、value不想写死，可以作为参数传递。key类型参数会放入KEYS数组，其它参数会放入ARGV数组，在脚本中可以从KEYS和ARGV数组获取这些参数： 接下来我们来回一下我们释放锁的逻辑： 释放锁的业务流程是这样的 ​ 1、获取锁中的线程标示 ​ 2、判断是否与指定的标示（当前线程标示）一致 ​ 3、如果一致则释放锁（删除） ​ 4、如果不一致则什么都不做 如果用Lua脚本来表示则是这样的： 最终我们操作redis的拿锁比锁删锁的lua脚本就会变成这样 -- 这里的 KEYS[1] 就是锁的key，这里的ARGV[1] 就是当前线程标示 -- 获取锁中的标示，判断是否与当前线程标示一致 if (redis.call('GET', KEYS[1]) == ARGV[1]) then -- 一致，则删除锁 return redis.call('DEL', KEYS[1]) end -- 不一致，则直接返回 return 0 4.8 利用Java代码调用Lua脚本改造分布式锁lua脚本本身并不需要大家花费太多时间去研究，只需要知道如何调用，大致是什么意思即可，所以在笔记中并不会详细的去解释这些lua表达式的含义。 我们的RedisTemplate中，可以利用execute方法去执行lua脚本，参数对应关系就如下图股 Java代码 private static final DefaultRedisScript&lt;Long&gt; UNLOCK_SCRIPT; static { UNLOCK_SCRIPT = new DefaultRedisScript&lt;&gt;(); UNLOCK_SCRIPT.setLocation(new ClassPathResource(\"unlock.lua\")); UNLOCK_SCRIPT.setResultType(Long.class); } public void unlock() { // 调用lua脚本 stringRedisTemplate.execute( UNLOCK_SCRIPT, Collections.singletonList(KEY_PREFIX + name), ID_PREFIX + Thread.currentThread().getId()); } 经过以上代码改造后，我们就能够实现 拿锁比锁删锁的原子性动作了~ 小总结： 基于Redis的分布式锁实现思路： 利用set nx ex获取锁，并设置过期时间，保存线程标示 释放锁时先判断线程标示是否与自己一致，一致则删除锁 特性： 利用set nx满足互斥性 利用set ex保证故障时锁依然能释放，避免死锁，提高安全性 利用Redis集群保证高可用和高并发特性 笔者总结：我们一路走来，利用添加过期时间，防止死锁问题的发生，但是有了过期时间之后，可能出现误删别人锁的问题，这个问题我们开始是利用删之前 通过拿锁，比锁，删锁这个逻辑来解决的，也就是删之前判断一下当前这把锁是否是属于自己的，但是现在还有原子性问题，也就是我们没法保证拿锁比锁删锁是一个原子性的动作，最后通过lua表达式来解决这个问题 但是目前还剩下一个问题锁不住，什么是锁不住呢，你想一想，如果当过期时间到了之后，我们可以给他续期一下，比如续个30s，就好像是网吧上网， 网费到了之后，然后说，来，网管，再给我来10块的，是不是后边的问题都不会发生了，那么续期问题怎么解决呢，可以依赖于我们接下来要学习redission啦 测试逻辑： 第一个线程进来，得到了锁，手动删除锁，模拟锁超时了，其他线程会执行lua来抢锁，当第一天线程利用lua删除锁时，lua能保证他不能删除他的锁，第二个线程删除锁时，利用lua同样可以保证不会删除别人的锁，同时还能保证原子性。 5、分布式锁-redission5.1 分布式锁-redission功能介绍基于setnx实现的分布式锁存在下面的问题： 重入问题：重入问题是指 获得锁的线程可以再次进入到相同的锁的代码块中，可重入锁的意义在于防止死锁，比如HashTable这样的代码中，他的方法都是使用synchronized修饰的，假如他在一个方法内，调用另一个方法，那么此时如果是不可重入的，不就死锁了吗？所以可重入锁他的主要意义是防止死锁，我们的synchronized和Lock锁都是可重入的。 不可重试：是指目前的分布式只能尝试一次，我们认为合理的情况是：当线程在获得锁失败后，他应该能再次尝试获得锁。 超时释放：我们在加锁时增加了过期时间，这样的我们可以防止死锁，但是如果卡顿的时间超长，虽然我们采用了lua表达式防止删锁的时候，误删别人的锁，但是毕竟没有锁住，有安全隐患 主从一致性： 如果Redis提供了主从集群，当我们向集群写数据时，主机需要异步的将数据同步给从机，而万一在同步过去之前，主机宕机了，就会出现死锁问题。 那么什么是Redission呢 Redisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还提供了许多分布式服务，其中就包含了各种分布式锁的实现。 Redission提供了分布式锁的多种多样的功能 5.2 分布式锁-Redission快速入门引入依赖： &lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.13.6&lt;/version&gt; &lt;/dependency&gt; 配置Redisson客户端： @Configuration public class RedissonConfig { @Bean public RedissonClient redissonClient(){ // 配置 Config config = new Config(); config.useSingleServer().setAddress(\"redis://192.168.150.101:6379\") .setPassword(\"123321\"); // 创建RedissonClient对象 return Redisson.create(config); } } 如何使用Redission的分布式锁 @Resource private RedissionClient redissonClient; @Test void testRedisson() throws Exception{ //获取锁(可重入)，指定锁的名称 RLock lock = redissonClient.getLock(\"anyLock\"); //尝试获取锁，参数分别是：获取锁的最大等待时间(期间会重试)，锁自动释放时间，时间单位 boolean isLock = lock.tryLock(1,10,TimeUnit.SECONDS); //判断获取锁成功 if(isLock){ try{ System.out.println(\"执行业务\"); }finally{ //释放锁 lock.unlock(); } } } 在 VoucherOrderServiceImpl 注入RedissonClient @Resource private RedissonClient redissonClient; @Override public Result seckillVoucher(Long voucherId) { // 1.查询优惠券 SeckillVoucher voucher = seckillVoucherService.getById(voucherId); // 2.判断秒杀是否开始 if (voucher.getBeginTime().isAfter(LocalDateTime.now())) { // 尚未开始 return Result.fail(\"秒杀尚未开始！\"); } // 3.判断秒杀是否已经结束 if (voucher.getEndTime().isBefore(LocalDateTime.now())) { // 尚未开始 return Result.fail(\"秒杀已经结束！\"); } // 4.判断库存是否充足 if (voucher.getStock() &lt; 1) { // 库存不足 return Result.fail(\"库存不足！\"); } Long userId = UserHolder.getUser().getId(); //创建锁对象 这个代码不用了，因为我们现在要使用分布式锁 //SimpleRedisLock lock = new SimpleRedisLock(\"order:\" + userId, stringRedisTemplate); RLock lock = redissonClient.getLock(\"lock:order:\" + userId); //获取锁对象 boolean isLock = lock.tryLock(); //加锁失败 if (!isLock) { return Result.fail(\"不允许重复下单\"); } try { //获取代理对象(事务) IVoucherOrderService proxy = (IVoucherOrderService) AopContext.currentProxy(); return proxy.createVoucherOrder(voucherId); } finally { //释放锁 lock.unlock(); } } 5.3 分布式锁-redission可重入锁原理在Lock锁中，他是借助于底层的一个voaltile的一个state变量来记录重入的状态的，比如当前没有人持有这把锁，那么state=0，假如有人持有这把锁，那么state=1，如果持有这把锁的人再次持有这把锁，那么state就会+1 ，如果是对于synchronized而言，他在c语言代码中会有一个count，原理和state类似，也是重入一次就加一，释放一次就-1 ，直到减少成0 时，表示当前这把锁没有被人持有。 在redission中，我们的也支持支持可重入锁 在分布式锁中，他采用hash结构用来存储锁，其中大key表示表示这把锁是否存在，用小key表示当前这把锁被哪个线程持有，所以接下来我们一起分析一下当前的这个lua表达式 这个地方一共有3个参数 KEYS[1] ： 锁名称 ARGV[1]： 锁失效时间 ARGV[2]： id + “:” + threadId; 锁的小key exists: 判断数据是否存在 name：是lock是否存在,如果==0，就表示当前这把锁不存在 redis.call(‘hset’, KEYS[1], ARGV[2], 1);此时他就开始往redis里边去写数据 ，写成一个hash结构 Lock{ ​ id + “:” + threadId : 1 } 如果当前这把锁存在，则第一个条件不满足，再判断 redis.call(‘hexists’, KEYS[1], ARGV[2]) == 1 此时需要通过大key+小key判断当前这把锁是否是属于自己的，如果是自己的，则进行 redis.call(‘hincrby’, KEYS[1], ARGV[2], 1) 将当前这个锁的value进行+1 ，redis.call(‘pexpire’, KEYS[1], ARGV[1]); 然后再对其设置过期时间，如果以上两个条件都不满足，则表示当前这把锁抢锁失败，最后返回pttl，即为当前这把锁的失效时间 如果小伙帮们看了前边的源码， 你会发现他会去判断当前这个方法的返回值是否为null，如果是null，则对应则前两个if对应的条件，退出抢锁逻辑，如果返回的不是null，即走了第三个分支，在源码处会进行while(true)的自旋抢锁。 \"if (redis.call('exists', KEYS[1]) == 0) then \" + \"redis.call('hset', KEYS[1], ARGV[2], 1); \" + \"redis.call('pexpire', KEYS[1], ARGV[1]); \" + \"return nil; \" + \"end; \" + \"if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then \" + \"redis.call('hincrby', KEYS[1], ARGV[2], 1); \" + \"redis.call('pexpire', KEYS[1], ARGV[1]); \" + \"return nil; \" + \"end; \" + \"return redis.call('pttl', KEYS[1]);\" 5.4 分布式锁-redission锁重试和WatchDog机制说，明：由于课程中已经说明了有关tryLock的源码解析以及其看门狗原理，所以笔者在这里给大家分析lock()方法的源码解析，希望大家在学习过程中，能够掌握更多的知识 抢锁过程中，获得当前线程，通过tryAcquire进行抢锁，该抢锁逻辑和之前逻辑相同 1、先判断当前这把锁是否存在，如果不存在，插入一把锁，返回null 2、判断当前这把锁是否是属于当前线程，如果是，则返回null 所以如果返回是null，则代表着当前这哥们已经抢锁完毕，或者可重入完毕，但是如果以上两个条件都不满足，则进入到第三个条件，返回的是锁的失效时间，同学们可以自行往下翻一点点，你能发现有个while( true) 再次进行tryAcquire进行抢锁 long threadId = Thread.currentThread().getId(); Long ttl = tryAcquire(-1, leaseTime, unit, threadId); // lock acquired if (ttl == null) { return; } 接下来会有一个条件分支，因为lock方法有重载方法，一个是带参数，一个是不带参数，如果带带参数传入的值是-1，如果传入参数，则leaseTime是他本身，所以如果传入了参数，此时leaseTime != -1 则会进去抢锁，抢锁的逻辑就是之前说的那三个逻辑 if (leaseTime != -1) { return tryLockInnerAsync(waitTime, leaseTime, unit, threadId, RedisCommands.EVAL_LONG); } 如果是没有传入时间，则此时也会进行抢锁， 而且抢锁时间是默认看门狗时间 commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout() ttlRemainingFuture.onComplete((ttlRemaining, e) 这句话相当于对以上抢锁进行了监听，也就是说当上边抢锁完毕后，此方法会被调用，具体调用的逻辑就是去后台开启一个线程，进行续约逻辑，也就是看门狗线程 RFuture&lt;Long&gt; ttlRemainingFuture = tryLockInnerAsync(waitTime, commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(), TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG); ttlRemainingFuture.onComplete((ttlRemaining, e) -&gt; { if (e != null) { return; } // lock acquired if (ttlRemaining == null) { scheduleExpirationRenewal(threadId); } }); return ttlRemainingFuture; 此逻辑就是续约逻辑，注意看commandExecutor.getConnectionManager().newTimeout（） 此方法 Method( new TimerTask() {},参数2 ，参数3 ) 指的是：通过参数2，参数3 去描述什么时候去做参数1的事情，现在的情况是：10s之后去做参数一的事情 因为锁的失效时间是30s，当10s之后，此时这个timeTask 就触发了，他就去进行续约，把当前这把锁续约成30s，如果操作成功，那么此时就会递归调用自己，再重新设置一个timeTask()，于是再过10s后又再设置一个timerTask，完成不停的续约 那么大家可以想一想，假设我们的线程出现了宕机他还会续约吗？当然不会，因为没有人再去调用renewExpiration这个方法，所以等到时间之后自然就释放了。 private void renewExpiration() { ExpirationEntry ee = EXPIRATION_RENEWAL_MAP.get(getEntryName()); if (ee == null) { return; } Timeout task = commandExecutor.getConnectionManager().newTimeout(new TimerTask() { @Override public void run(Timeout timeout) throws Exception { ExpirationEntry ent = EXPIRATION_RENEWAL_MAP.get(getEntryName()); if (ent == null) { return; } Long threadId = ent.getFirstThreadId(); if (threadId == null) { return; } RFuture&lt;Boolean&gt; future = renewExpirationAsync(threadId); future.onComplete((res, e) -&gt; { if (e != null) { log.error(\"Can't update lock \" + getName() + \" expiration\", e); return; } if (res) { // reschedule itself renewExpiration(); } }); } }, internalLockLeaseTime / 3, TimeUnit.MILLISECONDS); ee.setTimeout(task); } 5.5 分布式锁-redission锁的MutiLock原理为了提高redis的可用性，我们会搭建集群或者主从，现在以主从为例 此时我们去写命令，写在主机上， 主机会将数据同步给从机，但是假设在主机还没有来得及把数据写入到从机去的时候，此时主机宕机，哨兵会发现主机宕机，并且选举一个slave变成master，而此时新的master中实际上并没有锁信息，此时锁信息就已经丢掉了。 为了解决这个问题，redission提出来了MutiLock锁，使用这把锁咱们就不使用主从了，每个节点的地位都是一样的， 这把锁加锁的逻辑需要写入到每一个主丛节点上，只有所有的服务器都写入成功，此时才是加锁成功，假设现在某个节点挂了，那么他去获得锁的时候，只要有一个节点拿不到，都不能算是加锁成功，就保证了加锁的可靠性。 那么MutiLock 加锁原理是什么呢？笔者画了一幅图来说明 当我们去设置了多个锁时，redission会将多个锁添加到一个集合中，然后用while循环去不停去尝试拿锁，但是会有一个总共的加锁时间，这个时间是用需要加锁的个数 * 1500ms ，假设有3个锁，那么时间就是4500ms，假设在这4500ms内，所有的锁都加锁成功， 那么此时才算是加锁成功，如果在4500ms有线程加锁失败，则会再次去进行重试. 6、秒杀优化6.1 秒杀优化-异步秒杀思路我们来回顾一下下单流程 当用户发起请求，此时会请求nginx，nginx会访问到tomcat，而tomcat中的程序，会进行串行操作，分成如下几个步骤 1、查询优惠卷 2、判断秒杀库存是否足够 3、查询订单 4、校验是否是一人一单 5、扣减库存 6、创建订单 在这六步操作中，又有很多操作是要去操作数据库的，而且还是一个线程串行执行， 这样就会导致我们的程序执行的很慢，所以我们需要异步程序执行，那么如何加速呢？ 在这里笔者想给大家分享一下课程内没有的思路，看看有没有小伙伴这么想，比如，我们可以不可以使用异步编排来做，或者说我开启N多线程，N多个线程，一个线程执行查询优惠卷，一个执行判断扣减库存，一个去创建订单等等，然后再统一做返回，这种做法和课程中有哪种好呢？答案是课程中的好，因为如果你采用我刚说的方式，如果访问的人很多，那么线程池中的线程可能一下子就被消耗完了，而且你使用上述方案，最大的特点在于，你觉得时效性会非常重要，但是你想想是吗？并不是，比如我只要确定他能做这件事，然后我后边慢慢做就可以了，我并不需要他一口气做完这件事，所以我们应当采用的是课程中，类似消息队列的方式来完成我们的需求，而不是使用线程池或者是异步编排的方式来完成这个需求 优化方案：我们将耗时比较短的逻辑判断放入到redis中，比如是否库存足够，比如是否一人一单，这样的操作，只要这种逻辑可以完成，就意味着我们是一定可以下单完成的，我们只需要进行快速的逻辑判断，根本就不用等下单逻辑走完，我们直接给用户返回成功， 再在后台开一个线程，后台线程慢慢的去执行queue里边的消息，这样程序不就超级快了吗？而且也不用担心线程池消耗殆尽的问题，因为这里我们的程序中并没有手动使用任何线程池，当然这里边有两个难点 第一个难点是我们怎么在redis中去快速校验一人一单，还有库存判断 第二个难点是由于我们校验和tomct下单是两个线程，那么我们如何知道到底哪个单他最后是否成功，或者是下单完成，为了完成这件事我们在redis操作完之后，我们会将一些信息返回给前端，同时也会把这些信息丢到异步queue中去，后续操作中，可以通过这个id来查询我们tomcat中的下单逻辑是否完成了。 我们现在来看看整体思路：当用户下单之后，判断库存是否充足只需要导redis中去根据key找对应的value是否大于0即可，如果不充足，则直接结束，如果充足，继续在redis中判断用户是否可以下单，如果set集合中没有这条数据，说明他可以下单，如果set集合中没有这条记录，则将userId和优惠卷存入到redis中，并且返回0，整个过程需要保证是原子性的，我们可以使用lua来操作 当以上判断逻辑走完之后，我们可以判断当前redis中返回的结果是否是0 ，如果是0，则表示可以下单，则将之前说的信息存入到到queue中去，然后返回，然后再来个线程异步的下单，前端可以通过返回的订单id来判断是否下单成功。 6.2 秒杀优化-Redis完成秒杀资格判断需求： 新增秒杀优惠券的同时，将优惠券信息保存到Redis中 基于Lua脚本，判断秒杀库存、一人一单，决定用户是否抢购成功 如果抢购成功，将优惠券id和用户id封装后存入阻塞队列 开启线程任务，不断从阻塞队列中获取信息，实现异步下单功能 VoucherServiceImpl @Override @Transactional public void addSeckillVoucher(Voucher voucher) { // 保存优惠券 save(voucher); // 保存秒杀信息 SeckillVoucher seckillVoucher = new SeckillVoucher(); seckillVoucher.setVoucherId(voucher.getId()); seckillVoucher.setStock(voucher.getStock()); seckillVoucher.setBeginTime(voucher.getBeginTime()); seckillVoucher.setEndTime(voucher.getEndTime()); seckillVoucherService.save(seckillVoucher); // 保存秒杀库存到Redis中 //SECKILL_STOCK_KEY 这个变量定义在RedisConstans中 //private static final String SECKILL_STOCK_KEY =\"seckill:stock:\" stringRedisTemplate.opsForValue().set(SECKILL_STOCK_KEY + voucher.getId(), voucher.getStock().toString()); } 完整lua表达式 -- 1.参数列表 -- 1.1.优惠券id local voucherId = ARGV[1] -- 1.2.用户id local userId = ARGV[2] -- 1.3.订单id local orderId = ARGV[3] -- 2.数据key -- 2.1.库存key local stockKey = 'seckill:stock:' .. voucherId -- 2.2.订单key local orderKey = 'seckill:order:' .. voucherId -- 3.脚本业务 -- 3.1.判断库存是否充足 get stockKey if(tonumber(redis.call('get', stockKey)) &lt;= 0) then -- 3.2.库存不足，返回1 return 1 end -- 3.2.判断用户是否下单 SISMEMBER orderKey userId if(redis.call('sismember', orderKey, userId) == 1) then -- 3.3.存在，说明是重复下单，返回2 return 2 end -- 3.4.扣库存 incrby stockKey -1 redis.call('incrby', stockKey, -1) -- 3.5.下单（保存用户）sadd orderKey userId redis.call('sadd', orderKey, userId) -- 3.6.发送消息到队列中， XADD stream.orders * k1 v1 k2 v2 ... redis.call('xadd', 'stream.orders', '*', 'userId', userId, 'voucherId', voucherId, 'id', orderId) return 0 当以上lua表达式执行完毕后，剩下的就是根据步骤3,4来执行我们接下来的任务了 VoucherOrderServiceImpl @Override public Result seckillVoucher(Long voucherId) { //获取用户 Long userId = UserHolder.getUser().getId(); long orderId = redisIdWorker.nextId(\"order\"); // 1.执行lua脚本 Long result = stringRedisTemplate.execute( SECKILL_SCRIPT, Collections.emptyList(), voucherId.toString(), userId.toString(), String.valueOf(orderId) ); int r = result.intValue(); // 2.判断结果是否为0 if (r != 0) { // 2.1.不为0 ，代表没有购买资格 return Result.fail(r == 1 ? \"库存不足\" : \"不能重复下单\"); } //TODO 保存阻塞队列 // 3.返回订单id return Result.ok(orderId); } 6.3 秒杀优化-基于阻塞队列实现秒杀优化VoucherOrderServiceImpl 修改下单动作，现在我们去下单时，是通过lua表达式去原子执行判断逻辑，如果判断我出来不为0 ，则要么是库存不足，要么是重复下单，返回错误信息，如果是0，则把下单的逻辑保存到队列中去，然后异步执行 //异步处理线程池 private static final ExecutorService SECKILL_ORDER_EXECUTOR = Executors.newSingleThreadExecutor(); //在类初始化之后执行，因为当这个类初始化好了之后，随时都是有可能要执行的 @PostConstruct private void init() { SECKILL_ORDER_EXECUTOR.submit(new VoucherOrderHandler()); } // 用于线程池处理的任务 // 当初始化完毕后，就会去从对列中去拿信息 private class VoucherOrderHandler implements Runnable{ @Override public void run() { while (true){ try { // 1.获取队列中的订单信息 VoucherOrder voucherOrder = orderTasks.take(); // 2.创建订单 handleVoucherOrder(voucherOrder); } catch (Exception e) { log.error(\"处理订单异常\", e); } } } private void handleVoucherOrder(VoucherOrder voucherOrder) { //1.获取用户 Long userId = voucherOrder.getUserId(); // 2.创建锁对象 RLock redisLock = redissonClient.getLock(\"lock:order:\" + userId); // 3.尝试获取锁 boolean isLock = redisLock.lock(); // 4.判断是否获得锁成功 if (!isLock) { // 获取锁失败，直接返回失败或者重试 log.error(\"不允许重复下单！\"); return; } try { //注意：由于是spring的事务是放在threadLocal中，此时的是多线程，事务会失效 proxy.createVoucherOrder(voucherOrder); } finally { // 释放锁 redisLock.unlock(); } } //a private BlockingQueue&lt;VoucherOrder&gt; orderTasks =new ArrayBlockingQueue&lt;&gt;(1024 * 1024); @Override public Result seckillVoucher(Long voucherId) { Long userId = UserHolder.getUser().getId(); long orderId = redisIdWorker.nextId(\"order\"); // 1.执行lua脚本 Long result = stringRedisTemplate.execute( SECKILL_SCRIPT, Collections.emptyList(), voucherId.toString(), userId.toString(), String.valueOf(orderId) ); int r = result.intValue(); // 2.判断结果是否为0 if (r != 0) { // 2.1.不为0 ，代表没有购买资格 return Result.fail(r == 1 ? \"库存不足\" : \"不能重复下单\"); } VoucherOrder voucherOrder = new VoucherOrder(); // 2.3.订单id long orderId = redisIdWorker.nextId(\"order\"); voucherOrder.setId(orderId); // 2.4.用户id voucherOrder.setUserId(userId); // 2.5.代金券id voucherOrder.setVoucherId(voucherId); // 2.6.放入阻塞队列 orderTasks.add(voucherOrder); //3.获取代理对象 proxy = (IVoucherOrderService)AopContext.currentProxy(); //4.返回订单id return Result.ok(orderId); } @Transactional public void createVoucherOrder(VoucherOrder voucherOrder) { Long userId = voucherOrder.getUserId(); // 5.1.查询订单 int count = query().eq(\"user_id\", userId).eq(\"voucher_id\", voucherOrder.getVoucherId()).count(); // 5.2.判断是否存在 if (count &gt; 0) { // 用户已经购买过了 log.error(\"用户已经购买过了\"); return ; } // 6.扣减库存 boolean success = seckillVoucherService.update() .setSql(\"stock = stock - 1\") // set stock = stock - 1 .eq(\"voucher_id\", voucherOrder.getVoucherId()).gt(\"stock\", 0) // where id = ? and stock &gt; 0 .update(); if (!success) { // 扣减失败 log.error(\"库存不足\"); return ; } save(voucherOrder); } 小总结： 秒杀业务的优化思路是什么？ 先利用Redis完成库存余量、一人一单判断，完成抢单业务 再将下单业务放入阻塞队列，利用独立线程异步下单 基于阻塞队列的异步秒杀存在哪些问题？ 内存限制问题 数据安全问题 7、Redis消息队列7.1 Redis消息队列-认识消息队列什么是消息队列：字面意思就是存放消息的队列。最简单的消息队列模型包括3个角色： 消息队列：存储和管理消息，也被称为消息代理（Message Broker） 生产者：发送消息到消息队列 消费者：从消息队列获取消息并处理消息 使用队列的好处在于 解耦：所谓解耦，举一个生活中的例子就是：快递员(生产者)把快递放到快递柜里边(Message Queue)去，我们(消费者)从快递柜里边去拿东西，这就是一个异步，如果耦合，那么这个快递员相当于直接把快递交给你，这事固然好，但是万一你不在家，那么快递员就会一直等你，这就浪费了快递员的时间，所以这种思想在我们日常开发中，是非常有必要的。 这种场景在我们秒杀中就变成了：我们下单之后，利用redis去进行校验下单条件，再通过队列把消息发送出去，然后再启动一个线程去消费这个消息，完成解耦，同时也加快我们的响应速度。 这里我们可以使用一些现成的mq，比如kafka，rabbitmq等等，但是呢，如果没有安装mq，我们也可以直接使用redis提供的mq方案，降低我们的部署和学习成本。 7.2 Redis消息队列-基于List实现消息队列基于List结构模拟消息队列 消息队列（Message Queue），字面意思就是存放消息的队列。而Redis的list数据结构是一个双向链表，很容易模拟出队列效果。 队列是入口和出口不在一边，因此我们可以利用：LPUSH 结合 RPOP、或者 RPUSH 结合 LPOP来实现。不过要注意的是，当队列中没有消息时RPOP或LPOP操作会返回null，并不像JVM的阻塞队列那样会阻塞并等待消息。因此这里应该使用BRPOP或者BLPOP来实现阻塞效果。 基于List的消息队列有哪些优缺点？优点： 利用Redis存储，不受限于JVM内存上限 基于Redis的持久化机制，数据安全性有保证 可以满足消息有序性 缺点： 无法避免消息丢失 只支持单消费者 7.3 Redis消息队列-基于PubSub的消息队列PubSub（发布订阅）是Redis2.0版本引入的消息传递模型。顾名思义，消费者可以订阅一个或多个channel，生产者向对应channel发送消息后，所有订阅者都能收到相关消息。 SUBSCRIBE channel [channel] ：订阅一个或多个频道 PUBLISH channel msg ：向一个频道发送消息 PSUBSCRIBE pattern[pattern] ：订阅与pattern格式匹配的所有频道 基于PubSub的消息队列有哪些优缺点？优点： 采用发布订阅模型，支持多生产、多消费 缺点： 不支持数据持久化 无法避免消息丢失 消息堆积有上限，超出时数据丢失 7.4 Redis消息队列-基于Stream的消息队列Stream 是 Redis 5.0 引入的一种新数据类型，可以实现一个功能非常完善的消息队列。 发送消息的命令： 例如： 读取消息的方式之一：XREAD 例如，使用XREAD读取第一个消息： XREAD阻塞方式，读取最新的消息： 在业务开发中，我们可以循环的调用XREAD阻塞方式来查询最新消息，从而实现持续监听队列的效果，伪代码如下 注意：当我们指定起始ID为$时，代表读取最新的消息，如果我们处理一条消息的过程中，又有超过1条以上的消息到达队列，则下次获取时也只能获取到最新的一条，会出现漏读消息的问题 STREAM类型消息队列的XREAD命令特点： 消息可回溯 一个消息可以被多个消费者读取 可以阻塞读取 有消息漏读的风险 7.5 Redis消息队列-基于Stream的消息队列-消费者组消费者组（Consumer Group）：将多个消费者划分到一个组中，监听同一个队列。具备下列特点： 创建消费者组：key：队列名称groupName：消费者组名称ID：起始ID标示，$代表队列中最后一个消息，0则代表队列中第一个消息MKSTREAM：队列不存在时自动创建队列其它常见命令： 删除指定的消费者组 XGROUP DESTORY key groupName 给指定的消费者组添加消费者 XGROUP CREATECONSUMER key groupname consumername 删除消费者组中的指定消费者 XGROUP DELCONSUMER key groupname consumername 从消费者组读取消息： XREADGROUP GROUP group consumer [COUNT count] [BLOCK milliseconds] [NOACK] STREAMS key [key ...] ID [ID ...] group：消费组名称 consumer：消费者名称，如果消费者不存在，会自动创建一个消费者 count：本次查询的最大数量 BLOCK milliseconds：当没有消息时最长等待时间 NOACK：无需手动ACK，获取到消息后自动确认 STREAMS key：指定队列名称 ID：获取消息的起始ID： “&gt;”：从下一个未消费的消息开始其它：根据指定id从pending-list中获取已消费但未确认的消息，例如0，是从pending-list中的第一个消息开始 消费者监听消息的基本思路： STREAM类型消息队列的XREADGROUP命令特点： 消息可回溯 可以多消费者争抢消息，加快消费速度 可以阻塞读取 没有消息漏读的风险 有消息确认机制，保证消息至少被消费一次 最后我们来个小对比 7.6 基于Redis的Stream结构作为消息队列，实现异步秒杀下单需求： 创建一个Stream类型的消息队列，名为stream.orders 修改之前的秒杀下单Lua脚本，在认定有抢购资格后，直接向stream.orders中添加消息，内容包含voucherId、userId、orderId 项目启动时，开启一个线程任务，尝试获取stream.orders中的消息，完成下单\\ 修改lua表达式,新增3.6 VoucherOrderServiceImpl private class VoucherOrderHandler implements Runnable { @Override public void run() { while (true) { try { // 1.获取消息队列中的订单信息 XREADGROUP GROUP g1 c1 COUNT 1 BLOCK 2000 STREAMS s1 &gt; List&lt;MapRecord&lt;String, Object, Object&gt;&gt; list = stringRedisTemplate.opsForStream().read( Consumer.from(\"g1\", \"c1\"), StreamReadOptions.empty().count(1).block(Duration.ofSeconds(2)), StreamOffset.create(\"stream.orders\", ReadOffset.lastConsumed()) ); // 2.判断订单信息是否为空 if (list == null || list.isEmpty()) { // 如果为null，说明没有消息，继续下一次循环 continue; } // 解析数据 MapRecord&lt;String, Object, Object&gt; record = list.get(0); Map&lt;Object, Object&gt; value = record.getValue(); VoucherOrder voucherOrder = BeanUtil.fillBeanWithMap(value, new VoucherOrder(), true); // 3.创建订单 createVoucherOrder(voucherOrder); // 4.确认消息 XACK stringRedisTemplate.opsForStream().acknowledge(\"s1\", \"g1\", record.getId()); } catch (Exception e) { log.error(\"处理订单异常\", e); //处理异常消息 handlePendingList(); } } } private void handlePendingList() { while (true) { try { // 1.获取pending-list中的订单信息 XREADGROUP GROUP g1 c1 COUNT 1 BLOCK 2000 STREAMS s1 0 List&lt;MapRecord&lt;String, Object, Object&gt;&gt; list = stringRedisTemplate.opsForStream().read( Consumer.from(\"g1\", \"c1\"), StreamReadOptions.empty().count(1), StreamOffset.create(\"stream.orders\", ReadOffset.from(\"0\")) ); // 2.判断订单信息是否为空 if (list == null || list.isEmpty()) { // 如果为null，说明没有异常消息，结束循环 break; } // 解析数据 MapRecord&lt;String, Object, Object&gt; record = list.get(0); Map&lt;Object, Object&gt; value = record.getValue(); VoucherOrder voucherOrder = BeanUtil.fillBeanWithMap(value, new VoucherOrder(), true); // 3.创建订单 createVoucherOrder(voucherOrder); // 4.确认消息 XACK stringRedisTemplate.opsForStream().acknowledge(\"s1\", \"g1\", record.getId()); } catch (Exception e) { log.error(\"处理pendding订单异常\", e); try{ Thread.sleep(20); }catch(Exception e){ e.printStackTrace(); } } } } }","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://gitee.com/yunyd/tags/Redis/"}],"author":"llllz."},{"title":"JUC-读写锁","slug":"JUC-读写锁 -13","date":"2023-08-21T01:22:42.000Z","updated":"2023-08-25T00:20:02.163Z","comments":true,"path":"posts/9840d0be.html","link":"","permalink":"https://gitee.com/yunyd/posts/9840d0be.html","excerpt":"","text":"ReentrantLock、ReentrantReadWriteLock、StampedLock讲解1.1 关于锁的面试题 你知道Java里面有那些锁 你说说你用过的锁，锁饥饿问题是什么？ 有没有比读写锁更快的锁 StampedLock知道吗？（邮戳锁/票据锁） ReentrantReadWriteLock有锁降级机制，你知道吗？ 1.2 简单聊聊ReentrantReadWriteLock1.2.1 是什么？ 读写锁说明 一个资源能够被多个读线程访问，或者被一个写线程访问，但是不能同时存在读写线程 再说说演变 无锁无序-&gt;加锁-&gt;读写锁-&gt;邮戳锁 读写锁意义和特点 它只允许读读共存，而读写和写写依然是互斥的，大多实际场景是”读/读“线程间不存在互斥关系，只有”读/写“线程或者”写/写“线程间的操作是需要互斥的，因此引入了 ReentrantReadWriteLock 一个ReentrantReadWriteLock同时只能存在一个写锁但是可以存在多个读锁，但是不能同时存在写锁和读锁，也即资源可以被多个读操作访问，或一个写操作访问，但两者不能同时进行。 只有在读多写少情景之下，读写锁才具有较高的性能体现。 1.2.2 特点 可重入 读写兼顾 结论：一体两面，读写互斥，读读共享，读没有完成的时候其他线程写锁无法获得 锁降级： 将写锁降级为读锁——&gt;遵循获取写锁、获取读锁再释放写锁的次序，写锁能够降级为读锁 如果一个线程持有了写锁，在没有释放写锁的情况下，它还可以继续获得读锁。这就是写锁的降级，降级成为了读锁。 如果释放了写锁，那么就完全转换为读锁 如果有线程在读，那么写线程是无法获取写锁的，是悲观锁的策略 1.3 面试题：有没有比读写锁更快的锁？1.4 邮戳锁StampedLock1.4.1 是什么？StampedLock是JDK1.8中新增的一个读写锁，也是对JDK1.5中的读写锁ReentrantReadWriteLock的优化 stamp 代表了锁的状态。当stamp返回零时，表示线程获取锁失败，并且当释放锁或者转换锁的时候，都要传入最初获取的stamp值。 1.4.2 它是由饥饿问题引出 锁饥饿问题： ReentrantReadWriteLock实现了读写分离，但是一旦读操作比较多的时候，想要获取写锁就变得比较困难了，因此当前有可能会一直存在读锁，而无法获得写锁。 如何解决锁饥饿问题： 使用”公平“策略可以一定程度上缓解这个问题 使用”公平“策略是以牺牲系统吞吐量为代价的 StampedLock类的乐观读锁方式—&gt;采取乐观获取锁，其他线程尝试获取写锁时不会被阻塞，在获取乐观读锁后，还需要对结果进行校验 1.4.3 StampedLock的特点 所有获取锁的方法，都返回一个邮戳，stamp为零表示失败，其余都表示成功 所有释放锁的方法，都需要一个邮戳，这个stamp必须是和成功获取锁时得到的stamp一致 StampedLock是不可重入的，危险（如果一个线程已经持有了写锁，在去获取写锁的话会造成死锁） StampedLock有三种访问模式： Reading（读模式悲观）：功能和ReentrantReadWriteLock的读锁类似 Writing（写模式）：功能和ReentrantReadWriteLock的写锁类似 Optimistic reading（乐观读模式）：无锁机制，类似与数据库中的乐观锁，支持读写并发，很乐观认为读时没人修改，假如被修改在实现升级为悲观读模式 一句话：读的过程中也允许写锁介入 1.4.5 乐观读模式Code演示 传统的读写锁模式—-读的时候写锁不能获取 传统的读写锁模式案例演示： public class StampedLockDemo { static int number = 37; static StampedLock stampedLock = new StampedLock(); public void write() { long stamp = stampedLock.writeLock(); System.out.println(Thread.currentThread().getName() + \"\\t\" + \"写线程准备修改\"); try { number = number + 13; } finally { stampedLock.unlockWrite(stamp); } System.out.println(Thread.currentThread().getName() + \"\\t\" + \"写线程结束修改\"); } public void read() { long stamp = stampedLock.readLock(); System.out.println(Thread.currentThread().getName() + \"\\t\" + \" come in readLock codeBlock\"); for (int i = 0; i &lt; 4; i++) { try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + \"\\t\" + \" 正在读取中\"); } try { int result = number; System.out.println(Thread.currentThread().getName() + \"\\t\" + \"获得成员变量值result: \" + result); System.out.println(\"写线程没有修改成功，读锁时候写锁无法介入，传统的读写互斥\"); } finally { stampedLock.unlockRead(stamp); } } public static void main(String[] args) { StampedLockDemo resource = new StampedLockDemo(); new Thread(() -&gt; { resource.read(); }, \"readThread\").start(); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } new Thread(() -&gt; { System.out.println(Thread.currentThread().getName()+\"\\t\"+\" come in\"); resource.write(); }, \"writeThread\").start(); } } /** * readThread come in readLock codeBlock * readThread 正在读取中 * writeThread come in * readThread 正在读取中 * readThread 正在读取中 * readThread 正在读取中 * readThread 获得成员变量值result: 37 * 写线程没有修改成功，读锁时候写锁无法介入，传统的读写互斥 * writeThread 写线程准备修改 * writeThread 写线程结束修改 */ 乐观读模式—-读的过程中也允许写锁介入 乐观读模式途中有写操作介入案例演示： public class StampedLockDemo { static int number = 37; static StampedLock stampedLock = new StampedLock(); public void write() { long stamp = stampedLock.writeLock(); System.out.println(Thread.currentThread().getName() + \"\\t\" + \"写线程准备修改\"); try { number = number + 13; } finally { stampedLock.unlockWrite(stamp); } System.out.println(Thread.currentThread().getName() + \"\\t\" + \"写线程结束修改\"); } public void read() { long stamp = stampedLock.tryOptimisticRead(); int result = number; System.out.println(\"4秒前 stampedLock.validate方法值（true 无修改 false有修改）\" + \"\\t\" + stampedLock.validate(stamp)); for (int i = 0; i &lt; 4; i++) { try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + \"\\t\" + \" 正在读取....\" + i + \"秒后\" + \"stampedLock.validate方法值（true 无修改 false有修改）\" + \"\\t\" + stampedLock.validate(stamp)); } if (!stampedLock.validate(stamp)) { System.out.println(\"有人修改----------有写操作\"); stamp = stampedLock.readLock(); try { System.out.println(\"从乐观读升级为悲观读\"); result = number; System.out.println(\"重新悲观读后result：\" + result); } finally { stampedLock.unlockRead(stamp); } } System.out.println(Thread.currentThread().getName() + \"\\t\" + \"finally value: \" + result); } public static void main(String[] args) { StampedLockDemo resource = new StampedLockDemo(); new Thread(() -&gt; { resource.read(); }, \"readThread\").start(); try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } new Thread(() -&gt; { System.out.println(Thread.currentThread().getName() + \"\\t\" + \" come in\"); resource.write(); }, \"writeThread\").start(); } } /** * 4秒前 stampedLock.validate方法值（true 无修改 false有修改） true * readThread 正在读取....0秒后stampedLock.validate方法值（true 无修改 false有修改） true * readThread 正在读取....1秒后stampedLock.validate方法值（true 无修改 false有修改） true * writeThread come in * writeThread 写线程准备修改 * writeThread 写线程结束修改 * readThread 正在读取....2秒后stampedLock.validate方法值（true 无修改 false有修改） false * readThread 正在读取....3秒后stampedLock.validate方法值（true 无修改 false有修改） false * 有人修改----------有写操作 * 从乐观读升级为悲观读 * 重新悲观读后result：50 * readThread finally value: 50 */ 1.4.6 StampedLock的缺点 StampedLock不支持重入，没有Re开头 StampedLock的悲观读锁和写锁都不支持条件变量，这个也需要主要 使用StampedLock一定不要调用中断操作，即不要调用inte","categories":[],"tags":[{"name":"JUC并发编程","slug":"JUC并发编程","permalink":"https://gitee.com/yunyd/tags/JUC%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"author":"llllz."},{"title":"Redis复习 -Ⅰ","slug":"Redis复习  -1","date":"2023-08-19T11:10:20.000Z","updated":"2023-08-25T00:21:50.293Z","comments":true,"path":"posts/fe453f25.html","link":"","permalink":"https://gitee.com/yunyd/posts/fe453f25.html","excerpt":"","text":"1.RedisRedis是一种键值型的NoSql数据库，这里有两个关键字： 键值型 NoSql 其中键值型，是指Redis中存储的数据都是以key、value对的形式存储，而value的形式多种多样，可以是字符串、数值、甚至json： 而NoSql则是相对于传统关系型数据库而言，有很大差异的一种数据库。 1.1.认识NoSQLNoSql可以翻译做Not Only Sql（不仅仅是SQL），或者是No Sql（非Sql的）数据库。是相对于传统关系型数据库而言，有很大差异的一种特殊的数据库，因此也称之为非关系型数据库。 1.1.1.结构化与非结构化传统关系型数据库是结构化数据，每一张表都有严格的约束信息：字段名、字段数据类型、字段约束等等信息，插入的数据必须遵守这些约束： 而NoSql则对数据库格式没有严格约束，往往形式松散，自由。 可以是键值型： 也可以是文档型： 甚至可以是图格式： 1.1.2.关联和非关联传统数据库的表与表之间往往存在关联，例如外键： 而非关系型数据库不存在关联关系，要维护关系要么靠代码中的业务逻辑，要么靠数据之间的耦合： { id: 1, name: \"张三\", orders: [ { id: 1, item: { id: 10, title: \"荣耀6\", price: 4999 } }, { id: 2, item: { id: 20, title: \"小米11\", price: 3999 } } ] } 此处要维护“张三”的订单与商品“荣耀”和“小米11”的关系，不得不冗余的将这两个商品保存在张三的订单文档中，不够优雅。还是建议用业务来维护关联关系。 1.1.3.查询方式传统关系型数据库会基于Sql语句做查询，语法有统一标准； 而不同的非关系数据库查询语法差异极大，五花八门各种各样。 1.1.4.事务传统关系型数据库能满足事务ACID的原则。 而非关系型数据库往往不支持事务，或者不能严格保证ACID的特性，只能实现基本的一致性。 1.1.5.总结除了上述四点以外，在存储方式、扩展性、查询性能上关系型与非关系型也都有着显著差异，总结如下： 存储方式 关系型数据库基于磁盘进行存储，会有大量的磁盘IO，对性能有一定影响 非关系型数据库，他们的操作更多的是依赖于内存来操作，内存的读写速度会非常快，性能自然会好一些 扩展性 关系型数据库集群模式一般是主从，主从数据一致，起到数据备份的作用，称为垂直扩展。 非关系型数据库可以将数据拆分，存储在不同机器上，可以保存海量数据，解决内存大小有限的问题。称为水平扩展。 关系型数据库因为表之间存在关联关系，如果做水平扩展会给数据查询带来很多麻烦 1.2.认识RedisRedis诞生于2009年全称是Remote Dictionary Server 远程词典服务器，是一个基于内存的键值型NoSQL数据库。 特征： 键值（key-value）型，value支持多种不同数据结构，功能丰富 单线程，每个命令具备原子性 低延迟，速度快（基于内存、IO多路复用、良好的编码）。 支持数据持久化 支持主从集群、分片集群 支持多语言客户端 作者：Antirez Redis的官方网站地址：https://redis.io/ 1.3.安装Redis大多数企业都是基于Linux服务器来部署项目，而且Redis官方也没有提供Windows版本的安装包。因此课程中我们会基于Linux系统来安装Redis. 此处选择的Linux版本为CentOS 7. 1.3.1.依赖库Redis是基于C语言编写的，因此首先需要安装Redis所需要的gcc依赖： yum install -y gcc tcl 1.3.2.上传安装包并解压然后将Redis安装包上传到虚拟机的任意目录： 例如，我放到了/usr/local/src 目录： 解压缩： tar -xzf redis-6.2.6.tar.gz 解压后： 进入redis目录： cd redis-6.2.6 运行编译命令： make &amp;&amp; make install 如果没有出错，应该就安装成功了。 默认的安装路径是在 /usr/local/bin目录下： 该目录已经默认配置到环境变量，因此可以在任意目录下运行这些命令。其中： redis-cli：是redis提供的命令行客户端 redis-server：是redis的服务端启动脚本 redis-sentinel：是redis的哨兵启动脚本 1.3.3.启动redis的启动方式有很多种，例如： 默认启动 指定配置启动 开机自启 1.3.4.默认启动安装完成后，在任意目录输入redis-server命令即可启动Redis： redis-server 如图： 这种启动属于前台启动，会阻塞整个会话窗口，窗口关闭或者按下CTRL + C则Redis停止。不推荐使用。 1.3.5.指定配置启动如果要让Redis以后台方式启动，则必须修改Redis配置文件，就在我们之前解压的redis安装包下（/usr/local/src/redis-6.2.6），名字叫redis.conf： 我们先将这个配置文件备份一份： cp redis.conf redis.conf.bck 然后修改redis.conf文件中的一些配置： # 允许访问的地址，默认是127.0.0.1，会导致只能在本地访问。修改为0.0.0.0则可以在任意IP访问，生产环境不要设置为0.0.0.0 bind 0.0.0.0 # 守护进程，修改为yes后即可后台运行 daemonize yes # 密码，设置后访问Redis必须输入密码 requirepass 123321 Redis的其它常见配置： # 监听的端口 port 6379 # 工作目录，默认是当前目录，也就是运行redis-server时的命令，日志、持久化等文件会保存在这个目录 dir . # 数据库数量，设置为1，代表只使用1个库，默认有16个库，编号0~15 databases 1 # 设置redis能够使用的最大内存 maxmemory 512mb # 日志文件，默认为空，不记录日志，可以指定日志文件名 logfile \"redis.log\" 启动Redis： # 进入redis安装目录 cd /usr/local/src/redis-6.2.6 # 启动 redis-server redis.conf # 查看redis是否启动 ps -ef | grep redis 停止服务： # 利用redis-cli来执行 shutdown 命令，即可停止 Redis 服务， # 因为之前配置了密码，因此需要通过 -u 来指定密码 redis-cli -u 123321 shutdown 1.3.6.开机自启我们也可以通过配置来实现开机自启。 首先，新建一个系统服务文件： vi /etc/systemd/system/redis.service 内容如下： [Unit] Description=redis-server After=network.target [Service] Type=forking ExecStart=/usr/local/bin/redis-server /usr/local/src/redis-6.2.6/redis.conf PrivateTmp=true [Install] WantedBy=multi-user.target 然后重载系统服务： systemctl daemon-reload 现在，我们可以用下面这组命令来操作redis了： # 启动 systemctl start redis # 停止 systemctl stop redis # 重启 systemctl restart redis # 查看状态 systemctl status redis 执行下面的命令，可以让redis开机自启： systemctl enable redis 1.4.Redis桌面客户端安装完成Redis，我们就可以操作Redis，实现数据的CRUD了。这需要用到Redis客户端，包括： 命令行客户端 图形化桌面客户端 编程客户端 1.4.1.Redis命令行客户端Redis安装完成后就自带了命令行客户端：redis-cli，使用方式如下： redis-cli [options] [commonds] 其中常见的options有： -h 127.0.0.1：指定要连接的redis节点的IP地址，默认是127.0.0.1 -p 6379：指定要连接的redis节点的端口，默认是6379 -a 123321：指定redis的访问密码 其中的commonds就是Redis的操作命令，例如： ping：与redis服务端做心跳测试，服务端正常会返回pong 不指定commond时，会进入redis-cli的交互控制台： 1.4.2.图形化桌面客户端GitHub上的大神编写了Redis的图形化桌面客户端，地址：https://github.com/uglide/RedisDesktopManager 不过该仓库提供的是RedisDesktopManager的源码，并未提供windows安装包。 在下面这个仓库可以找到安装包：https://github.com/lework/RedisDesktopManager-Windows/releases 1.4.3.安装在课前资料中可以找到Redis的图形化桌面客户端： 解压缩后，运行安装程序即可安装： 安装完成后，在安装目录下找到rdm.exe文件： 双击即可运行： 1.4.4.建立连接点击左上角的连接到Redis服务器按钮： 在弹出的窗口中填写Redis服务信息： 点击确定后，在左侧菜单会出现这个链接： 点击即可建立连接了。 Redis默认有16个仓库，编号从0至15. 通过配置文件可以设置仓库数量，但是不超过16，并且不能自定义仓库名称。 如果是基于redis-cli连接Redis服务，可以通过select命令来选择数据库： # 选择 0号库 select 0 2.Redis常见命令Redis是典型的key-value数据库，key一般是字符串，而value包含很多不同的数据类型： Redis为了方便我们学习，将操作不同数据类型的命令也做了分组，在官网（ https://redis.io/commands ）可以查看到不同的命令： 不同类型的命令称为一个group，我们也可以通过help命令来查看各种不同group的命令： 接下来，我们就学习常见的五种基本数据类型的相关命令。 2.1.Redis通用命令通用指令是部分数据类型的，都可以使用的指令，常见的有： KEYS：查看符合模板的所有key，不建议在生产环境使用 DEL：删除一个指定的key EXISTS：判断key是否存在 EXPIRE：给一个key设置有效期，有效期到期时该key会被自动删除 TTL：查看一个KEY的剩余有效期 通过help [command] 可以查看一个命令的具体用法，例如： # 查看keys命令的帮助信息： 127.0.0.1:6379&gt; help keys KEYS pattern summary: Find all keys matching the given pattern since: 1.0.0 group: generic 2.2.String类型String类型，也就是字符串类型，是Redis中最简单的存储类型。 其value是字符串，不过根据字符串的格式不同，又可以分为3类： string：普通字符串 int：整数类型，可以做自增、自减操作 float：浮点类型，可以做自增、自减操作 不管是哪种格式，底层都是字节数组形式存储，只不过是编码方式不同。字符串类型的最大空间不能超过512m. 2.2.1.String的常见命令String的常见命令有： SET：添加或者修改已经存在的一个String类型的键值对 GET：根据key获取String类型的value MSET：批量添加多个String类型的键值对 MGET：根据多个key获取多个String类型的value INCR：让一个整型的key自增1 INCRBY:让一个整型的key自增并指定步长，例如：incrby num 2 让num值自增2 INCRBYFLOAT：让一个浮点类型的数字自增并指定步长 SETNX：添加一个String类型的键值对，前提是这个key不存在，否则不执行 SETEX：添加一个String类型的键值对，并且指定有效期 2.2.2.Key结构Redis没有类似MySQL中的Table的概念，我们该如何区分不同类型的key呢？ 例如，需要存储用户、商品信息到redis，有一个用户id是1，有一个商品id恰好也是1，此时如果使用id作为key，那就会冲突了，该怎么办？ 我们可以通过给key添加前缀加以区分，不过这个前缀不是随便加的，有一定的规范： Redis的key允许有多个单词形成层级结构，多个单词之间用’:’隔开，格式如下： 项目名:业务名:类型:id 这个格式并非固定，也可以根据自己的需求来删除或添加词条。这样以来，我们就可以把不同类型的数据区分开了。从而避免了key的冲突问题。 例如我们的项目名称叫 heima，有user和product两种不同类型的数据，我们可以这样定义key： user相关的key：heima:user:1 product相关的key：heima:product:1 如果Value是一个Java对象，例如一个User对象，则可以将对象序列化为JSON字符串后存储： KEY VALUE heima:user:1 {“id”:1, “name”: “Jack”, “age”: 21} heima:product:1 {“id”:1, “name”: “小米11”, “price”: 4999} 并且，在Redis的桌面客户端中，还会以相同前缀作为层级结构，让数据看起来层次分明，关系清晰： 2.3.Hash类型Hash类型，也叫散列，其value是一个无序字典，类似于Java中的HashMap结构。 String结构是将对象序列化为JSON字符串后存储，当需要修改对象某个字段时很不方便： Hash结构可以将对象中的每个字段独立存储，可以针对单个字段做CRUD： Hash的常见命令有： HSET key field value：添加或者修改hash类型key的field的值 HGET key field：获取一个hash类型key的field的值 HMSET：批量添加多个hash类型key的field的值 HMGET：批量获取多个hash类型key的field的值 HGETALL：获取一个hash类型的key中的所有的field和value HKEYS：获取一个hash类型的key中的所有的field HINCRBY:让一个hash类型key的字段值自增并指定步长 HSETNX：添加一个hash类型的key的field值，前提是这个field不存在，否则不执行 2.4.List类型Redis中的List类型与Java中的LinkedList类似，可以看做是一个双向链表结构。既可以支持正向检索和也可以支持反向检索。 特征也与LinkedList类似： 有序 元素可以重复 插入和删除快 查询速度一般 常用来存储一个有序数据，例如：朋友圈点赞列表，评论列表等。 List的常见命令有： LPUSH key element … ：向列表左侧插入一个或多个元素 LPOP key：移除并返回列表左侧的第一个元素，没有则返回nil RPUSH key element … ：向列表右侧插入一个或多个元素 RPOP key：移除并返回列表右侧的第一个元素 LRANGE key star end：返回一段角标范围内的所有元素 BLPOP和BRPOP：与LPOP和RPOP类似，只不过在没有元素时等待指定时间，而不是直接返回nil 2.5.Set类型Redis的Set结构与Java中的HashSet类似，可以看做是一个value为null的HashMap。因为也是一个hash表，因此具备与HashSet类似的特征： 无序 元素不可重复 查找快 支持交集、并集、差集等功能 Set的常见命令有： SADD key member … ：向set中添加一个或多个元素 SREM key member … : 移除set中的指定元素 SCARD key： 返回set中元素的个数 SISMEMBER key member：判断一个元素是否存在于set中 SMEMBERS：获取set中的所有元素 SINTER key1 key2 … ：求key1与key2的交集 SDIFF key1 key2 …: 求key1和key2的差集 SUNION key1 key2…: 求key1和key2的并集 例如两个集合：s1和s2: 求交集：SINTER s1 s2 求s1与s2的不同：SDIFF s1 s2 练习： 将下列数据用Redis的Set集合来存储： 张三的好友有：李四、王五、赵六 李四的好友有：王五、麻子、二狗 利用Set的命令实现下列功能： 计算张三的好友有几人 计算张三和李四有哪些共同好友 查询哪些人是张三的好友却不是李四的好友 查询张三和李四的好友总共有哪些人 判断李四是否是张三的好友 判断张三是否是李四的好友 将李四从张三的好友列表中移除 2.6.SortedSet类型Redis的SortedSet是一个可排序的set集合，与Java中的TreeSet有些类似，但底层数据结构却差别很大。SortedSet中的每一个元素都带有一个score属性，可以基于score属性对元素排序，底层的实现是一个跳表（SkipList）加 hash表。 SortedSet具备下列特性： 可排序 元素不重复 查询速度快 因为SortedSet的可排序特性，经常被用来实现排行榜这样的功能。 SortedSet的常见命令有： ZADD key score member：添加一个或多个元素到sorted set ，如果已经存在则更新其score值 ZREM key member：删除sorted set中的一个指定元素 ZSCORE key member : 获取sorted set中的指定元素的score值 ZRANK key member：获取sorted set 中的指定元素的排名 ZCARD key：获取sorted set中的元素个数 ZCOUNT key min max：统计score值在给定范围内的所有元素的个数 ZINCRBY key increment member：让sorted set中的指定元素自增，步长为指定的increment值 ZRANGE key min max：按照score排序后，获取指定排名范围内的元素 ZRANGEBYSCORE key min max：按照score排序后，获取指定score范围内的元素 ZDIFF、ZINTER、ZUNION：求差集、交集、并集 注意：所有的排名默认都是升序，如果要降序则在命令的Z后面添加REV即可，例如： 升序获取sorted set 中的指定元素的排名：ZRANK key member 降序获取sorted set 中的指定元素的排名：ZREVRANK key memeber 练习题： 将班级的下列学生得分存入Redis的SortedSet中： Jack 85, Lucy 89, Rose 82, Tom 95, Jerry 78, Amy 92, Miles 76 并实现下列功能： 删除Tom同学 获取Amy同学的分数 获取Rose同学的排名 查询80分以下有几个学生 给Amy同学加2分 查出成绩前3名的同学 查出成绩80分以下的所有同学 3.Redis的Java客户端在Redis官网中提供了各种语言的客户端，地址：https://redis.io/docs/clients/ 其中Java客户端也包含很多： 标记为*的就是推荐使用的java客户端，包括： Jedis和Lettuce：这两个主要是提供了Redis命令对应的API，方便我们操作Redis，而SpringDataRedis又对这两种做了抽象和封装，因此我们后期会直接以SpringDataRedis来学习。 Redisson：是在Redis基础上实现了分布式的可伸缩的java数据结构，例如Map、Queue等，而且支持跨进程的同步机制：Lock、Semaphore等待，比较适合用来实现特殊的功能需求。 3.1.Jedis客户端Jedis的官网地址： https://github.com/redis/jedis 3.1.1.快速入门我们先来个快速入门： 1）引入依赖： &lt;!--jedis--&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.7.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--单元测试--&gt; &lt;dependency&gt; &lt;groupId&gt;org.junit.jupiter&lt;/groupId&gt; &lt;artifactId&gt;junit-jupiter&lt;/artifactId&gt; &lt;version&gt;5.7.0&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; 2）建立连接 新建一个单元测试类，内容如下： private Jedis jedis; @BeforeEach void setUp() { // 1.建立连接 // jedis = new Jedis(\"192.168.150.101\", 6379); jedis = JedisConnectionFactory.getJedis(); // 2.设置密码 jedis.auth(\"123321\"); // 3.选择库 jedis.select(0); } 3）测试： @Test void testString() { // 存入数据 String result = jedis.set(\"name\", \"虎哥\"); System.out.println(\"result = \" + result); // 获取数据 String name = jedis.get(\"name\"); System.out.println(\"name = \" + name); } @Test void testHash() { // 插入hash数据 jedis.hset(\"user:1\", \"name\", \"Jack\"); jedis.hset(\"user:1\", \"age\", \"21\"); // 获取 Map&lt;String, String&gt; map = jedis.hgetAll(\"user:1\"); System.out.println(map); } 4）释放资源 @AfterEach void tearDown() { if (jedis != null) { jedis.close(); } } 3.1.2.连接池Jedis本身是线程不安全的，并且频繁的创建和销毁连接会有性能损耗，因此我们推荐大家使用Jedis连接池代替Jedis的直连方式。 package com.heima.jedis.util; import redis.clients.jedis.*; public class JedisConnectionFactory { private static JedisPool jedisPool; static { // 配置连接池 JedisPoolConfig poolConfig = new JedisPoolConfig(); poolConfig.setMaxTotal(8); poolConfig.setMaxIdle(8); poolConfig.setMinIdle(0); poolConfig.setMaxWaitMillis(1000); // 创建连接池对象，参数：连接池配置、服务端ip、服务端端口、超时时间、密码 jedisPool = new JedisPool(poolConfig, \"192.168.150.101\", 6379, 1000, \"123321\"); } public static Jedis getJedis(){ return jedisPool.getResource(); } } 3.2.SpringDataRedis客户端SpringData是Spring中数据操作的模块，包含对各种数据库的集成，其中对Redis的集成模块就叫做SpringDataRedis，官网地址：https://spring.io/projects/spring-data-redis 提供了对不同Redis客户端的整合（Lettuce和Jedis） 提供了RedisTemplate统一API来操作Redis 支持Redis的发布订阅模型 支持Redis哨兵和Redis集群 支持基于Lettuce的响应式编程 支持基于JDK、JSON、字符串、Spring对象的数据序列化及反序列化 支持基于Redis的JDKCollection实现 SpringDataRedis中提供了RedisTemplate工具类，其中封装了各种对Redis的操作。并且将不同数据类型的操作API封装到了不同的类型中： 3.2.1.快速入门SpringBoot已经提供了对SpringDataRedis的支持，使用非常简单。 首先，新建一个maven项目，然后按照下面步骤执行： 1）引入依赖&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.5.7&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.heima&lt;/groupId&gt; &lt;artifactId&gt;redis-demo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;redis-demo&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--redis依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--common-pool--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--Jackson依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;excludes&gt; &lt;exclude&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 2）配置Redisspring: redis: host: 192.168.150.101 port: 6379 password: 123321 lettuce: pool: max-active: 8 max-idle: 8 min-idle: 0 max-wait: 100ms 3）注入RedisTemplate因为有了SpringBoot的自动装配，我们可以拿来就用： @SpringBootTest class RedisStringTests { @Autowired private RedisTemplate redisTemplate; } 4）编写测试@SpringBootTest class RedisStringTests { @Autowired private RedisTemplate edisTemplate; @Test void testString() { // 写入一条String数据 redisTemplate.opsForValue().set(\"name\", \"虎哥\"); // 获取string数据 Object name = stringRedisTemplate.opsForValue().get(\"name\"); System.out.println(\"name = \" + name); } } 3.2.2.自定义序列化RedisTemplate可以接收任意Object作为值写入Redis： 只不过写入前会把Object序列化为字节形式，默认是采用JDK序列化，得到的结果是这样的： 缺点： 可读性差 内存占用较大 我们可以自定义RedisTemplate的序列化方式，代码如下： @Configuration public class RedisConfig { @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory connectionFactory){ // 创建RedisTemplate对象 RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;(); // 设置连接工厂 template.setConnectionFactory(connectionFactory); // 创建JSON序列化工具 GenericJackson2JsonRedisSerializer jsonRedisSerializer = new GenericJackson2JsonRedisSerializer(); // 设置Key的序列化 template.setKeySerializer(RedisSerializer.string()); template.setHashKeySerializer(RedisSerializer.string()); // 设置Value的序列化 template.setValueSerializer(jsonRedisSerializer); template.setHashValueSerializer(jsonRedisSerializer); // 返回 return template; } } 这里采用了JSON序列化来代替默认的JDK序列化方式。最终结果如图： 整体可读性有了很大提升，并且能将Java对象自动的序列化为JSON字符串，并且查询时能自动把JSON反序列化为Java对象。不过，其中记录了序列化时对应的class名称，目的是为了查询时实现自动反序列化。这会带来额外的内存开销。 3.2.3.StringRedisTemplate为了节省内存空间，我们可以不使用JSON序列化器来处理value，而是统一使用String序列化器，要求只能存储String类型的key和value。当需要存储Java对象时，手动完成对象的序列化和反序列化。 因为存入和读取时的序列化及反序列化都是我们自己实现的，SpringDataRedis就不会将class信息写入Redis了。 这种用法比较普遍，因此SpringDataRedis就提供了RedisTemplate的子类：StringRedisTemplate，它的key和value的序列化方式默认就是String方式。 省去了我们自定义RedisTemplate的序列化方式的步骤，而是直接使用： @Autowired private StringRedisTemplate stringRedisTemplate; // JSON序列化工具 private static final ObjectMapper mapper = new ObjectMapper(); @Test void testSaveUser() throws JsonProcessingException { // 创建对象 User user = new User(\"虎哥\", 21); // 手动序列化 String json = mapper.writeValueAsString(user); // 写入数据 stringRedisTemplate.opsForValue().set(\"user:200\", json); // 获取数据 String jsonUser = stringRedisTemplate.opsForValue().get(\"user:200\"); // 手动反序列化 User user1 = mapper.readValue(jsonUser, User.class); System.out.println(\"user1 = \" + user1); }","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://gitee.com/yunyd/tags/Redis/"}],"author":"llllz."},{"title":"JUC-AbstractQueuedSynchronizer之AQS","slug":"JUC-AbstractQueuedSynchronizer之AQS  -12","date":"2023-08-19T02:26:34.000Z","updated":"2023-08-25T00:19:14.470Z","comments":true,"path":"posts/6bfa0f2f.html","link":"","permalink":"https://gitee.com/yunyd/posts/6bfa0f2f.html","excerpt":"","text":"AbstractQueuedSynchronizer之AQS1.1 前置知识 公平锁和非公平锁 公平锁：锁被释放以后，先申请的线程先得到锁。性能较差一些，因为公平锁为了保证时间上的绝对顺序，上下文切换更频繁 非公平锁：锁被释放以后，后申请的线程可能会先获取到锁，是随机或者按照其他优先级排序的。性能更好，但可能会导致某些线程永远无法获取到锁 可重入锁 也叫做递归锁，指的是线程可以再次获取自己的内部锁，比如一个线程获取到了对象锁，此时这个对象锁还没有释放，当其想再次获取这个对象锁的时候还是可以获取的，如果不可重入的话，会导致死锁。 自旋思想 当线程请求锁时，如果锁已经被其他线程持有，那么该线程会不断地重试获取锁，而不是被挂起等待，这种不断尝试获取锁的行为称为自旋 LockSupport 一个工具类，用于线程的阻塞和唤醒操作，类似于wait()和notify()方法，但是更加灵活和可控 提供了park()和unpark()两个静态方法用于线程阻塞和唤醒操作。 优点在于可以在任意时刻阻塞和唤醒线程而不需要事先获取锁或监视器对象。 数据结构之双向链表 双向链表（Doubly Linked List）是一种常见的数据结构，它是由一系列结点（Node）组成的，每个结点包含三个部分：数据域、前驱指针和后继指针。其中，数据域存储结点的数据，前驱指针指向前一个结点，后继指针指向后一个结点。通过这种方式，双向链表可以实现双向遍历和插入、删除操作。 设计模式之模板设计模式 模板设计模式是一种行为型设计模式，定义了一种算法的框架，并将某些步骤延迟到子类中事先，这种设计模式的主要目的是允许子类在不改变算法结构的情况下重新定义算法中的某些步骤。 优点是能够提高代码复用性和可维护性。 1.2 AQS入门级别理论知识1.2.1 是什么？抽象的队列同步器 技术解释 是用来实现锁或者其他同步器组件的公共基础部分的抽象实现 是重量级基础框架及整个JUC体系的基石，只要用于解决锁分配给”谁“的问题。 整体就是一个抽象的FIFO队列来完成资源获取线程的排队工作，并通过一个int类变量表示持有锁的状态 1.2.2 AQS为什么是JUC内容中最重要的基石 和AQS有关的 ReentrantLock CountDownLatch ReentrantReadWriteLock Semaphore ………….. 进一步理解锁和同步器的关系 锁，面向锁的使用者：定义了程序员和锁交互的使用层API，隐藏了实现细节，你调用即可 同步器，面向锁的实现者：Java并发大神DoungLee，提出了统一规范并简化了锁的实现，将其抽象出来，屏蔽了同步状态管理、同步队列的管理和维护、阻塞线程排队和通知、唤醒机制等，是一切锁和同步组件实现的—-公共基础部分 1.2.3 能干嘛？加锁会导致阻塞——有阻塞就需要排队，实现排队必然需要队列 抢到资源的线程直接使用处理业务，抢不到资源的必然涉及一种排队等候机制。抢占失败的线程继续去等待（类似于银行办理窗口都满了，暂时没有受理窗口的顾客只能去候客区排队等待），但等候线程仍然保留获取锁的可能且获取锁流程仍在继续（候客区的顾客也在等着叫号，轮到了再去受理窗口办理业务） 既然说到了排队等候机制，那么就一定会有某种队列形成，这样的队列是什么数据结构呢？ 如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是CLH队列的变体实现的，将暂时获取不到锁的线程加入到队列中，这个队列就是AQS同步队列的抽象表现。它将要请求共享资源的线程及自身的等待状态封装成队列的节点对象（Node），通过CAS、自旋以及LockSupport.park()的方式，维护着state变量的状态，使其达到同步的状态。 1.2.4 小总结AQS同步队列的基本结构 1.3 AQS源码分析前置知识储备1.3.1 AQS内部体系架构图 1.3.2 AQS内部体系架构—-AQS自身 AQS的int类型变量state AQS的同步状态State成员变量 银行办理业务的受理窗口状态 零就是没人，自由状态可以去办理 大于等于1，有人占用窗口，等着去 AQS的CLH队列 CLH（三个大牛的名字组成）队列为一个双向队列 银行候客区的等待顾客 小总结 有阻塞就需要排队，实现排队必然需要队列 State变量+CLH双端队列 1.3.1 AQS内部体系架构—-内部类Node Node的int变量 Node的等待状态waitState成员变量 说人话 等候区其他顾客（其他线程）的等待状态 队列中每个排队的个体就是一个Node Node此类的讲解 内部结构 属性说明 1.4 AQS源码深度讲解和分析1.4.1 ReentrantLock的原理Lock接口的实现类，基本都是通过聚合了一个队列同步器的子类完成线程访问控制的 1.4.2 从最简单的lock方法开始看看公平和非公平 公平锁和非公平锁的lock()方法唯一的区别就在于公平锁在获取同步状态时多了一个限制条件：hasQueuedPredecessors()—–公平锁加锁时判断等待队列中是否存在有效节点的方法 1.4.3 以非公平锁ReentrantLock()为例作为突破走起—方法lock()对比公平锁和非公平锁的tryAcquire()方法的实现代码，其实差异就在于非公平锁获取锁时比公平锁中少了一个判断!hasQueuedPredecessors()，hasQueuedPredecessors()中判断了是否需要排队，导致公平锁和非公平锁的差异如下： 公平锁：公平锁讲究先来后到，线程在获取锁时，如果这个锁的等待队列中已经有线程在等待，那么当前线程就会进入到等待队列中； 非公平锁：不管是否有等待队列，如果可以获取到锁，则立刻占有锁对象。也就是说队列的第一个排队线程苏醒后，不一定就是排头的这个线程获得锁，它还需要参加竞争锁（存在线程竞争的情况下），后来的线程可能不讲武德插队夺锁了。 正式开始源码解读： lock() acquire() tryAcquire(arg) return false：继续推进条件，走下一个方法 return true：结束 addwaiter(Node.EXCLUSIVE) 注意：在双向链表中，第一个节点为虚节点（也叫做哨兵节点），其实不存储任何信息，只是占位。真正的第一个有数据的节点，是从第二个节点开始的 假如此时有线程C进入： acquireQueued(addWeiter(Node.EXCLUSIVE), arg)—–坐稳队列 1.4.4 unlock()","categories":[],"tags":[{"name":"JUC并发编程","slug":"JUC并发编程","permalink":"https://gitee.com/yunyd/tags/JUC%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"author":"llllz."},{"title":"RabbitMQ复习","slug":"RabbitMQ复习","date":"2023-08-18T12:47:05.000Z","updated":"2023-08-25T00:21:35.267Z","comments":true,"path":"posts/2eca33fa.html","link":"","permalink":"https://gitee.com/yunyd/posts/2eca33fa.html","excerpt":"","text":"RabbitMQ1. 消息队列1.1. MQ 的相关概念1.1.1. 什么是MQMQ(message queue)，从字面意思上看，本质是个队列，FIFO 先入先出，只不过队列中存放的内容是 message 而已，还是一种跨进程的通信机制，用于上下游传递消息。在互联网架构中，MQ 是一种非常常 见的上下游“逻辑解耦+物理解耦”的消息通信服务。使用了 MQ 之后，消息发送上游只需要依赖 MQ，不 用依赖其他服务。 1.1.2. 为什么要用MQ 1.流量消峰 举个例子，如果订单系统最多能处理一万次订单，这个处理能力应付正常时段的下单时绰绰有余，正 常时段我们下单一秒后就能返回结果。但是在高峰期，如果有两万次下单操作系统是处理不了的，只能限 制订单超过一万后不允许用户下单。使用消息队列做缓冲，我们可以取消这个限制，把一秒内下的订单分 散成一段时间来处理，这时有些用户可能在下单十几秒后才能收到下单成功的操作，但是比不能下单的体 验要好。 2.应用解耦 以电商应用为例，应用中有订单系统、库存系统、物流系统、支付系统。用户创建订单后，如果耦合 调用库存系统、物流系统、支付系统，任何一个子系统出了故障，都会造成下单操作异常。当转变成基于 消息队列的方式后，系统间调用的问题会减少很多，比如物流系统因为发生故障，需要几分钟来修复。在 这几分钟的时间里，物流系统要处理的内存被缓存在消息队列中，用户的下单操作可以正常完成。当物流 系统恢复后，继续处理订单信息即可，中单用户感受不到物流系统的故障，提升系统的可用性。 3.异步处理 有些服务间调用是异步的，例如 A 调用 B，B 需要花费很长时间执行，但是 A 需要知道 B 什么时候可 以执行完，以前一般有两种方式，A 过一段时间去调用 B 的查询 api 查询。或者 A 提供一个 callback api， B 执行完之后调用 api 通知 A 服务。这两种方式都不是很优雅，使用消息总线，可以很方便解决这个问题， A 调用 B 服务后，只需要监听 B 处理完成的消息，当 B 处理完成后，会发送一条消息给 MQ，MQ 会将此消 息转发给 A 服务。这样 A 服务既不用循环调用 B 的查询 api，也不用提供 callback api。同样B 服务也不用 做这些操作。A 服务还能及时的得到异步处理成功的消息。 1.1.3. MQ 的分类 1.ActiveMQ 优点：单机吞吐量万级，时效性 ms 级，可用性高，基于主从架构实现高可用性，消息可靠性较 低的概率丢失数据 缺点:官方社区现在对 ActiveMQ 5.x 维护越来越少，高吞吐量场景较少使用。 2.Kafka 大数据的杀手锏，谈到大数据领域内的消息传输，则绕不开 Kafka，这款为大数据而生的消息中间件， 以其百万级 TPS 的吞吐量名声大噪，迅速成为大数据领域的宠儿，在数据采集、传输、存储的过程中发挥 着举足轻重的作用。目前已经被 LinkedIn，Uber, Twitter, Netflix 等大公司所采纳。 优点: 性能卓越，单机写入 TPS 约在百万条/秒，最大的优点，就是吞吐量高。时效性 ms 级可用性非 常高，kafka 是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用,消费者采 用 Pull 方式获取消息, 消息有序, 通过控制能够保证所有消息被消费且仅被消费一次;有优秀的第三方Kafka Web 管理界面 Kafka-Manager；在日志领域比较成熟，被多家公司和多个开源项目使用；功能支持： 功能 较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用 缺点：Kafka 单机超过 64 个队列/分区，Load 会发生明显的飙高现象，队列越多，load 越高，发送消 息响应时间变长，使用短轮询方式，实时性取决于轮询间隔时间，消费失败不支持重试；支持消息顺序， 但是一台代理宕机后，就会产生消息乱序，社区更新较慢； 3.RocketMQ RocketMQ 出自阿里巴巴的开源产品，用 Java 语言实现，在设计时参考了 Kafka，并做出了自己的一 些改进。被阿里巴巴广泛应用在订单，交易，充值，流计算，消息推送，日志流式处理，binglog 分发等场 景。 优点:单机吞吐量十万级,可用性非常高，分布式架构,消息可以做到 0 丢失**,**MQ 功能较为完善，还是分 布式的，扩展性好,支持 10 亿级别的消息堆积，不会因为堆积导致性能下降,源码是 java 我们可以自己阅 读源码，定制自己公司的 MQ 缺点：支持的客户端语言不多，目前是 java 及 c++，其中 c++不成熟；社区活跃度一般,没有在MQ 核心中去实现 JMS 等接口,有些系统要迁移需要修改大量代码 4.RabbitMQ 2007 年发布，是一个在AMQP(高级消息队列协议)基础上完成的，可复用的企业消息系统，是当前最 主流的消息中间件之一。 优点:由于 erlang 语言的高并发特性，性能较好；吞吐量到万级，MQ 功能比较完备,健壮、稳定、易 用、跨平台、支持多种语言 如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP 等，支持 AJAX 文档齐全；开源提供的管理界面非常棒，用起来很好用,社区活跃度高；更新频率相当高 https://www.rabbitmq.com/news.html 缺点：商业版需要收费,学习成本较高 1.1.4. MQ 的选择 Kafka Kafka 主要特点是基于Pull 的模式来处理消息消费，追求高吞吐量，一开始的目的就是用于日志收集 和传输，适合产生大量数据的互联网服务的数据收集业务。大型公司建议可以选用，如果有日志采集功能， 肯定是首选 kafka 了。尚硅谷官网 kafka 视频连接http://www.gulixueyuan.com/course/330/tasks RocketMQ 天生为金融互联网领域而生，对于可靠性要求很高的场景，尤其是电商里面的订单扣款，以及业务削 峰，在大量交易涌入时，后端可能无法及时处理的情况。RoketMQ 在稳定性上可能更值得信赖，这些业务 场景在阿里双 11 已经经历了多次考验，如果你的业务有上述并发场景，建议可以选择 RocketMQ。 RabbitMQ 结合 erlang 语言本身的并发优势，性能好时效性微秒级，社区活跃度也比较高，管理界面用起来十分 方便，如果你的数据量没有那么大，中小型公司优先选择功能比较完备的 RabbitMQ。 1.2. RabbitMQ1.2.1. RabbitMQ 的概念RabbitMQ 是一个消息中间件：它接受并转发消息。你可以把它当做一个快递站点，当你要发送一个包 裹时，你把你的包裹放到快递站，快递员最终会把你的快递送到收件人那里，按照这种逻辑 RabbitMQ 是 一个快递站，一个快递员帮你传递快件。RabbitMQ 与快递站的主要区别在于，它不处理快件而是接收， 存储和转发消息数据。 1.2.2. 四大核心概念 生产者 产生数据发送消息的程序是生产者 交换机 交换机是 RabbitMQ 非常重要的一个部件，一方面它接收来自生产者的消息，另一方面它将消息 推送到队列中。交换机必须确切知道如何处理它接收到的消息，是将这些消息推送到特定队列还是推 送到多个队列，亦或者是把消息丢弃，这个得有交换机类型决定 队列 队列是 RabbitMQ 内部使用的一种数据结构，尽管消息流经 RabbitMQ 和应用程序，但它们只能存 储在队列中。队列仅受主机的内存和磁盘限制的约束，本质上是一个大的消息缓冲区。许多生产者可 以将消息发送到一个队列，许多消费者可以尝试从一个队列接收数据。这就是我们使用队列的方式 消费者 消费与接收具有相似的含义。消费者大多时候是一个等待接收消息的程序。请注意生产者，消费 者和消息中间件很多时候并不在同一机器上。同一个应用程序既可以是生产者又是可以是消费者。 1.2.3. RabbitMQ 核心部分 1.2.4. 各个名词介绍 Broker：接收和分发消息的应用，RabbitMQ Server 就是 Message Broker Virtual host：出于多租户和安全因素设计的，把 AMQP 的基本组件划分到一个虚拟的分组中，类似 于网络中的 namespace 概念。当多个不同的用户使用同一个 RabbitMQ server 提供的服务时，可以划分出 多个 vhost，每个用户在自己的 vhost 创建 exchange／queue 等 Connection：publisher／consumer 和 broker 之间的 TCP 连接 Channel：如果每一次访问 RabbitMQ 都建立一个 Connection，在消息量大的时候建立 TCP Connection 的开销将是巨大的，效率也较低。Channel 是在 connection 内部建立的逻辑连接，如果应用程 序支持多线程，通常每个 thread 创建单独的 channel 进行通讯，AMQP method 包含了 channel id 帮助客 户端和 message broker 识别 channel，所以 channel 之间是完全隔离的。Channel 作为轻量级的 Connection 极大减少了操作系统建立 TCP connection 的开销 Exchange：message 到达 broker 的第一站，根据分发规则，匹配查询表中的 routing key，分发 消息到 queue 中去。常用的类型有：direct (point-to-point), topic (publish-subscribe) and fanout (multicast) Queue：消息最终被送到这里等待 consumer 取走 Binding：exchange 和 queue 之间的虚拟连接，binding 中可以包含 routing key，Binding 信息被保 存到 exchange 中的查询表中，用于 message 的分发依据 2. Hello World 在这一部分中，我们将用 Java 编写两个程序。发送单个消息的生产者和接收消息并打印 出来的消费者。我们将介绍 Java API 中的一些细节。 在下图中，“ P”是我们的生产者，“ C”是我们的消费者。中间的框是一个队列-RabbitMQ 代 表使用者保留的消息缓冲区 2.1. 依赖&lt;!--指定 jdk 编译版本--&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;8&lt;/source&gt; &lt;target&gt;8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;dependencies&gt; &lt;!--rabbitmq 依赖客户端--&gt; &lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;5.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--操作文件流的一个依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 2.2. 消息生产者public class Producer { private final static String QUEUE_NAME = \"hello\"; public static void main(String[] args) throws Exception { //创建一个连接工厂 ConnectionFactory factory = new ConnectionFactory(); factory.setHost(\"182.92.234.71\"); factory.setUsername(\"admin\"); factory.setPassword(\"123\"); //channel 实现了自动 close 接口 自动关闭 不需要显示关闭 try (Connection connection = factory.newConnection(); Channel channel = connection.createChannel()){ /** * 生成一个队列 * 1.队列名称 * 2.队列里面的消息是否持久化 默认消息存储在内存中 * 3.该队列是否只供一个消费者进行消费 是否进行共享 false 可以多个消费者消费 * 4.是否自动删除 最后一个消费者端开连接以后 该队列是否自动删除 true 自动删除 * 5.其他参数 */ channel.queueDeclare(QUEUE_NAME, false, false, false, null); String message = \"hello world\"; /** * 发送一个消息 * 1.发送到那个交换机 * 2.路由的 key 是哪个 * 3.其他的参数信息 * 4.发送消息的消息体 */ channel.basicPublish(\"\", QUEUE_NAME, null, message.getBytes()); System.out.println(\"消息发送完毕\"); } } } 2.3. 消息消费者public class Consumer { private final static String QUEUE_NAME = \"hello\"; public static void main(String[] args) throws Exception { ConnectionFactory factory = new ConnectionFactory(); factory.setHost(\"182.92.234.71\"); factory.setUsername(\"admin\"); factory.setPassword(\"123\"); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); System.out.println(\"等待接收消息.........\"); //推送的消息如何进行消费的接口回调 DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; { String message = new String(delivery.getBody()); System.out.println(message); }; //取消消费的一个回调接口 如在消费的时候队列被删除掉了 CancelCallback cancelCallback = (consumerTag) -&gt; { System.out.println(\"消息消费被中断\"); }; /** * 消费者消费消息 * 1.消费哪个队列 * 2.消费成功之后是否要自动应答 true 代表自动应答 false 手动应答 * 3.消费者未成功消费的回调 */ channel.basicConsume(QUEUE_NAME, true, deliverCallback, cancelCallback); } } 3. Work Queues工作队列(又称任务队列)的主要思想是避免立即执行资源密集型任务，而不得不等待它完成。 相反我们安排任务在之后执行。我们把任务封装为消息并将其发送到队列。在后台运行的工作进 程将弹出任务并最终执行作业。当有多个工作线程时，这些工作线程将一起处理这些任务。 3.1. 轮训分发消息在这个案例中我们会启动两个工作线程，一个消息发送线程，我们来看看他们两个工作线程 是如何工作的。 3.1.1. 抽取工具类public class RabbitMqUtils { //得到一个连接的 channel public static Channel getChannel() throws Exception{ //创建一个连接工厂 ConnectionFactory factory = new ConnectionFactory(); factory.setHost(\"182.92.234.71\"); factory.setUsername(\"admin\"); factory.setPassword(\"123\"); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); return channel; } } 3.1.2. 启动两个工作线程public class Worker01 { private static final String QUEUE_NAME = \"hello\"; public static void main(String[] args) throws Exception { Channel channel = RabbitMqUtils.getChannel(); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; { String receivedMessage = new String(delivery.getBody()); System.out.println(\"接收到消息:\" + receivedMessage); }; CancelCallback cancelCallback = (consumerTag) - &gt; {System.out.println(consumerTag + \"消费者取消消费接口回调逻辑\"); }; System.out.println(\"C2 消费者启动等待消费.................. \"); channel.basicConsume(QUEUE_NAME, true, deliverCallback, cancelCallback); } } 3.1.3. 启动一个发送线程public class Task01 { private static final String QUEUE_NAME=\"hello\"; public static void main(String[] args) throws Exception { try(Channel channel=RabbitMqUtils.getChannel();) { channel.queueDeclare(QUEUE_NAME,false,false,false,null); //从控制台当中接受信息 Scanner scanner = new Scanner(System.in); while (scanner.hasNext()){ String message = scanner.next(); channel.basicPublish(\"\",QUEUE_NAME,null,message.getBytes()); System.out.println(\"发送消息完成:\"+message); } } } } 3.1.4. 结果展示​ 通过程序执行发现生产者总共发送 4 个消息，消费者 1 和消费者 2 分别分得两个消息，并且 是按照有序的一个接收一次消息 3.2 消息应答3.2.1. 概念​ 消费者完成一个任务可能需要一段时间，如果其中一个消费者处理一个长的任务并仅只完成 了部分突然它挂掉了，会发生什么情况。RabbitMQ 一旦向消费者传递了一条消息，便立即将该消 息标记为删除。在这种情况下，突然有个消费者挂掉了，我们将丢失正在处理的消息。以及后续 发送给该消费这的消息，因为它无法接收到。 ​ 为了保证消息在发送过程中不丢失，rabbitmq 引入消息应答机制，消息应答就是:消费者在接收 到消息并且处理该消息之后，告诉 rabbitmq 它已经处理了，rabbitmq 可以把该消息删除了。 3.2.2. 自动应答​ 消息发送后立即被认为已经传送成功，这种模式需要在高吞吐量和数据传输安全性方面做权 衡,因为这种模式如果消息在接收到之前，消费者那边出现连接或者 channel 关闭，那么消息就丢失 了,当然另一方面这种模式消费者那边可以传递过载的消息，没有对传递的消息数量进行限制，当 然这样有可能使得消费者这边由于接收太多还来不及处理的消息，导致这些消息的积压，最终使 得内存耗尽，最终这些消费者线程被操作系统杀死，所以这种模式仅适用在消费者可以高效并以 某种速率能够处理这些消息的情况下使用。 3.2.3. 消息应答的方法 A. Channel.basicAck(用于肯定确认) RabbitMQ 已知道该消息并且成功的处理消息，可以将其丢弃了 B. Channel.basicNack(用于否定确认) C. Channel.basicReject(用于否定确认) 与 Channel.basicNack 相比少一个参数 不处理该消息了直接拒绝，可以将其丢弃了 3.2.4. Multiple 的解释手动应答的好处是可以批量应答并且减少网络拥堵 multiple 的 true 和 false 代表不同意思 true 代表批量应答 channel 上未应答的消息 比如说 channel 上有传送 tag 的消息 5,6,7,8 当前 tag 是8 那么此时 5-8 的这些还未应答的消息都会被确认收到消息应答 false 同上面相比 只会应答 tag=8 的消息 5,6,7 这三个消息依然不会被确认收到消息应答 3.2.5. 消息自动重新入队​ 如果消费者由于某些原因失去连接(其通道已关闭，连接已关闭或 TCP 连接丢失)，导致消息​ 未发送 ACK 确认，RabbitMQ 将了解到消息未完全处理，并将对其重新排队。如果此时其他消费者​ 可以处理，它将很快将其重新分发给另一个消费者。这样，即使某个消费者偶尔死亡，也可以确​ 保不会丢失任何消息。 3.2.6. 消息手动应答代码​ 默认消息采用的是自动应答，所以我们要想实现消息消费过程中不丢失，需要把自动应答改 为手动应答，消费者在上面代码的基础上增加下面画红色部分代码。 消费者 01 消费者 02 3.2.7. 手动应答效果演示​ 正常情况下消息发送方发送两个消息 C1 和 C2 分别接收到消息并进行处理 3.3. RabbitMQ 持久化3.3.1. 概念​ 刚刚我们已经看到了如何处理任务不丢失的情况，但是如何保障当 RabbitMQ 服务停掉以后消息生产者发送过来的消息不丢失。默认情况下 RabbitMQ 退出或由于某种原因崩溃时，它忽视队列和消息，除非告知它不要这样做。确保消息不会丢失需要做两件事：我们需要将队列和消息都标记为持久化。 3.3.2. 队列如何实现持久化​ 之前我们创建的队列都是非持久化的，rabbitmq 如果重启的化，该队列就会被删除掉，如果要队列实现持久化 需要在声明队列的时候把 durable 参数设置为持久化 ​ 但是需要注意的就是如果之前声明的队列不是持久化的，需要把原先队列先删除，或者重新创建一个持久化的队列，不然就会出现错误 以下为控制台中持久化与非持久化队列的 UI 显示区： 这个时候即使重启 rabbitmq 队列也依然存在 3.3.3. 消息实现持久化​ 要想让消息实现持久化需要在消息生产者修改代码，MessageProperties.PERSISTENT_TEXT_PLAIN 添加这个属性 ​ 将消息标记为持久化并不能完全保证不会丢失消息。尽管它告诉 RabbitMQ 将消息保存到磁盘，但是这里依然存在当消息刚准备储在磁盘的时候 但是还没有存储完，消息还在缓存的一个间隔点。此时并没有真正写入磁盘。持久性保证并不强，但是对于我们的简单任务队列而言，这已经绰绰有余了。如果需要更强有力的持久化策略，参考后边课件发布确认章节。 3.3.4. 不公平分发​ 在最开始的时候我们学习到 RabbitMQ 分发消息采用的轮训分发，但是在某种场景下这种策略并不是很好，比方说有两个消费者在处理任务，其中有个消费者 1 处理任务的速度非常快，而另外一个消费者 2处理速度却很慢，这个时候我们还是采用轮训分发的化就会到这处理速度快的这个消费者很大一部分时间处于空闲状态，而处理慢的那个消费者一直在干活，这种分配方式在这种情况下其实就不太好，但是RabbitMQ 并不知道这种情况它依然很公平的进行分发。为了避免这种情况，我们可以设置参数 channel.basicQos(1); ​ 意思就是如果这个任务我还没有处理完或者我还没有应答你，你先别分配给我，我目前只能处理一个任务，然后 rabbitmq 就会把该任务分配给没有那么忙的那个空闲消费者，当然如果所有的消费者都没有完成手上任务，队列还在不停的添加新任务，队列有可能就会遇到队列被撑满的情况，这个时候就只能添加新的 worker 或者改变其他存储任务的策略。 3.3.5. 预取值​ 本身消息的发送就是异步发送的，所以在任何时候，channel 上肯定不止只有一个消息另外来自消费者的手动确认本质上也是异步的。因此这里就存在一个未确认的消息缓冲区，因此希望开发人员能限制此缓冲区的大小，以避免缓冲区里面无限制的未确认消息问题。这个时候就可以通过使用 basic.qos 方法设置“预取计数”值来完成的。该值定义通道上允许的未确认消息的最大数量。 ​ 一旦数量达到配置的数量，RabbitMQ 将停止在通道上传递更多消息，除非至少有一个未处理的消息被确认，例如，假设在通道上有未确认的消息 5、6、7，8，并且通道的预取计数设置为 4，此时RabbitMQ 将不会在该通道上再传递任何消息，除非至少有一个未应答的消息被 ack。比方说 tag=6 这个消息刚刚被确认 ACK，RabbitMQ 将会感知这个情况到并再发送一条消息。消息应答和 QoS 预取值对用户吞吐量有重大影响。 ​ 通常，增加预取将提高向消费者传递消息的速度。虽然自动应答传输消息速率是最佳的，但是，在这种情况下已传递但尚未处理的消息的数量也会增加，从而增加了消费者的 RAM 消耗(随机存取存储器)应该小心使用具有无限预处理的自动确认模式或手动确认模式，消费者消费了大量的消息如果没有确认的话，会导致消费者连接节点的内存消耗变大，所以找到合适的预取值是一个反复试验的过程，不同的负载该值取值也不同 100 到 300 范围内的值通常可提供最佳的吞吐量，并且不会给消费者带来太大的风险。预取值为 1 是最保守的。当然这将使吞吐量变得很低，特别是消费者连接延迟很严重的情况下，特别是在消费者连接等待时间较长的环境中。对于大多数应用来说，稍微高一点的值将是最佳的。 4. 发布确认4.1. 发布确认原理​ 生产者将信道设置成 confirm 模式，一旦信道进入 confirm 模式，所有在该信道上面发布的消息都将会被指派一个唯一的 ID(从 1 开始)，一旦消息被投递到所有匹配的队列之后，broker 就会发送一个确认给生产者(包含消息的唯一 ID)，这就使得生产者知道消息已经正确到达目的队列了，如果消息和队列是可持久化的，那么确认消息会在将消息写入磁盘之后发出，broker 回传给生产者的确认消息中 delivery-tag 域包含了确认消息的序列号，此外 broker 也可以设置basic.ack 的multiple 域，表示到这个序列号之前的所有消息都已经得到了处理。confirm 模式最大的好处在于他是异步的，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果 RabbitMQ 因为自身内部错误导致消息丢失，就会发送一条 nack 消息，生产者应用程序同样可以在回调方法中处理该 nack 消息。 4.2. 发布确认的策略4.2.1. 开启发布确认的方法​ 发布确认默认是没有开启的，如果要开启需要调用方法 confirmSelect，每当你要想使用发布确认，都需要在 channel 上调用该方法 4.2.2. 单个确认发布​ 这是一种简单的确认方式，它是一种同步确认发布的方式，也就是发布一个消息之后只有它被确认发布，后续的消息才能继续发布,waitForConfirmsOrDie(long)这个方法只有在消息被确认的时候才返回，如果在指定时间范围内这个消息没有被确认那么它将抛出异常。这种确认方式有一个最大的缺点就是:发布速度特别的慢，因为如果没有确认发布的消息就会阻塞所有后续消息的发布，这种方式最多提供每秒不超过数百条发布消息的吞吐量。当然对于某些应用程序来说这可能已经足够了。 public static void publishMessageIndividually() throws Exception { try (Channel channel = RabbitMqUtils.getChannel()) { String queueName = UUID.randomUUID().toString(); channel.queueDeclare(queueName, false, false, false, null); //开启发布确认 channel.confirmSelect(); long begin = System.currentTimeMillis(); for (int i = 0; i &lt; MESSAGE_COUNT; i++) { String message = i + \"\"; channel.basicPublish(\"\", queueName, null, message.getBytes()); //服务端返回 false 或超时时间内未返回，生产者可以消息重发 boolean flag = channel.waitForConfirms(); if (flag) { System.out.println(\"消息发送成功\"); } } long end = System.currentTimeMillis(); System.out.println(\"发布\" + MESSAGE_COUNT + \"个单独确认消息,耗时\" + (end - begin) + \"ms\"); } } 4.2.3. 批量确认发布​ 上面那种方式非常慢，与单个等待确认消息相比，先发布一批消息然后一起确认可以极大地提高吞吐量，当然这种方式的缺点就是:当发生故障导致发布出现问题时，不知道是哪个消息出现问题了，我们必须将整个批处理保存在内存中，以记录重要的信息而后重新发布消息。当然这种方案仍然是同步的，也一样阻塞消息的发布。 public static void publishMessageBatch() throws Exception { try (Channel channel = RabbitMqUtils.getChannel()) { String queueName = UUID.randomUUID().toString(); channel.queueDeclare(queueName, false, false, false, null); //开启发布确认 channel.confirmSelect(); //批量确认消息大小 int batchSize = 100; //未确认消息个数 int outstandingMessageCount = 0; long begin = System.currentTimeMillis(); for (int i = 0; i &lt; MESSAGE_COUNT; i++) { String message = i + \"\"; channel.basicPublish(\"\", queueName, null, message.getBytes()); outstandingMessageCount++; if (outstandingMessageCount == batchSize) { channel.waitForConfirms(); outstandingMessageCount = 0; } } //为了确保还有剩余没有确认消息 再次确认 if (outstandingMessageCount &gt; 0) { channel.waitForConfirms(); } long end = System.currentTimeMillis(); System.out.println(\"发布\" + MESSAGE_COUNT + \"个批量确认消息,耗时\" + (end - begin) + \"ms\"); } } 4.2.4. 异步确认发布​ 异步确认虽然编程逻辑比上两个要复杂，但是性价比最高，无论是可靠性还是效率都没得说，他是利用回调函数来达到消息可靠性传递的，这个中间件也是通过函数回调来保证是否投递成功，下面就让我们来详细讲解异步确认是怎么实现的。 public static void publishMessageAsync() throws Exception { try (Channel channel = RabbitMqUtils.getChannel()) { String queueName = UUID.randomUUID().toString(); channel.queueDeclare(queueName, false, false, false, null); //开启发布确认 channel.confirmSelect(); /** * 线程安全有序的一个哈希表，适用于高并发的情况 * 1.轻松的将序号与消息进行关联 * 2.轻松批量删除条目 只要给到序列号 * 3.支持并发访问 */ ConcurrentSkipListMap&lt;Long, String&gt; outstandingConfirms = new ConcurrentSkipListMap&lt;&gt;(); /** * 确认收到消息的一个回调 * 1.消息序列号 * 2.true 可以确认小于等于当前序列号的消息 * false 确认当前序列号消息 */ ConfirmCallback ackCallback = (sequenceNumber, multiple) -&gt; { if (multiple) { //返回的是小于等于当前序列号的未确认消息 是一个 map ConcurrentNavigableMap&lt;Long, String&gt; confirmed = outstandingConfirms.headMap(sequenceNumber, true); //清除该部分未确认消息 confirmed.clear(); } else { //只清除当前序列号的消息 outstandingConfirms.remove(sequenceNumber); } }; ConfirmCallback nackCallback = (sequenceNumber, multiple) -&gt; { String message = outstandingConfirms.get(sequenceNumber); System.out.println(\"发布的消息\" + message + \"未被确认，序列号\" + sequenceNumber); }; /** * 添加一个异步确认的监听器 * 1.确认收到消息的回调 * 2.未收到消息的回调 */ channel.addConfirmListener(ackCallback, null); long begin = System.currentTimeMillis(); for (int i = 0; i &lt; MESSAGE_COUNT; i++) { String message = \"消息\" + i; /** * channel.getNextPublishSeqNo()获取下一个消息的序列号 * 通过序列号与消息体进行一个关联 * 全部都是未确认的消息体 */ outstandingConfirms.put(channel.getNextPublishSeqNo(), message); channel.basicPublish(\"\", queueName, null, message.getBytes()); \"ms\"); } } long end = System.currentTimeMillis(); System.out.println(\"发布\" + MESSAGE_COUNT + \"个异步确认消息,耗时\" + (end - begin) + } 4.2.5. 如何处理异步未确认消息​ 最好的解决的解决方案就是把未确认的消息放到一个基于内存的能被发布线程访问的队列，比如说用 ConcurrentLinkedQueue 这个队列在 confirm callbacks 与发布线程之间进行消息的传递。 4.2.6. 以上 3 种发布确认速度对比 单独发布消息 同步等待确认，简单，但吞吐量非常有限。 批量发布消息 批量同步等待确认，简单，合理的吞吐量，一旦出现问题但很难推断出是哪条消息出现了问题 异步处理： 最佳性能和资源使用，在出现错误的情况下可以很好地控制，但是实现起来稍微难些 public static void main(String[] args) throws Exception { //这个消息数量设置为 1000 好些 不然花费时间太长 publishMessagesIndividually(); publishMessagesInBatch(); handlePublishConfirmsAsynchronously(); } //运行结果 发布 1,000 个单独确认消息耗时 50,278 ms 发布 1,000 个批量确认消息耗时 635 ms 发布 1,000 个异步确认消息耗时 92 ms 5. 交换机​ 在上一节中，我们创建了一个工作队列。我们假设的是工作队列背后，每个任务都恰好交付给一个消费者(工作进程)。在这一部分中，我们将做一些完全不同的事情-我们将消息传达给多个消费者。这种模式称为 ”发布/订阅”.为了说明这种模式，我们将构建一个简单的日志系统。它将由两个程序组成:第一个程序将发出日志消息，第二个程序是消费者。其中我们会启动两个消费者，其中一个消费者接收到消息后把日志存储在磁盘，另外一个消费者接收到消息后把消息打印在屏幕上，事实上第一个程序发出的日志消息将广播给所有消费者者 5.1. Exchanges5.1.1. Exchanges 概念​ RabbitMQ 消息传递模型的核心思想是: 生产者生产的消息从不会直接发送到队列。实际上，通常生产 者甚至都不知道这些消息传递传递到了哪些队列中。 ​ 相反，生产者只能将消息发送到交换机**(exchange)**，交换机工作的内容非常简单，一方面它接收来 自生产者的消息，另一方面将它们推入队列。交换机必须确切知道如何处理收到的消息。是应该把这些消 息放到特定队列还是说把他们到许多队列中还是说应该丢弃它们。这就的由交换机的类型来决定。 5.1.2. Exchanges 的类型总共有以下类型： 直接(direct), 主题(topic) ,标题(headers) , 扇出(fanout) 5.1.3. 无名exchange​ 在前面部分我们对 exchange 一无所知，但仍然能够将消息发送到队列。之前能实现的原因是因为我们使用的是默认交换，我们通过空字符串(“”)进行标识 ​ 第一个参数是交换机的名称。空字符串表示默认或无名称交换机：消息能路由发送到队列中其实是由 routingKey(bindingkey)绑定 key 指定的，如果它存在的话 5.2. 临时队列​ 之前的章节我们使用的是具有特定名称的队列(还记得 hello 和 ack_queue 吗？)。队列的名称我们来说至关重要-我们需要指定我们的消费者去消费哪个队列的消息。每当我们连接到 Rabbit 时，我们都需要一个全新的空队列，为此我们可以创建一个具有随机名称的队列，或者能让服务器为我们选择一个随机队列名称那就更好了。其次一旦我们断开了消费者的连接，队列将被自动删除。 ​ 创建临时队列的方式如下: ​ String queueName = channel.queueDeclare().getQueue(); ​ 创建出来之后长成这样: 5.3. 绑定(bindings)​ 什么是 bingding 呢，binding 其实是 exchange 和 queue 之间的桥梁，它告诉我们 exchange 和那个队列进行了绑定关系。比如说下面这张图告诉我们的就是 X 与 Q1 和 Q2 进行了绑定 5.4. Fanout5.4.1. Fanout 介绍​ Fanout 这种类型非常简单。正如从名称中猜到的那样，它是将接收到的所有消息广播到它知道的所有队列中。系统中默认有些 exchange 类型 5.4.2. Fanout 实战 Logs 和临时队列的绑定关系如下图 ReceiveLogs01 将接收到的消息打印在控制台 public class ReceiveLogs01 { private static final String EXCHANGE_NAME = \"logs\"; public static void main(String[] argv) throws Exception { Channel channel = RabbitUtils.getChannel(); channel.exchangeDeclare(EXCHANGE_NAME, \"fanout\"); /** * 生成一个临时的队列 队列的名称是随机的 * 当消费者断开和该队列的连接时 队列自动删除 */ String queueName = channel.queueDeclare().getQueue(); //把该临时队列绑定我们的 exchange 其中 routingkey(也称之为 binding key)为空字符串 channel.queueBind(queueName, EXCHANGE_NAME, \"\"); System.out.println(\"等待接收消息,把接收到的消息打印在屏幕........... \"); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; { String message = new String(delivery.getBody(), \"UTF-8\"); System.out.println(\"控制台打印接收到的消息\" + message); }; channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; { }); } } ReceiveLogs02 将接收到的消息存储在磁盘 public class ReceiveLogs02 { private static final String EXCHANGE_NAME = \"logs\"; public static void main(String[] argv) throws Exception { Channel channel = RabbitUtils.getChannel(); channel.exchangeDeclare(EXCHANGE_NAME, \"fanout\"); /** * 生成一个临时的队列 队列的名称是随机的 * 当消费者断开和该队列的连接时 队列自动删除 */ String queueName = channel.queueDeclare().getQueue(); //把该临时队列绑定我们的 exchange 其中 routingkey(也称之为 binding key)为空字符串 channel.queueBind(queueName, EXCHANGE_NAME, \"\"); System.out.println(\"等待接收消息,把接收到的消息写到文件........... \"); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; {String message = new String(delivery.getBody(), \"UTF-8\"); File file = new File(\"C:\\\\work\\\\rabbitmq_info.txt\"); FileUtils.writeStringToFile(file,message,\"UTF-8\"); System.out.println(\"数据写入文件成功\"); }; channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; { }); } } EmitLog 发送消息给两个消费者接收 public class EmitLog { private static final String EXCHANGE_NAME = \"logs\"; public static void main(String[] argv) throws Exception { try (Channel channel = RabbitUtils.getChannel()) { /** * 声明一个 exchange * 1.exchange 的名称 * 2.exchange 的类型 */ channel.exchangeDeclare(EXCHANGE_NAME, \"fanout\"); Scanner sc = new Scanner(System.in); System.out.println(\"请输入信息\"); while (sc.hasNext()) { String message = sc.nextLine(); channel.basicPublish(EXCHANGE_NAME, \"\", null, message.getBytes(\"UTF-8\")); System.out.println(\"生产者发出消息\" + message); } } } } 5.5. Direct exchange5.5.1. 回顾​ 在上一节中，我们构建了一个简单的日志记录系统。我们能够向许多接收者广播日志消息。在本节我们将向其中添加一些特别的功能-比方说我们只让某个消费者订阅发布的部分消息。例如我们只把严重错误消息定向存储到日志文件(以节省磁盘空间)，同时仍然能够在控制台上打印所有日志消息。我们再次来回顾一下什么是 bindings，绑定是交换机和队列之间的桥梁关系。也可以这么理解：队列只对它绑定的交换机的消息感兴趣。绑定用参数：routingKey 来表示也可称该参数为 binding key，创建绑定我们用代码:channel.queueBind(queueName, EXCHANGE_NAME, “routingKey”);绑定之后的意义由其交换类型决定。 5.5.2. Direct exchange 介绍​ 上一节中的我们的日志系统将所有消息广播给所有消费者，对此我们想做一些改变，例如我们希望将日志消息写入磁盘的程序仅接收严重错误(errros)，而不存储哪些警告(warning)或信息(info)日志消息避免浪费磁盘空间。Fanout 这种交换类型并不能给我们带来很大的灵活性-它只能进行无意识的广播，在这里我们将使用 direct 这种类型来进行替换，这种类型的工作方式是，消息只去到它绑定的routingKey 队列中去。 ​ 在上面这张图中，我们可以看到 X 绑定了两个队列，绑定类型是 direct。队列Q1 绑定键为 orange，队列 Q2 绑定键有两个:一个绑定键为 black，另一个绑定键为 green. ​ 在这种绑定情况下，生产者发布消息到 exchange 上，绑定键为 orange 的消息会被发布到队列Q1。绑定键为 black 和green的消息会被发布到队列 Q2，其他消息类型的消息将被丢弃。 5.5.3. 多重绑定 ​ 当然如果 exchange 的绑定类型是direct，但是它绑定的多个队列的 key 如果都相同，在这种情况下虽然绑定类型是 direct 但是它表现的就和 fanout 有点类似了，就跟广播差不多，如上图所示。 5.5.4. 实战 public class ReceiveLogsDirect01 { private static final String EXCHANGE_NAME = \"direct_logs\"; public static void main(String[] argv) throws Exception { Channel channel = RabbitUtils.getChannel(); channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); String queueName = \"disk\"; channel.queueDeclare(queueName, false, false, false, null); channel.queueBind(queueName, EXCHANGE_NAME, \"error\"); System.out.println(\"等待接收消息........... \"); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; {String message = new String(delivery.getBody(), \"UTF-8\"); message=\"接收绑定键:\"+delivery.getEnvelope().getRoutingKey()+\",消息:\"+message; File file = new File(\"C:\\\\work\\\\rabbitmq_info.txt\"); FileUtils.writeStringToFile(file,message,\"UTF-8\"); System.out.println(\"错误日志已经接收\"); }; channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; { }); } } public class ReceiveLogsDirect02 { private static final String EXCHANGE_NAME = \"direct_logs\"; public static void main(String[] argv) throws Exception { Channel channel = RabbitUtils.getChannel(); channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); String queueName = \"console\"; channel.queueDeclare(queueName, false, false, false, null); channel.queueBind(queueName, EXCHANGE_NAME, \"info\"); channel.queueBind(queueName, EXCHANGE_NAME, \"warning\"); System.out.println(\"等待接收消息........... \"); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; {String message = new String(delivery.getBody(), \"UTF-8\"); System.out.println(\" 接收绑定键 :\"+delivery.getEnvelope().getRoutingKey()+\", 消 息:\"+message); }; channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; { }); } } public class EmitLogDirect { private static final String EXCHANGE_NAME = \"direct_logs\"; public static void main(String[] argv) throws Exception { try (Channel channel = RabbitUtils.getChannel()) { channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); //创建多个 bindingKey Map&lt;String, String&gt; bindingKeyMap = new HashMap&lt;&gt;(); bindingKeyMap.put(\"info\", \"普通 info 信息\"); bindingKeyMap.put(\"warning\", \"警告 warning 信息\"); bindingKeyMap.put(\"error\", \"错误 error 信息\"); //debug 没有消费这接收这个消息 所有就丢失了 bindingKeyMap.put(\"debug\", \"调试 debug 信息\"); for (Map.Entry&lt;String, String&gt; bindingKeyEntry : bindingKeyMap.entrySet()) { String bindingKey = bindingKeyEntry.getKey(); String message = bindingKeyEntry.getValue(); channel.basicPublish(EXCHANGE_NAME, bindingKey, null, message.getBytes(\"UTF-8\")); System.out.println(\"生产者发出消息:\" + message); } } } } 5.6. Topics5.6.1. 之前类型的问题​ 在上一个小节中，我们改进了日志记录系统。我们没有使用只能进行随意广播的 fanout 交换机，而是使用了 direct 交换机，从而有能实现有选择性地接收日志。 ​ 尽管使用direct 交换机改进了我们的系统，但是它仍然存在局限性-比方说我们想接收的日志类型有info.base 和 info.advantage，某个队列只想 info.base 的消息，那这个时候direct 就办不到了。这个时候就只能使用 topic 类型 5.6.2. Topic 的要求​ 发送到类型是 topic 交换机的消息的 routing_key 不能随意写，必须满足一定的要求，它必须是一个单词列表，以点号分隔开。这些单词可以是任意单词，比如说：”stock.usd.nyse”, “nyse.vmw”,”quick.orange.rabbit”.这种类型的。当然这个单词列表最多不能超过 255 个字节。 在这个规则列表中，其中有两个替换符是大家需要注意的 (星号)可以代替一个单词 #(井号)可以替代零个或多个单词 5.6.3. Topic 匹配案例下图绑定关系如下： Q1–&gt;绑定的是 中间带 orange 带 3 个单词的字符串(.orange.) Q2–&gt;绑定的是 最后一个单词是 rabbit 的 3 个单词(..rabbit) 第一个单词是 lazy 的多个单词(lazy.#) 上图是一个队列绑定关系图，我们来看看他们之间数据接收情况是怎么样的 quick.orange.rabbit 被队列 Q1Q2 接收到 lazy.orange.elephant 被队列 Q1Q2 接收到 quick.orange.fox 被队列 Q1 接收到 lazy.brown.fox 被队列 Q2 接收到 lazy.pink.rabbit 虽然满足两个绑定但只被队列 Q2 接收一次 quick.brown.fox 不匹配任何绑定不会被任何队列接收到会被丢弃 quick.orange.male.rabbit 是四个单词不匹配任何绑定会被丢弃 lazy.orange.male.rabbit 是四个单词但匹配 Q2 ​ 当队列绑定关系是下列这种情况时需要引起注意当一个队列绑定键是**#,那么这个队列将接收所有数据，就有点像 **fanout了如果队列绑定键当中没有#和出现，那么该队列绑定类型就是 direct 了 5.6.4. 实战 public class EmitLogTopic { private static final String EXCHANGE_NAME = \"topic_logs\"; public static void main(String[] argv) throws Exception {try (Channel channel = RabbitUtils.getChannel()) { channel.exchangeDeclare(EXCHANGE_NAME, \"topic\"); /** * Q1--&gt;绑定的是 * 中间带 orange 带 3 个单词的字符串(*.orange.*) * Q2--&gt;绑定的是 * 最后一个单词是 rabbit 的 3 个单词(*.*.rabbit) * 第一个单词是 lazy 的多个单词(lazy.#) * */ Map&lt;String, String&gt; bindingKeyMap = new HashMap&lt;&gt;(); bindingKeyMap.put(\"quick.orange.rabbit\",\"被队列 Q1Q2 接收到\"); bindingKeyMap.put(\"lazy.orange.elephant\",\"被队列 Q1Q2 接收到\"); bindingKeyMap.put(\"quick.orange.fox\",\"被队列 Q1 接收到\"); bindingKeyMap.put(\"lazy.brown.fox\",\"被队列 Q2 接收到\"); bindingKeyMap.put(\"lazy.pink.rabbit\",\"虽然满足两个绑定但只被队列 Q2 接收一次\"); bindingKeyMap.put(\"quick.brown.fox\",\"不匹配任何绑定不会被任何队列接收到会被丢弃\"); bindingKeyMap.put(\"quick.orange.male.rabbit\",\"是四个单词不匹配任何绑定会被丢弃\"); bindingKeyMap.put(\"lazy.orange.male.rabbit\",\"是四个单词但匹配 Q2\"); for (Map.Entry&lt;String, String&gt; bindingKeyEntry: bindingKeyMap.entrySet()){String bindingKey = bindingKeyEntry.getKey(); String message = bindingKeyEntry.getValue(); channel.basicPublish(EXCHANGE_NAME,bindingKey, null, message.getBytes(\"UTF-8\")); System.out.println(\"生产者发出消息\" + message); } } } } public class ReceiveLogsTopic01 { private static final String EXCHANGE_NAME = \"topic_logs\"; public static void main(String[] argv) throws Exception { Channel channel = RabbitUtils.getChannel(); channel.exchangeDeclare(EXCHANGE_NAME, \"topic\"); //声明 Q1 队列与绑定关系 String queueName=\"Q1\"; channel.queueDeclare(queueName, false, false, false, null); channel.queueBind(queueName, EXCHANGE_NAME, \"*.orange.*\"); System.out.println(\"等待接收消息........... \"); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; { String message = new String(delivery.getBody(), \"UTF-8\"); System.out.println(\" 接 收 队 列 :\"+queueName+\" 绑 定 键:\"+delivery.getEnvelope().getRoutingKey()+\",消息:\"+message); }; channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; { }); } } public class ReceiveLogsTopic02 { private static final String EXCHANGE_NAME = \"topic_logs\"; public static void main(String[] argv) throws Exception { Channel channel = RabbitUtils.getChannel(); channel.exchangeDeclare(EXCHANGE_NAME, \"topic\"); //声明 Q2 队列与绑定关系 String queueName=\"Q2\"; channel.queueDeclare(queueName, false, false, false, null); channel.queueBind(queueName, EXCHANGE_NAME, \"*.*.rabbit\"); channel.queueBind(queueName, EXCHANGE_NAME, \"lazy.#\"); System.out.println(\"等待接收消息........... \"); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; { String message = new String(delivery.getBody(), \"UTF-8\"); System.out.println(\" 接 收 队 列 :\"+queueName+\" 绑 定 键:\"+delivery.getEnvelope().getRoutingKey()+\",消息:\"+message); }; channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; { }); } } 6. 死信队列6.1. 死信的概念​ 先从概念解释上搞清楚这个定义，死信，顾名思义就是无法被消费的消息，字面意思可以这样理 解，一般来说，producer 将消息投递到 broker 或者直接到queue 里了，consumer 从 queue 取出消息 进行消费，但某些时候由于特定的原因导致 queue 中的某些消息无法被消费，这样的消息如果没有 后续的处理，就变成了死信，有死信自然就有了死信队列。 ​ 应用场景:为了保证订单业务的消息数据不丢失，需要使用到 RabbitMQ 的死信队列机制，当消息 消费发生异常时，将消息投入死信队列中.还有比如说: 用户在商城下单成功并点击去支付后在指定时 间未支付时自动失效 6.2. 死信的来源 消息 TTL 过期 队列达到最大长度(队列满了，无法再添加数据到 mq 中) 消息被拒绝(basic.reject 或 basic.nack)并且 requeue=false. 6.3. 死信实战6.3.1. 代码架构图 6.3.2. 消息TTL 过期生产者代码 public class Producer { private static final String NORMAL_EXCHANGE = \"normal_exchange\"; public static void main(String[] argv) throws Exception { try (Channel channel = RabbitMqUtils.getChannel()) { channel.exchangeDeclare(NORMAL_EXCHANGE, BuiltinExchangeType.DIRECT); //设置消息的 TTL 时间 AMQP.BasicProperties properties = new AMQP.BasicProperties().builder().expiration(\"10000\").build(); //该信息是用作演示队列个数限制 for (int i = 1; i &lt;11 ; i++) { String message=\"info\"+i; channel.basicPublish(NORMAL_EXCHANGE,\"zhangsan\",properties,message.getBytes()); System.out.println(\"生产者发送消息:\"+message); } } } } 消费者 C1 代码(启动之后关闭该消费者 模拟其接收不到消息) public class Consumer01 { //普通交换机名称 private static final String NORMAL_EXCHANGE = \"normal_exchange\"; //死信交换机名称 private static final String DEAD_EXCHANGE = \"dead_exchange\"; public static void main(String[] argv) throws Exception { Channel channel = RabbitUtils.getChannel(); //声明死信和普通交换机 类型为 direct channel.exchangeDeclare(NORMAL_EXCHANGE, BuiltinExchangeType.DIRECT); channel.exchangeDeclare(DEAD_EXCHANGE, BuiltinExchangeType.DIRECT); //声明死信队列 String deadQueue = \"dead-queue\"; channel.queueDeclare(deadQueue, false, false, false, null); //死信队列绑定死信交换机与 routingkey channel.queueBind(deadQueue, DEAD_EXCHANGE, \"lisi\"); //正常队列绑定死信队列信息 Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); //正常队列设置死信交换机 参数 key 是固定值 params.put(\"x-dead-letter-exchange\", DEAD_EXCHANGE); //正常队列设置死信 routing-key 参数 key 是固定值 params.put(\"x-dead-letter-routing-key\", \"lisi\"); String normalQueue = \"normal-queue\"; channel.queueDeclare(normalQueue, false, false, false, params); channel.queueBind(normalQueue, NORMAL_EXCHANGE, \"zhangsan\"); System.out.println(\"等待接收消息........... \"); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; {String message = new String(delivery.getBody(), \"UTF-8\"); System.out.println(\"Consumer01 接收到消息\"+message); }; channel.basicConsume(normalQueue, true, deliverCallback, consumerTag -&gt; { }); } } 消费者 C2 代码(以上步骤完成后 启动 C2 消费者 它消费死信队列里面的消息) public class Consumer02 { private static final String DEAD_EXCHANGE = \"dead_exchange\"; public static void main(String[] argv) throws Exception { Channel channel = RabbitUtils.getChannel(); channel.exchangeDeclare(DEAD_EXCHANGE, BuiltinExchangeType.DIRECT); String deadQueue = \"dead-queue\"; channel.queueDeclare(deadQueue, false, false, false, null); channel.queueBind(deadQueue, DEAD_EXCHANGE, \"lisi\"); System.out.println(\"等待接收死信队列消息........... \"); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; { String message = new String(delivery.getBody(), \"UTF-8\"); System.out.println(\"Consumer02 接收死信队列的消息\" + message); }; channel.basicConsume(deadQueue, true, deliverCallback, consumerTag -&gt; { }); } } 6.3.3. 队列达到最大长度 消息生产者代码去掉 TTL 属性 public class Producer { private static final String NORMAL_EXCHANGE = \"normal_exchange\"; public static void main(String[] argv) throws Exception { try (Channel channel = RabbitMqUtils.getChannel()) { channel.exchangeDeclare(NORMAL_EXCHANGE, BuiltinExchangeType.DIRECT); //该信息是用作演示队列个数限制 for (int i = 1; i &lt;11 ; i++) { String message=\"info\"+i; channel.basicPublish(NORMAL_EXCHANGE,\"zhangsan\",null, message.getBytes()); System.out.println(\"生产者发送消息:\"+message); } } } } C1 消费者修改以下代码(启动之后关闭该消费者 模拟其接收不到消息) 注意此时需要把原先队列删除 因为参数改变了 C2 消费者代码不变(启动 C2 消费者) 6.3.4. 消息被拒1.消息生产者代码同上生产者一致 2.C1 消费者代码(启动之后关闭该消费者 模拟其接收不到消息) public class Consumer01 { //普通交换机名称 private static final String NORMAL_EXCHANGE = \"normal_exchange\"; //死信交换机名称 private static final String DEAD_EXCHANGE = \"dead_exchange\"; public static void main(String[] argv) throws Exception { Channel channel = RabbitUtils.getChannel(); //声明死信和普通交换机 类型为 direct channel.exchangeDeclare(NORMAL_EXCHANGE, BuiltinExchangeType.DIRECT); channel.exchangeDeclare(DEAD_EXCHANGE, BuiltinExchangeType.DIRECT); //声明死信队列 String deadQueue = \"dead-queue\"; channel.queueDeclare(deadQueue, false, false, false, null); //死信队列绑定死信交换机与 routingkey channel.queueBind(deadQueue, DEAD_EXCHANGE, \"lisi\"); //正常队列绑定死信队列信息 Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); //正常队列设置死信交换机 参数 key 是固定值 params.put(\"x-dead-letter-exchange\", DEAD_EXCHANGE); //正常队列设置死信 routing-key 参数 key 是固定值 params.put(\"x-dead-letter-routing-key\", \"lisi\"); String normalQueue = \"normal-queue\"; channel.queueDeclare(normalQueue, false, false, false, params); channel.queueBind(normalQueue, NORMAL_EXCHANGE, \"zhangsan\"); System.out.println(\"等待接收消息........... \"); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; {String message = new String(delivery.getBody(), \"UTF-8\"); if(message.equals(\"info5\")){ System.out.println(\"Consumer01 接收到消息\" + message + \"并拒绝签收该消息\"); //requeue 设置为 false 代表拒绝重新入队 该队列如果配置了死信交换机将发送到死信队列中 channel.basicReject(delivery.getEnvelope().getDeliveryTag(), false); }else { System.out.println(\"Consumer01 接收到消息\"+message); channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); } }; boolean autoAck = false; channel.basicConsume(normalQueue, autoAck, deliverCallback, consumerTag -&gt; { }); } } 3.C2 消费者代码不变 ​ 启动消费者 1 然后再启动消费者 2 7. 延迟队列7.1. 延迟队列概念​ 延时队列,队列内部是有序的，最重要的特性就体现在它的延时属性上，延时队列中的元素是希望在指定时间到了以后或之前取出和处理，简单来说，延时队列就是用来存放需要在指定时间被处理的元素的队列。 7.2. 延迟队列使用场景 订单在十分钟之内未支付则自动取消 新创建的店铺，如果在十天内都没有上传过商品，则自动发送消息提醒。 用户注册成功后，如果三天内没有登陆则进行短信提醒 用户发起退款，如果三天内没有得到处理则通知相关运营人员 预定会议后，需要在预定的时间点前十分钟通知各个与会人员参加会议 ​ 这些场景都有一个特点，需要在某个事件发生之后或者之前的指定时间点完成某一项任务，如：发生订单生成事件，在十分钟之后检查该订单支付状态，然后将未支付的订单进行关闭；看起来似乎使用定时任务，一直轮询数据，每秒查一次，取出需要被处理的数据，然后处理不就完事了吗？如果数据量比较少，确实可以这样做，比如：对于“如果账单一周内未支付则进行自动结算”这样的需求，如果对于时间不是严格限制，而是宽松意义上的一周，那么每天晚上跑个定时任务检查一下所有未支付的账单，确实也是一个可行的方案。但对于数据量比较大，并且时效性较强的场景，如：“订单十分钟内未支付则关闭“，短期内未支付的订单数据可能会有很多，活动期间甚至会达到百万甚至千万级别，对这么庞大的数据量仍旧使用轮询的方式显然是不可取的，很可能在一秒内无法完成所有订单的检查，同时会给数据库带来很大压力，无法满足业务要求而且性能低下。 7.3. RabbitMQ 中的 TTL​ TTL 是什么呢？TTL 是 RabbitMQ 中一个消息或者队列的属性，表明一条消息或者该队列中的所有消息的最大存活时间，单位是毫秒。换句话说，如果一条消息设置了 TTL 属性或者进入了设置TTL 属性的队列，那么这条消息如果在TTL 设置的时间内没有被消费，则会成为”死信”。如果同时配置了队列的TTL 和消息的TTL，那么较小的那个值将会被使用，有两种方式设置 TTL。 7.3.1. 消息设置TTL​ 另一种方式便是针对每条消息设置TTL 7.3.2. 队列设置TTL​ 第一种是在创建队列的时候设置队列的“x-message-ttl”属性 7.3.3. 两者的区别​ 如果设置了队列的 TTL 属性，那么一旦消息过期，就会被队列丢弃(如果配置了死信队列被丢到死信队列中)，而第二种方式，消息即使过期，也不一定会被马上丢弃，因为消息是否过期是在即将投递到消费者之前判定的，如果当前队列有严重的消息积压情况，则已过期的消息也许还能存活较长时间；另外，还需要注意的一点是，如果不设置 TTL，表示消息永远不会过期，如果将 TTL 设置为 0，则表示除非此时可以直接投递该消息到消费者，否则该消息将会被丢弃。 ​ 前一小节我们介绍了死信队列，刚刚又介绍了 TTL，至此利用 RabbitMQ 实现延时队列的两大要素已经集齐，接下来只需要将它们进行融合，再加入一点点调味料，延时队列就可以新鲜出炉了。想想看，延时队列，不就是想要消息延迟多久被处理吗，TTL 则刚好能让消息在延迟多久之后成为死信，另一方面，成为死信的消息都会被投递到死信队列里，这样只需要消费者一直消费死信队列里的消息就完事了，因为里面的消息都是希望被立即处理的消息。 7.4. 整合 springboot7.4.1. 创建项目 7.4.2. 添加依赖&lt;dependencies&gt; &lt;!--RabbitMQ 依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.47&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--swagger--&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--RabbitMQ 测试依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.amqp&lt;/groupId&gt; &lt;artifactId&gt;spring-rabbit-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 7.4.3. 修改配置文件spring.rabbitmq.host=182.92.234.71 spring.rabbitmq.port=5672 spring.rabbitmq.username=admin spring.rabbitmq.password=123 7.4.4. 添加Swagger 配置类import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import springfox.documentation.builders.ApiInfoBuilder; import springfox.documentation.service.ApiInfo; import springfox.documentation.service.Contact; import springfox.documentation.spi.DocumentationType; import springfox.documentation.spring.web.plugins.Docket; import springfox.documentation.swagger2.annotations.EnableSwagger2; @Configuration @EnableSwagger2 public class SwaggerConfig {@Bean public Docket webApiConfig(){ return new Docket(DocumentationType.SWAGGER_2) .groupName(\"webApi\") .apiInfo(webApiInfo()) .select() .build(); } private ApiInfo webApiInfo(){ return new ApiInfoBuilder() .title(\"rabbitmq 接口文档\") .description(\"本文档描述了 rabbitmq 微服务接口定义\") .version(\"1.0\") .contact(new \"1551388580@qq.com\")) .build(); } } 7.5. 队列 TTL7.5.1. 代码架构图 ​ 创建两个队列 QA 和 QB，两者队列 TTL 分别设置为 10S 和 40S，然后在创建一个交换机 X 和死信交换机 Y，它们的类型都是direct，创建一个死信队列 QD，它们的绑定关系如下： 7.5.2. 配置文件类代码@Configuration public class TtlQueueConfig { public static final String X_EXCHANGE = \"X\"; public static final String QUEUE_A = \"QA\"; public static final String QUEUE_B = \"QB\"; public static final String Y_DEAD_LETTER_EXCHANGE = \"Y\"; public static final String DEAD_LETTER_QUEUE = \"QD\"; // 声明 xExchange @Bean(\"xExchange\") public DirectExchange xExchange() { return new DirectExchange(X_EXCHANGE); } // 声明 xExchange @Bean(\"yExchange\") public DirectExchange yExchange() { return new DirectExchange(Y_DEAD_LETTER_EXCHANGE); } //声明队列 A ttl 为 10s 并绑定到对应的死信交换机 @Bean(\"queueA\") public Queue queueA() { Map&lt;String, Object&gt; args = new HashMap&lt;&gt;(3); //声明当前队列绑定的死信交换机 args.put(\"x-dead-letter-exchange\", Y_DEAD_LETTER_EXCHANGE); //声明当前队列的死信路由 key args.put(\"x-dead-letter-routing-key\", \"YD\"); //声明队列的 TTL args.put(\"x-message-ttl\", 10000); return QueueBuilder.durable(QUEUE_A).withArguments(args).build(); } // 声明队列 A 绑定 X 交换机 @Bean public Binding queueaBindingX(@Qualifier(\"queueA\") Queue queueA, @Qualifier(\"xExchange\") DirectExchange xExchange) { return BindingBuilder.bind(queueA).to(xExchange).with(\"XA\"); } //声明队列 B ttl 为 40s 并绑定到对应的死信交换机 @Bean(\"queueB\") public Queue queueB() { Map&lt;String, Object&gt; args = new HashMap&lt;&gt;(3); //声明当前队列绑定的死信交换机 args.put(\"x-dead-letter-exchange\", Y_DEAD_LETTER_EXCHANGE); //声明当前队列的死信路由 key args.put(\"x-dead-letter-routing-key\", \"YD\"); //声明队列的 TTL args.put(\"x-message-ttl\", 40000); return QueueBuilder.durable(QUEUE_B).withArguments(args).build(); } //声明队列 B 绑定 X 交换机 @Bean public Binding queuebBindingX(@Qualifier(\"queueB\") Queue queue1B, @Qualifier(\"xExchange\") DirectExchange xExchange) { return BindingBuilder.bind(queue1B).to(xExchange).with(\"XB\"); } //声明死信队列 QD @Bean(\"queueD\") public Queue queueD() { return new Queue(DEAD_LETTER_QUEUE); } //声明死信队列 QD 绑定关系 @Bean public Binding deadLetterBindingQAD(@Qualifier(\"queueD\") Queue queueD, @Qualifier(\"yExchange\") DirectExchange yExchange) { return BindingBuilder.bind(queueD).to(yExchange).with(\"YD\"); } } 7.5.3. 消息生产者代码@RequestMapping(\"ttl\") @RestController public class SendMsgController {@Autowired private RabbitTemplate rabbitTemplate; @GetMapping(\"sendMsg/{message}\") public void sendMsg(@PathVariable String message){ log.info(\"当前时间：{},发送一条信息给两个 TTL 队列:{}\", new Date(), message); rabbitTemplate.convertAndSend(\"X\", \"XA\", \"消息来自 ttl 为 10S 的队列: \"+message); rabbitTemplate.convertAndSend(\"X\", \"XB\", \"消息来自 ttl 为 40S 的队列: \"+message); } } 7.5.4. 消息消费者代码@Slf4j @Component public class DeadLetterQueueConsumer { @RabbitListener(queues = \"QD\") public void receiveD(Message message, Channel channel) throws IOException {String msg = new String(message.getBody()); log.info(\"当前时间：{},收到死信队列信息{}\", new Date().toString(), msg); } } 发起一个请求 http://localhost:8080/ttl/sendMsg/嘻嘻嘻 ​ 第一条消息在 10S 后变成了死信消息，然后被消费者消费掉，第二条消息在 40S 之后变成了死信消息，然后被消费掉，这样一个延时队列就打造完成了。 ​ 不过，如果这样使用的话，岂不是每增加一个新的时间需求，就要新增一个队列，这里只有 10S 和 40S两个时间选项，如果需要一个小时后处理，那么就需要增加TTL 为一个小时的队列，如果是预定会议室然后提前通知这样的场景，岂不是要增加无数个队列才能满足需求？ 7.6. 延时队列优化7.6.1. 代码架构图​ 在这里新增了一个队列 QC,绑定关系如下,该队列不设置TTL 时间 7.6.2. 配置文件类代码@Component public class MsgTtlQueueConfig { public static final String Y_DEAD_LETTER_EXCHANGE = \"Y\"; public static final String QUEUE_C = \"QC\"; //声明队列 C 死信交换机 @Bean(\"queueC\") public Queue queueB(){ Map&lt;String, Object&gt; args = new HashMap&lt;&gt;(3); //声明当前队列绑定的死信交换机 args.put(\"x-dead-letter-exchange\", Y_DEAD_LETTER_EXCHANGE); //声明当前队列的死信路由 key args.put(\"x-dead-letter-routing-key\", \"YD\"); //没有声明 TTL 属性 return QueueBuilder.durable(QUEUE_C).withArguments(args).build(); } //声明队列 B 绑定 X 交换机 @Bean public Binding queuecBindingX(@Qualifier(\"queueC\") Queue queueC, @Qualifier(\"xExchange\") DirectExchange xExchange){ return BindingBuilder.bind(queueC).to(xExchange).with(\"XC\"); } } 7.6.3. 消息生产者代码@GetMapping(\"sendExpirationMsg/{message}/{ttlTime}\") public void sendMsg(@PathVariable String message,@PathVariable String ttlTime) { rabbitTemplate.convertAndSend(\"X\", \"XC\", message, correlationData -&gt;{correlationData.getMessageProperties().setExpiration(ttlTime); return correlationData; }); log.info(\"当前时间：{},发送一条时长{}毫秒 TTL 信息给队列 C:{}\", new Date(),ttlTime, message); } 发起请求 http://localhost:8080/ttl/sendExpirationMsg/你好 1/20000 http://localhost:8080/ttl/sendExpirationMsg/你好 2/2000 ​ 看起来似乎没什么问题，但是在最开始的时候，就介绍过如果使用在消息属性上设置 TTL 的方式，消息可能并不会按时“死亡“，因为 RabbitMQ 只会检查第一个消息是否过期，如果过期则丢到死信队列，如果第一个消息的延时时长很长，而第二个消息的延时时长很短，第二个消息并不会优先得到执行。 7.7. Rabbitmq 插件实现延迟队列​ 上文中提到的问题，确实是一个问题，如果不能实现在消息粒度上的 TTL，并使其在设置的TTL 时间及时死亡，就无法设计成一个通用的延时队列。那如何解决呢，接下来我们就去解决该问题。 7.7.1.安装延时队列插件 ​ 在官网上下载 https://www.rabbitmq.com/community-plugins.html，下载 rabbitmq_delayed_message_exchange 插件，然后解压放置到 RabbitMQ 的插件目录。进入 RabbitMQ 的安装目录下的 plgins 目录，执行下面命令让该插件生效，然后重启 RabbitMQ ​ /usr/lib/rabbitmq/lib/rabbitmq_server-3.8.8/plugins ​ rabbitmq-plugins enable rabbitmq_delayed_message_exchange 7.7.2. 代码架构图​ 在这里新增了一个队列delayed.queue,一个自定义交换机 delayed.exchange，绑定关系如下: 7.7.3. 配置文件类代码​ 在我们自定义的交换机中，这是一种新的交换类型，该类型消息支持延迟投递机制 消息传递后并不会立即投递到目标队列中，而是存储在 mnesia(一个分布式数据系统)表中，当达到投递时间时，才投递到目标队列中。 @Configuration public class DelayedQueueConfig { public static final String DELAYED_QUEUE_NAME = \"delayed.queue\"; public static final String DELAYED_EXCHANGE_NAME = \"delayed.exchange\"; public static final String DELAYED_ROUTING_KEY = \"delayed.routingkey\"; @Bean public Queue delayedQueue() { return new Queue(DELAYED_QUEUE_NAME); } //自定义交换机 我们在这里定义的是一个延迟交换机 @Bean public CustomExchange delayedExchange() { Map&lt;String, Object&gt; args = new HashMap&lt;&gt;(); //自定义交换机的类型 args.put(\"x-delayed-type\", \"direct\"); return new CustomExchange(DELAYED_EXCHANGE_NAME, \"x-delayed-message\", true, false, args); } @Bean public Binding bindingDelayedQueue(@Qualifier(\"delayedQueue\") Queue queue, @Qualifier(\"delayedExchange\") CustomExchange delayedExchange) { return BindingBuilder.bind(queue).to(delayedExchange).with(DELAYED_ROUTING_KEY).noargs(); } } 7.7.4. 消息生产者代码public static final String DELAYED_EXCHANGE_NAME = \"delayed.exchange\"; public static final String DELAYED_ROUTING_KEY = \"delayed.routingkey\"; @GetMapping(\"sendDelayMsg/{message}/{delayTime}\") public void sendMsg(@PathVariable String message, @PathVariable Integer delayTime) { rabbitTemplate.convertAndSend(DELAYED_EXCHANGE_NAME, DELAYED_ROUTING_KEY, message, correlationData -&gt; { correlationData.getMessageProperties().setDelay(delayTime); return correlationData; }); log.info(\" 当 前 时 间 ： {}, 发 送 一 条 延 迟 {} 毫秒的信息给队列 delayed.queue:{}\", new Date(), delayTime, message); } 7.7.5. 消息消费者代码public static final String DELAYED_QUEUE_NAME = \"delayed.queue\"; @RabbitListener(queues = DELAYED_QUEUE_NAME) public void receiveDelayedQueue(Message message) { String msg = new String(message.getBody()); log.info(\"当前时间：{},收到延时队列的消息：{}\", new Date().toString(), msg); 发起请求： http://localhost:8080/ttl/sendDelayMsg/come on baby1/20000 http://localhost:8080/ttl/sendDelayMsg/come on baby2/2000 第二个消息被先消费掉了，符合预期 7.8. 总结​ 延时队列在需要延时处理的场景下非常有用，使用 RabbitMQ 来实现延时队列可以很好的利用RabbitMQ 的特性，如：消息可靠发送、消息可靠投递、死信队列来保障消息至少被消费一次以及未被正确处理的消息不会被丢弃。另外，通过 RabbitMQ 集群的特性，可以很好的解决单点故障问题，不会因为单个节点挂掉导致延时队列不可用或者消息丢失。 ​ 当然，延时队列还有很多其它选择，比如利用 Java 的 DelayQueue，利用 Redis 的 zset，利用 Quartz 或者利用 kafka 的时间轮，这些方式各有特点,看需要适用的场景 8. 发布确认高级​ 在生产环境中由于一些不明原因，导致 rabbitmq 重启，在 RabbitMQ 重启期间生产者消息投递失败，导致消息丢失，需要手动处理和恢复。于是，我们开始思考，如何才能进行 RabbitMQ 的消息可靠投递呢？ 特别是在这样比较极端的情况，RabbitMQ 集群不可用的时候，无法投递的消息该如何处理呢: 应 用 [xxx] 在 [08-1516:36:04] 发 生 [ 错 误 日 志 异 常 ] ， alertId=[xxx] 。 由[org.springframework.amqp.rabbit.listener.BlockingQueueConsumer:start:620] 触 发 . 应用 xxx 可能原因如下 服 务 名 为 ： 异 常 为 ： org.springframework.amqp.rabbit.listener.BlockingQueueConsumer:start:620, 产 生 原 因 如 下 :1.org.springframework.amqp.rabbit.listener.QueuesNotAvailableException: Cannot prepare queue for listener. Either the queue doesn’t exist or the broker will not allow us to use it.||Consumer received fatal=false exception on startup: 8.1. 发布确认 springboot 版本8.1.1. 确认机制方案 8.1.2. 代码架构图 8.1.3. 配置文件 在配置文件当中需要添加spring.rabbitmq.publisher-confirm-type=correlated NONE 禁用发布确认模式，是默认值 CORRELATED 发布消息成功到交换器后会触发回调方法 SIMPLE ​ 经测试有两种效果，其一效果和 CORRELATED 值一样会触发回调方法，其二在发布消息成功后使用 rabbitTemplate 调用 waitForConfirms 或 waitForConfirmsOrDie 方法等待 broker 节点返回发送结果，根据返回结果来判定下一步的逻辑，要注意的点是 waitForConfirmsOrDie 方法如果返回 false 则会关闭 channel，则接下来无法发送消息到 broker spring.rabbitmq.host=182.92.234.71 spring.rabbitmq.port=5672 spring.rabbitmq.username=admin spring.rabbitmq.password=123 spring.rabbitmq.publisher-confirm-type=correlated 8.1.4. 添加配置类@Configuration public class ConfirmConfig { public static final String CONFIRM_EXCHANGE_NAME = \"confirm.exchange\"; public static final String CONFIRM_QUEUE_NAME = \"confirm.queue\"; //声明业务 Exchange @Bean(\"confirmExchange\") public DirectExchange confirmExchange(){ return new DirectExchange(CONFIRM_EXCHANGE_NAME); } // 声明确认队列 @Bean(\"confirmQueue\") public Queue confirmQueue(){ return QueueBuilder.durable(CONFIRM_QUEUE_NAME).build(); } // 声明确认队列绑定关系 @Bean public Binding queueBinding(@Qualifier(\"confirmQueue\") Queue queue, @Qualifier(\"confirmExchange\") DirectExchange exchange){ return BindingBuilder.bind(queue).to(exchange).with(\"key1\"); } } 8.1.5. 消息生产者@RestController @RequestMapping(\"/confirm\") @Slf4j public class Producer { public static final String CONFIRM_EXCHANGE_NAME = \"confirm.exchange\"; @Autowired private RabbitTemplate rabbitTemplate; @Autowired private MyCallBack myCallBack; //依赖注入 rabbitTemplate 之后再设置它的回调对象 @PostConstruct public void init(){ rabbitTemplate.setConfirmCallback(myCallBack); } @GetMapping(\"sendMessage/{message}\") public void sendMessage(@PathVariable String message){ //指定消息 id 为 1 CorrelationData correlationData1=new CorrelationData(\"1\"); String routingKey=\"key1\"; rabbitTemplate.convertAndSend(CONFIRM_EXCHANGE_NAME,routingKey,message+routingKey,correl ationData1); CorrelationData correlationData2=new CorrelationData(\"2\"); routingKey=\"key2\"; rabbitTemplate.convertAndSend(CONFIRM_EXCHANGE_NAME,routingKey,message+routingKey,correl ationData2); log.info(\"发送消息内容:{}\",message); } } 8.1.6. 回调接口@Component @Slf4j public class MyCallBack implements RabbitTemplate.ConfirmCallback { /** * 交换机不管是否收到消息的一个回调方法 * CorrelationData * 消息相关数据 * ack * 交换机是否收到消息 */ @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) {String id=correlationData!=null?correlationData.getId():\"\"; if(ack){ log.info(\"交换机已经收到 id 为:{}的消息\",id); }else{ log.info(\"交换机还未收到 id 为:{}消息,由于原因:{}\",id,cause); } } } 8.1.7. 消息消费者@Component @Slf4j public class ConfirmConsumer { public static final String CONFIRM_QUEUE_NAME = \"confirm.queue\"; @RabbitListener(queues =CONFIRM_QUEUE_NAME) public void receiveMsg(Message message){ String msg=new String(message.getBody()); log.info(\"接受到队列 confirm.queue 消息:{}\",msg); } } 8.1.8. 结果分析 ​ 可以看到，发送了两条消息，第一条消息的 RoutingKey 为 “key1”，第二条消息的 RoutingKey 为”key2”，两条消息都成功被交换机接收，也收到了交换机的确认回调，但消费者只收到了一条消息，因为第二条消息的 RoutingKey 与队列的 BindingKey 不一致，也没有其它队列能接收这个消息，所有第二条消息被直接丢弃了。 8.2. 回退消息8.2.1. Mandatory 参数在仅开启了生产者确认机制的情况下，交换机接收到消息后，会直接给消息生产者发送确认消息，如 果发现该消息不可路由，那么消息会被直接丢弃，此时生产者是不知道消息被丢弃这个事件的。那么如何 让无法被路由的消息帮我想办法处理一下？最起码通知我一声，我好自己处理啊。通过设置 mandatory 参 数可以在当消息传递过程中不可达目的地时将消息返回给生产者。 8.2.2. 消息生产者代码@Slf4j @Component public class MessageProducer implements RabbitTemplate.ConfirmCallback, RabbitTemplate.ReturnCallback{ @Autowired private RabbitTemplate rabbitTemplate; //rabbitTemplate 注入之后就设置该值 @PostConstruct private void init() { rabbitTemplate.setConfirmCallback(this); /** * true： * 交换机无法将消息进行路由时，会将该消息返回给生产者 * false： * 如果发现消息无法进行路由，则直接丢弃 */ rabbitTemplate.setMandatory(true); //设置回退消息交给谁处理 rabbitTemplate.setReturnCallback(this); } @GetMapping(\"sendMessage\") public void sendMessage(String message){ //让消息绑定一个 id 值 CorrelationData correlationData1 = new CorrelationData(UUID.randomUUID().toString()); rabbitTemplate.convertAndSend(\"confirm.exchange\",\"key1\",message+\"key1\",correlationData1) ; log.info(\"发送消息 id 为:{}内容为{}\",correlationData1.getId(),message+\"key1\"); CorrelationData correlationData2 = new CorrelationData(UUID.randomUUID().toString()); rabbitTemplate.convertAndSend(\"confirm.exchange\",\"key2\",message+\"key2\",correlationData2) ; log.info(\"发送消息 id 为:{}内容为{}\",correlationData2.getId(),message+\"key2\"); } @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) {String id = correlationData != null ? correlationData.getId() : \"\"; if (ack) { log.info(\"交换机收到消息确认成功, id:{}\", id); } else { log.error(\"消息 id:{}未成功投递到交换机,原因是:{}\", id, cause); } } @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) { log.info(\"消息:{}被服务器退回，退回原因:{}, 交换机是:{}, 路由 key:{}\", new String(message.getBody()),replyText, exchange, routingKey); } } 8.2.3. 回调接口@Component @Slf4j public class MyCallBack implements RabbitTemplate.ConfirmCallback,RabbitTemplate.ReturnCallback { /** * 交换机不管是否收到消息的一个回调方法 * CorrelationData * 消息相关数据 * ack * 交换机是否收到消息 */ @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) {String id=correlationData!=null?correlationData.getId():\"\"; if(ack){ log.info(\"交换机已经收到 id 为:{}的消息\",id); }else{ log.info(\"交换机还未收到 id 为:{}消息,由于原因:{}\",id,cause); } } //当消息无法路由的时候的回调方法 @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) { log.error(\" 消 息 {}, 被 交 换 机 {} 退 回 ， 退 回 原 因 :{}, 路 由 key:{}\",new String(message.getBody()),exchange,replyText,routingKey); } } 8.2.4. 结果分析 8.3. 备份交换机​ 有了 mandatory 参数和回退消息，我们获得了对无法投递消息的感知能力，有机会在生产者的消息无法被投递时发现并处理。但有时候，我们并不知道该如何处理这些无法路由的消息，最多打个日志，然后触发报警，再来手动处理。而通过日志来处理这些无法路由的消息是很不优雅的做法，特别是当生产者所在的服务有多台机器的时候，手动复制日志会更加麻烦而且容易出错。而且设置 mandatory 参数会增加生产者的复杂性，需要添加处理这些被退回的消息的逻辑。如果既不想丢失消息，又不想增加生产者的复杂性，该怎么做呢？前面在设置死信队列的文章中，我们提到，可以为队列设置死信交换机来存储那些处理失败的消息，可是这些不可路由消息根本没有机会进入到队列，因此无法使用死信队列来保存消息。在 RabbitMQ 中，有一种备份交换机的机制存在，可以很好的应对这个问题。什么是备份交换机呢？备份交换机可以理解为 RabbitMQ 中交换机的“备胎”，当我们为某一个交换机声明一个对应的备份交换机时，就是为它创建一个备胎，当交换机接收到一条不可路由消息时，将会把这条消息转发到备份交换机中，由备份交换机来进行转发和处理，通常备份交换机的类型为 Fanout ，这样就能把所有消息都投递到与其绑定的队列中，然后我们在备份交换机下绑定一个队列，这样所有那些原交换机无法被路由的消息，就会都进入这个队列了。当然，我们还可以建立一个报警队列，用独立的消费者来进行监测和报警。 8.3.1. 代码架构图 8.3.2. 修改配置类@Configuration public class ConfirmConfig { public static final String CONFIRM_EXCHANGE_NAME = \"confirm.exchange\"; public static final String CONFIRM_QUEUE_NAME = \"confirm.queue\"; public static final String BACKUP_EXCHANGE_NAME = \"backup.exchange\"; public static final String BACKUP_QUEUE_NAME = \"backup.queue\"; public static final String WARNING_QUEUE_NAME = \"warning.queue\"; // 声明确认队列 @Bean(\"confirmQueue\") public Queue confirmQueue(){ return QueueBuilder.durable(CONFIRM_QUEUE_NAME).build(); } //声明确认队列绑定关系 @Bean public Binding queueBinding(@Qualifier(\"confirmQueue\") Queue queue, @Qualifier(\"confirmExchange\") DirectExchange exchange){ return BindingBuilder.bind(queue).to(exchange).with(\"key1\"); } //声明备份 Exchange @Bean(\"backupExchange\") public FanoutExchange backupExchange(){ return new FanoutExchange(BACKUP_EXCHANGE_NAME); } //声明确认 Exchange 交换机的备份交换机 @Bean(\"confirmExchange\") public DirectExchange confirmExchange(){ExchangeBuilder exchangeBuilder = ExchangeBuilder.directExchange(CONFIRM_EXCHANGE_NAME) .durable(true) //设置该交换机的备份交换机 .withArgument(\"alternate-exchange\", BACKUP_EXCHANGE_NAME); return (DirectExchange)exchangeBuilder.build(); } // 声明警告队列 @Bean(\"warningQueue\") public Queue warningQueue(){ return QueueBuilder.durable(WARNING_QUEUE_NAME).build(); } // 声明报警队列绑定关系 @Bean public Binding warningBinding(@Qualifier(\"warningQueue\") Queue queue, @Qualifier(\"backupExchange\") FanoutExchange backupExchange){ return BindingBuilder.bind(queue).to(backupExchange); } // 声明备份队列 @Bean(\"backQueue\") public Queue backQueue(){ return QueueBuilder.durable(BACKUP_QUEUE_NAME).build(); } // 声明备份队列绑定关系 @Bean public Binding backupBinding(@Qualifier(\"backQueue\") Queue queue, @Qualifier(\"backupExchange\") FanoutExchange backupExchange){ return BindingBuilder.bind(queue).to(backupExchange); } } 8.3.3. 报警消费者@Component @Slf4j public class WarningConsumer { public static final String WARNING_QUEUE_NAME = \"warning.queue\"; @RabbitListener(queues = WARNING_QUEUE_NAME) public void receiveWarningMsg(Message message) {String msg = new String(message.getBody()); log.error(\"报警发现不可路由消息：{}\", msg); } } 8.3.4. 测试注意事项​ 重新启动项目的时候需要把原来的confirm.exchange 删除因为我们修改了其绑定属性，不然报以下错: 8.3.5. 结果分析 ​ mandatory 参数与备份交换机可以一起使用的时候，如果两者同时开启，消息究竟何去何从？谁优先级高，经过上面结果显示答案是备份交换机优先级高 9. RabbitMQ 其他知识点9.1. 幂等性9.1.1. 概念​ 用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。举个最简单的例子，那就是支付，用户购买商品后支付，支付扣款成功，但是返回结果的时候网络异常，此时钱已经扣了，用户再次点击按钮，此时会进行第二次扣款，返回结果成功，用户查询余额发现多扣钱了，流水记录也变成了两条。在以前的单应用系统中，我们只需要把数据操作放入事务中即可，发生错误 9.1.2. 消息重复消费​ 消费者在消费 MQ 中的消息时，MQ 已把消息发送给消费者，消费者在给MQ 返回 ack 时网络中断，故 MQ 未收到确认信息，该条消息会重新发给其他的消费者，或者在网络重连后再次发送给该消费者，但实际上该消费者已成功消费了该条消息，造成消费者消费了重复的消息。 9.1.3. 解决思路​ MQ 消费者的幂等性的解决一般使用全局 ID 或者写个唯一标识比如时间戳 或者 UUID 或者订单消费者消费 MQ 中的消息也可利用 MQ 的该 id 来判断，或者可按自己的规则生成一个全局唯一 id，每次消费消息时用该 id 先判断该消息是否已消费过。 9.1.4. 消费端的幂等性保障​ 在海量订单生成的业务高峰期，生产端有可能就会重复发生了消息，这时候消费端就要实现幂等性，这就意味着我们的消息永远不会被消费多次，即使我们收到了一样的消息。业界主流的幂等性有两种操作:a.唯一 ID+指纹码机制,利用数据库主键去重, b.利用 redis 的原子性去实现 9.1.5. 唯一ID+指纹码机制​ 指纹码:我们的一些规则或者时间戳加别的服务给到的唯一信息码,它并不一定是我们系统生成的，基本都是由我们的业务规则拼接而来，但是一定要保证唯一性，然后就利用查询语句进行判断这个 id 是否存在数据库中,优势就是实现简单就一个拼接，然后查询判断是否重复；劣势就是在高并发时，如果是单个数据库就会有写入性能瓶颈当然也可以采用分库分表提升性能，但也不是我们最推荐的方式。 9.1.6. Redis 原子性​ 利用 redis 执行 setnx 命令，天然具有幂等性。从而实现不重复消费 9.2. 优先级队列​ 立即回滚，但是再响应客户端的时候也有可能出现网络中断或者异常等等 9.2.1. 使用场景​ 在我们系统中有一个订单催付的场景，我们的客户在天猫下的订单,淘宝会及时将订单推送给我们，如果在用户设定的时间内未付款那么就会给用户推送一条短信提醒，很简单的一个功能对吧，但是，tmall商家对我们来说，肯定是要分大客户和小客户的对吧，比如像苹果，小米这样大商家一年起码能给我们创造很大的利润，所以理应当然，他们的订单必须得到优先处理，而曾经我们的后端系统是使用 redis 来存放的定时轮询，大家都知道 redis 只能用 List 做一个简简单单的消息队列，并不能实现一个优先级的场景，所以订单量大了后采用 RabbitMQ 进行改造和优化,如果发现是大客户的订单给一个相对比较高的优先级， 否则就是默认优先级。 9.2.2. 如何添加a.控制台页面添加 b.队列中代码添加优先级 c.消息中代码添加优先级 d.注意事项 ​ 要让队列实现优先级需要做的事情有如下事情:队列需要设置为优先级队列，消息需要设置消息的优先级，消费者需要等待消息已经发送到队列中才去消费因为，这样才有机会对消息进行排序 9.2.3. 实战a.消息生产者 public class Producer { private static final String QUEUE_NAME=\"hello\"; public static void main(String[] args) throws Exception { try (Channel channel = RabbitMqUtils.getChannel();) { //给消息赋予一个 priority 属性 AMQP.BasicProperties properties = new AMQP.BasicProperties().builder().priority(5).build(); for (int i = 1; i &lt;11; i++) { String message = \"info\"+i; if(i==5){ channel.basicPublish(\"\", QUEUE_NAME, properties, message.getBytes()); }else{ channel.basicPublish(\"\", QUEUE_NAME, null, message.getBytes()); } System.out.println(\"发送消息完成:\" + message); } } } } b.消息消费者 public class Consumer { private static final String QUEUE_NAME = \"hello\"; public static void main(String[] args) throws Exception { Channel channel = RabbitMqUtils.getChannel(); //设置队列的最大优先级 最大可以设置到 255 官网推荐 1-10 如果设置太高比较吃内存和 CPU Map&lt;String, Object&gt; params = new HashMap(); params.put(\"x-max-priority\", 10); channel.queueDeclare(QUEUE_NAME, true, false, false, params); System.out.println(\"消费者启动等待消费..............\"); DeliverCallback deliverCallback = (consumerTag, delivery)- &gt; {String receivedMessage = new String(delivery.getBody()); System.out.println(\"接收到消 息:\"+receivedMessage); }; channel.basicConsume(QUEUE_NAME, true, deliverCallback, (consumerTag) -&gt; { System.out.println(\"消费者无法消费消息时调用，如队列被删除\"); }); } } 9.3. 惰性队列9.3.1. 使用场景​ RabbitMQ 从 3.6.0 版本开始引入了惰性队列的概念。惰性队列会尽可能的将消息存入磁盘中，而在消费者消费到相应的消息时才会被加载到内存中，它的一个重要的设计目标是能够支持更长的队列，即支持更多的消息存储。当消费者由于各种各样的原因(比如消费者下线、宕机亦或者是由于维护而关闭等)而致使长时间内不能消费消息造成堆积时，惰性队列就很有必要了。默认情况下，当生产者将消息发送到 RabbitMQ 的时候，队列中的消息会尽可能的存储在内存之中，这样可以更加快速的将消息发送给消费者。即使是持久化的消息，在被写入磁盘的同时也会在内存中驻留一份备份。当 RabbitMQ 需要释放内存的时候，会将内存中的消息换页至磁盘中，这个操作会耗费较长的时间，也会阻塞队列的操作，进而无法接收新的消息。虽然 RabbitMQ 的开发者们一直在升级相关的算法，但是效果始终不太理想，尤其是在消息量特别大的时候。 9.3.2. 两种模式​ 队列具备两种模式：default 和 lazy。默认的为default 模式，在3.6.0 之前的版本无需做任何变更。lazy模式即为惰性队列的模式，可以通过调用 channel.queueDeclare 方法的时候在参数中设置，也可以通过Policy 的方式设置，如果一个队列同时使用这两种方式设置的话，那么 Policy 的方式具备更高的优先级。如果要通过声明的方式改变已有队列的模式的话，那么只能先删除队列，然后再重新声明一个新的。在队列声明的时候可以通过“x-queue-mode”参数来设置队列的模式，取值为“default”和“lazy”。下面示例中演示了一个惰性队列的声明细节： Map&lt;String, Object&gt; args = new HashMap&lt;String, Object&gt;(); args.put(“x-queue-mode”, “lazy”); channel.queueDeclare(“myqueue”, false, false, false, args); 9.3.3. 内存开销对比 ​ 在发送 1 百万条消息，每条消息大概占 1KB 的情况下，普通队列占用内存是 1.2GB，而惰性队列仅仅10. RabbitMQ 集群","categories":[],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://gitee.com/yunyd/tags/SpringCloud/"},{"name":"MQ","slug":"MQ","permalink":"https://gitee.com/yunyd/tags/MQ/"}],"author":"llllz."},{"title":"JUC-Synchronized与锁升级","slug":"JUC-Synchronized与锁升级 -11","date":"2023-08-18T02:33:43.000Z","updated":"2023-08-25T00:19:48.668Z","comments":true,"path":"posts/f7c5edf7.html","link":"","permalink":"https://gitee.com/yunyd/posts/f7c5edf7.html","excerpt":"","text":"11. Synchronized与锁升级11.1 面试题 谈谈你对Synchronized的理解 Sychronized的锁升级你聊聊 Synchronized实现原理，monitor对象什么时候生成的？知道monitor的monitorenter和monitorexit这两个是怎么保证同步的嘛？或者说这两个操作计算机底层是如何执行的 偏向锁和轻量级锁有什么区别 11.2 Synchronized的性能变化 Java5以前，只有Synchronized，这个是操作系统级别的重量级操作 重量级锁，假如锁的竞争比较激烈的话，性能下降 Java 5之前 用户态和内核态之间的转换 Java6 之后为了减少获得锁和释放锁所带来的性能消耗，引入了轻量级锁和偏向锁 11.3 Synchronized锁种类及升级步骤11.3.1 多线程访问情况 只有一个线程来访问，有且唯一Only One 有两个线程（2个线程交替访问） 竞争激烈，更多线程来访问 11.3.2 升级流程 Synchronized用的锁是存在Java对象头里的MarkWord中，锁升级功能主要依赖MarkWord中锁标志位和释放偏向锁标志位 锁指向，请牢记 偏向锁：MarkWord存储的是偏向的线程ID 轻量锁：MarkWord存储的是指向线程栈中Lock Record的指针 重量锁：MarkWord存储的是指向堆中的monitor对象（系统互斥量指针） 11.3.3 无锁 11.3.4 偏锁偏向锁：单线程竞争，当线程A第一次竞争到锁时，通过修改MarkWord中的偏向线程ID、偏向模式。如果不存在其他线程竞争，那么持有偏向锁的线程将永远不需要进行同步。 主要作用： 当一段同步代码一直被同一个线程多次访问，由于只有一个线程那么该线程在后续访问时便会自动获得锁 同一个老顾客来访，直接老规矩行方便 结论： HotSpot的作者经过研究发现，大多数情况下：在多线程情况下，锁不仅存在多线程竞争，还存在由同一个线程多次获得的情况，偏向锁就是在这种情况下出现的，它的出现是为了解决只有一个线程执行同步时提高性能。 偏向锁会偏向于第一个访问锁的线程，如果在接下来的运行过程中，该锁没有被其他线程访问，则持有偏向锁的线程将永远不需要出发同步。也即偏向锁在资源在没有竞争情况下消除了同步语句，懒得连CAS操作都不做了，直接提高程序性能。 理论落地： 技术实现： 偏向锁JVM命令： 案例演示： 偏向锁默认情况演示—只有一个线程： public class SynchronizedUpDemo { public static void main(String[] args) { /** * 这里偏向锁在JDK6以上默认开启，开启后程序启动几秒后才会被激活，可以通过JVM参数来关闭延迟 -XX:BiasedLockingStartupDelay=0 */ // try { TimeUnit.SECONDS.sleep(5); } catch (InterruptedException e) { e.printStackTrace(); } Object o = new Object(); synchronized (o) { System.out.println(ClassLayout.parseInstance(o).toPrintable()); } } } 偏向锁的撤销： 当有另外一个线程逐步来竞争锁的时候，就不能再使用偏向锁了，要升级为轻量级锁，使用的是等到竞争出现才释放锁的机制 竞争线程尝试CAS更新对象头失败，会等到全局安全点（此时不会执行任何代码）撤销偏向锁，同时检查持有偏向锁的线程是否还在执行： 第一个线程正在执行Synchronized方法（处于同步块），它还没有执行完，其他线程来抢夺，该偏向锁会被取消掉并出现锁升级，此时轻量级锁由原来持有偏向锁的线程持有，继续执行同步代码块，而正在竞争的线程会自动进入自旋等待获得该轻量级锁 第一个线程执行完Synchronized（退出同步块），则将对象头设置为无所状态并撤销偏向锁，重新偏向。 题外话：Java15以后逐步废弃偏向锁，需要手动开启——-&gt;维护成本高 11.3.5 轻锁概念：多线程竞争，但是任意时候最多只有一个线程竞争，即不存在锁竞争太激烈的情况，也就没有线程阻塞。 主要作用：有线程来参与锁的竞争，但是获取锁的冲突时间极短———-&gt;本质是自旋锁CAS 轻量锁的获取： 案例演示： 自旋一定程度和次数（Java8 之后是自适应自旋锁——意味着自旋的次数不是固定不变的）： 线程如果自旋成功了，那下次自旋的最大次数会增加，因为JVM认为既然上次成功了，那么这一次也大概率会成功 如果很少会自选成功，那么下次会减少自旋的次数甚至不自旋，避免CPU空转 轻量锁和偏向锁的区别： 争夺轻量锁失败时，自旋尝试抢占锁 轻量级锁每次退出同步块都需要释放锁，而偏向锁是在竞争发生时才释放锁 11.3.6 重锁有大量线程参与锁的竞争，冲突性很高 11.3.7 小总结 锁升级的过程 锁升级后，hashcode去哪儿了? 各种锁优缺点、synchronized锁升级和实现原理 11.4 JIT编译器对锁的优化11.4.1 JITJust In Time Compiler 即时编译器 11.4.2 锁消除锁消除案例演示: public class LockClearUpDemo { static Object object = new Object(); public void m1() { //锁消除问题，JIT会无视它，synchronized(o)每次new出来的，都不存在了，非正常的 Object o = new Object(); synchronized (o) { System.out.println(\"-----------hello LockClearUpDemo\" + \"\\t\" + o.hashCode() + \"\\t\" + object.hashCode()); } } public static void main(String[] args) { LockClearUpDemo lockClearUpDemo = new LockClearUpDemo(); for (int i = 0; i &lt; 10; i++) { new Thread(() -&gt; { lockClearUpDemo.m1(); }, String.valueOf(i)).start(); } } } /** * -----------hello LockClearUpDemo 229465744 57319765 * -----------hello LockClearUpDemo 219013680 57319765 * -----------hello LockClearUpDemo 1109337020 57319765 * -----------hello LockClearUpDemo 94808467 57319765 * -----------hello LockClearUpDemo 973369600 57319765 * -----------hello LockClearUpDemo 64667370 57319765 * -----------hello LockClearUpDemo 1201983305 57319765 * -----------hello LockClearUpDemo 573110659 57319765 * -----------hello LockClearUpDemo 1863380256 57319765 * -----------hello LockClearUpDemo 1119787251 57319765 */ 11.4.3 锁粗化锁粗化案例演示: public class LockBigDemo { static Object objectLock = new Object(); public static void main(String[] args) { new Thread(() -&gt; { synchronized (objectLock) { System.out.println(\"111111111111\"); } synchronized (objectLock) { System.out.println(\"222222222222\"); } synchronized (objectLock) { System.out.println(\"333333333333\"); } synchronized (objectLock) { System.out.println(\"444444444444\"); } //底层JIT的锁粗化优化 synchronized (objectLock) { System.out.println(\"111111111111\"); System.out.println(\"222222222222\"); System.out.println(\"333333333333\"); System.out.println(\"444444444444\"); } }, \"t1\").start(); } } 11.5 小总结 没有锁：自由自在 偏向锁：唯我独尊 轻量锁：楚汉争霸 重量锁：群雄逐鹿","categories":[],"tags":[{"name":"JUC并发编程","slug":"JUC并发编程","permalink":"https://gitee.com/yunyd/tags/JUC%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"author":"llllz."},{"title":"Maven复习","slug":"Maven复习","date":"2023-08-17T14:35:21.000Z","updated":"2023-08-25T00:20:49.238Z","comments":true,"path":"posts/1962ba96.html","link":"","permalink":"https://gitee.com/yunyd/posts/1962ba96.html","excerpt":"","text":"Maven复习1. 分模块开发1.1 分模块开发设计(1)按照功能拆分 我们现在的项目都是在一个模块中，比如前面的SSM整合开发。虽然这样做功能也都实现了，但是也存在了一些问题，我们拿银行的项目为例来聊聊这个事。 网络没有那么发达的时候，我们需要到银行柜台或者取款机进行业务操作 随着互联网的发展,我们有了电脑以后，就可以在网页上登录银行网站使用U盾进行业务操作 再来就是随着智能手机的普及，我们只需要用手机登录APP就可以进行业务操作 上面三个场景出现的时间是不相同的，如果非要把三个场景的模块代码放入到一个项目，那么当其中某一个模块代码出现问题，就会导致整个项目无法正常启动，从而导致银行的多个业务都无法正常班理。所以我们会==按照功能==将项目进行拆分。 (2)按照模块拆分 比如电商的项目中，有订单和商品两个模块，订单中需要包含商品的详细信息，所以需要商品的模型类，商品模块也会用到商品的模型类，这个时候如果两个模块中都写模型类，就会出现重复代码，后期的维护成本就比较高。我们就想能不能将它们公共的部分抽取成一个独立的模块，其他模块要想使用可以像添加第三方jar包依赖一样来使用我们自己抽取的模块，这样就解决了代码重复的问题,这种拆分方式就说我们所说的==按照模块==拆分。 经过两个案例的分析，我们就知道: 将原始模块按照功能拆分成若干个子模块，方便模块间的相互调用，接口共享。 刚刚我们说了可以将domain层进行拆分，除了domain层，我们也可以将其他的层也拆成一个个对立的模块，如: 这样的话，项目中的每一层都可以单独维护，也可以很方便的被别人使用。关于分模块开发的意义，我们就说完了，说了这么多好处，那么该如何实现呢? 1.2 分模块开发实现前面我们已经完成了SSM整合，接下来，咱们就基于SSM整合的项目来实现对项目的拆分。 1.2.1 环境准备 1.2.2 抽取domain层步骤1:创建新模块创建一个名称为maven_03_pojo的jar项目,为什么项目名是从02到03这样创建，原因后面我们会提到，这块的名称可以任意。 步骤2:项目中创建domain包在maven_03_pojo项目中创建com.itheima.domain包，并将maven_02_ssm中Book类拷贝到该包中 步骤3:删除原项目中的domain包删除后，maven_02_ssm项目中用到Book的类中都会有红色提示，如下: **说明:**出错的原因是maven_02_ssm中已经将Book类删除，所以该项目找不到Book类，所以报错 要想解决上述问题，我们需要在maven_02_ssm中添加maven_03_pojo的依赖。 步骤4:建立依赖关系在maven_02_ssm项目的pom.xml添加maven_03_pojo的依赖 &lt;dependency&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;maven_03_pojo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; 因为添加了依赖，所以在maven_02_ssm中就已经能找到Book类，所以刚才的报红提示就会消失。 步骤5:编译maven_02_ssm项目编译maven_02_ssm你会在控制台看到如下错误 错误信息为：不能解决maven_02_ssm项目的依赖问题，找不到maven_03_pojo这个jar包。 为什么找不到呢? 原因是Maven会从本地仓库找对应的jar包，但是本地仓库又不存在该jar包所以会报错。 在IDEA中是有maven_03_pojo这个项目，所以我们只需要将maven_03_pojo项目安装到本地仓库即可。 步骤6:将项目安装本地仓库将需要被依赖的项目maven_03_pojo，使用maven的install命令，把其安装到Maven的本地仓库中。 安装成功后，在对应的路径下就看到安装好的jar包 **说明:**具体安装在哪里，和你们自己电脑上Maven的本地仓库配置的位置有关。 当再次执行maven_02_ssm的compile的命令后，就已经能够成功编译。 1.2.3 抽取Dao层步骤1:创建新模块创建一个名称为maven_04_dao的jar项目 步骤2:项目中创建dao包在maven_04_dao项目中创建com.itheima.dao包，并将maven_02_ssm中BookDao类拷贝到该包中 在maven_04_dao中会有如下几个问题需要解决下: 项目maven_04_dao的BookDao接口中Book类找不到报错 解决方案在maven_04_dao项目的pom.xml中添加maven_03_pojo项目 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;maven_03_pojo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 项目maven_04_dao的BookDao接口中，Mybatis的增删改查注解报错 解决方案在maven_04_dao项目的pom.xml中添加mybatis的相关依赖 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 步骤3:删除原项目中的dao包删除Dao包以后，因为maven_02_ssm中的BookServiceImpl类中有使用到Dao的内容，所以需要在maven_02_ssm的pom.xml添加maven_04_dao的依赖 &lt;dependency&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;maven_04_dao&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; 此时在maven_02_ssm项目中就已经添加了maven_03_pojo和maven_04_dao包 再次对maven_02_ssm项目进行编译，又会报错，如下: 和刚才的错误原因是一样的，maven在仓库中没有找到maven_04_dao,所以此时我们只需要将maven_04_dao安装到Maven的本地仓库即可。 步骤4:将项目安装到本地仓库将需要被依赖的项目maven_04_dao，使用maven的install命令，把其安装到Maven的本地仓库中。 安装成功后，在对应的路径下就看到了安装好对应的jar包 当再次执行maven_02_ssm的compile的指令后，就已经能够成功编译。 1.2.4 运行测试并总结将抽取后的项目进行运行，测试之前的增删改查功能依然能够使用。 所以对于项目的拆分，大致会有如下几个步骤: (1) 创建Maven模块 (2) 书写模块代码 分模块开发需要先针对模块功能进行设计，再进行编码。不会先将工程开发完毕，然后进行拆分。拆分方式可以按照功能拆也可以按照模块拆。 (3)通过maven指令安装模块到本地仓库(install 指令) 团队内部开发需要发布模块功能到团队内部可共享的仓库中(私服)，私服我们后面会讲解。 2.依赖管理我们现在已经能把项目拆分成一个个独立的模块，当在其他项目中想要使用独立出来的这些模块，只需要在其pom.xml使用标签来进行jar包的引入即可。 其实就是依赖，关于依赖管理里面都涉及哪些内容，我们就一个个来学习下: 依赖传递 可选依赖 排除依赖 我们先来说说什么是依赖: 依赖指当前项目运行所需的jar，一个项目可以设置多个依赖。 格式为: &lt;!--设置当前项目所依赖的所有jar--&gt; &lt;dependencies&gt; &lt;!--设置具体的依赖--&gt; &lt;dependency&gt; &lt;!--依赖所属群组id--&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;!--依赖所属项目id--&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;!--依赖版本号--&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 2.1 依赖传递与冲突问题回到我们刚才的项目案例中，打开Maven的面板，你会发现: 在项目所依赖的这些jar包中，有一个比较大的区别就是有的依赖前面有箭头&gt;,有的依赖前面没有。 那么这个箭头所代表的含义是什么? 打开前面的箭头，你会发现这个jar包下面还包含有其他的jar包 你会发现有两个maven_03_pojo的依赖被加载到Dependencies中，那么maven_04_dao中的maven_03_pojo能不能使用呢? 要想验证非常简单，只需要把maven_02_ssm项目中pom.xml关于maven_03_pojo的依赖注释或删除掉 在Dependencies中移除自己所添加maven_03_pojo依赖后，打开BookServiceImpl的类，你会发现Book类依然存在，可以被正常使用 这个特性其实就是我们要讲解的==依赖传递==。 依赖是具有传递性的: **说明:**A代表自己的项目；B,C,D,E,F,G代表的是项目所依赖的jar包；D1和D2 E1和E2代表是相同jar包的不同版本 (1) A依赖了B和C,B和C有分别依赖了其他jar包，所以在A项目中就可以使用上面所有jar包，这就是所说的依赖传递 (2) 依赖传递有直接依赖和间接依赖 相对于A来说，A直接依赖B和C,间接依赖了D1,E1,G，F,D2和E2 相对于B来说，B直接依赖了D1和E1,间接依赖了G 直接依赖和间接依赖是一个相对的概念 (3)因为有依赖传递的存在，就会导致jar包在依赖的过程中出现冲突问题，具体什么是冲突?Maven是如何解决冲突的? 这里所说的==依赖冲突==是指项目依赖的某一个jar包，有多个不同的版本，因而造成类包版本冲突。 情况一: 在maven_02_ssm的pom.xml中添加两个不同版本的Junit依赖: &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 通过对比，会发现一个结论 特殊优先：当同级配置了相同资源的不同版本，后配置的覆盖先配置的。 情况二: 路径优先：当依赖中出现相同的资源时，层级越深，优先级越低，层级越浅，优先级越高 A通过B间接依赖到E1 A通过C间接依赖到E2 A就会间接依赖到E1和E2,Maven会按照层级来选择，E1是2度，E2是3度，所以最终会选择E1 情况三: 声明优先：当资源在相同层级被依赖时，配置顺序靠前的覆盖配置顺序靠后的 A通过B间接依赖到D1 A通过C间接依赖到D2 D1和D2都是两度，这个时候就不能按照层级来选择，需要按照声明来，谁先声明用谁，也就是说B在C之前声明，这个时候使用的是D1，反之则为D2 但是对应上面这些结果，大家不需要刻意去记它。因为不管Maven怎么选，最终的结果都会在Maven的Dependencies面板中展示出来，展示的是哪个版本，也就是说它选择的就是哪个版本，如: 如果想更全面的查看Maven中各个坐标的依赖关系，可以点击Maven面板中的show Dependencies 在这个视图中就能很明显的展示出jar包之间的相互依赖关系。 2.2 可选依赖和排除依赖依赖传递介绍完以后，我们来思考一个问题， maven_02_ssm 依赖了 maven_04_dao maven_04_dao 依赖了 maven_03_pojo 因为现在有依赖传递，所以maven_02_ssm能够使用到maven_03_pojo的内容 如果说现在不想让maven_02_ssm依赖到maven_03_pojo，有哪些解决方案? **说明:**在真实使用的过程中，maven_02_ssm中是需要用到maven_03_pojo的，我们这里只是用这个例子描述我们的需求。因为有时候，maven_04_dao出于某些因素的考虑，就是不想让别人使用自己所依赖的maven_03_pojo。 方案一:可选依赖 可选依赖指对外隐藏当前所依赖的资源—不透明 在maven_04_dao的pom.xml,在引入maven_03_pojo的时候，添加optional &lt;dependency&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;maven_03_pojo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!--可选依赖是隐藏当前工程所依赖的资源，隐藏后对应资源将不具有依赖传递--&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; 此时BookServiceImpl就已经报错了,说明由于maven_04_dao将maven_03_pojo设置成可选依赖，导致maven_02_ssm无法引用到maven_03_pojo中的内容，导致Book类找不到。 方案二:排除依赖 排除依赖指主动断开依赖的资源，被排除的资源无需指定版本—不需要 前面我们已经通过可选依赖实现了阻断maven_03_pojo的依赖传递，对于排除依赖，则指的是已经有依赖的事实，也就是说maven_02_ssm项目中已经通过依赖传递用到了maven_03_pojo，此时我们需要做的是将其进行排除，所以接下来需要修改maven_02_ssm的pom.xml &lt;dependency&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;maven_04_dao&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!--排除依赖是隐藏当前资源对应的依赖关系--&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;maven_03_pojo&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; 这样操作后，BookServiceImpl中的Book类一样也会报错。 当然exclusions标签带s说明我们是可以依次排除多个依赖到的jar包，比如maven_04_dao中有依赖junit和mybatis,我们也可以一并将其排除。 &lt;dependency&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;maven_04_dao&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!--排除依赖是隐藏当前资源对应的依赖关系--&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;maven_03_pojo&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; 介绍我这两种方式后，简单来梳理下，就是 A依赖B,B依赖C,C通过依赖传递会被A使用到，现在要想办法让A不去依赖C 可选依赖是在B上设置&lt;optional&gt;,A不知道有C的存在， 排除依赖是在A上设置&lt;exclusions&gt;,A知道有C的存在，主动将其排除掉。 3. 聚合和继承我们的项目已经从以前的单模块，变成了现在的多模块开发。项目一旦变成了多模块开发以后，就会引发一些问题，在这一节中我们主要会学习两个内容聚合和继承，用这两个知识来解决下分模块后的一些问题。 3.1 聚合 分模块开发后，需要将这四个项目都安装到本地仓库，目前我们只能通过项目Maven面板的install来安装，并且需要安装四个，如果我们的项目足够多，那么一个个安装起来还是比较麻烦的 如果四个项目都已经安装成功，当ssm_pojo发生变化后，我们就得将ssm_pojo重新安装到maven仓库，但是为了确保我们对ssm_pojo的修改不会影响到其他项目模块，我们需要对所有的模块进行重新编译，那又需要将所有的模块再来一遍 项目少的话还好，但是如果项目多的话，一个个操作项目就容易出现漏掉或重复操作的问题，所以我们就想能不能抽取一个项目，把所有的项目管理起来，以后我们要想操作这些项目，只需要操作这一个项目，其他所有的项目都走一样的流程，这个不就很省事省力。 这就用到了我们接下来要讲解的==聚合==， 所谓聚合:将多个模块组织成一个整体，同时进行项目构建的过程称为聚合 聚合工程：通常是一个不具有业务功能的”空”工程（有且仅有一个pom文件） 作用：使用聚合工程可以将多个工程编组，通过对聚合工程进行构建，实现对所包含的模块进行同步构建 当工程中某个模块发生更新（变更）时，必须保障工程中与已更新模块关联的模块同步更新，此时可以使用聚合工程来解决批量模块同步构建的问题。 关于聚合具体的实现步骤为: 步骤1:创建一个空的maven项目 步骤2:将项目的打包方式改为pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;maven_01_parent&lt;/artifactId&gt; &lt;version&gt;1.0-RELEASE&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;/project&gt; **说明:**项目的打包方式，我们接触到的有三种，分别是 jar:默认情况，说明该项目为java项目 war:说明该项目为web项目 pom:说明该项目为聚合或继承(后面会讲)项目 步骤3:pom.xml添加所要管理的项目&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;maven_01_parent&lt;/artifactId&gt; &lt;version&gt;1.0-RELEASE&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;!--设置管理的模块名称--&gt; &lt;modules&gt; &lt;module&gt;../maven_02_ssm&lt;/module&gt; &lt;module&gt;../maven_03_pojo&lt;/module&gt; &lt;module&gt;../maven_04_dao&lt;/module&gt; &lt;/modules&gt; &lt;/project&gt; 步骤4:使用聚合统一管理项目 测试发现，当maven_01_parent的compile被点击后，所有被其管理的项目都会被执行编译操作。这就是聚合工程的作用。 说明：聚合工程管理的项目在进行运行的时候，会按照项目与项目之间的依赖关系来自动决定执行的顺序和配置的顺序无关。 聚合的知识我们就讲解完了，最后总结一句话就是，聚合工程主要是用来管理项目。 3.2 继承我们已经完成了使用聚合工程去管理项目，聚合工程进行某一个构建操作，其他被其管理的项目也会执行相同的构建操作。那么接下来，我们再来分析下，多模块开发存在的另外一个问题，重复配置的问题，我们先来看张图: spring-webmvc、spring-jdbc在三个项目模块中都有出现，这样就出现了重复的内容 spring-test只在ssm_crm和ssm_goods中出现，而在ssm_order中没有，这里是部分重复的内容 我们使用的spring版本目前是5.2.10.RELEASE,假如后期要想升级spring版本，所有跟Spring相关jar包都得被修改，涉及到的项目越多，维护成本越高 面对上面的这些问题，我们就得用到接下来要学习的==继承== 所谓继承:描述的是两个工程间的关系，与java中的继承相似，子工程可以继承父工程中的配置信息，常见于依赖关系的继承。 作用： 简化配置 减少版本冲突 接下来，我们到程序中去看看继承该如何实现? 步骤1:创建一个空的Maven项目并将其打包方式设置为pom因为这一步和前面maven创建聚合工程的方式是一摸一样，所以我们可以单独创建一个新的工程，也可以直接和聚合公用一个工程。实际开发中，聚合和继承一般也都放在同一个项目中，但是这两个的功能是不一样的。 步骤2:在子项目中设置其父工程分别在maven_02_ssm,maven_03_pojo,maven_04_dao的pom.xml中添加其父项目为maven_01_parent &lt;!--配置当前工程继承自parent工程--&gt; &lt;parent&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;maven_01_parent&lt;/artifactId&gt; &lt;version&gt;1.0-RELEASE&lt;/version&gt; &lt;!--设置父项目pom.xml位置路径--&gt; &lt;relativePath&gt;../maven_01_parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; 步骤3:优化子项目共有依赖导入问题 将子项目共同使用的jar包都抽取出来，维护在父项目的pom.xml中 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;maven_01_parent&lt;/artifactId&gt; &lt;version&gt;1.0-RELEASE&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;!--设置管理的模块名称--&gt; &lt;modules&gt; &lt;module&gt;../maven_02_ssm&lt;/module&gt; &lt;module&gt;../maven_03_pojo&lt;/module&gt; &lt;module&gt;../maven_04_dao&lt;/module&gt; &lt;/modules&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.16&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 删除子项目中已经被抽取到父项目的pom.xml中的jar包，如在maven_02_ssm的pom.xml中将已经出现在父项目的jar包删除掉 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;maven_02_ssm&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;!--配置当前工程继承自parent工程--&gt; &lt;parent&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;maven_01_parent&lt;/artifactId&gt; &lt;version&gt;1.0-RELEASE&lt;/version&gt; &lt;relativePath&gt;../maven_01_parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;maven_04_dao&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!--排除依赖是隐藏当前资源对应的依赖关系--&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;80&lt;/port&gt; &lt;path&gt;/&lt;/path&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 删除完后，你会发现父项目中有依赖对应的jar包，子项目虽然已经将重复的依赖删除掉了，但是刷新的时候，子项目中所需要的jar包依然存在。 当项目的&lt;parent&gt;标签被移除掉，会发现多出来的jar包依赖也会随之消失。 将maven_04_dao项目的pom.xml中的所有依赖删除，然后添加上maven_01_parent的父项目坐标 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;maven_04_dao&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!--配置当前工程继承自parent工程--&gt; &lt;parent&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;maven_01_parent&lt;/artifactId&gt; &lt;version&gt;1.0-RELEASE&lt;/version&gt; &lt;relativePath&gt;../maven_01_parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;/project&gt; 刷新并查看Maven的面板，会发现maven_04_dao同样引入了父项目中的所有依赖。 这样我们就可以解决刚才提到的第一个问题，将子项目中的公共jar包抽取到父工程中进行统一添加依赖，这样做的可以简化配置，并且当父工程中所依赖的jar包版本发生变化，所有子项目中对应的jar包版本也会跟着更新。 步骤4:优化子项目依赖版本问题如果把所有用到的jar包都管理在父项目的pom.xml，看上去更简单些，但是这样就会导致有很多项目引入了过多自己不需要的jar包。如上面看到的这张图: 如果把所有的依赖都放在了父工程中进行统一维护，就会导致ssm_order项目中多引入了spring-test的jar包，如果这样的jar包过多的话，对于ssm_order来说也是一种”负担”。 那针对于这种部分项目有的jar包，我们该如何管理优化呢? 在父工程mavne_01_parent的pom.xml来定义依赖管理 &lt;!--定义依赖管理--&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 将maven_02_ssm的pom.xml中的junit依赖删除掉，刷新Maven 刷新完会发现，在maven_02_ssm项目中的junit依赖并没有出现，所以我们得到一个结论: ==&lt;dependencyManagement&gt;标签不真正引入jar包，而是配置可供子项目选择的jar包依赖== 子项目要想使用它所提供的这些jar包，需要自己添加依赖，并且不需要指定&lt;version&gt; 在maven_02_ssm的pom.xml添加junit的依赖 &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; 注意：这里就不需要添加版本了，这样做的好处就是当父工程dependencyManagement标签中的版本发生变化后，子项目中的依赖版本也会跟着发生变化 在maven_04_dao的pom.xml添加junit的依赖 &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; 这个时候，maven_02_ssm和maven_04_dao这两个项目中的junit版本就会跟随着父项目中的标签dependencyManagement中junit的版本发生变化而变化。不需要junit的项目就不需要添加对应的依赖即可。 至此继承就已经学习完了，总结来说，继承可以帮助做两件事 将所有项目公共的jar包依赖提取到父工程的pom.xml中，子项目就可以不用重复编写，简化开发 将所有项目的jar包配置到父工程的dependencyManagement标签下，实现版本管理，方便维护 ==dependencyManagement标签不真正引入jar包，只是管理jar包的版本== 子项目在引入的时候，只需要指定groupId和artifactId，不需要加version 当dependencyManagement标签中jar包版本发生变化，所有子项目中有用到该jar包的地方对应的版本会自动随之更新 最后总结一句话就是，父工程主要是用来快速配置依赖jar包和管理项目中所使用的资源。 小结 继承的实现步骤: 创建Maven模块，设置打包类型为pom &lt;packaging&gt;pom&lt;/packaging&gt; 在父工程的pom文件中配置依赖关系(子工程将沿用父工程中的依赖关系),一般只抽取子项目中公有的jar包 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; ... &lt;/dependencies&gt; 在父工程中配置子工程中可选的依赖关系 &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.16&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; ... &lt;/dependencyManagement&gt; 在子工程中配置当前工程所继承的父工程 &lt;!--定义该工程的父工程--&gt; &lt;parent&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;maven_01_parent&lt;/artifactId&gt; &lt;version&gt;1.0-RELEASE&lt;/version&gt; &lt;!--填写父工程的pom文件,可以不写--&gt; &lt;relativePath&gt;../maven_01_parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; 在子工程中配置使用父工程中可选依赖的坐标 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 注意事项: 1.子工程中使用父工程中的可选依赖时，仅需要提供群组id和项目id，无需提供版本，版本由父工程统一提供，避免版本冲突 2.子工程中还可以定义父工程中没有定义的依赖关系,只不过不能被父工程进行版本统一管理。 3.3 聚合与继承的区别3.3.1 聚合与继承的区别两种之间的作用: 聚合用于快速构建项目，对项目进行管理 继承用于快速配置和管理子项目中所使用jar包的版本 聚合和继承的相同点: 聚合与继承的pom.xml文件打包方式均为pom，可以将两种关系制作到同一个pom文件中 聚合与继承均属于设计型模块，并无实际的模块内容 聚合和继承的不同点: 聚合是在当前模块中配置关系，聚合可以感知到参与聚合的模块有哪些 继承是在子模块中配置关系，父模块无法感知哪些子模块继承了自己 相信到这里，大家已经能区分开什么是聚合和继承，但是有一个稍微麻烦的地方就是聚合和继承的工程构建，需要在聚合项目中手动添加modules标签，需要在所有的子项目中添加parent标签，万一写错了咋办? 3.3.2 IDEA构建聚合与继承工程其实对于聚合和继承工程的创建，IDEA已经能帮助我们快速构建，具体的实现步骤为: 步骤1:创建一个Maven项目创建一个空的Maven项目，可以将项目中的src目录删除掉，这个项目作为聚合工程和父工程。 步骤2:创建子项目该项目可以被聚合工程管理，同时会继承父工程。 创建成功后，maven_parent即是聚合工程又是父工程，maven_web中也有parent标签，继承的就是maven_parent,对于难以配置的内容都自动生成。 按照上面这种方式，大家就可以根据自己的需要来构建分模块项目。 4. 属性在这一章节内容中，我们将学习两个内容，分别是 属性 版本管理 属性中会继续解决分模块开发项目存在的问题，版本管理主要是认识下当前主流的版本定义方式。 4.1 属性4.1.1 问题分析讲解内容之前，我们还是先来分析问题: 前面我们已经在父工程中的dependencyManagement标签中对项目中所使用的jar包版本进行了统一的管理，但是如果在标签中有如下的内容: 你会发现，如果我们现在想更新Spring的版本，你会发现我们依然需要更新多个jar包的版本，这样的话还是有可能出现漏改导致程序出问题，而且改起来也是比较麻烦。 问题清楚后，我们需要解决的话，就可以参考咱们java基础所学习的变量，声明一个变量，在其他地方使用该变量，当变量的值发生变化后，所有使用变量的地方，就会跟着修改，即: 4.1.2 解决步骤步骤1:父工程中定义属性&lt;properties&gt; &lt;spring.version&gt;5.2.10.RELEASE&lt;/spring.version&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;mybatis-spring.version&gt;1.3.0&lt;/mybatis-spring.version&gt; &lt;/properties&gt; 步骤2:修改依赖的version&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; 此时，我们只需要更新父工程中properties标签中所维护的jar包版本，所有子项目中的版本也就跟着更新。当然除了将spring相关版本进行维护，我们可以将其他的jar包版本也进行抽取，这样就可以对项目中所有jar包的版本进行统一维护，如: &lt;!--定义属性--&gt; &lt;properties&gt; &lt;spring.version&gt;5.2.10.RELEASE&lt;/spring.version&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;mybatis-spring.version&gt;1.3.0&lt;/mybatis-spring.version&gt; &lt;/properties&gt; 4.2 配置文件加载属性Maven中的属性我们已经介绍过了，现在也已经能够通过Maven来集中管理Maven中依赖jar包的版本。但是又有新的需求，就是想让Maven对于属性的管理范围能更大些，比如我们之前项目中的jdbc.properties，这个配置文件中的属性，能不能也来让Maven进行管理呢? 答案是肯定的，具体的实现步骤为: 步骤1:父工程定义属性&lt;properties&gt; &lt;jdbc.url&gt;jdbc:mysql://127.1.1.1:3306/ssm_db&lt;/jdbc.url&gt; &lt;/properties&gt; 步骤2:jdbc.properties文件中引用属性在jdbc.properties，将jdbc.url的值直接获取Maven配置的属性 jdbc.driver=com.mysql.jdbc.Driver jdbc.url=${jdbc.url} jdbc.username=root jdbc.password=root 步骤3:设置maven过滤文件范围Maven在默认情况下是从当前项目的src\\main\\resources下读取文件进行打包。现在我们需要打包的资源文件是在maven_02_ssm下,需要我们通过配置来指定下具体的资源目录。 &lt;build&gt; &lt;resources&gt; &lt;!--设置资源目录--&gt; &lt;resource&gt; &lt;directory&gt;../maven_02_ssm/src/main/resources&lt;/directory&gt; &lt;!--设置能够解析${}，默认是false --&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; **说明:**directory路径前要添加../的原因是maven_02_ssm相对于父工程的pom.xml路径是在其上一层的目录中，所以需要添加。 修改完后，注意maven_02_ssm项目的resources目录就多了些东西，如下: 步骤4:测试是否生效测试的时候，只需要将maven_02_ssm项目进行打包，然后观察打包结果中最终生成的内容是否为Maven中配置的内容。 上面的属性管理就已经完成，但是有一个问题没有解决，因为不只是maven_02_ssm项目需要有属性被父工程管理，如果有多个项目需要配置，该如何实现呢? 方式一: &lt;build&gt; &lt;resources&gt; &lt;!--设置资源目录，并设置能够解析${}--&gt; &lt;resource&gt; &lt;directory&gt;../maven_02_ssm/src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;../maven_03_pojo/src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; ... &lt;/resources&gt; &lt;/build&gt; 可以配，但是如果项目够多的话，这个配置也是比较繁琐 方式二: &lt;build&gt; &lt;resources&gt; &lt;!-- ${project.basedir}: 当前项目所在目录,子项目继承了父项目， 相当于所有的子项目都添加了资源目录的过滤 --&gt; &lt;resource&gt; &lt;directory&gt;${project.basedir}/src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; **说明:**打包的过程中如果报如下错误: 原因就是Maven发现你的项目为web项目，就会去找web项目的入口web.xml[配置文件配置的方式]，发现没有找到，就会报错。 解决方案1：在maven_02_ssm项目的src\\main\\webapp\\WEB-INF\\添加一个web.xml文件 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd\" version=\"3.1\"&gt; &lt;/web-app&gt; 解决方案2: 配置maven打包war时，忽略web.xml检查 &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;3.2.3&lt;/version&gt; &lt;configuration&gt; &lt;failOnMissingWebXml&gt;false&lt;/failOnMissingWebXml&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 上面我们所使用的都是Maven的自定义属性，除了${project.basedir},它属于Maven的内置系统属性。 在Maven中的属性分为: 自定义属性（常用） 内置属性 Setting属性 Java系统属性 环境变量属性 具体如何查看这些属性: 在cmd命令行中输入mvn help:system 具体使用，就是使用 ${key}来获取，key为等号左边的，值为等号右边的，比如获取红线的值，对应的写法为 ${java.runtime.name}。 4.3 版本管理关于这个版本管理解决的问题是，在Maven创建项目和引用别人项目的时候，我们都看到过如下内容: 这里面有两个单词，SNAPSHOT和RELEASE，它们所代表的含义是什么呢? 我们打开Maven仓库地址https://mvnrepository.com/ 在我们jar包的版本定义中，有两个工程版本用的比较多: SNAPSHOT（快照版本） 项目开发过程中临时输出的版本，称为快照版本 快照版本会随着开发的进展不断更新 RELEASE（发布版本） 项目开发到一定阶段里程碑后，向团队外部发布较为稳定的版本，这种版本所对应的构件文件是稳定的 即便进行功能的后续开发，也不会改变当前发布版本内容，这种版本称为发布版本 除了上面的工程版本，我们还经常能看到一些发布版本: alpha版:内测版，bug多不稳定内部版本不断添加新功能 beta版:公测版，不稳定(比alpha稳定些)，bug相对较多不断添加新功能 纯数字版 对于这些版本，大家只需要简单认识下即可。 5. 多环境配置与应用这一节中，我们会讲两个内容，分别是多环境开发和跳过测试 5.1 多环境开发 我们平常都是在自己的开发环境进行开发， 当开发完成后，需要把开发的功能部署到测试环境供测试人员进行测试使用， 等测试人员测试通过后，我们会将项目部署到生成环境上线使用。 这个时候就有一个问题是，不同环境的配置是不相同的，如不可能让三个环境都用一个数据库，所以就会有三个数据库的url配置， 我们在项目中如何配置? 要想实现不同环境之间的配置切换又该如何来实现呢? maven提供配置多种环境的设定，帮助开发者在使用过程中快速切换环境。具体实现步骤: 步骤1:父工程配置多个环境,并指定默认激活环境&lt;profiles&gt; &lt;!--开发环境--&gt; &lt;profile&gt; &lt;id&gt;env_dep&lt;/id&gt; &lt;properties&gt; &lt;jdbc.url&gt;jdbc:mysql://127.1.1.1:3306/ssm_db&lt;/jdbc.url&gt; &lt;/properties&gt; &lt;!--设定是否为默认启动环境--&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;!--生产环境--&gt; &lt;profile&gt; &lt;id&gt;env_pro&lt;/id&gt; &lt;properties&gt; &lt;jdbc.url&gt;jdbc:mysql://127.2.2.2:3306/ssm_db&lt;/jdbc.url&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;!--测试环境--&gt; &lt;profile&gt; &lt;id&gt;env_test&lt;/id&gt; &lt;properties&gt; &lt;jdbc.url&gt;jdbc:mysql://127.3.3.3:3306/ssm_db&lt;/jdbc.url&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt; 步骤2:执行安装查看env_dep环境是否生效 查看到的结果为: 步骤3:切换默认环境为生产环境&lt;profiles&gt; &lt;!--开发环境--&gt; &lt;profile&gt; &lt;id&gt;env_dep&lt;/id&gt; &lt;properties&gt; &lt;jdbc.url&gt;jdbc:mysql://127.1.1.1:3306/ssm_db&lt;/jdbc.url&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;!--生产环境--&gt; &lt;profile&gt; &lt;id&gt;env_pro&lt;/id&gt; &lt;properties&gt; &lt;jdbc.url&gt;jdbc:mysql://127.2.2.2:3306/ssm_db&lt;/jdbc.url&gt; &lt;/properties&gt; &lt;!--设定是否为默认启动环境--&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;!--测试环境--&gt; &lt;profile&gt; &lt;id&gt;env_test&lt;/id&gt; &lt;properties&gt; &lt;jdbc.url&gt;jdbc:mysql://127.3.3.3:3306/ssm_db&lt;/jdbc.url&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt; 步骤4:执行安装并查看env_pro环境是否生效查看到的结果为jdbc:mysql://127.2.2.2:3306/ssm_db 虽然已经能够实现不同环境的切换，但是每次切换都是需要手动修改，如何来实现在不改变代码的前提下完成环境的切换呢? 步骤5:命令行实现环境切换 步骤6:执行安装并查看env_test环境是否生效查看到的结果为jdbc:mysql://127.3.3.3:3306/ssm_db 所以总结来说，对于多环境切换只需要两步即可: 父工程中定义多环境 &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;环境名称&lt;/id&gt; &lt;properties&gt; &lt;key&gt;value&lt;/key&gt; &lt;/properties&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; ... &lt;/profiles&gt; 使用多环境(构建过程) mvn 指令 -P 环境定义ID[环境定义中获取] 5.2 跳过测试前面在执行install指令的时候，Maven都会按照顺序从上往下依次执行，每次都会执行test, 对于test来说有它存在的意义， 可以确保每次打包或者安装的时候，程序的正确性，假如测试已经通过在我们没有修改程序的前提下再次执行打包或安装命令，由于顺序执行，测试会被再次执行，就有点耗费时间了。 功能开发过程中有部分模块还没有开发完毕，测试无法通过，但是想要把其中某一部分进行快速打包，此时由于测试环境失败就会导致打包失败。 遇到上面这些情况的时候，我们就想跳过测试执行下面的构建命令，具体实现方式有很多： 方式一:IDEA工具实现跳过测试 图中的按钮为Toggle 'Skip Tests' Mode, Toggle翻译为切换的意思，也就是说在测试与不测试之间进行切换。 点击一下，出现测试画横线的图片，如下: 说明测试已经被关闭，再次点击就会恢复。 这种方式最简单，但是有点”暴力”，会把所有的测试都跳过，如果我们想更精细的控制哪些跳过哪些不跳过，就需要使用配置插件的方式。 方式二:配置插件实现跳过测试在父工程中的pom.xml中添加测试插件配置 &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.12.4&lt;/version&gt; &lt;configuration&gt; &lt;skipTests&gt;false&lt;/skipTests&gt; &lt;!--排除掉不参与测试的内容--&gt; &lt;excludes&gt; &lt;exclude&gt;**/BookServiceTest.java&lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; skipTests:如果为true，则跳过所有测试，如果为false，则不跳过测试 excludes：哪些测试类不参与测试，即排除，针对skipTests为false来设置的 includes: 哪些测试类要参与测试，即包含,针对skipTests为true来设置的 方式三:命令行跳过测试 使用Maven的命令行，mvn 指令 -D skipTests 注意事项: 执行的项目构建指令必须包含测试生命周期，否则无效果。例如执行compile生命周期，不经过test生命周期。 该命令可以不借助IDEA，直接使用cmd命令行进行跳过测试，需要注意的是cmd要在pom.xml所在目录下进行执行。 6. 私服这一节，我们主要学习的内容是: 私服简介 私服仓库分类 资源上传与下载 首先来说一说什么是私服? 6.1 私服简介团队开发现状分析 (1)张三负责ssm_crm的开发，自己写了一个ssm_pojo模块，要想使用直接将ssm_pojo安装到本地仓库即可 (2)李四负责ssm_order的开发，需要用到张三所写的ssm_pojo模块，这个时候如何将张三写的ssm_pojo模块交给李四呢? (3)如果直接拷贝，那么团队之间的jar包管理会非常混乱而且容器出错，这个时候我们就想能不能将写好的项目上传到中央仓库，谁想用就直接联网下载即可 (4)Maven的中央仓库不允许私人上传自己的jar包,那么我们就得换种思路，自己搭建一个类似于中央仓库的东西，把自己的内容上传上去，其他人就可以从上面下载jar包使用 (5)这个类似于中央仓库的东西就是我们接下来要学习的==私服== 所以到这就有两个概念，一个是私服，一个是中央仓库 私服:公司内部搭建的用于存储Maven资源的服务器 远程仓库:Maven开发团队维护的用于存储Maven资源的服务器 所以说: 私服是一台独立的服务器，用于解决团队内部的资源共享与资源同步问题 搭建Maven私服的方式有很多，我们来介绍其中一种使用量比较大的实现方式: Nexus Sonatype公司的一款maven私服产品 下载地址：https://help.sonatype.com/repomanager3/download 6.2 私服安装步骤1:下载解压将资料\\latest-win64.zip解压到一个空目录下。 步骤2:启动Nexus 使用cmd进入到解压目录下的nexus-3.30.1-01\\bin,执行如下命令: nexus.exe /run nexus 看到如下内容，说明启动成功。 步骤3:浏览器访问访问地址为: http://localhost:8081 步骤4:首次登录重置密码 输入用户名和密码进行登录，登录成功后，出现如下页面 点击下一步，需要重新输入新密码，为了和后面的保持一致，密码修改为admin 设置是否运行匿名访问 点击完成 至此私服就已经安装成功。如果要想修改一些基础配置信息，可以使用: 修改基础配置信息 安装路径下etc目录中nexus-default.properties文件保存有nexus基础配置信息，例如默认访问端口。 修改服务器运行配置信息 安装路径下bin目录中nexus.vmoptions文件保存有nexus服务器启动对应的配置信息，例如默认占用内存空间。 6.3 私服仓库分类私服资源操作流程分析: (1)在没有私服的情况下，我们自己创建的服务都是安装在Maven的本地仓库中 (2)私服中也有仓库，我们要把自己的资源上传到私服，最终也是放在私服的仓库中 (3)其他人要想使用你所上传的资源，就需要从私服的仓库中获取 (4)当我们要使用的资源不是自己写的，是远程中央仓库有的第三方jar包，这个时候就需要从远程中央仓库下载，每个开发者都去远程中央仓库下速度比较慢(中央仓库服务器在国外) (5)私服就再准备一个仓库，用来专门存储从远程中央仓库下载的第三方jar包，第一次访问没有就会去远程中央仓库下载，下次再访问就直接走私服下载 (6)前面在介绍版本管理的时候提到过有SNAPSHOT和RELEASE，如果把这两类的都放到同一个仓库，比较混乱，所以私服就把这两个种jar包放入不同的仓库 (7)上面我们已经介绍了有三种仓库，一种是存放SNAPSHOT的，一种是存放RELEASE还有一种是存放从远程仓库下载的第三方jar包，那么我们在获取资源的时候要从哪个仓库种获取呢? (8)为了方便获取，我们将所有的仓库编成一个组，我们只需要访问仓库组去获取资源。 所有私服仓库总共分为三大类: 宿主仓库hosted 保存无法从中央仓库获取的资源 自主研发 第三方非开源项目,比如Oracle,因为是付费产品，所以中央仓库没有 代理仓库proxy 代理远程仓库，通过nexus访问其他公共仓库，例如中央仓库 仓库组group 将若干个仓库组成一个群组，简化配置 仓库组不能保存资源，属于设计型仓库 6.4 本地仓库访问私服配置 我们通过IDEA将开发的模块上传到私服，中间是要经过本地Maven的 本地Maven需要知道私服的访问地址以及私服访问的用户名和密码 私服中的仓库很多，Maven最终要把资源上传到哪个仓库? Maven下载的时候，又需要携带用户名和密码到私服上找对应的仓库组进行下载，然后再给IDEA 上面所说的这些内容，我们需要在本地Maven的配置文件settings.xml中进行配置。 步骤1:私服上配置仓库 说明: 第5，6步骤是创建itheima-snapshot仓库 第7，8步骤是创建itheima-release仓库 步骤2:配置本地Maven对私服的访问权限&lt;servers&gt; &lt;server&gt; &lt;id&gt;itheima-snapshot&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;itheima-release&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; 步骤3:配置私服的访问路径&lt;mirrors&gt; &lt;mirror&gt; &lt;!--配置仓库组的ID--&gt; &lt;id&gt;maven-public&lt;/id&gt; &lt;!--*代表所有内容都从私服获取--&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;!--私服仓库组maven-public的访问路径--&gt; &lt;url&gt;http://localhost:8081/repository/maven-public/&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt; 为了避免阿里云Maven私服地址的影响，建议先将之前配置的阿里云Maven私服镜像地址注释掉，等练习完后，再将其恢复。 至此本地仓库就能与私服进行交互了。 6.5 私服资源上传与下载本地仓库与私服已经建立了连接，接下来我们就需要往私服上上传资源和下载资源，具体的实现步骤为: 步骤1:配置工程上传私服的具体位置 &lt;!--配置当前工程保存在私服中的具体位置--&gt; &lt;distributionManagement&gt; &lt;repository&gt; &lt;!--和maven/settings.xml中server中的id一致，表示使用该id对应的用户名和密码--&gt; &lt;id&gt;itheima-release&lt;/id&gt; &lt;!--release版本上传仓库的具体地址--&gt; &lt;url&gt;http://localhost:8081/repository/itheima-release/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;!--和maven/settings.xml中server中的id一致，表示使用该id对应的用户名和密码--&gt; &lt;id&gt;itheima-snapshot&lt;/id&gt; &lt;!--snapshot版本上传仓库的具体地址--&gt; &lt;url&gt;http://localhost:8081/repository/itheima-snapshot/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt; 步骤2:发布资源到私服 或者执行Maven命令 mvn deploy 注意: 要发布的项目都需要配置distributionManagement标签，要么在自己的pom.xml中配置，要么在其父项目中配置，然后子项目中继承父项目即可。 发布成功，在私服中就能看到: 现在发布是在itheima-snapshot仓库中，如果想发布到itheima-release仓库中就需要将项目pom.xml中的version修改成RELEASE即可。 如果想删除已经上传的资源，可以在界面上进行删除操作: 如果私服中没有对应的jar，会去中央仓库下载，速度很慢。可以配置让私服去阿里云中下载依赖。 至此私服的搭建就已经完成，相对来说有点麻烦，但是步骤都比较固定，后期大家如果需要的话，就可以参考上面的步骤一步步完成搭建即可。","categories":[],"tags":[{"name":"Maven","slug":"Maven","permalink":"https://gitee.com/yunyd/tags/Maven/"}],"author":"llllz."},{"title":"JUC-Java对象内存布局和对象头","slug":"JUC-Java对象内存布局和对象头 -10","date":"2023-08-17T12:06:43.000Z","updated":"2023-08-25T00:19:35.473Z","comments":true,"path":"posts/8c8efda1.html","link":"","permalink":"https://gitee.com/yunyd/posts/8c8efda1.html","excerpt":"","text":"Java对象内存布局和对象头1.1 面试题 说下JUC，AQS的大致流程 CAS自旋锁，是获取不到锁就一直自旋吗？CAS和synchronized区别在哪里，为什么CAS好，具体优势在哪里？ sychronized底层是如何实现的，实现同步的时候用到了CAS 了吗？具体哪里用到了？ 对象头存储那些信息？长度是多少位存储？ 1.2 Object object = new Object()谈谈你对这句话的理解？Object(模板，在方法区) object(对象的引用，在栈内存) = new Object()(对象，在堆内存) 位置所在——–&gt;JVM堆-&gt;新生区-&gt;伊甸园区 构成布局——–&gt;对象头+实例数据+对齐填充 1.3 对象在堆内存中布局1.3.1 权威定义—-周志明老师JVM在HotSpot虚拟机里，对象在堆内存的存储布局可以划分为三个部分：对象头（Header）、实例数据（Instance Data） 和对齐填充（Padding）。 1.3.2 对象在堆内存中的存储布局 对象头（在64位系统中，Mark Word占了8个字节，类型指针占了8个字节，一共是16个字节） 对象标记（Mark Word） 默认存储对象的HashCode、分代年龄和锁标志等信息。 这些信息都是与对象自身定义无关的数据，所以Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据。 它会根据对象的状态复用自己的存储空间，也就是说在运行期间MarkWord里存储的数据会随着锁标志位的变化而变化。 类元信息（类型指针） 对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象哪个类的实例 实例数据 存放类的属性（Field）数据信息，包括父类的属性信息 对齐填充（保证8个字节的倍数） 虚拟机要求对象起始地址必须是8字节的整数倍，填充数据不是必须存在的，仅仅是为了字节对齐，这部分内存按8字节补充对齐 1.4 再说对象头的MarkWord 1.5 聊聊Object obj = new Object()1.5.1 运行结果展示 1.5.2 压缩指针 Java -XX:+PrintCommandLineFlags -version 查看当前虚拟机信息 默认开启压缩指针，开启后将上述类型指针压缩为4字节，以节约空间 手动关闭压缩指针： -XX: -UseCompressedClassPointers 1.6 换成其他对象试试","categories":[],"tags":[{"name":"JUC并发编程","slug":"JUC并发编程","permalink":"https://gitee.com/yunyd/tags/JUC%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"author":"llllz."},{"title":"JUC-聊聊ThreadLocal","slug":"JUC-聊聊ThreadLocal -9","date":"2023-08-16T03:27:33.000Z","updated":"2023-08-25T00:20:08.303Z","comments":true,"path":"posts/a2a7cd7f.html","link":"","permalink":"https://gitee.com/yunyd/posts/a2a7cd7f.html","excerpt":"","text":"聊聊ThreadLocal1.1 ThreadLocal简介1.1.1 面试题●ThreadLocal中ThreadLocalMap的数据结构和关系 ●ThreadLocal的key是弱引用，这是为什么？ ●ThreadLocal内存泄漏问题你知道吗？ ●ThreadLocal中最后为什么要加remove方法？ 1.1.2 是什么？ThreadLocal提供线程局部变量。这些变量与正常的变量不同，因为每一个线程在访问ThreadLocal实例的时候（通过其get或set方法）都有自己的、独立初始化的变量副本。ThreadLocal实例通常是类中的私有静态字段，使用它的目的是希望将状态（例如，用户ID或事物ID）与线程关联起来。 1.1.3 能干嘛？实现每一个线程都有自己专属的本地变量副本（自己用自己的变量不用麻烦别人，不和其他人共享，人人有份，人各一份）。主要解决了让每个线程绑定自己的值，通过使用get()和set()方法，获取默认值或将其改为当前线程所存的副本的值从而避免了线程安全问题。比如8锁案例中，资源类是使用同一部手机，多个线程抢夺同一部手机，假如人手一份不是天下太平？ 1.1.4 API介绍 1.1.5 永远的helloworld讲起 问题描述：5个销售买房子，集团只关心销售总量的准确统计数，按照总销售额统计，方便集团公司给部分发送奖金——–群雄逐鹿起纷争——为了数据安全只能加锁 需求1演示： class House { int saleCount = 0; public synchronized void saleHouse() { saleCount++; } } public class ThreadLocalDemo { public static void main(String[] args) { House house = new House(); for (int i = 1; i &lt;= 5; i++) { new Thread(() -&gt; { int size = new Random().nextInt(5) + 1; System.out.println(size); for (int j = 1; j &lt;= size; j++) { house.saleHouse(); } }, String.valueOf(i)).start(); } try { TimeUnit.MILLISECONDS.sleep(300); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + \"\\t\" + \"共计卖出多少套： \" + house.saleCount); } } /** * 3 * 4 * 2 * 4 * 2 * main 共计卖出多少套： 15 */ 需求变更：希望各自分灶吃饭，各凭销售本事提成，按照出单数各自统计——-比如房产中介销售都有自己的销售额指标，自己专属自己的，不和别人参和。—-人手一份天下安 需求2： class House { int saleCount = 0; public synchronized void saleHouse() { saleCount++; } ThreadLocal&lt;Integer&gt; saleVolume = ThreadLocal.withInitial(() -&gt; 0); public void saleVolumeByThreadLocal() { saleVolume.set(1 + saleVolume.get()); } } public class ThreadLocalDemo { public static void main(String[] args) { House house = new House(); for (int i = 1; i &lt;= 5; i++) { new Thread(() -&gt; { int size = new Random().nextInt(5) + 1; try { for (int j = 1; j &lt;= size; j++) { house.saleHouse(); house.saleVolumeByThreadLocal(); } System.out.println(Thread.currentThread().getName() + \"\\t\" + \"号销售卖出：\" + house.saleVolume.get()); } finally { house.saleVolume.remove(); } }, String.valueOf(i)).start(); } try { TimeUnit.MILLISECONDS.sleep(300); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + \"\\t\" + \"共计卖出多少套： \" + house.saleCount); } } /** * 3 号销售卖出：1 * 4 号销售卖出：3 * 5 号销售卖出：4 * 2 号销售卖出：3 * 1 号销售卖出：5 * main 共计卖出多少套： 16 */ 1.1.6 总结 因为每个Thread内有自己的实例副本且该副本只有当前线程自己使用 既然其他ThreadLocal不可访问，那就不存在多线程间共享问题 统一设置初始值，但是每个线程对这个值得修改都是各自线程互相独立得 如何才能不争抢 加入synchronized或者Lock控制资源的访问顺序 人手一份，大家各自安好，没有必要争抢 1.2 ThreadLocal源码分析1.2.1 源码解读1.2.2 Thread、ThreadLocal、ThreadLocalMap关系 Thread和ThreadLocal，人手一份 img ThreadLocal和ThreadLocalMap 三者总概括 ThreadLocalMap实际上就是一个以ThreadLocal实例为Key，任意对象为value的Entry对象 当我们为ThreadLocal变量赋值，实际上就是以当前ThreadLocal实例为Key，值为value的Entry往这个ThreadLocalMap中存放 1.2.3 总结 ThreadLocalMap从字面上就可以看出这是一个保存ThreadLocal对象的map（其实是以ThreadLocal为Key），不过是经过了两层包装的ThreadLocal对象： JVM内部维护了一个线程版的Map&lt;ThreadLocal, Value&gt;（通过ThreadLocal对象的set方法，结果把ThreadLocal对象自己当作Key，放进了ThreadLocalMap中），每个线程要用到这个T的时候，用当前的线程去Map里面获取，通过这样让每个线程都拥有了自己独立的变量，人手一份，竞争条件被彻底消除，在并发模式下是绝对安全的变量。 1.3 ThreadLocal内存泄漏问题1.3.1 什么是内存泄漏不再会被使用的对象或者变量占用的内存不能被回收，就是内存泄漏 1.3.2 谁惹的祸？ 再回首ThreadLocalMap 强软弱虚引用 强引用： 对于强引用的对象，就算是出现了OOM也不会对该对象进行回收，死都不收，当一个对象被强引用变量引用时，它处于可达状态，是不可能被垃圾回收机制回收的，即使该对象以后永远都不会被用到，JVM也不会回收，因此强引用是造成Java内存泄露的主要原因之一。 软引用： 是一种相对强引用弱化了一些的引用，对于只有软引用的对象而言，当系统内存充足时，不会被回收，当系统内存不足时，他会被回收，软引用通常用在对内存敏感的程序中，比如高速缓存，内存够用就保留，不够用就回收。 弱引用： 比软引用的生命周期更短，对于只有弱引用的对象而言，只要垃圾回收机制一运行，不管JVM的内存空间是否足够，都会回收该对象占用的内存。 软引用和弱引用的使用场景—–&gt;假如有一个应用需要读取大量的本地图片： 如果每次读取图片都从硬盘读取则会严重影响性能 如果一次性全部加载到内存中又可能会造成内存溢出 此时使用软应用来解决，设计思路时：用一个HashMap来保存图片的路径和与相应图片对象关联的软引用之间的映射关系，在内存不足时，JVM会自动回收这些缓存图片对象所占用的空间，有效避免了OOM的问题 虚引用： 虚引用必须和引用队列联合使用，如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都有可能被垃圾回收器回收，它不能单独使用也不能通过它访问对象。 虚引用的主要作用是跟踪对象被垃圾回收的状态。仅仅是提供了一种确保对象被finalize后，做某些事情的通知机制。换句话说就是在对象被GC的时候会收到一个系统通知或者后续添加进一步的处理，用来实现比finalize机制更灵活的回收操作。 1.3.3 为什么要用弱引用？不用如何？ 为什么要用弱引用： 当方法执行完毕后，栈帧销毁，强引用t1也就没有了，但此时线程的ThreadLocalMap里某个entry的Key引用还指向这个对象，若这个Key是强引用，就会导致Key指向的ThreadLocal对象即V指向的对象不能被gc回收，造成内存泄露 若这个引用时弱引用就大概率会减少内存泄漏的问题（当然，还得考虑key为null这个坑），使用弱引用就可以使ThreadLocal对象在方法执行完毕后顺利被回收且entry的key引用指向为null 这里有个需要注意的问题： ThreadLocalMap使用ThreadLocal的弱引用作为Key，如果一个ThreadLocal没有外部强引用引用他，那么系统gc时，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现Key为null的Entry，就没有办法访问这些Key为null的Entry的value，如果当前线程迟迟不结束的话（好比正在使用线程池），这些key为null的Entry的value就会一直存在一条强引用链 虽然弱引用，保证了Key指向的ThreadLocal对象能够被及时回收，但是v指向的value对象是需要ThreadLocalMap调用get、set时发现key为null时才会去回收整个entry、value，因此弱引用不能100%保证内存不泄露，我们要在不使用某个ThreadLocal对象后，手动调用remove方法来删除它，尤其是在线程池中，不仅仅是内存泄漏的问题，因为线程池中的线程是重复使用的，意味着这个线程的ThreadLocalMap对象也是重复使用的，如果我们不手动调用remove方法，那么后面的线程就有可能获取到上个线程遗留下来的value值，造成bug。 清除脏Entry—-key为null的entry set()方法 get()方法 remove() 1.3.4 最佳实践 ThreadLocal一定要初始化，避免空指针异常。 建议把ThreadLocal修饰为static 用完记得手动remove 1.4 小总结 ThreadLocal并不解决线程间共享数据的问题 ThreadLocal适用于变量在线程间隔离且在方法间共享的场景 ThreadLocal通过隐式的在不同线程内创建独立实例副本避免了实例线程安全的问题 每个线程持有一个只属于它自己的专属map并维护了ThreadLocal对象与具体实例的映射，该Map由于只被持有他的线程访问，故不存在线程安全以及锁的问题 ThreadLocalMap的Entry对ThreadLocal的引用为弱引用。避免了ThreadLocal对象无法被回收的问题 都会通过expungeStaleEntry，cleanSomeSlots，replaceStaleEntry这三个方法回收键为null的Entry对象的值（即为具体实例）以及entry对象本身从而防止内存泄漏，属于安全加固的方法 群雄逐鹿起纷争，人各一份天下安","categories":[],"tags":[{"name":"JUC并发编程","slug":"JUC并发编程","permalink":"https://gitee.com/yunyd/tags/JUC%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"author":"llllz."},{"title":"JUC-原子操作类","slug":"JUC-原子操作类 -8","date":"2023-08-13T23:39:37.000Z","updated":"2023-08-25T00:20:34.157Z","comments":true,"path":"posts/d6c7d2ae.html","link":"","permalink":"https://gitee.com/yunyd/posts/d6c7d2ae.html","excerpt":"","text":"原子操作类 Atomic 翻译成中文是原子的意思。在化学上，我们知道原子是构成一般物质的最小单位，在化学反应中是不可分割的。在我们这里 Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。 1.1 基本类型原子类 AtomicInteger：整型原子类 AtomicBoolean：布尔型原子类 AtomicLong：长整型原子类 1.1.1 常用API简介基本类型原子类常用API简介： public final int get() //获取当前的值 public final int getAndSet(int newValue)//获取当前的值，并设置新的值 public final int getAndIncrement()//获取当前的值，并自增 public final int getAndDecrement() //获取当前的值，并自减 public final int getAndAdd(int delta) //获取当前的值，并加上预期的值 boolean compareAndSet(int expect, int update) //如果输入的数值等于预期值，则以原子方式将该值设置为输入值（update） public final void lazySet(int newValue)//最终设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。 1.1.2 CaseAtomicInteger案例演示： class MyNumber { AtomicInteger atomicInteger = new AtomicInteger(); public void addPlusPlus() { atomicInteger.getAndIncrement(); } } public class AtomicIntegerDemo { public static final int SIZE = 50; public static void main(String[] args) throws InterruptedException { MyNumber myNumber = new MyNumber(); CountDownLatch countDownLatch = new CountDownLatch(SIZE); for (int i = 1; i &lt;= SIZE; i++) { new Thread(() -&gt; { try { for (int j = 1; j &lt;= 10; j++) { myNumber.addPlusPlus(); } } finally { countDownLatch.countDown(); } }, String.valueOf(i)).start(); } countDownLatch.await(); System.out.println(Thread.currentThread().getName() + \"\\t\" + \"result: \" + myNumber.atomicInteger.get());//main result: 500 } } 1.2 数组类型原子类 AtomicIntegerArray：整型数组原子类 AtomicLongrArray：长整型数组原子类 AtomicReferenceArray：用类型数组原子类 1.2.1 常用API简介数组类型原子类常用API简介： public final int get(int i) //获取 index=i 位置元素的值 public final int getAndSet(int i, int newValue)//返回 index=i 位置的当前的值，并将其设置为新值：newValue public final int getAndIncrement(int i)//获取 index=i 位置元素的值，并让该位置的元素自增 public final int getAndDecrement(int i) //获取 index=i 位置元素的值，并让该位置的元素自减 public final int getAndAdd(int i, int delta) //获取 index=i 位置元素的值，并加上预期的值 boolean compareAndSet(int i, int expect, int update) //如果输入的数值等于预期值，则以原子方式将 index=i 位置的元素值设置为输入值（update） public final void lazySet(int i, int newValue)//最终 将index=i 位置的元素设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。 1.2.2 CaseAtomicIntegerArray案例演示： public class AtomicIntegerArrayDemo { public static void main(String[] args) { // AtomicIntegerArray atomicIntegerArray = new AtomicIntegerArray(new int[]{1, 2, 3, 4, 5}); AtomicIntegerArray atomicIntegerArray = new AtomicIntegerArray(new int[5]); for (int i = 0; i &lt; atomicIntegerArray.length(); i++) { System.out.println(atomicIntegerArray.get(i)); } System.out.println(); int tempInt = 0; tempInt = atomicIntegerArray.getAndSet(0, 1122); System.out.println(tempInt + \"\\t\" + atomicIntegerArray.get(0)); tempInt = atomicIntegerArray.getAndIncrement(0); System.out.println(tempInt + \"\\t\" + atomicIntegerArray.get(0)); } } 1.3 引用类型原子类 AtomicReference :引用类型原子类 AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。 解决修改过几次 AtomicMarkableReference：原子更新带有标记的引用类型。该类将 boolean 标记与引用关联起来 解决是否修改过，它的定义就是将标记戳简化为true/false，类似于一次性筷子 AtomicMarkableReference案例演示： public class AtomicMarkableReferenceDemo { static AtomicMarkableReference markableReference = new AtomicMarkableReference(100, false); public static void main(String[] args) { new Thread(() -&gt; { boolean marked = markableReference.isMarked(); System.out.println(Thread.currentThread().getName() + \"\\t\" + \"默认标识: \" + marked);//t1 默认标识: false try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } markableReference.compareAndSet(100, 1000, marked, !marked);//t2 默认标识: false }, \"t1\").start(); new Thread(() -&gt; { boolean marked = markableReference.isMarked(); System.out.println(Thread.currentThread().getName() + \"\\t\" + \"默认标识: \" + marked);//t2 t2线程CASResult：false try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } boolean b = markableReference.compareAndSet(100, 2000, marked, !marked); System.out.println(Thread.currentThread().getName() + \"\\t\" + \"t2线程CASResult：\" + b); System.out.println(Thread.currentThread().getName() + \"\\t\" + markableReference.isMarked());//t2 true System.out.println(Thread.currentThread().getName() + \"\\t\" + markableReference.getReference());//t2 1000 }, \"t2\").start(); } } 1.4 对象的属性修改原子类 AtomicIntegerFieldUpdater：原子更新对象中int类型字段的值 AtomicLongFieldUpdater：原子更新对象中Long类型字段的值 AtomicReferenceFieldUpdater：原子更新对象中引用类型字段的值 1.4.1 使用目的以一种线程安全的方式操作非线程安全对象内的某些字段 1.4.2 使用要求 更新的对象属性必须使用public volatile修饰符 因为对象的属性修改类型原子类都是抽象类，所以每次使用都必须使用静态方法newUpdater()创建一个更新器，并且需要设置想要更新的类和属性 1.4.3 CaseAtomicIntegerFieldUpdater使用案例： class BankAccount { public volatile int money = 0; AtomicIntegerFieldUpdater&lt;BankAccount&gt; atomicIntegerFieldUpdater = AtomicIntegerFieldUpdater.newUpdater(BankAccount.class, \"money\"); public void transferMoney(BankAccount bankAccount) { atomicIntegerFieldUpdater.getAndIncrement(bankAccount); } } public class AtomicIntegerFieldUpdaterDemo { public static void main(String[] args) throws InterruptedException { BankAccount bankAccount = new BankAccount(); CountDownLatch countDownLatch = new CountDownLatch(10); for (int i = 1; i &lt;= 10; i++) { new Thread(() -&gt; { try { for (int j = 1; j &lt;= 1000; j++) { bankAccount.transferMoney(bankAccount); } } finally { countDownLatch.countDown(); } }, String.valueOf(i)).start(); } countDownLatch.await(); System.out.println(Thread.currentThread().getName() + '\\t' + \"result: \" + bankAccount.money); //main result: 10000 } } AtomicReferenceFieldUpdater案例演示： class MyVar { public volatile Boolean isInit = Boolean.FALSE; AtomicReferenceFieldUpdater&lt;MyVar, Boolean&gt; referenceFieldUpdater = AtomicReferenceFieldUpdater.newUpdater(MyVar.class, Boolean.class, \"isInit\"); public void init(MyVar myVar) { if (referenceFieldUpdater.compareAndSet(myVar, Boolean.FALSE, Boolean.TRUE)) { System.out.println(Thread.currentThread().getName() + \"\\t\" + \"--------------start init ,need 2 secondes\"); try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + \"\\t\" + \"--------------over init\"); } else { System.out.println(Thread.currentThread().getName() + \"\\t\" + \"--------------已经有线程进行初始化工作了。。。。。\"); } } } public class AtomicReferenceFieldUpdaterDemo { public static void main(String[] args) { MyVar myVar = new MyVar(); for (int i = 1; i &lt;= 5; i++) { new Thread(() -&gt; { myVar.init(myVar); }, String.valueOf(i)).start(); } } } /** * 1 --------------start init ,need 2 secondes * 5 --------------已经有线程进行初始化工作了。。。。。 * 2 --------------已经有线程进行初始化工作了。。。。。 * 4 --------------已经有线程进行初始化工作了。。。。。 * 3 --------------已经有线程进行初始化工作了。。。。。 * 1 --------------over init */ 1.5 原子操作增强类原理深度解析 DoubleAccumulator：一个或多个变量，它们一起保持运行double使用所提供的功能更新值 DoubleAdder：一个或多个变量一起保持初始为零double总和 LongAccumulator：一个或多个变量，一起保持使用提供的功能更新运行的值long ，提供了自定义的函数操作 LongAdder：一个或多个变量一起维持初始为零long总和（重点），只能用来计算加法，且从0开始计算 1.5.1 常用API 1.5.2 面试题 热点商品点赞计算器，点赞数加加统计，不要求实时精确 一个很大的list，里面都是int类型，如何实现加加，思路？ 1.5.3 点赞计数器多种方式实现点赞计数器案例演示结果： class ClickNumber { int number = 0; public synchronized void clickBySynchronized() { number++; } AtomicLong atomicLong = new AtomicLong(0); public void clickByAtomicLong() { atomicLong.getAndIncrement(); } LongAdder longAdder = new LongAdder(); public void clickByLongAdder() { longAdder.increment(); } LongAccumulator longAccumulator = new LongAccumulator((x, y) -&gt; x + y, 0); public void clickByLongAccumulator() { longAccumulator.accumulate(1); } } public class AccumulatorCompareDemo { public static final int _1W = 10000; public static final int THREAD_NUMBER = 50; public static void main(String[] args) throws InterruptedException { ClickNumber clickNumber = new ClickNumber(); long StartTime; long endTime; CountDownLatch countDownLatch1 = new CountDownLatch(THREAD_NUMBER); CountDownLatch countDownLatch2 = new CountDownLatch(THREAD_NUMBER); CountDownLatch countDownLatch3 = new CountDownLatch(THREAD_NUMBER); CountDownLatch countDownLatch4 = new CountDownLatch(THREAD_NUMBER); StartTime = System.currentTimeMillis(); for (int i = 1; i &lt;= 50; i++) { new Thread(() -&gt; { try { for (int j = 1; j &lt;= 100 * _1W; j++) { clickNumber.clickBySynchronized(); } } finally { countDownLatch1.countDown(); } }, String.valueOf(i)).start(); } countDownLatch1.await(); endTime = System.currentTimeMillis(); System.out.println(\"------costTime: \" + (endTime - StartTime) + \" 毫秒\" + \"\\t clickBySynchronized: \" + clickNumber.number); StartTime = System.currentTimeMillis(); for (int i = 1; i &lt;= 50; i++) { new Thread(() -&gt; { try { for (int j = 1; j &lt;= 100 * _1W; j++) { clickNumber.clickByAtomicLong(); } } finally { countDownLatch2.countDown(); } }, String.valueOf(i)).start(); } countDownLatch2.await(); endTime = System.currentTimeMillis(); System.out.println(\"------costTime: \" + (endTime - StartTime) + \" 毫秒\" + \"\\t clickByAtomicLong: \" + clickNumber.atomicLong.get()); StartTime = System.currentTimeMillis(); for (int i = 1; i &lt;= 50; i++) { new Thread(() -&gt; { try { for (int j = 1; j &lt;= 100 * _1W; j++) { clickNumber.clickByLongAdder(); } } finally { countDownLatch3.countDown(); } }, String.valueOf(i)).start(); } countDownLatch3.await(); endTime = System.currentTimeMillis(); System.out.println(\"------costTime: \" + (endTime - StartTime) + \" 毫秒\" + \"\\t clickByLongAdder: \" + clickNumber.longAdder.sum()); StartTime = System.currentTimeMillis(); for (int i = 1; i &lt;= 50; i++) { new Thread(() -&gt; { try { for (int j = 1; j &lt;= 100 * _1W; j++) { clickNumber.clickByLongAccumulator(); } } finally { countDownLatch4.countDown(); } }, String.valueOf(i)).start(); } countDownLatch4.await(); endTime = System.currentTimeMillis(); System.out.println(\"------costTime: \" + (endTime - StartTime) + \" 毫秒\" + \"\\t clickByLongAccumulator: \" + clickNumber.longAccumulator.get()); } } /** * ------costTime: 1313 毫秒 clickBySynchronized: 50000000 * ------costTime: 825 毫秒 clickByAtomicLong: 50000000 * ------costTime: 92 毫秒 clickByLongAdder: 50000000 * ------costTime: 61 毫秒 clickByLongAccumulator: 50000000 */ 1.5.4 源码、原理分析 架构 原理（LongAdder为什么这么快） 如果是JDK8，推荐使用LongAdder对象，比AtomicLong性能更好（减少乐观锁的重试次数） LongAdder是Striped64的子类 Striped64的基本结构 cell：是java.util.concurrent.atomic下Striped64的一个内部类 LongAdder为什么这么快 LongAdder的基本思路就是分散热点，将value值分散到一个Cell数组中，不同线程会命中到数组的不同槽中，各个线程只对自己槽中的那个值进行CAS操作，这样热点就被分散了，冲突的概率就小很多，如果要获取真正的long值，只要将各个槽中的变量值累加返回 sum()会将所有的Cell数组中的value和base累加作为返回值，核心的思想就是将之前AtomicLong一个value的更新压力分散到多个value中去，从而降级更新热点。 内部有一个base变量，一个Cell[]数组 base变量：低并发，直接累加到该变量上 Cell[]数组：高并发，累加进各个线程自己的槽Cell[i]中 源码解读深度分析 LongAdder在无竞争的情况下，跟AtomicLong一样，对同一个base进行操作，当出现竞争关系时则是采用化整为零分散热点的做法，用空间换时间，用一个数组cells，将一个value值拆分进这个数组cells。多个线程需要同时对value进行操作的时候，可以对线程id进行hash得到hash值，再根据hash值映射到这个数组cells的某个下标，再对该下标所对应的值进行自增操作。当所有线程操作完毕，将数组cells的所有值和base都加起来作为最终结果 add(1L) 1 如果Cells表为空，尝试用CAS更新base字段，成功则退出 2 如果Cells表为空，CAS更新base字段失败，出现竞争，uncontended为true，调用longAccumulate（新建数组） 3 如果Cells表非空，但当前线程映射的槽为空，uncontended为true，调用longAccumulate（初始化） 4 如果Cells表非空，且当前线程映射的槽非空，CAS更新Cell的值，成功则返回，否则，uncontended设为false，调用longAccumulate（扩容） longAccumulate sum sum()会将所有Cell数组中的value和base累加作为返回值。核心思想就是将之前AtomicLong一个value的更新压力分散到多个value中去，从而降级更新热点。 sum执行时，并没有限制对base和cells的更新，所以LongAdder不是强一致性的，它是最终一致性的，对cell的读取无法保证是最后一次写入的值，所以在没有并发的场景下，可以获得正确的结果。 使用总结 AtomicLong线程安全，可允许一些性能损耗，要求高精度时可使用，保证精度，多个线程对单个热点值value进行了原子操作—–保证精度，性能代码 LongAdder当需要在高并发场景下有较好的性能表现，且对值得精确度要求不高时，可以使用，LongAdder时每个线程拥有自己得槽，各个线程一般只对自己槽中得那个值进行CAS操作—保证性能，精度代价 1.5.5 总结 AtomicLong 原理：CAS+自旋 场景：低并发下的全局计算，AtomicLong能保证并发情况下计数的准确性，其内部通过CAS来解决并发安全性问题 缺陷：高并发后性能急剧下降—-AtomicLong的自旋会成为瓶颈（N个线程CAS操作修改线程的值，每次只有一个成功过，其他N-1失败，失败的不停自旋直至成功，这样大量失败自旋的情况，一下子cpu就打高了） LongAdder 原理：CAS+Base+Cell数组分散—–空间换时间并分散了热点数据 场景：高并发下的全局计算 缺陷：sum求和后还有计算线程修改结果的话，最后结果不够准确","categories":[],"tags":[{"name":"JUC并发编程","slug":"JUC并发编程","permalink":"https://gitee.com/yunyd/tags/JUC%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"author":"llllz."},{"title":"JUC-CAS","slug":"JUC-CAS -7","date":"2023-08-12T02:12:22.000Z","updated":"2023-08-25T00:19:20.119Z","comments":true,"path":"posts/ce927603.html","link":"","permalink":"https://gitee.com/yunyd/posts/ce927603.html","excerpt":"","text":"CAS1.1 原子类Java.util.concurrent.atomic 1.2 没有CAS之前多线程环境中不使用原子类保证线程安全i++（基本数据类型） class Test { private volatile int count = 0; //若要线程安全执行执行count++，需要加锁 public synchronized void increment() { count++; } public int getCount() { return count; } } 1.3 使用CAS之后多线程环境中使用原子类保证线程安全i++（基本数据类型）———-&gt;类似于乐观锁 class Test2 { private AtomicInteger count = new AtomicInteger(); public void increment() { count.incrementAndGet(); } //使用AtomicInteger之后，不需要加锁，也可以实现线程安全。 public int getCount() { return count.get(); } } 1.4 是什么？CAS(compare and swap)，中文翻译为比较并交换，实现并发算法时常用到的一种技术，用于保证共享变量的原子性更新，它包含三个操作数—内存位置、预期原值与更新值。 执行CAS操作的时候，将内存位置的值与预期原值进行比较： 如果相匹配，那么处理器会自动将该位置更新为新值 如果不匹配，处理器不做任何操作，多个线程同时执行CAS操作只有一个会成功。 CASDemo演示： public class CASDemo { public static void main(String[] args) { AtomicInteger atomicInteger = new AtomicInteger(5); System.out.println(atomicInteger.compareAndSet(5, 2022) + \"\\t\" + atomicInteger.get());//true 2022 System.out.println(atomicInteger.compareAndSet(5, 2022) + \"\\t\" + atomicInteger.get());//false 2022 } } compareAndSet 源码 1.5 CAS底层原理？谈谈对Unsafe类的理解？1.5.1 UnsafeUnsafe类是CAS的核心类，由于Java方法无法直接访问底层系统，需要通过本地（native）方法来访问，Unsafe相当于一个后门，基于该类可以直接操作特定内存的数据。Unsafe类存在于sun.misc包中，其内部方法操作可以像C的指针一样直接操作内存，因此Java中CAS操作的执行依赖于Unsafe类的方法。 注意：Unsafe类中的所有方法都是native修饰的，也就是说Unsafe类中的所有方法都直接调用操作系统底层资源执行相应任务。 问题：我们知道i++是线程不安全的，那AtomicInteger.getAndIncrement()如何保证原子性？ AtomicInteger类主要利用CAS+volatile和native方法来保证原子操作，从而避免synchronized的高开销，执行效率大为提升： CAS并发原语体现在Java语言中就是sun.misc.Unsafe类中的各个方法。调用Unsafe类中的CAS方法，JVM会帮我们实现出CAS汇编指令。这是一种完全依赖于硬件的功能，通过它实现了原子操作。再次强调，由于CAS是一种系统原语，原语属于操作系统用语范畴，是由若干条指令组成的，用于完成某个功能的一个过程，并且原语的执行必须是连续的，在执行过程中不允许被中断，也就是说CAS是一条CPU的原子指令，不会造成所谓的数据不一致问题。 1.5.2 源码分析 1.5.3 底层汇编 JDK提供的CAS机制，在汇编层级会禁止变量两侧的指令优化，然后使用compxchg指令比较并更新变量值（原子性） 总结： CAS是靠硬件实现的从而在硬件层面提升效率，最底层还是交给硬件来保证原子性和可见性 实现方式是基于硬件平台的汇编指令，在inter的CPU中，使用的是汇编指令compxchg指令 核心思想就是比较要更新变量V的值和预期值E，相等才会将V的值设为新值N，如果不相等自旋再来 1.6 原子引用 原子引用演示： @Data @AllArgsConstructor @NoArgsConstructor class User { String userName; int age; } public class AtomicReferenceDemo { public static void main(String[] args) { AtomicReference&lt;User&gt; atomicReference = new AtomicReference&lt;&gt;(); User z3 = new User(\"z3\", 22); User li4 = new User(\"li4\", 25); atomicReference.set(z3); System.out.println(atomicReference.compareAndSet(z3, li4) + \"\\t\" + atomicReference.get().toString());//true User(userName=li4, age=25) System.out.println(atomicReference.compareAndSet(z3, li4) + \"\\t\" + atomicReference.get().toString());//false User(userName=li4, age=25) } } 1.7 CAS与自旋锁，借鉴CAS思想1.7.1 是什么？CAS是实现自旋锁的基础，CAS利用CPU指令保证了操作的原子性，以达到锁的效果，至于自旋锁—字面意思自己旋转。是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，当线程发现锁被占用时，会不断循环判断锁的状态，直到获取。这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。 1.7.2 自己实现一个自旋锁spinLockDemo题目：实现一个自旋锁，借鉴CAS思想 通过CAS完成自旋锁，A线程先进来调用myLock方法自己持有锁5秒钟，B随后进来后发现当前有线程持有锁，所以只能通过自旋等待，直到A释放锁后B随后抢到。 借鉴CAS思想实现自旋锁： public class SpinLockDemo { AtomicReference&lt;Thread&gt; atomicReference = new AtomicReference&lt;&gt;(); public void lock() { Thread thread = Thread.currentThread(); System.out.println(Thread.currentThread().getName() + \"\\t --------come in\"); while (!atomicReference.compareAndSet(null, thread)) { } } public void unLock() { Thread thread = Thread.currentThread(); atomicReference.compareAndSet(thread, null); System.out.println(Thread.currentThread().getName() + \"\\t --------task over,unLock.........\"); } public static void main(String[] args) { SpinLockDemo spinLockDemo = new SpinLockDemo(); new Thread(() -&gt; { spinLockDemo.lock(); try { TimeUnit.SECONDS.sleep(5); } catch (InterruptedException e) { e.printStackTrace(); } spinLockDemo.unLock(); }, \"A\").start(); try { TimeUnit.MILLISECONDS.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } new Thread(() -&gt; { spinLockDemo.lock(); spinLockDemo.unLock(); }, \"B\").start(); } } /** * A --------come in * B --------come in * A --------task over,unLock......... * B --------task over,unLock......... */ 1.8 CAS缺点1.8.1 循环时间长开销很大 getAndAddInt方法有一个do while 如果CAS失败，会一直进行尝试，如果CAS长时间一直不成功，可能会给CPU带来很大开销 1.8.2 引出来ABA问题？ ABA问题怎么产生的？ CAS算法实现一个重要前提需要提取出内存中某时刻的数据并在当下时刻比较并替换，那么在这个时间差类会导致数据的变化。 比如说一个线程1从内存位置V中取出A，这时候另一个线程2也从内存中取出A，并且线程2进行了一些操作将值变成了B，然后线程2又将V位置的数据变成A，这时候线程1进行CAS操作发现内存中仍然是A，预期ok，然后线程1操作成功——–尽管线程1的CAS操作成功，但是不代表这个过程就是没有问题的。 版本号时间戳原子引用 AtomicStampedReference带戳记流水的简单演示（单线程）： @Data @AllArgsConstructor @NoArgsConstructor class Book { private int id; private String bookName; } public class AtomicStampedReferenceDemo { public static void main(String[] args) { Book javaBook = new Book(1, \"javaBook\"); AtomicStampedReference&lt;Book&gt; atomicStampedReference = new AtomicStampedReference&lt;&gt;(javaBook, 1); System.out.println(atomicStampedReference.getReference() + \"\\t\" + atomicStampedReference.getStamp()); Book mysqlBook = new Book(2, \"mysqlBook\"); boolean b; b = atomicStampedReference.compareAndSet(javaBook, mysqlBook, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1); System.out.println(b + \"\\t\" + atomicStampedReference.getReference() + \"\\t\" + atomicStampedReference.getStamp()); b = atomicStampedReference.compareAndSet(mysqlBook, javaBook, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1); System.out.println(b + \"\\t\" + atomicStampedReference.getReference() + \"\\t\" + atomicStampedReference.getStamp()); } } /** * Book(id=1, bookName=javaBook) 1 * true Book(id=2, bookName=mysqlBook) 2 * true Book(id=1, bookName=javaBook) 3 */ 多线程情况下演示AtomicStampedReference解决ABA问题： public class ABADemo { static AtomicInteger atomicInteger = new AtomicInteger(100); static AtomicStampedReference&lt;Integer&gt; atomicStampedReference = new AtomicStampedReference&lt;&gt;(100, 1); public static void main(String[] args) { // abaHappen();//true 2023 /** * t3 首次版本号: 1 * t4 首次版本号: 1 * t3 2次版本号: 2 * t3 3次版本号: 3 * false 100 3 */ abaNoHappen(); } private static void abaNoHappen() { new Thread(() -&gt; { int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + \"\\t\" + \"首次版本号: \" + stamp); try { TimeUnit.MILLISECONDS.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } atomicStampedReference.compareAndSet(100, 101, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1); System.out.println(Thread.currentThread().getName() + \"\\t\" + \"2次版本号: \" + atomicStampedReference.getStamp()); atomicStampedReference.compareAndSet(101, 100, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1); System.out.println(Thread.currentThread().getName() + \"\\t\" + \"3次版本号: \" + atomicStampedReference.getStamp()); }, \"t3\").start(); new Thread(() -&gt; { int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + \"\\t\" + \"首次版本号: \" + stamp); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } boolean b = atomicStampedReference.compareAndSet(100, 200, stamp, stamp + 1); System.out.println(b + \"\\t\" + atomicStampedReference.getReference() + \"\\t\" + atomicStampedReference.getStamp()); }, \"t4\").start(); } private static void abaHappen() { new Thread(() -&gt; { atomicInteger.compareAndSet(100, 101); try { TimeUnit.MILLISECONDS.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } atomicInteger.compareAndSet(101, 100); }, \"t1\").start(); new Thread(() -&gt; { try { TimeUnit.MILLISECONDS.sleep(200); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(atomicInteger.compareAndSet(100, 2023) + \"\\t\" + atomicInteger.get());//true 2023 }, \"t2\").start(); } } 一句话：比较加版本号一起上","categories":[],"tags":[{"name":"JUC并发编程","slug":"JUC并发编程","permalink":"https://gitee.com/yunyd/tags/JUC%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"author":"llllz."},{"title":"JUC-volatile与JMM","slug":"JUC-volatile与JMM -6","date":"2023-08-11T14:06:31.000Z","updated":"2023-08-25T00:19:55.738Z","comments":true,"path":"posts/3885bbd.html","link":"","permalink":"https://gitee.com/yunyd/posts/3885bbd.html","excerpt":"","text":"volatile与JMM1.1 被volatile修饰的变量有两大特点 特点： 可见性 有序性：有排序要求，有时需要禁重排 内存语义 当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值立即刷新回主内存中 当读一个volatile变量时，JMM会把该线程对应的本地内存设置为无效，重新回到主内存中读取最新共享变量的值 所以volatile的写内存语义是直接刷新到主内存中，读的内存语义是直接从主内存中读取 volatile凭什么可以保证可见性和有序性？ 内存屏障Memory Barrier 1.2内存屏障（面试重点必须拿下）1.2.1 生活case 没有管控，顺序难保 设定规则，禁止乱序—-&gt;上海南京路武警当红灯 再说vilatile两大特性： 可见：写完后立即刷新回主内存并及时发出通知，大家可以去主内存拿最新版，前面的修改对后面所有线程可见 有序性（禁重排）： 重排序是指编译器和处理器为了优化程序性能而对指令序列进行重新排序的一种手段，有时候会改变程序语句的先后顺序，若不存在数据依赖关系，可以重排序；存在数据依赖关系，禁止重排序；但重排后的指令绝对不能改变原有的串行语义！这点在并发设计中必须要重点考虑！ 1.2.2 是什么内存屏障（也称内存栅栏，屏障指令等）是一类同步屏障指令，是CPU或编译器在对内存随机访问的操作中的一个同步点，使得此点之前的所有读写操作都执行后才可以开始执行此点之后的操作，避免代码重排序。内存屏障其实就是一种JVM指令，Java内存模型的重排规则会要求Java编译器在生成JVM指令时插入特定的内存屏障指令，通过这些内存屏障指令，volatile实现了Java内存模型中的可见性和有序性（禁重排），但volatile无法保证原子性 内存屏障之前的所有写操作都要回写到主内存 内存屏障之后的所有读操作都能获得内存屏障之前的所有写操作的最新结果（实现了可见性） 写屏障(Store Memory Barrier)：告诉处理器在写屏障之前将所有存储在缓存(store buffers)中的数据同步到主内存，也就是说当看到Store屏障指令，就必须把该指令之前的所有写入指令执行完毕才能继续往下执行 读屏障(Load Memory Barrier)：处理器在读屏障之后的读操作，都在读屏障之后执行。也就是说在Load屏障指令之后就能够保证后面的读取数据指令一定能够读取到最新的数据。 因此重排序时，不允许把内存屏障之后的指令重排序到内存屏障之前。一句话：对一个volatile变量的写，先行发生于任意后续对这个volatile变量的读，也叫写后读。 1.2.3 内存屏障分类 粗分两种： 读屏障（Load Barrier）：在读指令之前插入读屏障，让工作内存或CPU高速缓存 当中的缓存数据失效，重新回到主内存中获取最新数据。 写屏障（Store Barrier）：在写指令之后插入写屏障，强制把缓冲区的数据刷回到主内存中。 细分四种： 屏障类型 指令示例 说明 LoadLoad Load1;LoadLoad;Load2 保证Load1的读取操作在Load2及后续读取操作之前执行 StoreStore Store1;StoreStore;Store2 在store2及其后的写操作执行前，保证Store1的写操作已经刷新到主内存 LoadStore Load1;LoadStore;Store2 在Store2及其后的写操作执行前，保证Load1的读操作已经结束 StoreLoad Store1;StoreLoad;Load2 保证Store1的写操作已经刷新到主内存后，Load2及其后的读操作才能执行 1.2.4 困难内容 什么叫保证有序性？—–&gt;通过内存屏障禁重排 重排序有可能影响程序的执行和实现，因此，我们有时候希望告诉JVM别自动重排序，我这里不需要重排序，一切听我的。 对于编译器的重排序，JMM会根据重排序的规则，禁止特定类型的编译器重排序 对于处理器的重排序，Java编译器在生成指令序列的适当位置，插入内存屏障指令，来禁止特定类型的处理器排序。 happens-before之volatile变量规则 第一个操作 第二个操作：普通读写 第二个操作：volatile读 第二个操作：volatile写 普通读写 可以重排 可以重排 不可以重排 volatile读 不可以重排 不可以重排 不可以重排 volatile写 可以重排 不可以重排 不可以重排 当第一个操作为volatile读时，不论第二个操作是什么，都不能重排序，这个操作保证了volatile读之后的操作不会被重排到volatile读之前。 当第一个操作为volatile写时，第二个操作为volatile读时，不能重排 当第二个操作为volatile写时，不论第一个操作是什么，都不能重排序，这个操作保证了volatile写之前的操作不会被重排到volatile写之后 JMM就将内存屏障插入策略分为4种规则 读屏障：在每个volatile读操作的后面插入一个LoadLoad屏障或者LoadStore屏障 写屏障：在每个volatile写操作的前面插入StoreStore屏障；在每个volatile写操作的后面插入StoreLoad屏障； 1.3 volatile特性1.3.1 保证可见性保证不同线程对某个变量完成操作后结果及时可见，即该共享变量一旦改变所有线程立即可见 Code 不加volatile，没有可见性，程序无法停止 加了volatile，保证可见性，程序可以停止 加了volatile保证可见性 public class VolatileSeeDemo { /** * t1 -------come in * main 修改完成 * t1 -------flag被设置为false，程序停止 */ static volatile boolean flag = true; public static void main(String[] args) { new Thread(() -&gt; { System.out.println(Thread.currentThread().getName() + \"\\t-------come in\"); while (flag) { } System.out.println(Thread.currentThread().getName() + \"\\t-------flag被设置为false，程序停止\"); }, \"t1\").start(); try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } //更新flag值 flag = false; System.out.println(Thread.currentThread().getName() + \"\\t 修改完成\"); } } volatile变量的读写过程（了解即可） 1.3.2 没有原子性volatile变量的符合操作不具有原子性 对于voaltile变量具备可见性，JVM只是保证从主内存加载到线程工作内存的值是最新的，也仅仅是数据加载时是最新的。但是多线程环境下，“数据计算”和“数据赋值”操作可能多次出现，若数据在加载之后，若主内存volatile修饰变量发生修改之后，线程工作内存的操作将会作废去读主内存最新值，操作出现写丢失问题。即各线程私有内存和主内存公共内存中变量不同步，进而导致数据不一致。由此可见volatile解决的是变量读时的可见性问题，但无法保证原子性，对于多线程修改主内存共享变量的场景必须加锁同步。 至于怎么去理解这个写丢失的问题，就是再将数据读取到本地内存到写回主内存中有三个步骤：数据加载—-&gt;数据计算—-&gt;数据赋值，如果第二个线程在第一个线程读取旧值与写回新值期间读取共享变量的值，那么第二个线程将会与第一个线程一起看到同一个值，并执行自己的操作，一旦其中一个线程对volatile修饰的变量先行完成操作刷回主内存后，另一个线程会作废自己的操作，然后重新去读取最新的值再进行操作，这样的话，它自身的那一次操作就丢失了，这就造成了 线程安全失败，因此，这个问题需要使用synchronized修饰以保证线程安全性。 结论：volatile变量不适合参与到依赖当前值的运算，如i++，i=i+1之类的，通常用来保存某个状态的boolean值或者int值，也正是由于volatile变量只能保证可见性，在不符合以下规则的运算场景中，我们仍然要通过加锁来保证原子性： 运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值 变量不需要与其他的状态变量共同参与不变约束 面试回答为什么不具备原子性：举例i++的例子，在字节码文件中，i++分为三部，间隙期间不同步非原子操作 对于volatile变量，JVM只是保证从主内存加载到线程工作内存的值是最新的，也就是数据加载时是最新的，如果第二个线程在第一个线程读取旧值和写回新值期间读取i的域值，也就造成了线程安全问题。 1.3.3 指令禁重排 在每一个volatile写操作前面插入一个StoreStore屏障—&gt;StoreStore屏障可以保证在volatile写之前，其前面所有的普通写操作都已经刷新到主内存中。 在每一个volatile写操作后面插入一个StoreLoad屏障—&gt;StoreLoad屏障的作用是避免volatile写与后面可能有的volatile读/写操作重排序 在每一个volatile读操作后面插入一个LoadLoad屏障—&gt;LoadLoad屏障用来禁止处理器把上面的volatile读与下面的普通读重排序 在每一个volatile读操作后面插入一个LoadStore屏障—&gt;LoadTore屏障用来禁止处理器把上面的volatile读与下面的普通写重排序 案例说明（volatile读写前或后加了屏障保证有序性）： 1.4 如何正确使用volatile 单一赋值可以，但是含复合运算赋值不可以（i++之类的） volatile int a = 10; volatile boolean flag = true; 状态标志，判断业务是否结束 作为一个布尔状态标志，用于指示发生了一个重要的一次性事件，例如完成初始化或任务结束 开销较低的读，写锁策略 当读远多于写，结合使用内部锁和volatile变量来减少同步的开销 原理是：利用volatile保证读操作的可见性，利用synchronized保证符合操作的原子性 DCL双端锁的发布 问题描述：首先设定一个加锁的单例模式场景 在单线程环境下（或者说正常情况下），在“问题代码处”，会执行以下操作，保证能获取到已完成初始化的实例： 隐患：在多线程环境下，在“问题代码处”，会执行以下操作，由于重排序导致2，3乱序，后果就是其他线程得到的是null而不是完成初始化的对象，其中第3步中实例化分多步执行（分配内存空间、初始化对象、将对象指向分配的内存空间），某些编译器为了性能原因，会将第二步和第三步重排序，这样某个线程肯能会获得一个未完全初始化的实例： 多线程下的解决方案：加volatile修饰 1.5 本章最后的小总结1.5.1 volatile可见性 volatile关键字保证可见性： 对一个被volatile关键字修饰的变量 1 写操作的话，这个变量的最新值会立即刷新回到主内存中 2 读操作的话，总是能够读取到这个变量的最新值，也就是这个变量最后被修改的值 3 当某个线程收到通知，去读取volatile修饰的变量的值的时候，线程私有工作内存的数据失效，需要重新回到主内存中去读取最新的数据。 1.5.2 volatile没有原子性1.5.3 volatile禁重排 1.5.4 凭什么我们Java写了一个volatile关键字，系统底层加入内存屏障？两者的关系如何勾搭？ 1.5.5 内存屏障是什么？是一种屏障指令，它使得CPU或编译器对屏障指令的前和后所发出的内存操作执行一个排序的约束。也称为内存栅栏或栅栏指令。 1.5.6 内存屏障能干吗？ 阻止屏障两边的指令重排序 写操作时加入屏障，强制将线程私有工作内存的数据刷回主物理内存 读操作时加入屏障，线程私有工作内存的数据失效，重新回到主物理内存中获取最新值 1.5.7 内存屏障四大指令 1.5.8 3句话总结 volatile写之前的操作，都禁止重排序到volatile之后 volatile读之后的操作，都禁止重排序到volatile之前 volatile写之后volatile读，禁止重排序","categories":[],"tags":[{"name":"JUC并发编程","slug":"JUC并发编程","permalink":"https://gitee.com/yunyd/tags/JUC%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"author":"llllz."},{"title":"Git常用命令复习","slug":"Git常用命令复习","date":"2023-08-09T23:22:50.000Z","updated":"2023-08-25T00:18:59.808Z","comments":true,"path":"posts/d33e17b2.html","link":"","permalink":"https://gitee.com/yunyd/posts/d33e17b2.html","excerpt":"","text":"Git常用命令复习Git工作区中文件的状态Git工作区中的文件存在两种状态： untracked 未跟踪 （未被纳入版本控制） tracked 已跟踪 （被纳入版本控制） Unmodified 未修改状态 Modified 已修改状态 Staged 已暂存状态 注意： 这些文件的状态会随着我们执行Git的命令发生改变 Git常用命令 命令名称 作用 git config –global user.name 用户名 设置用户签名 git config –global user.email 邮箱 设置用户签名 git init 初始化本地库 git status 查看本地库状态 git add 文件名 添加到暂存区 git commit -m “日志信息” 文件名 提交到本地库 git reflog 查看历史版本记录 git log 查看版本详细信息 git reset –hard 版本号 版本穿梭 git reset 文件名 将暂存区的文件取消暂存 分支的操作 命令名称 作用 git branch 分支名 创建分支 git branch -v 查看本地分支 git branch -r 查看所有远程分支 git branch -a 查看所有分支 git checkout 分支名 切换分支 git merge 分支名 把指定的分支合并到当前分支上 远程仓库操作 命令名称 作用 git remote -v 查看当前所有远程地址别名 git remote add 别名 远程地址 起别名 git push 别名 分支 推送本地分支上的内容到远程仓库 git clone 远程地址 将远程仓库的内容克隆到本地 git pull 远程库地址别名 远程分支名 将远程仓库对于分支最新内容拉下来后与当前本地分支直接合并 标签操作 命令名称 作用 git tag 列出已有的标签 git tag [name] 创建标签 git push [shortName] [name] 将标签推送至远程仓库 (shortName为远程仓库别名) （name为标签名） git checkout -b [branch] [name] 检出标签 （branch为分支名，随便写，会自动创建该分支） 创建远程仓库的远程分支 在本地仓库创建分支 git branch + 分支名 查看全部分支 git branch -a 在远程仓库上生成分支 git push 远程仓库地址 + 刚刚创建的分支名 免密登录先删除用户里面的.ssh目录 然后输入如下命令: ssh-keygen -t rsa -C \"你的github登录邮箱\"","categories":[],"tags":[{"name":"Git","slug":"Git","permalink":"https://gitee.com/yunyd/tags/Git/"}],"author":"llllz."},{"title":"校园美食圈","slug":"校园美食圈","date":"2023-08-09T08:02:31.000Z","updated":"2023-08-25T00:23:45.514Z","comments":true,"path":"posts/38f0fa30.html","link":"","permalink":"https://gitee.com/yunyd/posts/38f0fa30.html","excerpt":"","text":"校园美食圈项目所用到的技术：Spring 相关： Spring Boot 2.x Spring MVC 数据存储层： MySQL：存储数据 MyBatis Plus：数据访问框架 Redis 相关： spring-data-redis：操作 Redis Lettuce：操作 Redis 的高级客户端 Apache Commons Pool：用于实现 Redis 连接池 Redisson：基于 Redis 的分布式数据网格 工具库： HuTool：工具库合集 Lombok：注解式代码生成工具 后端： 为方便其他业务后续使用缓存，使用泛型 + 函数式编程实现了缓存访问静态方法，并解决了缓存雪崩、缓存穿透等问题； 优惠券秒杀： 使用Redis + Lua 脚本实现库存预检，并通过Stream队列实现订单的异步创建，解决了超卖问题，实现一人一单； 店铺查询：使用Redis 对高频访问店铺进行缓存，降低DB压力同时提高数据查询性能； 短信登陆：使用Redis实现分布式Session，解决了集群间登录态同步问题；使用Hash代替String来存储用户信息，节约了内存并便于单字段的修改； 使用Redis Set数据结构实现用户关注、共同关注功能； 使用常量类全局管理Redis Key前缀、TTL等，保证了键空间的业务隔离，减少冲突； 项目功能：登陆界面： 项目主页面：登录进来后，展示的主页面 从主页面点击美食：会展示商家列表信息 这个是探店的人发表的评论 优惠券秒杀：","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"https://gitee.com/yunyd/tags/%E9%A1%B9%E7%9B%AE/"}],"author":"llllz."},{"title":"JUC-Java内存模型之JMM","slug":"Java内存模型之JMM -5","date":"2023-08-09T01:06:49.000Z","updated":"2023-08-25T00:19:06.433Z","comments":true,"path":"posts/6c9d84e4.html","link":"","permalink":"https://gitee.com/yunyd/posts/6c9d84e4.html","excerpt":"","text":"Java内存模型之JMM1.1 先从大场面试开始●你知道什么是Java内存模型JMM吗？ ●JMM和volatile他们两个之间的关系？ ●JMM没有那些特征或者它的三大特征是什么？ ●为什么要有JMM，它为什么出现？作用和功能是什么？ ●happens-before先行并发原则你有了解过吗？ 1.2 计算机硬件存储体系 CPU的运行并不是直接操作内存而是先把内存里面的数据读到缓存，而内存的读和写操作的时候会造成不一致的问题。JVM规范中试图定义一种Java内存模型来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致性的内存访问效果。 1.3 Java内存模型Java Memory ModelJMM（Java内存模型Java Memory Model）本身是一种抽象的概念并不真实存在，它仅仅描述的是一组约定或规范，通过这组规范定义了程序中（尤其是多线程）各个变量的读写访问方式并决定一个线程对共享变量的写入以及如何变成对另一个线程可见，关键技术点都是围绕多线程的原子性、可见性和有序性展开的。 能干嘛？ 通过JMM来实现线程和主内存之间的抽象关系 屏蔽各个硬件平台和操作系统的内存访问差异以实现让Java程序再各种平台下都能达到一致性的内存访问效果。 1.4 JMM规范下三大特性 可见性：是指当一个线程修改了某一个共享变量的值，其他线程是否能够立即知道该变更，JMM规定了所有的变量都存储在主内存中。 系统中主内存共享变量数据修改被写入的时机是不确定的，多线程并发下很可能出现“脏读”，所以每个线程都有自己的工作内存，线程自己的工作内存中保存了该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作（读取、赋值等）都必须在线程自己的工作内存中进行，而不能够直接写入主内存中的变量，不同线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。 线程脏读 主内存中有变量X，初始值为0 线程A要将X加1，先将X=0拷贝到自己的私有内存中，然后更新X的值 线程A将更新后的X值回刷到主内存的时间是不固定的 刚好在线程A没有回刷x到主内存时，线程B同样从主内存中读取X，此时为0，和线程A一样的操作，最后期盼的X=2就会变成X=1 原子性：指一个操作是不可被打断的，即多线程环境下，操作不能被其他线程干扰 有序性：对于一个线程的执行代码而言，我们总是习惯性地认为代码的执行总是从上到下，有序执行。但为了提升性能，编译器和处理器通常会对指令序列进行重新排序。Java规范规定JVM线程内部维持顺序化语义，即只要程序的最终结果与它顺序话执行的结果相等，那么指令的执行顺序可以与代码顺序不一致，此过程叫指令的重排序。 优缺点： JVM能根据处理器特性（CPU多级缓存系统、多核处理器等）适当的对机器指令进行重排序，使机器指令更符合CPU的执行特性，最大限度的发挥机器性能。 但是指令重排可以保证串行语义一致，但没有义务保证多线程的语义也一致（即可能产生“脏读”），简单而言就是两行以上不相干的代码在执行的时候有可能先执行的不是第一条，不见得是从上到下顺序执行，执行顺序会被优化。 从源码到最终执行示例图： 单线程环境里确实能够保证程序最终执行结果和代码顺序执行的结果一致 处理器在进行重排序时必须考虑到指令之间的数据依赖性 多线程环境中线程交替执行，由于编译器优化重排的存在，可能出现乱序现象，两个线程使用的变量能否保证一致性是无法确定的，结果无法预测 1.5JMM规范下多线程对变量的读写过程由于JVM运行程序的实体是线程，而每个线程创建时JVM都会为其创建一个工作内存（有的地方成为栈空间），工作内存是每个线程的私有数据区域，而Java内存模型中规定所有变量都存储在主内存，主内存是共享内存区域，所有线程都可以访问，但线程对变量的操作（读写赋值等）必须在工作内存中进行，首先要将变量从主内存拷贝到线程自己的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主内存，不能直接操作主内存中的变量，各个线程中的工作内存存储着主内存中的变量副本拷贝，因此不同的线程无法访问对方的工作内存，线程间的通信（传值）必须通过主内存来完成，其简要访问过程如下图： JMM定义了线程和主内存之间的抽象关系： 线程之间的共享变量存储在主内存中（从硬件角度讲就是内存条） 每个线程都有一个自己的本地工作内存，本地工作内存中存储了该线程用来读写共享变量的副本（从硬件角度来说就是CPU的缓存） 小总结： 我们定义的所有共享变量都储存在物理主内存中 每个线程都有自己独立的工作内存，里面保证该线程使用到的共享变量的副本（主内存中该变量的一份拷贝） 线程对共享变量所有的操作都必须先在线程自己的工作内存中进行后写回主内存，不能直接从主内存在读写（不能越级） 不同线程之间也无法直接访问其他线程的工作内存中的变量，线程间变量值的传递需要通过主内存来进行（同级不能互相访问） 1.6 JMM规范下多线程先行发生原则之happens-before在JVM中，如果一个操作执行的结果需要对另一个操作可见或者代码重排序，那么这两个操作之间必须存在happens-before（先行发生）原则，逻辑上的先后关系。 1.6.1 x,y案例说明 ——————- ——————- x = 5 线程A执行 y = x 线程B执行 上述称之为： 写后读 问题？ y是否等于5呢？如果线程A的操作（x=5）happens-before（先行发生）线程B的操作(y=x)，那么可以确定线程B执行y=5一定成立；如果他们不存在happens-before原则，那么y=5不一定成立这就是happens-before原则的为例———–&gt;包含可见性和有序性的约束 1.6.2 先行并发原则说明如果Java内存模型中所有的有序性都仅靠volatile和synchronized来完成，那么有很多操作都将变得非常罗嗦，但是我们在编写Java并发代码的时候并没有察觉到这一点。 我们没有时时、处处、次次，添加volatile和synchronized来完成程序，这是因为Java语言中JMM原则下，有一个“先行发生”（happens-before）的原则限制和规矩，给你理好了规矩！ 这个原则非常重要：它是判断数据是否存在竞争，线程是否安全的非常有用的手段。依赖这个原则，我们可以通过几条简单规则一揽子解决并发环境下两个操作之间是否可能存在冲突的所有问题，而不需要陷入Java内存模型晦涩难懂的底层编译原理之中。 1.6.3 happens-before总原则 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前 如果两个操作之间存在happens-before关系，并不意味着一定要按照happens-before原则制定的顺序来执行。如果重排之后的执行结果与按照happens-before关系来执行的结果一致，那么这种重排序并不非法。 1.6.4 happens-before之8条从JDK 5开始，Java使用新的JSR-133内存模型，提供了 happens-before 原则来辅助保证程序执行的原子性、可见性以及有序性的问题，它是判断数据是否存在竞争、线程是否安全的依据，happens-before 原则内容如下： 次序规则：一个线程内，按照代码的顺序，写在前面的操作先行发生于写在后面的操作，也就是说前一个操作的结果可以被后续的操作获取（保证语义串行性，按照代码顺序执行）。比如前一个操作把变量x赋值为1，那后面一个操作肯定能知道x已经变成了1 锁定规则：一个unLock操作先行发生于后面对同一个锁的lock操作（后面指时间上的先后） volatile变量规则：对一个volatile变量的写操作先行发生于后面对这个变量的读操作，前面的写对后面的读是可见的，这里的后面同样指时间上的先后 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C 线程启动规则（Thread start Rule）：Thread对象的start()方法先行发生于此线程的每一个动作 线程中断规则（Thread Interruption Rule）： 对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生 可以通过Thread.interrupted()检测到是否发生中断 也就是说你要先调用interrupt()方法设置过中断标志位，我才能检测到中断发生 线程终止规则（Thread Termination Rule）：线程中的所有操作都优先发生于对此线程的终止检测，我们可以通过isAlive()等手段检测线程是否已经终止执行 对象终结规则（Finalizer Rule）：一个对象的初始化完成（构造函数执行结束）先行发生于它的finalize(）方法的开始——-&gt;对象没有完成初始化之前，是不能调用finalized()方法的 1.6.5 happens-before小总结 在Java语言里面，Happens-before的语义本质上是一种可见性 A happens-before B ,意味着A发生过的事情对B而言是可见的，无论A事件和B事件是否发生在同一线程里 JVM的设计分为两部分： 一部分是面向我们程序员提供的，也就是happens-before规则，它通俗易懂的向我们程序员阐述了一个强内存模型，我们只要理解happens-before规则，就可以编写并发安全的程序了 另一部分是针对JVM实现的，为了尽可能少的对编译器和处理器做约束从而提升性能，JMM在不影响程序执行结果的前提下对其不做要求，即允许优化重排序，我们只要关注前者就好了，也就是理解happens-before规则即可，其他繁杂的内容由JMM规范结合操作系统给我们搞定，我们只写好代码即可 1.6.6 案例说明初始案例演示： private int value =0; public int getValue(){ return value; } public int setValue(){ return ++value; } 问题描述：假设存在线程A和B，线程A先（时间上的先后）调用了setValue()方法，然后线程B调用了同一个对象的getValue()方法，那么线程B收到的返回值是什么？ 答案：不一定 分析happens-before规则（规则5，6，7，8可以忽略，和代码无关） 1 由于两个方法由不同线程调用，不满足一个线程的条件，不满足程序次序规则 2 两个方法都没有用锁，不满足锁定规则 3 变量没有使用volatile修饰，所以不满足volatile变量规则 4 传递规则肯定不满足 综上：无法通过happens-before原则推导出线程A happens-before 线程B，虽然可以确定时间上线程A优于线程B，但就是无法确定线程B获得的结果是什么，所以这段代码不是线程安全的 注意： ● 如果两个操作的执行次序无法从happens-before原则推导出来，那么就不能保证他们的有序性，虚拟机可以随意对他们进行重排序 如何修复？ 把getter/setter方法都定义为synchronized方法——-&gt;不好，重量锁，并发性下降 把getter/setter方法都定义为synchronized方法： private int value =0; public synchronized int getValue(){ return value; } public synchronized int setValue(){ return ++value; } 把Value定义为volatile变量，由于setter方法对value的修改不依赖value的原值，满足volatile关键字使用场景 把Value定义为volatile变量： /** * 利用volatile保证读取操作的可见性， * 利用synchronized保证符合操作的原子性结合使用锁和volatile变量来减少同步的开销 */ private volatile int value =0; public int getValue(){ return value; } public synchronized int setValue(){ return ++value; }","categories":[],"tags":[{"name":"JUC并发编程","slug":"JUC并发编程","permalink":"https://gitee.com/yunyd/tags/JUC%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"author":"llllz."},{"title":"MyBatis-Plus","slug":"MyBatis-Plus复习","date":"2023-08-08T03:56:16.000Z","updated":"2023-08-25T00:21:06.044Z","comments":true,"path":"posts/1276cc28.html","link":"","permalink":"https://gitee.com/yunyd/posts/1276cc28.html","excerpt":"","text":"MyBatis-Plus复习1.MyBatisPlus入门案例与简介这一节我们来学习下MyBatisPlus的入门案例与简介，这个和其他课程都不太一样，其他的课程都是先介绍概念，然后再写入门案例。而对于MyBatisPlus的学习，我们将顺序做了调整，主要的原因MyBatisPlus主要是对MyBatis的简化，所有我们先体会下它简化在哪，然后再学习它是什么，以及它帮我们都做哪些事。 1.1 入门案例 MybatisPlus(简称MP)是基于MyBatis框架基础上开发的增强型工具，旨在简化开发、提供效率。 开发方式 基于MyBatis使用MyBatisPlus 基于Spring使用MyBatisPlus ==基于SpringBoot使用MyBatisPlus== SpringBoot刚刚我们学习完成，它能快速构建Spring开发环境用以整合其他技术，使用起来是非常简单，对于MP的学习，我们也基于SpringBoot来构建学习。 学习之前，我们先来回顾下，SpringBoot整合Mybatis的开发过程: 创建SpringBoot工程 勾选配置使用的技术，能够实现自动添加起步依赖包 设置dataSource相关属性(JDBC参数) 定义数据层接口映射配置 我们可以参考着上面的这个实现步骤把SpringBoot整合MyBatisPlus来快速实现下，具体的实现步骤为: 步骤1:创建数据库及表create database if not exists mybatisplus_db character set utf8; use mybatisplus_db; CREATE TABLE user ( id bigint(20) primary key auto_increment, name varchar(32) not null, password varchar(32) not null, age int(3) not null , tel varchar(32) not null ); insert into user values(1,'Tom','tom',3,'18866668888'); insert into user values(2,'Jerry','jerry',4,'16688886666'); insert into user values(3,'Jock','123456',41,'18812345678'); insert into user values(4,'传智播客','itcast',15,'4006184000'); 步骤2:创建SpringBoot工程 步骤3:勾选配置使用技术 说明: 由于MP并未被收录到idea的系统内置配置，无法直接选择加入，需要手动在pom.xml中配置添加 步骤4:pom.xml补全依赖&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.4.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.16&lt;/version&gt; &lt;/dependency&gt; 说明: druid数据源可以加也可以不加，SpringBoot有内置的数据源，可以配置成使用Druid数据源 从MP的依赖关系可以看出，通过依赖传递已经将MyBatis与MyBatis整合Spring的jar包导入，我们不需要额外在添加MyBatis的相关jar包 步骤5:添加MP的相关配置信息resources默认生成的是properties配置文件，可以将其替换成yml文件，并在文件中配置数据库连接的相关信息:application.yml spring: datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/mybatisplus_db?serverTimezone=UTC username: root password: root 说明:==serverTimezone是用来设置时区，UTC是标准时区，和咱们的时间差8小时，所以可以将其修改为Asia/Shanghai== 步骤6:根据数据库表创建实体类public class User { private Long id; private String name; private String password; private Integer age; private String tel; //setter...getter...toString方法略 } 步骤7:创建Dao接口@Mapper public interface UserDao extends BaseMapper&lt;User&gt;{ } 步骤8:编写引导类@SpringBootApplication //@MapperScan(\"com.itheima.dao\") public class Mybatisplus01QuickstartApplication { public static void main(String[] args) { SpringApplication.run(Mybatisplus01QuickstartApplication.class, args); } } **说明:**Dao接口要想被容器扫描到，有两种解决方案: 方案一:在Dao接口上添加@Mapper注解，并且确保Dao处在引导类所在包或其子包中 该方案的缺点是需要在每一Dao接口中添加注解 方案二:在引导类上添加@MapperScan注解，其属性为所要扫描的Dao所在包 该方案的好处是只需要写一次，则指定包下的所有Dao接口都能被扫描到，@Mapper就可以不写。 步骤9:编写测试类@SpringBootTest class MpDemoApplicationTests { @Autowired private UserDao userDao; @Test public void testGetAll() { List&lt;User&gt; userList = userDao.selectList(null); System.out.println(userList); } } 说明: userDao注入的时候下面有红线提示的原因是什么? UserDao是一个接口，不能实例化对象 只有在服务器启动IOC容器初始化后，由框架创建DAO接口的代理对象来注入 现在服务器并未启动，所以代理对象也未创建，IDEA查找不到对应的对象注入，所以提示报红 一旦服务启动，就能注入其代理对象，所以该错误提示不影响正常运行。 查看运行结果: 跟之前整合MyBatis相比，你会发现我们不需要在DAO接口中编写方法和SQL语句了，只需要继承BaseMapper接口即可。整体来说简化很多。 1.2 MybatisPlus简介MyBatisPlus（简称MP）是基于MyBatis框架基础上开发的增强型工具，旨在==简化开发、提高效率== 通过刚才的案例，相信大家能够体会简化开发和提高效率这两个方面的优点。 MyBatisPlus的官网为:https://mp.baomidou.com/ 说明: 现在的页面中，这一行已经被删除，现在再去访问https://mybatis.plus会发现访问不到，这个就有很多可能性供我们猜想了，所以大家使用baomidou的网址进行访问即可。 官方文档中有一张很多小伙伴比较熟悉的图片: 从这张图中我们可以看出MP旨在成为MyBatis的最好搭档，而不是替换MyBatis,所以可以理解为MP是MyBatis的一套增强工具，它是在MyBatis的基础上进行开发的，我们虽然使用MP但是底层依然是MyBatis的东西，也就是说我们也可以在MP中写MyBatis的内容。 对于MP的学习，大家可以参考着官方文档来进行学习，里面都有详细的代码案例。 MP的特性: 无侵入：只做增强不做改变，不会对现有工程产生影响 强大的 CRUD 操作：内置通用 Mapper，少量配置即可实现单表CRUD 操作 支持 Lambda：编写查询条件无需担心字段写错 支持主键自动生成 内置分页插件 …… 2.标准数据层开发在这一节中我们重点学习的是数据层标准的CRUD(增删改查)的实现与分页功能。代码比较多，我们一个个来学习。 2.1 标准CRUD使用对于标准的CRUD功能都有哪些以及MP都提供了哪些方法可以使用呢? 我们先来看张图: 对于这张图的方法，我们挨个来演示下: 首先说下，案例中的环境就是咱们入门案例的内容，第一个先来完成新增功能 2.2 新增在进行新增之前，我们可以分析下新增的方法: int insert (T t) T:泛型，新增用来保存新增数据 int:返回值，新增成功后返回1，没有新增成功返回的是0 在测试类中进行新增操作: @SpringBootTest class Mybatisplus01QuickstartApplicationTests { @Autowired private UserDao userDao; @Test void testSave() { User user = new User(); user.setName(\"黑马程序员\"); user.setPassword(\"itheima\"); user.setAge(12); user.setTel(\"4006184000\"); userDao.insert(user); } } 执行测试后，数据库表中就会添加一条数据。 但是数据中的主键ID，有点长，那这个主键ID是如何来的?我们更想要的是主键自增，应该是5才对，这个是我们后面要学习的主键ID生成策略，这块的这个问题，我们暂时先放放。 2.3 删除在进行删除之前，我们可以分析下删除的方法: int deleteById (Serializable id) Serializable：参数类型 思考:参数类型为什么是一个序列化类? 从这张图可以看出， String和Number是Serializable的子类， Number又是Float,Double,Integer等类的父类， 能作为主键的数据类型都已经是Serializable的子类， MP使用Serializable作为参数类型，就好比我们可以用Object接收任何数据类型一样。 int:返回值类型，数据删除成功返回1，未删除数据返回0。 在测试类中进行新增操作: @SpringBootTest class Mybatisplus01QuickstartApplicationTests { @Autowired private UserDao userDao; @Test void testDelete() { userDao.deleteById(1401856123725713409L); } } 2.4 修改在进行修改之前，我们可以分析下修改的方法: int updateById(T t); T:泛型，需要修改的数据内容，注意因为是根据ID进行修改，所以传入的对象中需要有ID属性值 int:返回值，修改成功后返回1，未修改数据返回0 在测试类中进行新增操作: @SpringBootTest class Mybatisplus01QuickstartApplicationTests { @Autowired private UserDao userDao; @Test void testUpdate() { User user = new User(); user.setId(1L); user.setName(\"Tom888\"); user.setPassword(\"tom888\"); userDao.updateById(user); } } **说明:**修改的时候，只修改实体对象中有值的字段。 2.5 根据ID查询在进行根据ID查询之前，我们可以分析下根据ID查询的方法: T selectById (Serializable id) Serializable：参数类型,主键ID的值 T:根据ID查询只会返回一条数据 在测试类中进行新增操作: @SpringBootTest class Mybatisplus01QuickstartApplicationTests { @Autowired private UserDao userDao; @Test void testGetById() { User user = userDao.selectById(2L); System.out.println(user); } } 2.6 查询所有在进行查询所有之前，我们可以分析下查询所有的方法: List&lt;T&gt; selectList(Wrapper&lt;T&gt; queryWrapper) Wrapper：用来构建条件查询的条件，目前我们没有可直接传为Null List:因为查询的是所有，所以返回的数据是一个集合 在测试类中进行新增操作: @SpringBootTest class Mybatisplus01QuickstartApplicationTests { @Autowired private UserDao userDao; @Test void testGetAll() { List&lt;User&gt; userList = userDao.selectList(null); System.out.println(userList); } } 我们所调用的方法都是来自于DAO接口继承的BaseMapper类中。里面的方法有很多，我们后面会慢慢去学习里面的内容。 2.7 Lombok代码写到这，我们会发现DAO接口类的编写现在变成最简单的了，里面什么都不用写。反过来看看模型类的编写都需要哪些内容: 私有属性 setter…getter…方法 toString方法 构造函数 虽然这些内容不难，同时也都是通过IDEA工具生成的，但是过程还是必须得走一遍，那么对于模型类的编写有没有什么优化方法?就是我们接下来要学习的Lombok。 概念 Lombok，一个Java类库，提供了一组注解，简化POJO实体类开发。 使用步骤步骤1:添加lombok依赖&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;!--&lt;version&gt;1.18.12&lt;/version&gt;--&gt; &lt;/dependency&gt; 注意：版本可以不用写，因为SpringBoot中已经管理了lombok的版本。 步骤2:安装Lombok的插件==新版本IDEA已经内置了该插件，如果删除setter和getter方法程序有报红，则需要安装插件== 如果在IDEA中找不到lombok插件，可以访问如下网站 https://plugins.jetbrains.com/plugin/6317-lombok/versions 根据自己IDEA的版本下载对应的lombok插件，下载成功后，在IDEA中采用离线安装的方式进行安装。 步骤3:模型类上添加注解Lombok常见的注解有: @Setter:为模型类的属性提供setter方法 @Getter:为模型类的属性提供getter方法 @ToString:为模型类的属性提供toString方法 @EqualsAndHashCode:为模型类的属性提供equals和hashcode方法 ==@Data:是个组合注解，包含上面的注解的功能== ==@NoArgsConstructor:提供一个无参构造函数== ==@AllArgsConstructor:提供一个包含所有参数的构造函数== Lombok的注解还有很多，上面标红的三个是比较常用的，其他的大家后期用到了，再去补充学习。 @Data @AllArgsConstructor @NoArgsConstructor public class User { private Long id; private String name; private String password; private Integer age; private String tel; } 说明: Lombok只是简化模型类的编写，我们之前的方法也能用，比如有人会问:我如果只想要有name和password的构造函数，该如何编写? @Data @AllArgsConstructor @NoArgsConstructor public class User { private Long id; private String name; private String password; private Integer age; private String tel; public User(String name, String password) { this.name = name; this.password = password; } } 这种方式是被允许的。 2.8 分页功能基础的增删改查就已经学习完了，刚才我们在分析基础开发的时候，有一个分页功能还没有实现，在MP中如何实现分页功能，就是咱们接下来要学习的内容。 分页查询使用的方法是: IPage&lt;T&gt; selectPage(IPage&lt;T&gt; page, Wrapper&lt;T&gt; queryWrapper) IPage:用来构建分页查询条件 Wrapper：用来构建条件查询的条件，目前我们没有可直接传为Null IPage:返回值，你会发现构建分页条件和方法的返回值都是IPage IPage是一个接口，我们需要找到它的实现类来构建它，具体的实现类，可以进入到IPage类中按ctrl+h,会找到其有一个实现类为Page。 步骤1:调用方法传入参数获取返回值@SpringBootTest class Mybatisplus01QuickstartApplicationTests { @Autowired private UserDao userDao; //分页查询 @Test void testSelectPage(){ //1 创建IPage分页对象,设置分页参数,1为当前页码，3为每页显示的记录数 IPage&lt;User&gt; page=new Page&lt;&gt;(1,3); //2 执行分页查询 userDao.selectPage(page,null); //3 获取分页结果 System.out.println(\"当前页码值：\"+page.getCurrent()); System.out.println(\"每页显示数：\"+page.getSize()); System.out.println(\"一共多少页：\"+page.getPages()); System.out.println(\"一共多少条数据：\"+page.getTotal()); System.out.println(\"数据：\"+page.getRecords()); } } 步骤2:设置分页拦截器这个拦截器MP已经为我们提供好了，我们只需要将其配置成Spring管理的bean对象即可。 @Configuration public class MybatisPlusConfig { @Bean public MybatisPlusInterceptor mybatisPlusInterceptor(){ //1 创建MybatisPlusInterceptor拦截器对象 MybatisPlusInterceptor mpInterceptor=new MybatisPlusInterceptor(); //2 添加分页拦截器 mpInterceptor.addInnerInterceptor(new PaginationInnerInterceptor()); return mpInterceptor; } } **说明:**上面的代码记不住咋办呢? 这些内容在MP的官方文档中有详细的说明，我们可以查看官方文档类配置 步骤3:运行测试程序 如果想查看MP执行的SQL语句，可以修改application.yml配置文件， mybatis-plus: configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl #打印SQL日志到控制台 打开日志后，就可以在控制台打印出对应的SQL语句，开启日志功能性能就会受到影响，调试完后记得关闭。 3.DQL编程控制增删改查四个操作中，查询是非常重要的也是非常复杂的操作，这块需要我们重点学习下，这节我们主要学习的内容有: 条件查询方式 查询投影 查询条件设定 字段映射与表名映射 3.1 条件查询3.1.1 条件查询的类 MyBatisPlus将书写复杂的SQL查询条件进行了封装，使用编程的形式完成查询条件的组合。 这个我们在前面都有见过，比如查询所有和分页查询的时候，都有看到过一个Wrapper类，这个类就是用来构建查询条件的，如下图所示: 那么条件查询如何使用Wrapper来构建呢? 3.1.2 环境构建在构建条件查询之前，我们先来准备下环境 创建一个SpringBoot项目 pom.xml中添加对应的依赖 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.5.0&lt;/version&gt; &lt;/parent&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;mybatisplus_02_dql&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.4.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.16&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 编写UserDao接口 @Mapper public interface UserDao extends BaseMapper&lt;User&gt; { } 编写模型类 @Data public class User { private Long id; private String name; private String password; private Integer age; private String tel; } 编写引导类 @SpringBootApplication public class Mybatisplus02DqlApplication { public static void main(String[] args) { SpringApplication.run(Mybatisplus02DqlApplication.class, args); } } 编写配置文件 # dataSource spring: datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/mybatisplus_db?serverTimezone=UTC username: root password: root # mp日志 mybatis-plus: configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl 编写测试类 @SpringBootTest class Mybatisplus02DqlApplicationTests { @Autowired private UserDao userDao; @Test void testGetAll(){ List&lt;User&gt; userList = userDao.selectList(null); System.out.println(userList); } } 最终创建的项目结构为: 测试的时候，控制台打印的日志比较多，速度有点慢而且不利于查看运行结果，所以接下来我们把这个日志处理下: 取消初始化spring日志打印，resources目录下添加logback.xml，名称固定，内容如下: &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;configuration&gt; &lt;/configuration&gt; **说明:**logback.xml的配置内容，不是我们学习的重点，如果有兴趣可以自行百度查询。 取消MybatisPlus启动banner图标 application.yml添加如下内容: # mybatis-plus日志控制台输出 mybatis-plus: configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl global-config: banner: off # 关闭mybatisplus启动图标 取消SpringBoot的log打印 application.yml添加如下内容: spring: main: banner-mode: off # 关闭SpringBoot启动图标(banner) 解决控制台打印日志过多的相关操作可以不用去做，一般会被用来方便我们查看程序运行的结果。 3.1.3 构建条件查询在进行查询的时候，我们的入口是在Wrapper这个类上，因为它是一个接口，所以我们需要去找它对应的实现类，关于实现类也有很多，说明我们有多种构建查询条件对象的方式， 先来看第一种:==QueryWrapper== @SpringBootTest class Mybatisplus02DqlApplicationTests { @Autowired private UserDao userDao; @Test void testGetAll(){ QueryWrapper qw = new QueryWrapper(); qw.lt(\"age\",18); List&lt;User&gt; userList = userDao.selectList(qw); System.out.println(userList); } } lt: 小于(&lt;) ,最终的sql语句为 SELECT id,name,password,age,tel FROM user WHERE (age &lt; ?) 第一种方式介绍完后，有个小问题就是在写条件的时候，容易出错，比如age写错，就会导致查询不成功 接着来看第二种:==QueryWrapper的基础上使用lambda== @SpringBootTest class Mybatisplus02DqlApplicationTests { @Autowired private UserDao userDao; @Test void testGetAll(){ QueryWrapper&lt;User&gt; qw = new QueryWrapper&lt;User&gt;(); qw.lambda().lt(User::getAge, 10);//添加条件 List&lt;User&gt; userList = userDao.selectList(qw); System.out.println(userList); } } User::getAget,为lambda表达式中的，类名::方法名，最终的sql语句为: SELECT id,name,password,age,tel FROM user WHERE (age &lt; ?) **注意:**构建LambdaQueryWrapper的时候泛型不能省。 此时我们再次编写条件的时候，就不会存在写错名称的情况，但是qw后面多了一层lambda()调用 接着来看第三种:==LambdaQueryWrapper== @SpringBootTest class Mybatisplus02DqlApplicationTests { @Autowired private UserDao userDao; @Test void testGetAll(){ LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;(); lqw.lt(User::getAge, 10); List&lt;User&gt; userList = userDao.selectList(lqw); System.out.println(userList); } } 这种方式就解决了上一种方式所存在的问题。 3.1.4 多条件构建学完了三种构建查询对象的方式，每一种都有自己的特点，所以用哪一种都行，刚才都是一个条件，那如果有多个条件该如何构建呢? 需求:查询数据库表中，年龄在10岁到30岁之间的用户信息 @SpringBootTest class Mybatisplus02DqlApplicationTests { @Autowired private UserDao userDao; @Test void testGetAll(){ LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;(); lqw.lt(User::getAge, 30); lqw.gt(User::getAge, 10); List&lt;User&gt; userList = userDao.selectList(lqw); System.out.println(userList); } } gt：大于(&gt;),最终的SQL语句为 SELECT id,name,password,age,tel FROM user WHERE (age &lt; ? AND age &gt; ?) 构建多条件的时候，可以支持链式编程 LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;(); lqw.lt(User::getAge, 30).gt(User::getAge, 10); List&lt;User&gt; userList = userDao.selectList(lqw); System.out.println(userList); 需求:查询数据库表中，年龄小于10或年龄大于30的数据 @SpringBootTest class Mybatisplus02DqlApplicationTests { @Autowired private UserDao userDao; @Test void testGetAll(){ LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;(); lqw.lt(User::getAge, 10).or().gt(User::getAge, 30); List&lt;User&gt; userList = userDao.selectList(lqw); System.out.println(userList); } } or()就相当于我们sql语句中的or关键字,不加默认是and，最终的sql语句为: SELECT id,name,password,age,tel FROM user WHERE (age &lt; ? OR age &gt; ?) 3.1.5 null判定先来看一张图， 我们在做条件查询的时候，一般会有很多条件可以供用户进行选择查询。 这些条件用户可以选择使用也可以选择不使用，比如我要查询价格在8000以上的手机 在输入条件的时候，价格有一个区间范围，按照需求只需要在第一个价格输入框中输入8000 后台在做价格查询的时候，一般会让 price&gt;值1 and price &lt;值2 因为前端没有输入值2，所以如果不处理的话，就会出现 price&gt;8000 and price &lt; null问题 这个时候查询的结果就会出问题，具体该如何解决? 需求:查询数据库表中，根据输入年龄范围来查询符合条件的记录 用户在输入值的时候， ​ 如果只输入第一个框，说明要查询大于该年龄的用户 ​ 如果只输入第二个框，说明要查询小于该年龄的用户 ​ 如果两个框都输入了，说明要查询年龄在两个范围之间的用户 思考第一个问题：后台如果想接收前端的两个数据，该如何接收? 我们可以使用两个简单数据类型，也可以使用一个模型类，但是User类中目前只有一个age属性,如: @Data public class User { private Long id; private String name; private String password; private Integer age; private String tel; } 使用一个age属性，如何去接收页面上的两个值呢?这个时候我们有两个解决方案 方案一:添加属性age2,这种做法可以但是会影响到原模型类的属性内容 @Data public class User { private Long id; private String name; private String password; private Integer age; private String tel; private Integer age2; } 方案二:新建一个模型类,让其继承User类，并在其中添加age2属性，UserQuery在拥有User属性后同时添加了age2属性。 @Data public class User { private Long id; private String name; private String password; private Integer age; private String tel; } @Data public class UserQuery extends User { private Integer age2; } 环境准备好后，我们来实现下刚才的需求： @SpringBootTest class Mybatisplus02DqlApplicationTests { @Autowired private UserDao userDao; @Test void testGetAll(){ //模拟页面传递过来的查询数据 UserQuery uq = new UserQuery(); uq.setAge(10); uq.setAge2(30); LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;(); if(null != uq.getAge2()){ lqw.lt(User::getAge, uq.getAge2()); } if( null != uq.getAge()) { lqw.gt(User::getAge, uq.getAge()); } List&lt;User&gt; userList = userDao.selectList(lqw); System.out.println(userList); } } 上面的写法可以完成条件为非空的判断，但是问题很明显，如果条件多的话，每个条件都需要判断，代码量就比较大，来看MP给我们提供的简化方式： @SpringBootTest class Mybatisplus02DqlApplicationTests { @Autowired private UserDao userDao; @Test void testGetAll(){ //模拟页面传递过来的查询数据 UserQuery uq = new UserQuery(); uq.setAge(10); uq.setAge2(30); LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;(); lqw.lt(null!=uq.getAge2(),User::getAge, uq.getAge2()); lqw.gt(null!=uq.getAge(),User::getAge, uq.getAge()); List&lt;User&gt; userList = userDao.selectList(lqw); System.out.println(userList); } } lt()方法 condition为boolean类型，返回true，则添加条件，返回false则不添加条件 3.2 查询投影3.2.1 查询指定字段目前我们在查询数据的时候，什么都没有做默认就是查询表中所有字段的内容，我们所说的查询投影即不查询所有字段，只查询出指定内容的数据。 具体如何来实现? @SpringBootTest class Mybatisplus02DqlApplicationTests { @Autowired private UserDao userDao; @Test void testGetAll(){ LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;(); lqw.select(User::getId,User::getName,User::getAge); List&lt;User&gt; userList = userDao.selectList(lqw); System.out.println(userList); } } select(…)方法用来设置查询的字段列，可以设置多个，最终的sql语句为: SELECT id,name,age FROM user 如果使用的不是lambda，就需要手动指定字段 @SpringBootTest class Mybatisplus02DqlApplicationTests { @Autowired private UserDao userDao; @Test void testGetAll(){ QueryWrapper&lt;User&gt; lqw = new QueryWrapper&lt;User&gt;(); lqw.select(\"id\",\"name\",\"age\",\"tel\"); List&lt;User&gt; userList = userDao.selectList(lqw); System.out.println(userList); } } 最终的sql语句为:SELECT id,name,age,tel FROM user 3.2.2 聚合查询 需求:聚合函数查询，完成count、max、min、avg、sum的使用 count:总记录数 max:最大值 min:最小值 avg:平均值 sum:求和 @SpringBootTest class Mybatisplus02DqlApplicationTests { @Autowired private UserDao userDao; @Test void testGetAll(){ QueryWrapper&lt;User&gt; lqw = new QueryWrapper&lt;User&gt;(); //lqw.select(\"count(*) as count\"); //SELECT count(*) as count FROM user //lqw.select(\"max(age) as maxAge\"); //SELECT max(age) as maxAge FROM user //lqw.select(\"min(age) as minAge\"); //SELECT min(age) as minAge FROM user //lqw.select(\"sum(age) as sumAge\"); //SELECT sum(age) as sumAge FROM user lqw.select(\"avg(age) as avgAge\"); //SELECT avg(age) as avgAge FROM user List&lt;Map&lt;String, Object&gt;&gt; userList = userDao.selectMaps(lqw); System.out.println(userList); } } 为了在做结果封装的时候能够更简单，我们将上面的聚合函数都起了个名称，方面后期来获取这些数据 3.2.3 分组查询 需求:分组查询，完成 group by的查询使用 @SpringBootTest class Mybatisplus02DqlApplicationTests { @Autowired private UserDao userDao; @Test void testGetAll(){ QueryWrapper&lt;User&gt; lqw = new QueryWrapper&lt;User&gt;(); lqw.select(\"count(*) as count,tel\"); lqw.groupBy(\"tel\"); List&lt;Map&lt;String, Object&gt;&gt; list = userDao.selectMaps(lqw); System.out.println(list); } } groupBy为分组，最终的sql语句为 SELECT count(*) as count,tel FROM user GROUP BY tel 注意: 聚合与分组查询，无法使用lambda表达式来完成 MP只是对MyBatis的增强，如果MP实现不了，我们可以直接在DAO接口中使用MyBatis的方式实现 3.3 查询条件前面我们只使用了lt()和gt(),除了这两个方法外，MP还封装了很多条件对应的方法，这一节我们重点把MP提供的查询条件方法进行学习下。 MP的查询条件有很多: 范围匹配（&gt; 、 = 、between） 模糊匹配（like） 空判定（null） 包含性匹配（in） 分组（group） 排序（order） …… 3.3.1 等值查询 需求:根据用户名和密码查询用户信息 @SpringBootTest class Mybatisplus02DqlApplicationTests { @Autowired private UserDao userDao; @Test void testGetAll(){ LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;(); lqw.eq(User::getName, \"Jerry\").eq(User::getPassword, \"jerry\"); User loginUser = userDao.selectOne(lqw); System.out.println(loginUser); } } eq()： 相当于 =,对应的sql语句为 SELECT id,name,password,age,tel FROM user WHERE (name = ? AND password = ?) selectList：查询结果为多个或者单个 selectOne:查询结果为单个 3.3.2 范围查询 需求:对年龄进行范围查询，使用lt()、le()、gt()、ge()、between()进行范围查询 @SpringBootTest class Mybatisplus02DqlApplicationTests { @Autowired private UserDao userDao; @Test void testGetAll(){ LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;(); lqw.between(User::getAge, 10, 30); //SELECT id,name,password,age,tel FROM user WHERE (age BETWEEN ? AND ?) List&lt;User&gt; userList = userDao.selectList(lqw); System.out.println(userList); } } gt():大于(&gt;) ge():大于等于(&gt;=) lt():小于(&lt;) lte():小于等于(&lt;=) between():between ? and ? 3.3.3 模糊查询 需求:查询表中name属性的值以J开头的用户信息,使用like进行模糊查询 @SpringBootTest class Mybatisplus02DqlApplicationTests { @Autowired private UserDao userDao; @Test void testGetAll(){ LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;(); lqw.likeLeft(User::getName, \"J\"); //SELECT id,name,password,age,tel FROM user WHERE (name LIKE ?) List&lt;User&gt; userList = userDao.selectList(lqw); System.out.println(userList); } } like():前后加百分号,如 %J% likeLeft():前面加百分号,如 %J likeRight():后面加百分号,如 J% 3.3.4 排序查询 需求:查询所有数据，然后按照id降序 @SpringBootTest class Mybatisplus02DqlApplicationTests { @Autowired private UserDao userDao; @Test void testGetAll(){ LambdaQueryWrapper&lt;User&gt; lwq = new LambdaQueryWrapper&lt;&gt;(); /** * condition ：条件，返回boolean， 当condition为true，进行排序，如果为false，则不排序 * isAsc:是否为升序，true为升序，false为降序 * columns：需要操作的列 */ lwq.orderBy(true,false, User::getId); userDao.selectList(lw } } 除了上面演示的这种实现方式，还有很多其他的排序方法可以被调用，如图: orderBy排序 condition:条件，true则添加排序，false则不添加排序 isAsc:是否为升序，true升序，false降序 columns:排序字段，可以有多个 orderByAsc/Desc(单个column):按照指定字段进行升序/降序 orderByAsc/Desc(多个column):按照多个字段进行升序/降序 orderByAsc/Desc condition:条件，true添加排序，false不添加排序 多个columns：按照多个字段进行排序 除了上面介绍的这几种查询条件构建方法以外还会有很多其他的方法，比如isNull,isNotNull,in,notIn等等方法可供选择，具体参考官方文档的条件构造器来学习使用，具体的网址为: https://mp.baomidou.com/guide/wrapper.html#abstractwrapper 3.4 映射匹配兼容性前面我们已经能从表中查询出数据，并将数据封装到模型类中，这整个过程涉及到一张表和一个模型类: 之所以数据能够成功的从表中获取并封装到模型对象中，原因是表的字段列名和模型类的属性名一样。 那么问题就来了: 问题1:表字段与编码属性设计不同步当表的列名和模型类的属性名发生不一致，就会导致数据封装不到模型对象，这个时候就需要其中一方做出修改，那如果前提是两边都不能改又该如何解决? MP给我们提供了一个注解@TableField,使用该注解可以实现模型类属性名和表的列名之间的映射关系 问题2:编码中添加了数据库中未定义的属性当模型类中多了一个数据库表不存在的字段，就会导致生成的sql语句中在select的时候查询了数据库不存在的字段，程序运行就会报错，错误信息为: ==Unknown column ‘多出来的字段名称’ in ‘field list’== 具体的解决方案用到的还是@TableField注解，它有一个属性叫exist，设置该字段是否在数据库表中存在，如果设置为false则不存在，生成sql语句查询的时候，就不会再查询该字段了。 问题3：采用默认查询开放了更多的字段查看权限查询表中所有的列的数据，就可能把一些敏感数据查询到返回给前端，这个时候我们就需要限制哪些字段默认不要进行查询。解决方案是@TableField注解的一个属性叫select，该属性设置默认是否需要查询该字段的值，true(默认值)表示默认查询该字段，false表示默认不查询该字段。 知识点1：@TableField 名称 @TableField 类型 ==属性注解== 位置 模型类属性定义上方 作用 设置当前属性对应的数据库表中的字段关系 相关属性 value(默认)：设置数据库表字段名称exist:设置属性在数据库表字段中是否存在，默认为true，此属性不能与value合并使用select:设置属性是否参与查询，此属性与select()映射配置不冲突 问题4:表名与编码开发设计不同步该问题主要是表的名称和模型类的名称不一致，导致查询失败，这个时候通常会报如下错误信息: ==Table ‘databaseName.tableNaem’ doesn’t exist==,翻译过来就是数据库中的表不存在。 解决方案是使用MP提供的另外一个注解@TableName来设置表与模型类之间的对应关系。 知识点2：@TableName 名称 @TableName 类型 ==类注解== 位置 模型类定义上方 作用 设置当前类对应于数据库表关系 相关属性 value(默认)：设置数据库表名称 代码演示接下来我们使用案例的方式把刚才的知识演示下: 步骤1:修改数据库表user为tbl_user直接查询会报错，原因是MP默认情况下会使用模型类的类名首字母小写当表名使用。 步骤2:模型类添加@TableName注解@Data @TableName(\"tbl_user\") public class User { private Long id; private String name; private String password; private Integer age; private String tel; } 步骤3:将字段password修改成pwd直接查询会报错，原因是MP默认情况下会使用模型类的属性名当做表的列名使用 步骤4：使用@TableField映射关系@Data @TableName(\"tbl_user\") public class User { private Long id; private String name; @TableField(value=\"pwd\") private String password; private Integer age; private String tel; } 步骤5:添加一个数据库表不存在的字段@Data @TableName(\"tbl_user\") public class User { private Long id; private String name; @TableField(value=\"pwd\") private String password; private Integer age; private String tel; private Integer online; } 直接查询会报错，原因是MP默认情况下会查询模型类的所有属性对应的数据库表的列，而online不存在 步骤6：使用@TableField排除字段@Data @TableName(\"tbl_user\") public class User { private Long id; private String name; @TableField(value=\"pwd\") private String password; private Integer age; private String tel; @TableField(exist=false) private Integer online; } 步骤7:查询时将pwd隐藏@Data @TableName(\"tbl_user\") public class User { private Long id; private String name; @TableField(value=\"pwd\",select=false) private String password; private Integer age; private String tel; @TableField(exist=false) private Integer online; } 4.DML编程控制查询相关的操作我们已经介绍完了，紧接着我们需要对另外三个，增删改进行内容的讲解。挨个来说明下，首先是新增(insert)中的内容。 4.1 id生成策略控制前面我们在新增的时候留了一个问题，就是新增成功后，主键ID是一个很长串的内容，我们更想要的是按照数据库表字段进行自增长，在解决这个问题之前，我们先来分析下ID该如何选择: 不同的表应用不同的id生成策略 日志：自增（1,2,3,4，……） 购物订单：特殊规则（FQ23948AK3843） 外卖单：关联地区日期等信息（10 04 20200314 34 91） 关系表：可省略id …… 不同的业务采用的ID生成方式应该是不一样的，那么在MP中都提供了哪些主键生成策略，以及我们该如何进行选择? 在这里我们又需要用到MP的一个注解叫@TableId 知识点1：@TableId 名称 @TableId 类型 ==属性注解== 位置 模型类中用于表示主键的属性定义上方 作用 设置当前类中主键属性的生成策略 相关属性 value(默认)：设置数据库表主键名称type:设置主键属性的生成策略，值查照IdType的枚举值 4.1.1 环境构建在构建条件查询之前，我们先来准备下环境 创建一个SpringBoot项目 pom.xml中添加对应的依赖 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.5.0&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;mybatisplus_03_dml&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.4.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.16&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.12&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 编写UserDao接口 @Mapper public interface UserDao extends BaseMapper&lt;User&gt; { } 编写模型类 @Data @TableName(\"tbl_user\") public class User { private Long id; private String name; @TableField(value=\"pwd\",select=false) private String password; private Integer age; private String tel; @TableField(exist=false) private Integer online; } 编写引导类 @SpringBootApplication public class Mybatisplus03DqlApplication { public static void main(String[] args) { SpringApplication.run(Mybatisplus03DqlApplication.class, args); } } 编写配置文件 # dataSource spring: datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/mybatisplus_db?serverTimezone=UTC username: root password: root # mp日志 mybatis-plus: configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl 编写测试类 @SpringBootTest class Mybatisplus02DqlApplicationTests { @Autowired private UserDao userDao; @Test void testGetAll(){ List&lt;User&gt; userList = userDao.selectList(null); System.out.println(userList); } } 测试 @SpringBootTest class Mybatisplus03DqlApplicationTests { @Autowired private UserDao userDao; @Test void testSave(){ User user = new User(); user.setName(\"黑马程序员\"); user.setPassword(\"itheima\"); user.setAge(12); user.setTel(\"4006184000\"); userDao.insert(user); } @Test void testDelete(){ userDao.deleteById(1401856123925713409L) } @Test void testUpdate(){ User user = new User(); user.setId(3L); user.setName(\"Jock666\"); user.setVersion(1); userDao.updateById(user); } } 最终创建的项目结构为: 4.1.2 代码演示AUTO策略步骤1:设置生成策略为AUTO@Data @TableName(\"tbl_user\") public class User { @TableId(type = IdType.AUTO) private Long id; private String name; @TableField(value=\"pwd\",select=false) private String password; private Integer age; private String tel; @TableField(exist=false) private Integer online; } 步骤2:删除测试数据并修改自增值 删除测试数据 因为之前生成主键ID的值比较长，会把MySQL的自动增长的值变的很大，所以需要将其调整为目前最新的id值。 步骤3:运行新增方法会发现，新增成功，并且主键id也是从5开始 经过这三步的演示，会发现AUTO的作用是==使用数据库ID自增==，在使用该策略的时候一定要确保对应的数据库表设置了ID主键自增，否则无效。 接下来，我们可以进入源码查看下ID的生成策略有哪些? 打开源码后，你会发现并没有看到中文注释，这就需要我们点击右上角的Download Sources,会自动帮你把这个类的java文件下载下来，我们就能看到具体的注释内容。因为这个技术是国人制作的，所以他代码中的注释还是比较容易看懂的。 当把源码下载完后，就可以看到如下内容: 从源码中可以看到，除了AUTO这个策略以外，还有如下几种生成策略: NONE: 不设置id生成策略 INPUT:用户手工输入id ASSIGN_ID:雪花算法生成id(可兼容数值型与字符串型) ASSIGN_UUID:以UUID生成算法作为id生成策略 其他的几个策略均已过时，都将被ASSIGN_ID和ASSIGN_UUID代替掉。 拓展: 分布式ID是什么? 当数据量足够大的时候，一台数据库服务器存储不下，这个时候就需要多台数据库服务器进行存储 比如订单表就有可能被存储在不同的服务器上 如果用数据库表的自增主键，因为在两台服务器上所以会出现冲突 这个时候就需要一个全局唯一ID,这个ID就是分布式ID。 INPUT策略步骤1:设置生成策略为INPUT@Data @TableName(\"tbl_user\") public class User { @TableId(type = IdType.INPUT) private Long id; private String name; @TableField(value=\"pwd\",select=false) private String password; private Integer age; private String tel; @TableField(exist=false) private Integer online; } **注意:**这种ID生成策略，需要将表的自增策略删除掉 步骤2:添加数据手动设置ID@SpringBootTest class Mybatisplus03DqlApplicationTests { @Autowired private UserDao userDao; @Test void testSave(){ User user = new User(); //设置主键ID的值 user.setId(666L); user.setName(\"黑马程序员\"); user.setPassword(\"itheima\"); user.setAge(12); user.setTel(\"4006184000\"); userDao.insert(user); } } 步骤3:运行新增方法如果没有设置主键ID的值，则会报错，错误提示就是主键ID没有给值: 如果设置了主键ID,则数据添加成功，如下: ASSIGN_ID策略步骤1:设置生成策略为ASSIGN_ID@Data @TableName(\"tbl_user\") public class User { @TableId(type = IdType.ASSIGN_ID) private Long id; private String name; @TableField(value=\"pwd\",select=false) private String password; private Integer age; private String tel; @TableField(exist=false) private Integer online; } 步骤2:添加数据不设置ID@SpringBootTest class Mybatisplus03DqlApplicationTests { @Autowired private UserDao userDao; @Test void testSave(){ User user = new User(); user.setName(\"黑马程序员\"); user.setPassword(\"itheima\"); user.setAge(12); user.setTel(\"4006184000\"); userDao.insert(user); } } **注意:**这种生成策略，不需要手动设置ID，如果手动设置ID，则会使用自己设置的值。 步骤3:运行新增方法 生成的ID就是一个Long类型的数据。 ASSIGN_UUID策略步骤1:设置生成策略为ASSIGN_UUID使用uuid需要注意的是，主键的类型不能是Long，而应该改成String类型 @Data @TableName(\"tbl_user\") public class User { @TableId(type = IdType.ASSIGN_UUID) private String id; private String name; @TableField(value=\"pwd\",select=false) private String password; private Integer age; private String tel; @TableField(exist=false) private Integer online; } 步骤2:修改表的主键类型 主键类型设置为varchar，长度要大于32，因为UUID生成的主键为32位，如果长度小的话就会导致插入失败。 步骤3:添加数据不设置ID@SpringBootTest class Mybatisplus03DqlApplicationTests { @Autowired private UserDao userDao; @Test void testSave(){ User user = new User(); user.setName(\"黑马程序员\"); user.setPassword(\"itheima\"); user.setAge(12); user.setTel(\"4006184000\"); userDao.insert(user); } } 步骤4:运行新增方法 接下来我们来聊一聊雪花算法: 雪花算法(SnowFlake),是Twitter官方给出的算法实现 是用Scala写的。其生成的结果是一个64bit大小整数，它的结构如下图: 1bit,不用,因为二进制中最高位是符号位，1表示负数，0表示正数。生成的id一般都是用整数，所以最高位固定为0。 41bit-时间戳，用来记录时间戳，毫秒级 10bit-工作机器id，用来记录工作机器id,其中高位5bit是数据中心ID其取值范围0-31，低位5bit是工作节点ID其取值范围0-31，两个组合起来最多可以容纳1024个节点 序列号占用12bit，每个节点每毫秒0开始不断累加，最多可以累加到4095，一共可以产生4096个ID 4.1.3 ID生成策略对比介绍了这些主键ID的生成策略，我们以后该用哪个呢? NONE: 不设置id生成策略，MP不自动生成，约等于INPUT,所以这两种方式都需要用户手动设置，但是手动设置第一个问题是容易出现相同的ID造成主键冲突，为了保证主键不冲突就需要做很多判定，实现起来比较复杂 AUTO:数据库ID自增,这种策略适合在数据库服务器只有1台的情况下使用,不可作为分布式ID使用 ASSIGN_UUID:可以在分布式的情况下使用，而且能够保证唯一，但是生成的主键是32位的字符串，长度过长占用空间而且还不能排序，查询性能也慢 ASSIGN_ID:可以在分布式的情况下使用，生成的是Long类型的数字，可以排序性能也高，但是生成的策略和服务器时间有关，如果修改了系统时间就有可能导致出现重复主键 综上所述，每一种主键策略都有自己的优缺点，根据自己项目业务的实际情况来选择使用才是最明智的选择。 4.1.4 简化配置前面我们已经完成了表关系映射、数据库主键策略的设置，接下来对于这两个内容的使用，我们再讲下他们的简化配置: 模型类主键策略设置对于主键ID的策略已经介绍完，但是如果要在项目中的每一个模型类上都需要使用相同的生成策略，如: 确实是稍微有点繁琐，我们能不能在某一处进行配置，就能让所有的模型类都可以使用该主键ID策略呢? 答案是肯定有，我们只需要在配置文件中添加如下内容: mybatis-plus: global-config: db-config: id-type: assign_id 配置完成后，每个模型类的主键ID策略都将成为assign_id. 数据库表与模型类的映射关系MP会默认将模型类的类名名首字母小写作为表名使用，假如数据库表的名称都以tbl_开头，那么我们就需要将所有的模型类上添加@TableName，如: 配置起来还是比较繁琐，简化方式为在配置文件中配置如下内容: mybatis-plus: global-config: db-config: table-prefix: tbl_ 设置表的前缀内容，这样MP就会拿 tbl_加上模型类的首字母小写，就刚好组装成数据库的表名。 4.2 多记录操作先来看下问题: 之前添加了很多商品到购物车，过了几天发现这些东西又不想要了，该怎么办呢? 很简单删除掉，但是一个个删除的话还是比较慢和费事的，所以一般会给用户一个批量操作，也就是前面有一个复选框，用户一次可以勾选多个也可以进行全选，然后删一次就可以将购物车清空，这个就需要用到批量删除的操作了。 具体该如何实现多条删除，我们找找对应的API方法 int deleteBatchIds(@Param(Constants.COLLECTION) Collection&lt;? extends Serializable&gt; idList); 翻译方法的字面意思为:删除（根据ID 批量删除）,参数是一个集合，可以存放多个id值。 需求:根据传入的id集合将数据库表中的数据删除掉。 @SpringBootTest class Mybatisplus03DqlApplicationTests { @Autowired private UserDao userDao; @Test void testDelete(){ //删除指定多条数据 List&lt;Long&gt; list = new ArrayList&lt;&gt;(); list.add(1402551342481838081L); list.add(1402553134049501186L); list.add(1402553619611430913L); userDao.deleteBatchIds(list); } } 执行成功后，数据库表中的数据就会按照指定的id进行删除。 除了按照id集合进行批量删除，也可以按照id集合进行批量查询，还是先来看下API List&lt;T&gt; selectBatchIds(@Param(Constants.COLLECTION) Collection&lt;? extends Serializable&gt; idList); 方法名称翻译为:查询（根据ID 批量查询），参数是一个集合，可以存放多个id值。 需求：根据传入的ID集合查询用户信息 @SpringBootTest class Mybatisplus03DqlApplicationTests { @Autowired private UserDao userDao; @Test void testGetByIds(){ //查询指定多条数据 List&lt;Long&gt; list = new ArrayList&lt;&gt;(); list.add(1L); list.add(3L); list.add(4L); userDao.selectBatchIds(list); } } 查询结果就会按照指定传入的id值进行查询 4.3 逻辑删除接下来要讲解是删除中比较重要的一个操作，逻辑删除，先来分析下问题: 这是一个员工和其所签的合同表，关系是一个员工可以签多个合同，是一个一(员工)对多(合同)的表 员工ID为1的张业绩，总共签了三个合同，如果此时他离职了，我们需要将员工表中的数据进行删除，会执行delete操作 如果表在设计的时候有主外键关系，那么同时也得将合同表中的前三条数据也删除掉 后期要统计所签合同的总金额，就会发现对不上，原因是已经将员工1签的合同信息删除掉了 如果只删除员工不删除合同表数据，那么合同的员工编号对应的员工信息不存在，那么就会出现垃圾数据，就会出现无主合同，根本不知道有张业绩这个人的存在 所以经过分析，我们不应该将表中的数据删除掉，而是需要进行保留，但是又得把离职的人和在职的人进行区分，这样就解决了上述问题，如: 区分的方式，就是在员工表中添加一列数据deleted，如果为0说明在职员工，如果离职则将其改完1，（0和1所代表的含义是可以自定义的） 所以对于删除操作业务问题来说有: 物理删除:业务数据从数据库中丢弃，执行的是delete操作 逻辑删除:为数据设置是否可用状态字段，删除时设置状态字段为不可用状态，数据保留在数据库中，执行的是update操作 MP中逻辑删除具体该如何实现? 步骤1:修改数据库表添加deleted列字段名可以任意，内容也可以自定义，比如0代表正常，1代表删除，可以在添加列的同时设置其默认值为0正常。 步骤2:实体类添加属性(1)添加与数据库表的列对应的一个属性名，名称可以任意，如果和数据表列名对不上，可以使用@TableField进行关系映射，如果一致，则会自动对应。 (2)标识新增的字段为逻辑删除字段，使用@TableLogic @Data //@TableName(\"tbl_user\") 可以不写是因为配置了全局配置 public class User { @TableId(type = IdType.ASSIGN_UUID) private String id; private String name; @TableField(value=\"pwd\",select=false) private String password; private Integer age; private String tel; @TableField(exist=false) private Integer online; @TableLogic(value=\"0\",delval=\"1\") //value为正常数据的值，delval为删除数据的值 private Integer deleted; } 步骤3:运行删除方法@SpringBootTest class Mybatisplus03DqlApplicationTests { @Autowired private UserDao userDao; @Test void testDelete(){ userDao.deleteById(1L); } } 从测试结果来看，逻辑删除最后走的是update操作，会将指定的字段修改成删除状态对应的值。 思考 逻辑删除，对查询有没有影响呢? 执行查询操作 @SpringBootTest class Mybatisplus03DqlApplicationTests { @Autowired private UserDao userDao; @Test void testFind(){ System.out.println(userDao.selectList(null)); } } 运行测试，会发现打印出来的sql语句中会多一个查询条件，如: 可想而知，MP的逻辑删除会将所有的查询都添加一个未被删除的条件，也就是已经被删除的数据是不应该被查询出来的。 如果还是想把已经删除的数据都查询出来该如何实现呢? @Mapper public interface UserDao extends BaseMapper&lt;User&gt; { //查询所有数据包含已经被删除的数据 @Select(\"select * from tbl_user\") public List&lt;User&gt; selectAll(); } 如果每个表都要有逻辑删除，那么就需要在每个模型类的属性上添加@TableLogic注解，如何优化? 在配置文件中添加全局配置，如下: mybatis-plus: global-config: db-config: # 逻辑删除字段名 logic-delete-field: deleted # 逻辑删除字面值：未删除为0 logic-not-delete-value: 0 # 逻辑删除字面值：删除为1 logic-delete-value: 1 介绍完逻辑删除，逻辑删除的本质为: 逻辑删除的本质其实是修改操作。如果加了逻辑删除字段，查询数据时也会自动带上逻辑删除字段。 执行的SQL语句为: UPDATE tbl_user SET ==deleted===1 where id = ? AND ==deleted===0 执行数据结果为: 知识点1：@TableLogic 名称 @TableLogic 类型 ==属性注解== 位置 模型类中用于表示删除字段的属性定义上方 作用 标识该字段为进行逻辑删除的字段 相关属性 value：逻辑未删除值delval:逻辑删除值 4.4 乐观锁4.4.1 概念在讲解乐观锁之前，我们还是先来分析下问题: 业务并发现象带来的问题:==秒杀== 假如有100个商品或者票在出售，为了能保证每个商品或者票只能被一个人购买，如何保证不会出现超买或者重复卖 对于这一类问题，其实有很多的解决方案可以使用 第一个最先想到的就是锁，锁在一台服务器中是可以解决的，但是如果在多台服务器下锁就没有办法控制，比如12306有两台服务器在进行卖票，在两台服务器上都添加锁的话，那也有可能会导致在同一时刻有两个线程在进行卖票，还是会出现并发问题 我们接下来介绍的这种方式是针对于小型企业的解决方案，因为数据库本身的性能就是个瓶颈，如果对其并发量超过2000以上的就需要考虑其他的解决方案了。 简单来说，乐观锁主要解决的问题是当要更新一条记录的时候，希望这条记录没有被别人更新。 4.4.2 实现思路乐观锁的实现方式: 数据库表中添加version列，比如默认值给1 第一个线程要修改数据之前，取出记录时，获取当前数据库中的version=1 第二个线程要修改数据之前，取出记录时，获取当前数据库中的version=1 第一个线程执行更新时，set version = newVersion where version = oldVersion newVersion = version+1 [2] oldVersion = version [1] 第二个线程执行更新时，set version = newVersion where version = oldVersion newVersion = version+1 [2] oldVersion = version [1] 假如这两个线程都来更新数据，第一个和第二个线程都可能先执行 假如第一个线程先执行更新，会把version改为2， 第二个线程再更新的时候，set version = 2 where version = 1,此时数据库表的数据version已经为2，所以第二个线程会修改失败 假如第二个线程先执行更新，会把version改为2， 第一个线程再更新的时候，set version = 2 where version = 1,此时数据库表的数据version已经为2，所以第一个线程会修改失败 不管谁先执行都会确保只能有一个线程更新数据，这就是MP提供的乐观锁的实现原理分析。 上面所说的步骤具体该如何实现呢? 4.4.3 实现步骤分析完步骤后，具体的实现步骤如下: 步骤1:数据库表添加列列名可以任意，比如使用version,给列设置默认值为1 步骤2:在模型类中添加对应的属性根据添加的字段列名，在模型类中添加对应的属性值 @Data //@TableName(\"tbl_user\") 可以不写是因为配置了全局配置 public class User { @TableId(type = IdType.ASSIGN_UUID) private String id; private String name; @TableField(value=\"pwd\",select=false) private String password; private Integer age; private String tel; @TableField(exist=false) private Integer online; private Integer deleted; @Version private Integer version; } 步骤3:添加乐观锁的拦截器@Configuration public class MpConfig { @Bean public MybatisPlusInterceptor mpInterceptor() { //1.定义Mp拦截器 MybatisPlusInterceptor mpInterceptor = new MybatisPlusInterceptor(); //2.添加乐观锁拦截器 mpInterceptor.addInnerInterceptor(new OptimisticLockerInnerInterceptor()); return mpInterceptor; } } 步骤4:执行更新操作@SpringBootTest class Mybatisplus03DqlApplicationTests { @Autowired private UserDao userDao; @Test void testUpdate(){ User user = new User(); user.setId(3L); user.setName(\"Jock666\"); userDao.updateById(user); } } 你会发现，这次修改并没有更新version字段，原因是没有携带version数据。 添加version数据 @SpringBootTest class Mybatisplus03DqlApplicationTests { @Autowired private UserDao userDao; @Test void testUpdate(){ User user = new User(); user.setId(3L); user.setName(\"Jock666\"); user.setVersion(1); userDao.updateById(user); } } 你会发现，我们传递的是1，MP会将1进行加1，然后，更新回到数据库表中。 所以要想实现乐观锁，首先第一步应该是拿到表中的version，然后拿version当条件在将version加1更新回到数据库表中，所以我们在查询的时候，需要对其进行查询 @SpringBootTest class Mybatisplus03DqlApplicationTests { @Autowired private UserDao userDao; @Test void testUpdate(){ //1.先通过要修改的数据id将当前数据查询出来 User user = userDao.selectById(3L); //2.将要修改的属性逐一设置进去 user.setName(\"Jock888\"); userDao.updateById(user); } } 大概分析完乐观锁的实现步骤以后，我们来模拟一种加锁的情况，看看能不能实现多个人修改同一个数据的时候，只能有一个人修改成功。 @SpringBootTest class Mybatisplus03DqlApplicationTests { @Autowired private UserDao userDao; @Test void testUpdate(){ //1.先通过要修改的数据id将当前数据查询出来 User user = userDao.selectById(3L); //version=3 User user2 = userDao.selectById(3L); //version=3 user2.setName(\"Jock aaa\"); userDao.updateById(user2); //version=&gt;4 user.setName(\"Jock bbb\"); userDao.updateById(user); //verion=3?条件还成立吗？ } } 运行程序，分析结果： 乐观锁就已经实现完成了，如果对于上面的这些步骤记不住咋办呢? 参考官方文档来实现: https://mp.baomidou.com/guide/interceptor-optimistic-locker.html#optimisticlockerinnerinterceptor 5.快速开发5.1 代码生成器原理分析造句: 我们可以往空白内容进行填词造句，比如: 在比如: 观察我们之前写的代码，会发现其中也会有很多重复内容，比如: 那我们就想，如果我想做一个Book模块的开发，是不是只需要将红色部分的内容全部更换成Book即可，如： 所以我们会发现，做任何模块的开发，对于这段代码，基本上都是对红色部分的调整，所以我们把去掉红色内容的东西称之为==模板==，红色部分称之为==参数==，以后只需要传入不同的参数，就可以根据模板创建出不同模块的dao代码。 除了Dao可以抽取模块，其实我们常见的类都可以进行抽取，只要他们有公共部分即可。再来看下模型类的模板： ① 可以根据数据库表的表名来填充 ② 可以根据用户的配置来生成ID生成策略 ③到⑨可以根据数据库表字段名称来填充 所以只要我们知道是对哪张表进行代码生成，这些内容我们都可以进行填充。 分析完后，我们会发现，要想完成代码自动生成，我们需要有以下内容: 模板: MyBatisPlus提供，可以自己提供，但是麻烦，不建议 数据库相关配置:读取数据库获取表和字段信息 开发者自定义配置:手工配置，比如ID生成策略 5.2 代码生成器实现步骤1:创建一个Maven项目代码2:导入对应的jar包&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.5.1&lt;/version&gt; &lt;/parent&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;mybatisplus_04_generator&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--spring webmvc--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mybatisplus--&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.4.1&lt;/version&gt; &lt;/dependency&gt; &lt;!--druid--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.16&lt;/version&gt; &lt;/dependency&gt; &lt;!--mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!--test--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--lombok--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.12&lt;/version&gt; &lt;/dependency&gt; &lt;!--代码生成器--&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt; &lt;version&gt;3.4.1&lt;/version&gt; &lt;/dependency&gt; &lt;!--velocity模板引擎--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity-engine-core&lt;/artifactId&gt; &lt;version&gt;2.3&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 步骤3:编写引导类@SpringBootApplication public class Mybatisplus04GeneratorApplication { public static void main(String[] args) { SpringApplication.run(Mybatisplus04GeneratorApplication.class, args); } } 步骤4:创建代码生成类public class CodeGenerator { public static void main(String[] args) { //1.获取代码生成器的对象 AutoGenerator autoGenerator = new AutoGenerator(); //设置数据库相关配置 DataSourceConfig dataSource = new DataSourceConfig(); dataSource.setDriverName(\"com.mysql.cj.jdbc.Driver\"); dataSource.setUrl(\"jdbc:mysql://localhost:3306/mybatisplus_db?serverTimezone=UTC\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"root\"); autoGenerator.setDataSource(dataSource); //设置全局配置 GlobalConfig globalConfig = new GlobalConfig(); globalConfig.setOutputDir(System.getProperty(\"user.dir\")+\"/mybatisplus_04_generator/src/main/java\"); //设置代码生成位置 globalConfig.setOpen(false); //设置生成完毕后是否打开生成代码所在的目录 globalConfig.setAuthor(\"黑马程序员\"); //设置作者 globalConfig.setFileOverride(true); //设置是否覆盖原始生成的文件 globalConfig.setMapperName(\"%sDao\"); //设置数据层接口名，%s为占位符，指代模块名称 globalConfig.setIdType(IdType.ASSIGN_ID); //设置Id生成策略 autoGenerator.setGlobalConfig(globalConfig); //设置包名相关配置 PackageConfig packageInfo = new PackageConfig(); packageInfo.setParent(\"com.aaa\"); //设置生成的包名，与代码所在位置不冲突，二者叠加组成完整路径 packageInfo.setEntity(\"domain\"); //设置实体类包名 packageInfo.setMapper(\"dao\"); //设置数据层包名 autoGenerator.setPackageInfo(packageInfo); //策略设置 StrategyConfig strategyConfig = new StrategyConfig(); strategyConfig.setInclude(\"tbl_user\"); //设置当前参与生成的表名，参数为可变参数 strategyConfig.setTablePrefix(\"tbl_\"); //设置数据库表的前缀名称，模块名 = 数据库表名 - 前缀名 例如： User = tbl_user - tbl_ strategyConfig.setRestControllerStyle(true); //设置是否启用Rest风格 strategyConfig.setVersionFieldName(\"version\"); //设置乐观锁字段名 strategyConfig.setLogicDeleteFieldName(\"deleted\"); //设置逻辑删除字段名 strategyConfig.setEntityLombokModel(true); //设置是否启用lombok autoGenerator.setStrategy(strategyConfig); //2.执行生成操作 autoGenerator.execute(); } } 对于代码生成器中的代码内容，我们可以直接从官方文档中获取代码进行修改， https://mp.baomidou.com/guide/generator.html 步骤5:运行程序运行成功后，会在当前项目中生成很多代码，代码包含controller,service，mapper和entity 至此代码生成器就已经完成工作，我们能快速根据数据库表来创建对应的类，简化我们的代码开发。 5.3 MP中Service的CRUD回顾我们之前业务层代码的编写，编写接口和对应的实现类: public interface UserService{ } @Service public class UserServiceImpl implements UserService{ } 接口和实现类有了以后，需要在接口和实现类中声明方法 public interface UserService{ public List&lt;User&gt; findAll(); } @Service public class UserServiceImpl implements UserService{ @Autowired private UserDao userDao; public List&lt;User&gt; findAll(){ return userDao.selectList(null); } } MP看到上面的代码以后就说这些方法也是比较固定和通用的，那我来帮你抽取下，所以MP提供了一个Service接口和实现类，分别是:IService和ServiceImpl,后者是对前者的一个具体实现。 以后我们自己写的Service就可以进行如下修改: public interface UserService extends IService&lt;User&gt;{ } @Service public class UserServiceImpl extends ServiceImpl&lt;UserDao, User&gt; implements UserService{ } 修改以后的好处是，MP已经帮我们把业务层的一些基础的增删改查都已经实现了，可以直接进行使用。 编写测试类进行测试: @SpringBootTest class Mybatisplus04GeneratorApplicationTests { private IUserService userService; @Test void testFindAll() { List&lt;User&gt; list = userService.list(); System.out.println(list); } } **注意:**mybatisplus_04_generator项目中对于MyBatis的环境是没有进行配置，如果想要运行，需要提取将配置文件中的内容进行完善后在运行。 思考:在MP封装的Service层都有哪些方法可以用? 查看官方文档:https://mp.baomidou.com/guide/crud-interface.html,这些提供的方法大家可以参考官方文档进行学习使用，方法的名称可能有些变化，但是方法对应的参数和返回值基本类似。","categories":[],"tags":[{"name":"MyBatis-Plus","slug":"MyBatis-Plus","permalink":"https://gitee.com/yunyd/tags/MyBatis-Plus/"},{"name":"SSMP","slug":"SSMP","permalink":"https://gitee.com/yunyd/tags/SSMP/"}],"author":"llllz."},{"title":"OPEN-API开放平台","slug":"OPEN-API开放平台","date":"2023-08-07T05:12:22.000Z","updated":"2023-08-25T00:21:23.727Z","comments":true,"path":"posts/574f1a5b.html","link":"","permalink":"https://gitee.com/yunyd/posts/574f1a5b.html","excerpt":"","text":"OPEN-API开放平台项目所用到的技术： Java Spring Boot MySQL 数据库 MyBatis-Plus 及 MyBatis X 自动生成 Swagger + Knife4j 接口文档生成 API 签名认证（Http 调用） Spring Boot Starter（SDK 开发） Dubbo 分布式（RPC、Nacos） Spring Cloud Gateway 微服务网关 Hutool、Apache Common Utils、Gson 等工具库 后端： 根据业务流程，将整个项目后端划分为 web 系统、模拟接口、公共模块、客户端 SDK、API 网关这 5 个子项目，并使用 Maven 进行多模块依赖管理和打包。 基于 MyBatis Plus 框架的 QueryWrapper 实现对 MySQL 数据库的灵活查询，并配合 MyBatis X 插件自动生成后端 CRUD 基础代码，减少重复工作。 使用 Swagger + Knife4j 自动生成 OpenAPI 规范的接口文档，降低前后端协作成本。 为防止接口被恶意调用，设计 API 签名认证算法，为用户分配唯一 ak / sk 以鉴权，保障调用的安全性、便于统计接口调用次数。 为解决开发者调用成本过高的问题（须自己使用 HTTP + 封装签名去调用接口），基于 Spring Boot Starter 开发了客户端 SDK，一行代码 即可调用接口，提高开发体验。 选用 Spring Cloud Gateway 作为 API 网关，实现了路由转发、访问控制、流量染色，并集中处理签名校验、请求参数校验、接口调用统计等业务逻辑，提高安全性的同时、便于系统开发维护。 为解决多个子系统内代码大量重复的问题，抽象模型层和业务层代码为公共模块，并使用 Dubbo RPC 框架实现子系统间的高性能接口调用，大幅减少重复代码。 项目简介一个提供API接口供开发者调用的平台 管理员可以接入并发布接口，统计分析个接口调用情况；用户可以注册登录并开通接口调用权限，然后可以浏览接口及在线调试，还能使用客户端SDK轻松在代码中调用接口。 项目功能及各部分页面介绍，如下图：登陆界面： 主页浏览（管理员身份）： 接口管理（管理员身份）：管理员身份具有管理页等选项框，用于接口管理和接口分析这两个功能， 接口管理用来发布、下线接口，对接口信息的增删改查等等功能 点击修改，弹出此接口信息的信息框用来进行修改操作 接口分析（管理员身份）：用于调查接口里面的top3（接口调用次数最多的前三名接口名称及其调用次数），方便管理员进行接口分析和管理 在线调试：按照要求输入，即可调用已经发布上线的接口，并使用其功能 此处是一个功能简单的接口，在请求参数按照规范来输入，点击调用，即可调用该接口的功能。该接口的功能是：输入一个名字，即可返回调用的类型 + 用户输入的名字，调用成功后会弹出调用成功的框，并在下面返回结果出得到返回结果。 主页浏览（非管理员身份）:仅可以在线调用接口，不能对接口进行权限处理等功能 多个后端：开放平台项目涉及到了多个系统的交互（不止有一个后端），包括了API签名认证、网关、RPC、分布式等知识 （以上项目大体功能等仅粗略展示，如功能解释的不详细，还望见谅！！）.","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"https://gitee.com/yunyd/tags/%E9%A1%B9%E7%9B%AE/"}],"author":"llllz."},{"title":"商家外卖","slug":"商家外卖","date":"2023-08-07T05:12:22.000Z","updated":"2023-08-25T00:23:39.778Z","comments":true,"path":"posts/7161264.html","link":"","permalink":"https://gitee.com/yunyd/posts/7161264.html","excerpt":"","text":"商家外卖项目所用到的技术： Spring Boot SSM + Lombok MyBatis Plus Spring Cache Redis Sharding JDBC 读写分离 部署：前后端不分离 jar 包部署 后端： 为集中处理系统异常，自定义统一的错误码，并封装了 全局异常处理器 ，屏蔽了项目冗余的报错细节、便于接口调用方理解和统一处理。 基于静态 ThreadLocal 封装了线程隔离的全局上下文对象，便于在请求内部存取用户信息，减少用户远程查询次数。 为兼容请求参数 date 类型的序列化，自定义 Jackson 对象映射器处理日期；并扩展 SpringMVC 的消息转换器，实现自动序列化。 自定义 MyBatis Plus 的 MetaObjectHandler，配合全局上下文实现写数据前的创建时间、用户 id 字段的自动填充。 遵循 Restful 设计规范编写接口，降低前后端接口沟通和理解成本。 为解决原生 Jdk 序列化器导致的缓存 key 值乱码问题，自定义 RedisTemplate Bean 的 Redis Key 序列化器为 StringRedisSerializer。 使用 Knife4j + Swagger 自动生成后端接口文档，并通过编写 ApiOperation 等注解补充接口注释，避免了人工编写维护文档的麻烦。 为省去重复编写用户校验的麻烦，基于 WebFilter 实现全局登录校验；并通过 AntPathMatcher 来匹配动态请求路径，实现灵活的可选鉴权。 为保证数据的完整性和一致性，使用 @Transactional 实现数据库事务，并配置 rollbackFor = Exception.class 来支持受检异常的事务回滚。 为提高信息页加载速度，基于 Spring Cache 注解 + Redis 实现对信息的自动缓存，来降低数据库压力的同时将接口响应耗时 为降低开发成本，使用 MyBatis Plus 框架自动生成业务的增删改查重复代码，并使用 LambdaQueryWrapper 实现更灵活地自定义查询。 为提高数据库整体读写性能，配置 MySQL 主从同步，并使用 sharding-jdbc 实现业务无侵入的读写分离。 封装全局 Axios 请求实例，添加全局请求拦截和全局异常响应处理器，减少重复的状态码判断、提升项目可维护性。 项目功能及各部分页面介绍，如下图：项目分为用户端和管理端：用户端介绍：页面输入手机号，首先会对手机号码有一个校验，不符合规则的的手机号会进行提示。然后点击验证码会直接给出验证码，由于模拟真实的短信服务需要付费并调用XX云SDK接入短信服务，为了节省成本，我直接将返回的验证码写在输入框里（模拟一下接收短信的流程） 注册登录进来后就可以查看商家信息（都哪有些菜品，套餐之类的） 随机选择一个，点击选择规格，会弹出如下框，选择适合自己的口味并点击加入购物车 点击完加入购物车之后，即可在购物车中显示，如果同一菜品想要多份的话，就点击➕来增加份数，购物车显示的金额也会随之更新 点击去结算的按钮会到支付页面，当然如果是新注册的账号，则会先让你留下收货地址，如下图 保存完收货地址，就可以进行支付了 管理端介绍：管理端是用来商家来上传一些菜品，套餐之类的，并包括员工信息等，可以对员工信息、菜品、套餐等信息进行增删改查等功能 下图为管理端的登陆页面： 点击登录，来到管理端页面 分为左列几个功能，能对响应分类进行增上改查，拿员工管理界面的增上改查来举例子： 点击编辑，可以修改员工信息。点击添加员工可以进行添加，启用禁用功能是指如果员工加入企业或者退出企业，可以对他的账号进行封禁或者开启 点击修改，效果如下图： 其余界面如下，功能类似，都可以进行增删改查等功能： （以上项目大体功能等仅粗略展示，如功能解释的不详细，还望见谅！！）.","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"https://gitee.com/yunyd/tags/%E9%A1%B9%E7%9B%AE/"}],"author":"llllz."},{"title":"JUC-LockSupport与线程中断","slug":"JUC-LockSupport与线程中断 -4","date":"2023-08-05T08:42:32.000Z","updated":"2023-08-25T00:19:42.120Z","comments":true,"path":"posts/b972fab5.html","link":"","permalink":"https://gitee.com/yunyd/posts/b972fab5.html","excerpt":"","text":"LockSupport与线程中断1.1 线程中断机制1.1.1 从阿里蚂蚁金服面试题讲起Java.lang.Thread下的三个方法: 如何中断一个运行中的线程？ 如何停止一个运行中的线程？ 1.1.2 什么是中断机制 首先，一个线程不应该由其他线程来强制中断或停止，而是应该由线程自己自行停止，自己来决定自己的命运，所以，Thread.stop,Thread.suspend,Thread.resume都已经被废弃了 其次，在Java中没有办法立即停止一条线程，然而停止线程却显得尤为重要，如取消一个耗时操作。因此，Java提供了一种用于停止线程的协商机制—-中断，也即中断标识协商机制 中断只是一种协作协商机制，Java没有给中断增加任何语法，中断的过程完全需要程序员自行实现。若要中断一个线程，你需要手动调用该线程interrupt方法，该方法也仅仅是将该线程对象的中断标识设置为true，接着你需要自己写代码不断检测当前线程的标识位，如果为true，表示别的线程请求这条线程中断，此时究竟应该做什么需要你自己写代码实现。 每个线程对象都有一个中断标识位，用于表示线程是否被中断；该标识位为true表示中断，为false表示未中断；通过调用线程对象的interrupt方法将该线程的标识位设置为true；可以在别的线程中调用，也可以在自己的线程中调用。 1.1.3 中断的相关API方法之三大方法说明 public void interrupt() 实例方法 Just to set the interrupt flag 实例方法仅仅是设置线程的中断状态为true，发起一个协商而不会立刻停止线程 public static boolean interrupted() 静态方法 Thread.interrupted(); 判断线程是否被中断并清除当前中断状态（做了两件事情） 1.返回当前线程的中断状态，测试当前线程是否已被中断 2.将当前线程的中断状态清零并重新设置为false，清除线程的中断状态 3.这个方法有点不好理解在于如果连续两次调用此方法，则第二次返回false，因为连续调用两次的结果可能不一样 public boolean isInterrupted() 实例方法 判断当前线程是否被中断（通过检查中断标志位） 1.1.4 大厂面试题中断机制考点 如何停止中断运行中的线程？ 通过一个volatile变量实现 volatile中断线程演示： public class InterruptDemo { static volatile boolean isStop = false; //volatile表示的变量具有可见性 public static void main(String[] args) { new Thread(() -&gt; { while (true) { if (isStop) { System.out.println(Thread.currentThread().getName() + \" isStop的值被改为true，t1程序停止\"); break; } System.out.println(\"-----------hello volatile\"); } }, \"t1\").start(); try { TimeUnit.MILLISECONDS.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } new Thread(() -&gt; { isStop = true; }, \"t2\").start(); } } /** * -----------hello volatile * -----------hello volatile * -----------hello volatile * -----------hello volatile * -----------hello volatile * -----------hello volatile * t1 isStop的值被改为true，t1程序停止 */ 通过AutomicBoolean AutomicBoolean中断线程演示： public class InterruptDemo { static AtomicBoolean atomicBoolean = new AtomicBoolean(false); public static void main(String[] args) { new Thread(() -&gt; { while (true) { if (atomicBoolean.get()) { System.out.println(Thread.currentThread().getName() + \" atomicBoolean的值被改为true，t1程序停止\"); break; } System.out.println(\"-----------hello atomicBoolean\"); } }, \"t1\").start(); try { TimeUnit.MILLISECONDS.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } new Thread(() -&gt; { atomicBoolean.set(true); }, \"t2\").start(); } } /** * -----------hello atomicBoolean * -----------hello atomicBoolean * -----------hello atomicBoolean * -----------hello atomicBoolean * -----------hello atomicBoolean * t1 atomicBoolean的值被改为true，t1程序停止 */ 通过Thread类自带的中断API实例方法实现—-在需要中断的线程中不断监听中断状态，一旦发生中断，就执行相应的中断处理业务逻辑stop线程。 interrupt() 和isInterrupted()组合使用来中断某个线程演示： public class InterruptDemo { static AtomicBoolean atomicBoolean = new AtomicBoolean(false); public static void main(String[] args) { Thread t1 = new Thread(() -&gt; { while (true) { if (Thread.currentThread().isInterrupted()) { System.out.println(Thread.currentThread().getName() + \" isInterrupted()的值被改为true，t1程序停止\"); break; } System.out.println(\"-----------hello isInterrupted()\"); } }, \"t1\"); t1.start(); try { TimeUnit.MILLISECONDS.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } //t2向t1放出协商，将t1中的中断标识位设为true，希望t1停下来 new Thread(() -&gt; t1.interrupt(), \"t2\").start(); //当然，也可以t1自行设置 t1.interrupt(); } } /** * -----------hello isInterrupted() * -----------hello isInterrupted() * -----------hello isInterrupted() * -----------hello isInterrupted() * t1 isInterrupted()的值被改为true，t1程序停止 */ 当前线程的中断标识为true，是不是线程就立刻停止？ 答案是不立刻停止，具体来说，当对一个线程，调用interrupt时： 如果线程处于正常活动状态，那么会将该线程的中断标志设置为true，仅此而已，被设置中断标志的线程将继续正常运行，不受影响，所以interrupt()并不能真正的中断线程，需要被调用的线程自己进行配合才行，对于不活动的线程没有任何影响。 如果线程处于阻塞状态（例如sleep,wait,join状态等），在别的线程中调用当前线程对象的interrupt方法，那么线程将立即退出被阻塞状态（interrupt状态也将被清除），并抛出一个InterruptedException异常。 第一种情况正常活动状态演示： public class InterruptDemo2 { public static void main(String[] args) { //实例方法interrupt()仅仅是设置线程的中断状态位为true，不会停止线程 Thread t1 = new Thread(() -&gt; { for (int i = 1; i &lt;= 300; i++) { System.out.println(\"------: \" + i); } /** * ------: 298 * ------: 299 * ------: 300 * t1线程调用interrupt()后的中断标志位02：true */ System.out.println(\"t1线程调用interrupt()后的中断标志位02：\" + Thread.currentThread().isInterrupted()); }, \"t1\"); t1.start(); System.out.println(\"t1线程默认的中断标志位：\" + t1.isInterrupted());//false try { TimeUnit.MILLISECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } t1.interrupt();//true /** * ------: 251 * ------: 252 * ------: 253 * t1线程调用interrupt()后的中断标志位01：true */ System.out.println(\"t1线程调用interrupt()后的中断标志位01：\" + t1.isInterrupted());//true try { TimeUnit.MILLISECONDS.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } //2000毫秒后，t1线程已经不活动了，不会产生任何影响 System.out.println(\"t1线程调用interrupt()后的中断标志位03：\" + t1.isInterrupted());//false } } 第二种情况线程处于阻塞状态演示： public class InterruptDemo3 { public static void main(String[] args) { Thread t1 = new Thread(() -&gt; { while (true) { if (Thread.currentThread().isInterrupted()) { System.out.println(Thread.currentThread().getName() + \" 中断标志位为：\" + Thread.currentThread().isInterrupted() + \" 程序停止\"); break; } //sleep方法抛出InterruptedException后，中断标识也被清空置为false，如果没有在 //catch方法中调用interrupt方法再次将中断标识置为true，这将导致无限循环了 try { Thread.sleep(200); } catch (InterruptedException e) { //Thread.currentThread().interrupt(); e.printStackTrace(); } System.out.println(\"-------------hello InterruptDemo3\"); } }, \"t1\"); t1.start(); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } new Thread(() -&gt; { t1.interrupt(); }, \"t2\").start(); } } 对于第二种情况的源码分析如下； 总之，需要记住的是中断只是一种协商机制，修改中断标识位仅此而已，不是立刻stop打断 静态方法Thread.interrupted()，谈谈你的理解？ 静态方法Thread.interrupted()演示： public class InterruptDemo4 { public static void main(String[] args) { /** * main false * main false * -----------1 * -----------2 * main true * main false */ System.out.println(Thread.currentThread().getName() + \"\\t\" + Thread.interrupted());//false System.out.println(Thread.currentThread().getName() + \"\\t\" + Thread.interrupted());//false System.out.println(\"-----------1\"); Thread.currentThread().interrupt(); System.out.println(\"-----------2\"); System.out.println(Thread.currentThread().getName() + \"\\t\" + Thread.interrupted());//true System.out.println(Thread.currentThread().getName() + \"\\t\" + Thread.interrupted());//false } } 对于静态方法Thread.interrupted()和实例方法isInterrupted()区别在于： 静态方法interrupted将会清除中断状态（传入的参数ClearInterrupted为true） 实例方法isInterrupted则不会（传入的参数ClearInterrupted为false） 1.1.5 总结 public void interrupt() 是一个实例方法，它通知目标线程中断，也仅仅是设置目标线程的中断标志位为true public boolean isInterrupted() 是一个实例方法，它判断当前线程是否被中断（通过检查中断标志位）并获取中断标志 public static boolean interrupted() 是一个静态方法，返回当前线程的中断真实状态（boolean类型）后会将当前线程的中断状态设为false，此方法调用之后会清楚当前线程的中断标志位的状态（将中断标志置为false了），返回当前值并清零置为false。 1.2 LockSupport是什么LockSupport是用来创建锁和其他同步类的基本线程阻塞原语，其中park()和unpack()而作用分别是阻塞线程和解除阻塞线程. 1.3 线程等待唤醒机制1.3.1 三种让线程等待和唤醒的方法 方式一：使用Object中的wait()方法让线程等待，使用Object中的notify()方法唤醒线程 方式二：使用JUC包中的Condition的await()方法让线程等待，使用signal()方法唤醒线程 方式三：LockSupport类可以阻塞当前线程以及唤醒指定被阻塞的线程 1.3.2 Object类中的wait和notify方法实现线程等待和唤醒 wait和notify方法必须要在同步代码块或者方法里面，且成对出现使用 先wait再notify才ok Object类中的wait和notify方法实现线程等待和唤醒演示: public class LockSupportDemo { public static void main(String[] args) { Object objectLock = new Object(); /** * t1 -----------come in * t2 -----------发出通知 * t1 -------被唤醒 */ new Thread(() -&gt; { synchronized (objectLock) { System.out.println(Thread.currentThread().getName() + \"\\t -----------come in\"); try { objectLock.wait(); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + \"\\t -------被唤醒\"); } }, \"t1\").start(); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } new Thread(() -&gt; { synchronized (objectLock) { objectLock.notify(); System.out.println(Thread.currentThread().getName() + \"\\t -----------发出通知\"); } }, \"t2\").start(); } } 1.3.3 Condition接口中的await和signal方法实现线程的等待和唤醒 Condition中的线程等待和唤醒方法，需要先获取锁 一定要先await后signal，不要反了 Condition接口中的await和signal方法实现线程的等待和唤醒演示: public class LockSupportDemo { public static void main(String[] args) { Lock lock = new ReentrantLock(); Condition condition = lock.newCondition(); /** * t1 -----------come in * t2 -----------发出通知 * t1 -----------被唤醒 */ new Thread(() -&gt; { lock.lock(); try { System.out.println(Thread.currentThread().getName() + \"\\t -----------come in\"); condition.await(); System.out.println(Thread.currentThread().getName() + \"\\t -----------被唤醒\"); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } }, \"t1\").start(); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } new Thread(() -&gt; { lock.lock(); try { condition.signal(); System.out.println(Thread.currentThread().getName() + \"\\t -----------发出通知\"); } finally { lock.unlock(); } }, \"t2\").start(); } } 1.3.4 上述两个对象Object和Condition使用的限制条件 线程需要先获得并持有锁，必须在锁块（synchronized或lock）中 必须要先等待后唤醒，线程才能够被唤醒 1.3.5 LockSupport类中的park等待和unpark唤醒 是什么 LockSupport 是用于创建锁和其他同步类的基本线程阻塞原语 LockSupport类使用了一种名为Permit（许可）的概念来做到阻塞和唤醒线程的功能，每个线程都有一个许可（Permit），许可证只能有一个，累加上限是1。 主要方法 阻塞: Peimit许可证默认没有不能放行，所以一开始调用park()方法当前线程会阻塞，直到别的线程给当前线程发放peimit，park方法才会被唤醒。 park/park(Object blocker)——-阻塞当前线程/阻塞传入的具体线程 唤醒: 调用unpack(thread)方法后 就会将thread线程的许可证peimit发放，会自动唤醒park线程，即之前阻塞中的LockSupport.park()方法会立即返回。 unpark(Thread thread)——唤醒处于阻塞状态的指定线程 代码 LockSupport类中的park等待和unpark唤醒演示: public class LockSupportDemo { public static void main(String[] args) { /** * t1 -----------come in * t2 ----------发出通知 * t1 ----------被唤醒 */ Thread t1 = new Thread(() -&gt; { System.out.println(Thread.currentThread().getName() + \"\\t -----------come in\"); LockSupport.park(); System.out.println(Thread.currentThread().getName() + \"\\t ----------被唤醒\"); }, \"t1\"); t1.start(); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } new Thread(() -&gt; { LockSupport.unpark(t1); System.out.println(Thread.currentThread().getName() + \"\\t ----------发出通知\"); }, \"t2\").start(); } } 重点说明（重要） LockSupport是用来创建锁和其他同步类的基本线程阻塞原语，所有的方法都是静态方法，可以让线程再任意位置阻塞，阻塞后也有对应的唤醒方法。归根结底，LockSupport时调用Unsafe中的native代码 LockSupport提供park()和unpark()方法实现阻塞线程和解除线程阻塞的过程，LockSupport和每个使用它的线程都有一个许可（Peimit）关联，每个线程都有一个相关的permit，peimit最多只有一个，重复调用unpark也不会积累凭证。 形象理解：线程阻塞需要消耗凭证（Permit），这个凭证最多只有一个 当调用park时，如果有凭证，则会直接消耗掉这个凭证然后正常退出。如果没有凭证，则必须阻塞等待凭证可用； 当调用unpark时，它会增加一个凭证，但凭证最多只能有1各，累加无效。 面试题 为什么LockSupport可以突破wait/notify的原有调用顺序？ 因为unpark获得了一个凭证，之后再调用park方法，就可以名正言顺的凭证消费，故不会阻塞，先发放了凭证后续可以畅通无阻。 为什么唤醒两次后阻塞两次，但最终结果还会阻塞线程？ 因为凭证的数量最多为1，连续调用两次unpark和调用一次unpark效果一样，只会增加一个凭证，而调用两次park却需要消费两个凭证，证不够，不能放行。","categories":[],"tags":[{"name":"JUC并发编程","slug":"JUC并发编程","permalink":"https://gitee.com/yunyd/tags/JUC%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"author":"llllz."},{"title":"SpringBoot复习 -2","slug":"SpringBoot复习  -2","date":"2023-08-04T06:09:32.000Z","updated":"2023-08-25T00:22:26.587Z","comments":true,"path":"posts/fdb4f820.html","link":"","permalink":"https://gitee.com/yunyd/posts/fdb4f820.html","excerpt":"","text":"SpringBoot复习YW-1.SpringBoot程序的打包与运行​ 刚开始做开发学习的小伙伴可能在有一个知识上面有错误的认知，我们天天写程序是在Idea下写的，运行也是在Idea下运行的。 ​ 但是实际开发完成后，我们的项目是不可能运行在自己的电脑上的。 ​ 我们以后制作的程序是运行在专用的服务器上的，简单说就是将你做的程序放在一台独立运行的电脑上，这台电脑要比你开发使用的计算机更专业，并且安全等级各个方面要远超过你现在的电脑。 ​ 那我们的程序如何放置在这台专用的电脑上呢，这就要将我们的程序先组织成一个文件，然后将这个文件传输到这台服务器上。这里面就存在两个过程，一个是打包的过程，另一个是运行的过程。 温馨提示 ​ 企业项目上线为了保障环境适配性会采用下面流程发布项目，这里不讨论此过程。 开发部门使用Git、SVN等版本控制工具上传工程到版本服务器 服务器使用版本控制工具下载工程 服务器上使用Maven工具在当前真机环境下重新构建项目 启动服务 ​ 继续说我们的打包和运行过程。所谓打包指将程序转换成一个可执行的文件，所谓运行指不依赖开发环境执行打包产生的文件。上述两个操作都有对应的命令可以快速执行。 程序打包​ SpringBoot程序是基于Maven创建的，在Maven中提供有打包的指令，叫做package。本操作可以在Idea环境下执行。 mvn package ​ 打包后会产生一个与工程名类似的jar文件，其名称是由模块名+版本号+.jar组成的。 程序运行​ 程序包打好以后，就可以直接执行了。在程序包所在路径下，执行指令。 java -jar 工程包名.jar ​ 执行程序打包指令后，程序正常运行，与在Idea下执行程序没有区别。 ​ 特别关注：如果你的计算机中没有安装java的jdk环境，是无法正确执行上述操作的，因为程序执行使用的是java指令。 ​ 特别关注：在使用向导创建SpringBoot工程时，pom.xml文件中会有如下配置，这一段配置千万不能删除，否则打包后无法正常执行程序。 &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 总结 SpringBoot工程可以基于java环境下独立运行jar文件启动服务 SpringBoot工程执行mvn命令package进行打包 执行jar命令：java –jar 工程名.jar SpringBoot程序打包失败处理​ 有些小伙伴打包以后执行会出现一些问题，导致程序无法正常执行，例如下面的现象 ​ 要想搞清楚这个问题就要说说.jar文件的工作机制了，知道了这个东西就知道如何避免此类问题的发生了。 ​ 搞java开发平时会接触很多jar包，比如mysql的驱动jar包，而上面我们打包程序后得到的也是一个jar文件。这个时候如果你使用上面的java -jar指令去执行mysql的驱动jar包就会出现上述不可执行的现象，而我们的SpringBoot项目为什么能执行呢？其实是因为打包方式不一样。 ​ 在SpringBoot工程的pom.xml中有下面这组配置，这组配置决定了打包出来的程序包是否可以执行。 &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; ​ 我们分别开启这段配置和注释掉这段配置分别执行两次打包，然后观察两次打包后的程序包的差别，共有3处比较明显的特征 打包后文件的大小不同 打包后所包含的内容不同 打包程序中个别文件内容不同 ​ 先看第一个现象，文件大小不同。带有配置时打包生成的程序包大小如下： ​ 不难看出，带有配置的程序包体积比不带配置的大了30倍，那这里面都有什么呢？能差这么多？下面看看里面的内容有什么区别。 ​ ​ 我们发现内容也完全不一样，仅有一个目录是一样的，叫做META-INF。打开容量大的程序包中的BOOT-INF目录下的classes目录，我们发现其中的内容居然和容量小的程序包中的内容完全一样。 ​ ​ 原来大的程序包中除了包含小的程序包中的内容，还有别的东西。都有什么呢？回到BOOT-INF目录下，打开lib目录，里面显示了很多个jar文件。 ​ ​ 仔细翻阅不难发现，这些jar文件都是我们制作这个工程时导入的坐标对应的文件。大概可以想明白了，SpringBoot程序为了让自己打包生成的程序可以独立运行，不仅将项目中自己开发的内容进行了打包，还把当前工程运行需要使用的jar包全部打包进来了。为什么这样做呢？就是为了可以独立运行。不依赖程序包外部的任何资源可以独立运行当前程序。这也是为什么大的程序包容量是小的程序包容量的30倍的主要原因。 ​ 再看看大程序包还有什么不同之处，在最外层目录包含一个org目录，进入此目录，目录名是org\\springframework\\boot\\loader，在里面可以找到一个JarLauncher.class的文件，先记得这个文件。再看这套目录名，明显是一个Spring的目录名，为什么要把Spring框架的东西打包到这个程序包中呢？不清楚。 ​ 回到两个程序包的最外层目录，查看名称相同的文件夹META-INF下都有一个叫做MANIFEST.MF的文件，但是大小不同，打开文件，比较内容区别 小容量文件的MANIFEST.MF Manifest-Version: 1.0 Implementation-Title: springboot_08_ssmp Implementation-Version: 0.0.1-SNAPSHOT Build-Jdk-Spec: 1.8 Created-By: Maven Jar Plugin 3.2.0 大容量文件的MANIFEST.MF Manifest-Version: 1.0 Spring-Boot-Classpath-Index: BOOT-INF/classpath.idx Implementation-Title: springboot_08_ssmp Implementation-Version: 0.0.1-SNAPSHOT Spring-Boot-Layers-Index: BOOT-INF/layers.idx Start-Class: com.itheima.SSMPApplication Spring-Boot-Classes: BOOT-INF/classes/ Spring-Boot-Lib: BOOT-INF/lib/ Build-Jdk-Spec: 1.8 Spring-Boot-Version: 2.5.4 Created-By: Maven Jar Plugin 3.2.0 Main-Class: org.springframework.boot.loader.JarLauncher ​ 大文件中明显比小文件中多了几行信息，其中最后一行信息是Main-Class: org.springframework.boot.loader.JarLauncher。这句话什么意思呢？如果使用java -jar执行此程序包，将执行Main-Class属性配置的类，这个类恰巧就是前面看到的那个文件。原来SpringBoot打包程序中出现Spring框架的东西是为这里服务的。而这个org.springframework.boot.loader.JarLauncher类内部要查找Start-Class属性中配置的类，并执行对应的类。这个属性在当前配置中也存在，对应的就是我们的引导类类名。 ​ 现在这组设定的作用就搞清楚了 SpringBoot程序添加配置后会打出一个特殊的包，包含Spring框架部分功能，原始工程内容，原始工程依赖的jar包 首先读取MANIFEST.MF文件中的Main-Class属性，用来标记执行java -jar命令后运行的类 JarLauncher类执行时会找到Start-Class属性，也就是启动类类名 运行启动类时会运行当前工程的内容 运行当前工程时会使用依赖的jar包，从lib目录中查找 ​ 看来SpringBoot打出来了包为了能够独立运行，简直是煞费苦心，将所有需要使用的资源全部都添加到了这个包里。这就是为什么这个jar包能独立运行的原因。 ​ 再来看之前的报错信息： ​ 由于打包时没有使用那段配置，结果打包后形成了一个普通的jar包，在MANIFEST.MF文件中也就没有了Main-Class对应的属性了，所以运行时提示找不到主清单属性，这就是报错的原因。 ​ 上述内容搞清楚对我们编程意义并不大，但是对各位小伙伴理清楚SpringBoot工程独立运行的机制是有帮助的。其实整体过程主要是带着大家分析，如果以后遇到了类似的问题，多给自己提问，多问一个为什么，兴趣自己就可以独立解决问题了。 总结 spring-boot-maven-plugin插件用于将当前程序打包成一个可以独立运行的程序包 命令行启动常见问题及解决方案​ 各位小伙伴在DOS环境下启动SpringBoot工程时，可能会遇到端口占用的问题。给大家一组命令，不用深入学习，备用吧。 # 查询端口 netstat -ano # 查询指定端口 netstat -ano |findstr \"端口号\" # 根据进程PID查询进程名称 tasklist |findstr \"进程PID号\" # 根据PID杀死任务 taskkill /F /PID \"进程PID号\" # 根据进程名称杀死任务 taskkill -f -t -im \"进程名称\" ​ 关于打包与运行程序其实还有一系列的配置和参数，下面的内容中遇到再说，这里先开个头，知道如何打包和运行程序。 SpringBoot项目快速启动（Linux版）​ 其实对于Linux系统下的程序运行与Windows系统下的程序运行差别不大，命令还是那组命令，只不过各位小伙伴可能对Linux指令不太熟悉，结果就会导致各种各样的问题发生。比如防火墙如何关闭，IP地址如何查询，JDK如何安装等等。这里不作为重点内容给大家普及了，了解一下整体过程就行了。 YW-2.配置高级​ 关于配置在基础篇讲过一部分，基础篇的配置总体上来说就是让各位小伙伴掌握配置的格式。比如配置文件如何写啊，写好的数据如何读取啊，都是基础的语法级知识。在实用篇中就要集中在配置的应用这个方面了，下面就开始配置高级相关内容的第一部分学习，为什么说第一部分，因为在开发实用篇中还有对应的配置高级知识要进行学习。 YW-2-1.临时属性设置​ 目前我们的程序包打好了，可以发布了。但是程序包打好以后，里面的配置都已经是固定的了，比如配置了服务器的端口是8080。如果我要启动项目，发现当前我的服务器上已经有应用启动起来并且占用了8080端口，这个时候就尴尬了。难道要重新把打包好的程序修改一下吗？比如我要把打包好的程序启动端口改成80。 ​ SpringBoot提供了灵活的配置方式，如果你发现你的项目中有个别属性需要重新配置，可以使用临时属性的方式快速修改某些配置。方法也特别简单，在启动的时候添加上对应参数就可以了。 java –jar springboot.jar –-server.port=80 ​ 上面的命令是启动SpringBoot程序包的命令，在命令输入完毕后，空一格，然后输入两个-号。下面按照属性名=属性值的形式添加对应参数就可以了。记得，这里的格式不是yaml中的书写格式，当属性存在多级名称时，中间使用点分隔，和properties文件中的属性格式完全相同。 ​ 如果你发现要修改的属性不止一个，可以按照上述格式继续写，属性与属性之间使用空格分隔。 java –jar springboot.jar –-server.port=80 --logging.level.root=debug 属性加载优先级​ 现在我们的程序配置受两个地方控制了，第一配置文件，第二临时属性。并且我们发现临时属性的加载优先级要高于配置文件的。那是否还有其他的配置方式呢？其实是有的，而且还不少，打开官方文档中对应的内容，就可以查看配置读取的优先顺序。地址奉上：https://docs.spring.io/spring-boot/docs/current/reference/html/spring-boot-features.html#boot-features-external-config ​ 我们可以看到，居然有14种配置的位置，而我们现在使用的是这里面的2个。第3条Config data说的就是使用配置文件，第11条Command line arguments说的就是使用命令行临时参数。而这14种配置的顺序就是SpringBoot加载配置的顺序，言外之意，命令行临时属性比配置文件的加载优先级高，所以这个列表上面的优先级低，下面的优先级高。其实这个东西不用背的，你就记得一点，你最终要什么效果，你自己是知道的，不管这个顺序是怎么个高低排序，开发时一定要配置成你要的顺序为准。这个顺序只是在你想不明白问题的时候帮助你分析罢了。 ​ 比如你现在加载了一个user.name属性。结果你发现出来的结果和你想的不一样，那肯定是别的优先级比你高的属性覆盖你的配置属性了，那你就可以看着这个顺序挨个排查。哪个位置有可能覆盖了你的属性。 ​ 我在课程评论区看到小伙伴学习基础篇的时候问这个问题了，就是这个原因造成的。在yaml中配置了user.name属性值，然后读取出来的时候居然不是自己的配置值，因为在系统属性中有一个属性叫做user.name，两个相互冲突了。而系统属性的加载优先顺序在上面这个列表中是5号，高于3号，所以SpringBoot最终会加载系统配置属性user.name。 总结 使用jar命令启动SpringBoot工程时可以使用临时属性替换配置文件中的属性 临时属性添加方式：java –jar 工程名.jar –-属性名=值 多个临时属性之间使用空格分隔 临时属性必须是当前boot工程支持的属性，否则设置无效 开发环境中使用临时属性​ 临时使用目前是有了，但是上线的时候通过命令行输入的临时属性必须是正确的啊，那这些属性配置值我们必须在开发环境中测试好才行。下面说一下开发环境中如何使用临时属性，其实就是Idea界面下如何操作了。 ​ 打开SpringBoot引导类的运行界面，在里面找到配置项。其中Program arguments对应的位置就是添加临时属性的，可以加几个试试效果。 ​ 做到这里其实可以产生一个思考了，如果对java编程熟悉的小伙伴应该知道，我们运行main方法的时候，如果想使用main方法的参数，也就是下面的args参数，就是在上面这个位置添加的参数。 public static void main(String[] args) { } ​ 原来是这样，通过这个args就可以获取到参数。再来看我们的引导类是如何书写的 public static void main(String[] args) { SpringApplication.run(SSMPApplication.class,args); } ​ 这个args参数居然传递给了run方法，看来在Idea中配置的临时参数就是通过这个位置传递到我们的程序中的。言外之意，这里如果不用这个args是不是就断开了外部传递临时属性的入口呢？是这样的，我们可以使用下面的调用方式，这样外部临时属性就无法进入到SpringBoot程序中了。 public static void main(String[] args) { SpringApplication.run(SSMPApplication.class); } ​ 或者还可以使用如下格式来玩这个操作，就是将配置不写在配置文件中，直接写成一个字符串数组，传递给程序入口。当然，这种做法并没有什么实际开发意义。 public static void main(String[] args) { String[] arg = new String[1]; arg[0] = \"--server.port=8082\"; SpringApplication.run(SSMPApplication.class, arg); } 总结 启动SpringBoot程序时，可以选择是否使用命令行属性为SpringBoot程序传递启动属性 思考 ​ 现在使用临时属性可以在启动项目前临时更改配置了，但是新的问题又出来了。临时属性好用是好用，就是写的多了会很麻烦。比如我现在有个需求，上线的时候使用临时属性配置20个值，这下可麻烦了，能不能搞得简单点，集中管理一下呢？比如说搞个文件，加载指定文件？还真可以。怎么做呢？咱们下一节再说。 YW-2-2.配置文件分类​ SpringBoot提供了配置文件和临时属性的方式来对程序进行配置。前面一直说的是临时属性，这一节要说说配置文件了。其实这个配置文件我们一直在使用，只不过我们用的是SpringBoot提供的4级配置文件中的其中一个级别。4个级别分别是： 类路径下配置文件（一直使用的是这个，也就是resources目录中的application.yml文件） 类路径下config目录下配置文件 程序包所在目录中配置文件 程序包所在目录中config目录下配置文件 ​ 好复杂，一个一个说。其实上述4种文件是提供给你了4种配置文件书写的位置，功能都是一样的，都是做配置的。那大家关心的就是差别了，没错，就是因为位置不同，产生了差异。总体上来说，4种配置文件如果都存在的话，有一个优先级的问题，说白了就是加入4个文件我都有，里面都有一样的配置，谁生效的问题。上面4个文件的加载优先顺序为 file ：config/application.yml 【最高】 file ：application.yml classpath：config/application.yml classpath：application.yml 【最低】 ​ 那为什么设计这种多种呢？说一个最典型的应用吧。 场景A：你作为一个开发者，你做程序的时候为了方便自己写代码，配置的数据库肯定是连接你自己本机的，咱们使用4这个级别，也就是之前一直用的application.yml。 场景B：现在项目开发到了一个阶段，要联调测试了，连接的数据库是测试服务器的数据库，肯定要换一组配置吧。你可以选择把你之前的文件中的内容都改了，目前还不麻烦。 场景C：测试完了，一切OK。你继续写你的代码，你发现你原来写的配置文件被改成测试服务器的内容了，你要再改回来。现在明白了不？场景B中把你的内容都改掉了，你现在要重新改回来，以后呢？改来改去吗？ ​ 解决方案很简单，用上面的3这个级别的配置文件就可以快速解决这个问题，再写一个配置就行了。两个配置文件共存，因为config目录中的配置加载优先级比你的高，所以配置项如果和级别4里面的内容相同就覆盖了，这样是不是很简单？ ​ 级别1和2什么时候使用呢？程序打包以后就要用这个级别了，管你程序里面配置写的是什么？我的级别高，可以轻松覆盖你，就不用考虑这些配置冲突的问题了。 总结 配置文件分为4种 项目类路径配置文件：服务于开发人员本机开发与测试 项目类路径config目录中配置文件：服务于项目经理整体调控 工程路径配置文件：服务于运维人员配置涉密线上环境 工程路径config目录中配置文件：服务于运维经理整体调控 多层级配置文件间的属性采用叠加并覆盖的形式作用于程序 YW-2-3.自定义配置文件​ 之前咱们做配置使用的配置文件都是application.yml，其实这个文件也是可以改名字的，这样方便维护。比如我2020年4月1日搞活动，走了一组配置，2020年5月1日活动取消，恢复原始配置，这个时候只需要重新更换一下配置文件就可以了。但是你总不能在原始配置文件上修改吧，不然搞完活动以后，活动的配置就留不下来了，不利于维护。 ​ 自定义配置文件方式有如下两种： 方式一：使用临时属性设置配置文件名，注意仅仅是名称，不要带扩展名 方式二：使用临时属性设置配置文件路径，这个是全路径名 ​ 也可以设置加载多个配置文件 ​ 使用的属性一个是spring.config.name，另一个是spring.config.location，这个一定要区别清楚。 温馨提示 ​ 我们现在研究的都是SpringBoot单体项目，就是单服务器版本。其实企业开发现在更多的是使用基于SpringCloud技术的多服务器项目。这种配置方式和我们现在学习的完全不一样，所有的服务器将不再设置自己的配置文件，而是通过配置中心获取配置，动态加载配置信息。为什么这样做？集中管理。这里不再说这些了，后面再讲这些东西。 总结 配置文件可以修改名称，通过启动参数设定 配置文件可以修改路径，通过启动参数设定 微服务开发中配置文件通过配置中心进行设置 YW-3.多环境开发​ 讲的内容距离线上开发越来越近了，下面说一说多环境开发问题。 ​ 什么是多环境？其实就是说你的电脑上写的程序最终要放到别人的服务器上去运行。每个计算机环境不一样，这就是多环境。常见的多环境开发主要兼顾3种环境设置，开发环境——自己用的，测试环境——自己公司用的，生产环境——甲方爸爸用的。因为这是绝对不同的三台电脑，所以环境肯定有所不同，比如连接的数据库不一样，设置的访问端口不一样等等。 YW-3-1.多环境开发（yaml单一文件版）​ 那什么是多环境开发？就是针对不同的环境设置不同的配置属性即可。比如你自己开发时，配置你的端口如下： server: port: 80 ​ 如何想设计两组环境呢？中间使用三个减号分隔开 server: port: 80 --- server: port: 81 ​ 如何区分两种环境呢？起名字呗 spring: profiles: pro server: port: 80 --- spring: profiles: dev server: port: 81 ​ 那用哪一个呢？设置默认启动哪个就可以了 spring: profiles: active: pro # 启动pro --- spring: profiles: pro server: port: 80 --- spring: profiles: dev server: port: 81 ​ 就这么简单，再多来一组环境也OK spring: profiles: active: pro # 启动pro --- spring: profiles: pro server: port: 80 --- spring: profiles: dev server: port: 81 --- spring: profiles: test server: port: 82 ​ 其中关于环境名称定义上述格式是过时格式，标准格式如下 spring: config: activate: on-profile: pro 总结 多环境开发需要设置若干种常用环境，例如开发、生产、测试环境 yaml格式中设置多环境使用—区分环境设置边界 每种环境的区别在于加载的配置属性不同 启用某种环境时需要指定启动时使用该环境 YW-3-2.多环境开发（yaml多文件版）​ 将所有的配置都放在一个配置文件中，尤其是每一个配置应用场景都不一样，这显然不合理，于是就有了将一个配置文件拆分成多个配置文件的想法。拆分后，每个配置文件中写自己的配置，主配置文件中写清楚用哪一个配置文件就好了。 主配置文件 spring: profiles: active: pro # 启动pro 环境配置文件 server: port: 80 ​ 环境配置文件因为每一个都是配置自己的项，所以连名字都不用写里面了。那问题是如何区分这是哪一组配置呢？使用文件名区分。 application-pro.yaml server: port: 80 application-dev.yaml server: port: 81 ​ 文件的命名规则为：application-环境名.yml。 ​ 在配置文件中，如果某些配置项所有环境都一样，可以将这些项写入到主配置中，只有哪些有区别的项才写入到环境配置文件中。 主配置文件中设置公共配置（全局） 环境分类配置文件中常用于设置冲突属性（局部） 总结 可以使用独立配置文件定义环境属性 独立配置文件便于线上系统维护更新并保障系统安全性 YW-3-3.多环境开发（properties多文件版）​ SpringBoot最早期提供的配置文件格式是properties格式的，这种格式的多环境配置也了解一下吧。 主配置文件 spring.profiles.active=pro 环境配置文件 application-pro.properties server.port=80 application-dev.properties server.port=81 ​ 文件的命名规则为：application-环境名.properties。 总结 properties文件多环境配置仅支持多文件格式 YW-3-4.多环境开发独立配置文件书写技巧​ 作为程序员在搞配置的时候往往处于一种分久必合合久必分的局面。开始先写一起，后来为了方便维护就拆分。对于多环境开发也是如此，下面给大家说一下如何基于多环境开发做配置独立管理，务必掌握。 准备工作 ​ 将所有的配置根据功能对配置文件中的信息进行拆分，并制作成独立的配置文件，命名规则如下 application-devDB.yml application-devRedis.yml application-devMVC.yml 使用 ​ 使用include属性在激活指定环境的情况下，同时对多个环境进行加载使其生效，多个环境间使用逗号分隔 spring: profiles: active: dev include: devDB,devRedis,devMVC ​ 比较一下，现在相当于加载dev配置时，再加载对应的3组配置，从结构上就很清晰，用了什么，对应的名称是什么 注意 ​ 当主环境dev与其他环境有相同属性时，主环境属性生效；其他环境中有相同属性时，最后加载的环境属性生效 改良 ​ 但是上面的设置也有一个问题，比如我要切换dev环境为pro时，include也要修改。因为include属性只能使用一次，这就比较麻烦了。SpringBoot从2.4版开始使用group属性替代include属性，降低了配置书写量。简单说就是我先写好，你爱用哪个用哪个。 spring: profiles: active: dev group: \"dev\": devDB,devRedis,devMVC \"pro\": proDB,proRedis,proMVC \"test\": testDB,testRedis,testMVC ​ 现在再来看，如果切换dev到pro，只需要改一下是不是就结束了？完美！ 总结 多环境开发使用group属性设置配置文件分组，便于线上维护管理 YW-3-5.多环境开发控制​ 多环境开发到这里基本上说完了，最后说一个冲突问题。就是maven和SpringBoot同时设置多环境的话怎么搞。 ​ 要想处理这个冲突问题，你要先理清一个关系，究竟谁在多环境开发中其主导地位。也就是说如果现在都设置了多环境，谁的应该是保留下来的，另一个应该遵从相同的设置。 ​ maven是做什么的？项目构建管理的，最终生成代码包的，SpringBoot是干什么的？简化开发的。简化，又不是其主导作用。最终还是要靠maven来管理整个工程，所以SpringBoot应该听maven的。整个确认后下面就好做了。大体思想如下： 先在maven环境中设置用什么具体的环境 在SpringBoot中读取maven设置的环境即可 maven中设置多环境（使用属性方式区分环境） &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;env_dev&lt;/id&gt; &lt;properties&gt; &lt;profile.active&gt;dev&lt;/profile.active&gt; &lt;/properties&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;!--默认启动环境--&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;env_pro&lt;/id&gt; &lt;properties&gt; &lt;profile.active&gt;pro&lt;/profile.active&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt; SpringBoot中读取maven设置值 spring: profiles: active: @profile.active@ ​ 上面的@属性名@就是读取maven中配置的属性值的语法格式。 总结 当Maven与SpringBoot同时对多环境进行控制时，以Mavn为主，SpringBoot使用@..@占位符读取Maven对应的配置属性值 基于SpringBoot读取Maven配置属性的前提下，如果在Idea下测试工程时pom.xml每次更新需要手动compile方可生效 YW-4.日志​ 运维篇最后一部分我们来聊聊日志，日志大家不陌生，简单介绍一下。日志其实就是记录程序日常运行的信息，主要作用如下： 编程期调试代码 运营期记录信息 记录日常运营重要信息（峰值流量、平均响应时长……） 记录应用报错信息（错误堆栈） 记录运维过程数据（扩容、宕机、报警……） ​ 或许各位小伙伴并不习惯于使用日志，没关系，慢慢多用，习惯就好。想进大厂，这是最基本的，别去面试的时候说没用过，完了，没机会了。 YW-4-1.代码中使用日志工具记录日志​ 日志的使用格式非常固定，直接上操作步骤： 步骤①：添加日志记录操作 @RestController @RequestMapping(\"/books\") public class BookController extends BaseClass{ private static final Logger log = LoggerFactory.getLogger(BookController.class); @GetMapping public String getById(){ log.debug(\"debug...\"); log.info(\"info...\"); log.warn(\"warn...\"); log.error(\"error...\"); return \"springboot is running...2\"; } } ​ 上述代码中log对象就是用来记录日志的对象，下面的log.debug，log.info这些操作就是写日志的API了。 步骤②：设置日志输出级别 ​ 日志设置好以后可以根据设置选择哪些参与记录。这里是根据日志的级别来设置的。日志的级别分为6种，分别是： TRACE：运行堆栈信息，使用率低 DEBUG：程序员调试代码使用 INFO：记录运维过程数据 WARN：记录运维过程报警数据 ERROR：记录错误堆栈信息 FATAL：灾难信息，合并计入ERROR ​ 一般情况下，开发时候使用DEBUG，上线后使用INFO，运维信息记录使用WARN即可。下面就设置一下日志级别： # 开启debug模式，输出调试信息，常用于检查系统运行状况 debug: true ​ 这么设置太简单粗暴了，日志系统通常都提供了细粒度的控制 # 开启debug模式，输出调试信息，常用于检查系统运行状况 debug: true # 设置日志级别，root表示根节点，即整体应用日志级别 logging: level: root: debug ​ 还可以再设置更细粒度的控制 步骤③：设置日志组，控制指定包对应的日志输出级别，也可以直接控制指定包对应的日志输出级别 logging: # 设置日志组 group: # 自定义组名，设置当前组中所包含的包 ebank: com.itheima.controller level: root: warn # 为对应组设置日志级别 ebank: debug # 为对包设置日志级别 com.itheima.controller: debug ​ 说白了就是总体设置一下，每个包设置一下，如果感觉设置的麻烦，就先把包分个组，对组设置，没了，就这些。 总结 日志用于记录开发调试与运维过程消息 日志的级别共6种，通常使用4种即可，分别是DEBUG，INFO,WARN,ERROR 可以通过日志组或代码包的形式进行日志显示级别的控制 教你一招：优化日志对象创建代码​ 写代码的时候每个类都要写创建日志记录对象，这个可以优化一下，使用前面用过的lombok技术给我们提供的工具类即可。 @RestController @RequestMapping(\"/books\") public class BookController extends BaseClass{ private static final Logger log = LoggerFactory.getLogger(BookController.class); //这一句可以不写了 } ​ 导入lombok后使用注解搞定，日志对象名为log @Slf4j //这个注解替代了下面那一行 @RestController @RequestMapping(\"/books\") public class BookController extends BaseClass{ private static final Logger log = LoggerFactory.getLogger(BookController.class); //这一句可以不写了 } 总结 基于lombok提供的@Slf4j注解为类快速添加日志对象 YW-4-2.日志输出格式控制​ 日志已经能够记录了，但是目前记录的格式是SpringBoot给我们提供的，如果想自定义控制就需要自己设置了。先分析一下当前日志的记录格式。 ​ 对于单条日志信息来说，日期，触发位置，记录信息是最核心的信息。级别用于做筛选过滤，PID与线程名用于做精准分析。了解这些信息后就可以DIY日志格式了。本课程不做详细的研究，有兴趣的小伙伴可以学习相关的知识。下面给出课程中模拟的官方日志模板的书写格式，便于大家学习。 logging: pattern: console: \"%d %clr(%p) --- [%16t] %clr(%-40.40c){cyan} : %m %n\" 总结 日志输出格式设置规则 YW-4-3.日志文件​ 日志信息显示，记录已经控制住了，下面就要说一下日志的转存了。日志不能仅显示在控制台上，要把日志记录到文件中，方便后期维护查阅。 ​ 对于日志文件的使用存在各种各样的策略，例如每日记录，分类记录，报警后记录等。这里主要研究日志文件如何记录。 ​ 记录日志到文件中格式非常简单，设置日志文件名即可。 logging: file: name: server.log ​ 虽然使用上述格式可以将日志记录下来了，但是面对线上的复杂情况，一个文件记录肯定是不能够满足运维要求的，通常会每天记录日志文件，同时为了便于维护，还要限制每个日志文件的大小。下面给出日志文件的常用配置方式： logging: logback: rollingpolicy: max-file-size: 3KB file-name-pattern: server.%d{yyyy-MM-dd}.%i.log ​ 以上格式是基于logback日志技术设置每日日志文件的设置格式，要求容量到达3KB以后就转存信息到第二个文件中。文件命名规则中的%d标识日期，%i是一个递增变量，用于区分日志文件。 总结 日志记录到文件 日志文件格式设置 SpringBoot开发实用复习​ 怀着忐忑的心情，开始了开发实用篇文档的编写。为什么忐忑？特喵的债欠的太多，不知道从何写起。哎，不煽情了，开工。 ​ 运维实用篇完结以后，开发实用篇采用日更新的形式发布给各位小伙伴，基本上是每天一集，目前已经发布完毕。看评论区，好多小伙伴在求文档，所以赶紧来补文档，加班加点把开发实用篇的文档刨出来。 ​ 开发实用篇中因为牵扯到SpringBoot整合各种各样的技术，由于不是每个小伙伴对各种技术都有所掌握，所以在整合每一个技术之前，都会做一个快速的普及，这样的话内容整个开发实用篇所包含的内容就会比较多。各位小伙伴在学习的时候，如果对某一个技术不是很清楚，可以先跳过对应章节，或者先补充一下技术知识，然后再来看对应的课程。开发实用篇具体包含的内容如下： 热部署 配置高级 测试 数据层解决方案 整合第三方技术 监控 ​ 看目录感觉内容量并不是很大，但是在数据层解决方案和整合第三方技术中包含了大量的知识，一点一点慢慢学吧。下面开启第一部分热部署相关知识的学习 KF-1.热部署​ 什么是热部署？简单说就是你程序改了，现在要重新启动服务器，嫌麻烦？不用重启，服务器会自己悄悄的把更新后的程序给重新加载一遍，这就是热部署。 ​ 热部署的功能是如何实现的呢？这就要分两种情况来说了，非springboot工程和springboot工程的热部署实现方式完全不一样。先说一下原始的非springboot项目是如何实现热部署的。 非springboot项目热部署实现原理 ​ 开发非springboot项目时，我们要制作一个web工程并通过tomcat启动，通常需要先安装tomcat服务器到磁盘中，开发的程序配置发布到安装的tomcat服务器上。如果想实现热部署的效果，这种情况其实有两种做法，一种是在tomcat服务器的配置文件中进行配置，这种做法与你使用什么IDE工具无关，不管你使用eclipse还是idea都行。还有一种做法是通过IDE工具进行配置，比如在idea工具中进行设置，这种形式需要依赖IDE工具，每款IDE工具不同，对应的配置也不太一样。但是核心思想是一样的，就是使用服务器去监控其中加载的应用，发现产生了变化就重新加载一次。 ​ 上面所说的非springboot项目实现热部署看上去是一个非常简单的过程，几乎每个小伙伴都能自己写出来。如果你不会写，我给你个最简单的思路，但是实际设计要比这复杂一些。例如启动一个定时任务，任务启动时记录每个文件的大小，以后每5秒比对一下每个文件的大小是否有改变，或者是否有新文件。如果没有改变，放行，如果有改变，刷新当前记录的文件信息，然后重新启动服务器，这就可以实现热部署了。当然，这个过程肯定不能这么做，比如我把一个打印输出的字符串”abc”改成”cba”，比对大小是没有变化的，但是内容缺实变了，所以这么做肯定不行，只是给大家打个比方，而且重启服务器这就是冷启动了，不能算热部署，领会精神吧。 ​ 看上去这个过程也没多复杂，在springboot项目中难道还有其他的弯弯绕吗？还真有。 springboot项目热部署实现原理 ​ 基于springboot开发的web工程其实有一个显著的特征，就是tomcat服务器内置了，还记得内嵌服务器吗？服务器是以一个对象的形式在spring容器中运行的。本来我们期望于tomcat服务器加载程序后由tomcat服务器盯着程序，你变化后我就重新启动重新加载，但是现在tomcat和我们的程序是平级的了，都是spring容器中的组件，这下就麻烦了，缺乏了一个直接的管理权，那该怎么做呢？简单，再搞一个程序X在spring容器中盯着你原始开发的程序A不就行了吗？确实，搞一个盯着程序A的程序X就行了，如果你自己开发的程序A变化了，那么程序X就命令tomcat容器重新加载程序A就OK了。并且这样做有一个好处，spring容器中东西不用全部重新加载一遍，只需要重新加载你开发的程序那一部分就可以了，这下效率又高了，挺好。 ​ 下面就说说，怎么搞出来这么一个程序X，肯定不是我们自己手写了，springboot早就做好了，搞一个坐标导入进去就行了。 KF-1-1.手动启动热部署步骤①：导入开发者工具对应的坐标 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; 步骤②：构建项目，可以使用快捷键激活此功能 ​ 对应的快捷键一定要记得 &lt;CTR&gt;L+&lt;F9&gt; ​ 以上过程就实现了springboot工程的热部署，是不是挺简单的。不过这里需要把底层的工作工程给普及一下。 重启与重载 ​ 一个springboot项目在运行时实际上是分两个过程进行的，根据加载的东西不同，划分成base类加载器与restart类加载器。 base类加载器：用来加载jar包中的类，jar包中的类和配置文件由于不会发生变化，因此不管加载多少次，加载的内容不会发生变化 restart类加载器：用来加载开发者自己开发的类、配置文件、页面等信息，这一类文件受开发者影响 ​ 当springboot项目启动时，base类加载器执行，加载jar包中的信息后，restart类加载器执行，加载开发者制作的内容。当执行构建项目后，由于jar中的信息不会变化，因此base类加载器无需再次执行，所以仅仅运行restart类加载即可，也就是将开发者自己制作的内容重新加载就行了，这就完成了一次热部署的过程，也可以说热部署的过程实际上是重新加载restart类加载器中的信息。 总结 使用开发者工具可以为当前项目开启热部署功能 使用构建项目操作对工程进行热部署 思考 ​ 上述过程每次进行热部署都需要开发者手工操作，不管是点击按钮还是快捷键都需要开发者手工执行。这种操作的应用场景主要是在开发调试期，并且调试的代码处于不同的文件中，比如服务器启动了，我需要改4个文件中的内容，然后重启，等4个文件都改完了再执行热部署，使用一个快捷键就OK了。但是如果现在开发者要修改的内容就只有一个文件中的少量代码，这个时候代码修改完毕如果能够让程序自己执行热部署功能，就可以减少开发者的操作，也就是自动进行热部署，能这么做吗？是可以的。咱们下一节再说。 ​ KF-1-2.自动启动热部署​ 自动热部署其实就是设计一个开关，打开这个开关后，IDE工具就可以自动热部署。因此这个操作和IDE工具有关，以下以idea为例设置idea中启动热部署 步骤①：设置自动构建项目 ​ 打开【File】，选择【settings…】,在面板左侧的菜单中找到【Compile】选项，然后勾选【Build project automatically】，意思是自动构建项目 ​ 自动构建项目选项勾选后 步骤②：允许在程序运行时进行自动构建 ​ 使用快捷键【Ctrl】+【Alt】+【Shit】+【/】打开维护面板，选择第1项【Registry…】 ​ 在选项中搜索comple，然后勾选对应项即可 ​ 这样程序在运行的时候就可以进行自动构建了，实现了热部署的效果。 关注：如果你每敲一个字母，服务器就重新构建一次，这未免有点太频繁了，所以idea设置当idea工具失去焦点5秒后进行热部署。其实就是你从idea工具中切换到其他工具时进行热部署，比如改完程序需要到浏览器上去调试，这个时候idea就自动进行热部署操作。 总结 自动热部署要开启自动构建项目 自动热部署要开启在程序运行时自动构建项目 思考 ​ 现在已经实现了热部署了，但是到企业开发的时候你会发现，为了便于管理，在你的程序目录中除了有代码，还有可能有文档，如果你修改了一下文档，这个时候会进行热部署吗？不管是否进行热部署，这个过程我们需要自己控制才比较合理，那这个东西能控制吗？咱们下一节再说。 KF-1-3.参与热部署监控的文件范围配置​ 通过修改项目中的文件，你可以发现其实并不是所有的文件修改都会激活热部署的，原因在于在开发者工具中有一组配置，当满足了配置中的条件后，才会启动热部署，配置中默认不参与热部署的目录信息如下 /META-INF/maven /META-INF/resources /resources /static /public /templates ​ 以上目录中的文件如果发生变化，是不参与热部署的。如果想修改配置，可以通过application.yml文件进行设定哪些文件不参与热部署操作 spring: devtools: restart: # 设置不参与热部署的文件或文件夹 exclude: static/**,public/**,config/application.yml 总结 通过配置可以修改不参与热部署的文件或目录 思考 ​ 热部署功能是一个典型的开发阶段使用的功能，到了线上环境运行程序时，这个功能就没有意义了。能否关闭热部署功能呢？咱们下一节再说。 KF-1-4.关闭热部署​ 线上环境运行时是不可能使用热部署功能的，所以需要强制关闭此功能，通过配置可以关闭此功能。 spring: devtools: restart: enabled: false ​ 如果当心配置文件层级过多导致相符覆盖最终引起配置失效，可以提高配置的层级，在更高层级中配置关闭热部署。例如在启动容器前通过系统属性设置关闭热部署功能。 @SpringBootApplication public class SSMPApplication { public static void main(String[] args) { System.setProperty(\"spring.devtools.restart.enabled\",\"false\"); SpringApplication.run(SSMPApplication.class); } } ​ 其实上述担心略微有点多余，因为线上环境的维护是不可能出现修改代码的操作的，这么做唯一的作用是降低资源消耗，毕竟那双盯着你项目是不是产生变化的眼睛只要闭上了，就不具有热部署功能了，这个开关的作用就是禁用对应功能。 总结 通过配置可以关闭热部署功能降低线上程序的资源消耗 KF-2.配置高级​ 进入开发实用篇第二章内容，配置高级，其实配置在基础篇讲了一部分，在运维实用篇讲了一部分，这里还要讲，讲的东西有什么区别呢？距离开发过程越来越接近，解决的问题也越来越靠近线上环境，下面就开启本章的学习。 KF-2-1.@ConfigurationProperties​ 在基础篇学习了@ConfigurationProperties注解，此注解的作用是用来为bean绑定属性的。开发者可以在yml配置文件中以对象的格式添加若干属性 servers: ip-address: 192.168.0.1 port: 2345 timeout: -1 ​ 然后再开发一个用来封装数据的实体类，注意要提供属性对应的setter方法 @Component @Data public class ServerConfig { private String ipAddress; private int port; private long timeout; } ​ 使用@ConfigurationProperties注解就可以将配置中的属性值关联到开发的模型类上 @Component @Data @ConfigurationProperties(prefix = \"servers\") public class ServerConfig { private String ipAddress; private int port; private long timeout; } ​ 这样加载对应bean的时候就可以直接加载配置属性值了。但是目前我们学的都是给自定义的bean使用这种形式加载属性值，如果是第三方的bean呢？能不能用这种形式加载属性值呢？为什么会提出这个疑问？原因就在于当前@ConfigurationProperties注解是写在类定义的上方，而第三方开发的bean源代码不是你自己书写的，你也不可能到源代码中去添加@ConfigurationProperties注解，这种问题该怎么解决呢？下面就来说说这个问题。 ​ 使用@ConfigurationProperties注解其实可以为第三方bean加载属性，格式特殊一点而已。 步骤①：使用@Bean注解定义第三方bean @Bean public DruidDataSource datasource(){ DruidDataSource ds = new DruidDataSource(); return ds; } 步骤②：在yml中定义要绑定的属性，注意datasource此时全小写 datasource: driverClassName: com.mysql.jdbc.Driver 步骤③：使用@ConfigurationProperties注解为第三方bean进行属性绑定，注意前缀是全小写的datasource @Bean @ConfigurationProperties(prefix = \"datasource\") public DruidDataSource datasource(){ DruidDataSource ds = new DruidDataSource(); return ds; } ​ 操作方式完全一样，只不过@ConfigurationProperties注解不仅能添加到类上，还可以添加到方法上，添加到类上是为spring容器管理的当前类的对象绑定属性，添加到方法上是为spring容器管理的当前方法的返回值对象绑定属性，其实本质上都一样。 ​ 做到这其实就出现了一个新的问题，目前我们定义bean不是通过类注解定义就是通过@Bean定义，使用@ConfigurationProperties注解可以为bean进行属性绑定，那在一个业务系统中，哪些bean通过注解@ConfigurationProperties去绑定属性了呢？因为这个注解不仅可以写在类上，还可以写在方法上，所以找起来就比较麻烦了。为了解决这个问题，spring给我们提供了一个全新的注解，专门标注使用@ConfigurationProperties注解绑定属性的bean是哪些。这个注解叫做@EnableConfigurationProperties。具体如何使用呢？ 步骤①：在配置类上开启@EnableConfigurationProperties注解，并标注要使用@ConfigurationProperties注解绑定属性的类 @SpringBootApplication @EnableConfigurationProperties(ServerConfig.class) public class Springboot13ConfigurationApplication { } 步骤②：在对应的类上直接使用@ConfigurationProperties进行属性绑定 @Data @ConfigurationProperties(prefix = \"servers\") public class ServerConfig { private String ipAddress; private int port; private long timeout; } ​ 有人感觉这没区别啊？注意观察，现在绑定属性的ServerConfig类并没有声明@Component注解。当使用@EnableConfigurationProperties注解时，spring会默认将其标注的类定义为bean，因此无需再次声明@Component注解了。 ​ 最后再说一个小技巧，使用@ConfigurationProperties注解时，会出现一个提示信息 ​ 出现这个提示后只需要添加一个坐标此提醒就消失了 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;/dependency&gt; 总结 使用@ConfigurationProperties可以为使用@Bean声明的第三方bean绑定属性 当使用@EnableConfigurationProperties声明进行属性绑定的bean后，无需使用@Component注解再次进行bean声明 KF-2-2.宽松绑定/松散绑定​ 在进行属性绑定时，可能会遇到如下情况，为了进行标准命名，开发者会将属性名严格按照驼峰命名法书写，在yml配置文件中将datasource修改为dataSource，如下： dataSource: driverClassName: com.mysql.jdbc.Driver ​ 此时程序可以正常运行，然后又将代码中的前缀datasource修改为dataSource，如下： @Bean @ConfigurationProperties(prefix = \"dataSource\") public DruidDataSource datasource(){ DruidDataSource ds = new DruidDataSource(); return ds; } ​ 此时就发生了编译错误，而且并不是idea工具导致的，运行后依然会出现问题，配置属性名dataSource是无效的 Configuration property name 'dataSource' is not valid: Invalid characters: 'S' Bean: datasource Reason: Canonical names should be kebab-case ('-' separated), lowercase alpha-numeric characters and must start with a letter Action: Modify 'dataSource' so that it conforms to the canonical names requirements. ​ 为什么会出现这种问题，这就要来说一说springboot进行属性绑定时的一个重要知识点了，有关属性名称的宽松绑定，也可以称为宽松绑定。 ​ 什么是宽松绑定？实际上是springboot进行编程时人性化设计的一种体现，即配置文件中的命名格式与变量名的命名格式可以进行格式上的最大化兼容。兼容到什么程度呢？几乎主流的命名格式都支持，例如： ​ 在ServerConfig中的ipAddress属性名 @Component @Data @ConfigurationProperties(prefix = \"servers\") public class ServerConfig { private String ipAddress; } ​ 可以与下面的配置属性名规则全兼容 servers: ipAddress: 192.168.0.2 # 驼峰模式 ip_address: 192.168.0.2 # 下划线模式 ip-address: 192.168.0.2 # 烤肉串模式 IP_ADDRESS: 192.168.0.2 # 常量模式 ​ 也可以说，以上4种模式最终都可以匹配到ipAddress这个属性名。为什么这样呢？原因就是在进行匹配时，配置中的名称要去掉中划线和下划线后，忽略大小写的情况下去与java代码中的属性名进行忽略大小写的等值匹配，以上4种命名去掉下划线中划线忽略大小写后都是一个词ipaddress，java代码中的属性名忽略大小写后也是ipaddress，这样就可以进行等值匹配了，这就是为什么这4种格式都能匹配成功的原因。不过springboot官方推荐使用烤肉串模式，也就是中划线模式。 ​ 到这里我们掌握了一个知识点，就是命名的规范问题。再来看开始出现的编程错误信息 Configuration property name 'dataSource' is not valid: Invalid characters: 'S' Bean: datasource Reason: Canonical names should be kebab-case ('-' separated), lowercase alpha-numeric characters and must start with a letter Action: Modify 'dataSource' so that it conforms to the canonical names requirements. ​ 其中Reason描述了报错的原因，规范的名称应该是烤肉串(kebab)模式(case)，即使用-分隔，使用小写字母数字作为标准字符，且必须以字母开头。然后再看我们写的名称dataSource，就不满足上述要求。闹了半天，在书写前缀时，这个词不是随意支持的，必须使用上述标准。编程写了这么久，基本上编程习惯都养成了，到这里又被springboot教育了，没辙，谁让人家东西好用呢，按照人家的要求写吧。 ​ 最后说一句，以上规则仅针对springboot中@ConfigurationProperties注解进行属性绑定时有效，对@Value注解进行属性映射无效。有人就说，那我不用你不就行了？不用，你小看springboot的推广能力了，到原理篇我们看源码时，你会发现内部全是这玩意儿，算了，拿人手短吃人嘴短，认怂吧。 总结 @ConfigurationProperties绑定属性时支持属性名宽松绑定，这个宽松体现在属性名的命名规则上 @Value注解不支持松散绑定规则 绑定前缀名推荐采用烤肉串命名规则，即使用中划线做分隔符 KF-2-3.常用计量单位绑定​ 在前面的配置中，我们书写了如下配置值，其中第三项超时时间timeout描述了服务器操作超时时间，当前值是-1表示永不超时。 servers: ip-address: 192.168.0.1 port: 2345 timeout: -1 ​ 但是每个人都这个值的理解会产生不同，比如线上服务器完成一次主从备份，配置超时时间240，这个240如果单位是秒就是超时时间4分钟，如果单位是分钟就是超时时间4小时。面对一次线上服务器的主从备份，设置4分钟，简直是开玩笑，别说拷贝过程，备份之前的压缩过程4分钟也搞不定，这个时候问题就来了，怎么解决这个误会？ ​ 除了加强约定之外，springboot充分利用了JDK8中提供的全新的用来表示计量单位的新数据类型，从根本上解决这个问题。以下模型类中添加了两个JDK8中新增的类，分别是Duration和DataSize @Component @Data @ConfigurationProperties(prefix = \"servers\") public class ServerConfig { @DurationUnit(ChronoUnit.HOURS) private Duration serverTimeOut; @DataSizeUnit(DataUnit.MEGABYTES) private DataSize dataSize; } Duration：表示时间间隔，可以通过@DurationUnit注解描述时间单位，例如上例中描述的单位为小时（ChronoUnit.HOURS） DataSize：表示存储空间，可以通过@DataSizeUnit注解描述存储空间单位，例如上例中描述的单位为MB（DataUnit.MEGABYTES） ​ 使用上述两个单位就可以有效避免因沟通不同步或文档不健全导致的信息不对称问题，从根本上解决了问题，避免产生误读。 Druation常用单位如下： DataSize常用单位如下： KF-2-4.校验​ 目前我们在进行属性绑定时可以通过松散绑定规则在书写时放飞自我了，但是在书写时由于无法感知模型类中的数据类型，就会出现类型不匹配的问题，比如代码中需要int类型，配置中给了非法的数值，例如写一个“a”，这种数据肯定无法有效的绑定，还会引发错误。 SpringBoot给出了强大的数据校验功能，可以有效的避免此类问题的发生。在JAVAEE的JSR303规范中给出了具体的数据校验标准，开发者可以根据自己的需要选择对应的校验框架，此处使用Hibernate提供的校验框架来作为实现进行数据校验。书写应用格式非常固定，话不多说，直接上步骤 步骤①：开启校验框架 &lt;!--1.导入JSR303规范--&gt; &lt;dependency&gt; &lt;groupId&gt;javax.validation&lt;/groupId&gt; &lt;artifactId&gt;validation-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--使用hibernate框架提供的校验器做实现--&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate.validator&lt;/groupId&gt; &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt; &lt;/dependency&gt; 步骤②：在需要开启校验功能的类上使用注解@Validated开启校验功能 @Component @Data @ConfigurationProperties(prefix = \"servers\") //开启对当前bean的属性注入校验 @Validated public class ServerConfig { } 步骤③：对具体的字段设置校验规则 @Component @Data @ConfigurationProperties(prefix = \"servers\") //开启对当前bean的属性注入校验 @Validated public class ServerConfig { //设置具体的规则 @Max(value = 8888,message = \"最大值不能超过8888\") @Min(value = 202,message = \"最小值不能低于202\") private int port; } ​ 通过设置数据格式校验，就可以有效避免非法数据加载，其实使用起来还是挺轻松的，基本上就是一个格式。 总结 开启Bean属性校验功能一共3步：导入JSR303与Hibernate校验框架坐标、使用@Validated注解启用校验功能、使用具体校验规则规范数据校验格式 KF-2-5.数据类型转换​ 有关spring属性注入的问题到这里基本上就讲完了，但是最近一名开发者向我咨询了一个问题，我觉得需要给各位学习者分享一下。在学习阶段其实我们遇到的问题往往复杂度比较低，单一性比较强，但是到了线上开发时，都是综合性的问题，而这个开发者遇到的问题就是由于bean的属性注入引发的灾难。 ​ 先把问题描述一下，这位开发者连接数据库正常操作，但是运行程序后显示的信息是密码错误。 java.sql.SQLException: Access denied for user 'root'@'localhost' (using password: YES) ​ 其实看到这个报错，几乎所有的学习者都能分辨出来，这是用户名和密码不匹配，就就是密码输入错了，但是问题就在于密码并没有输入错误，这就比较讨厌了。给的报错信息无法帮助你有效的分析问题，甚至会给你带到沟里。如果是初学者，估计这会心态就崩了，我密码没错啊，你怎么能说我有错误呢？来看看用户名密码的配置是如何写的： spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=UTC username: root password: 0127 ​ 这名开发者的生日是1月27日，所以密码就使用了0127，其实问题就出在这里了。 ​ 之前在基础篇讲属性注入时，提到过类型相关的知识，在整数相关知识中有这么一句话，支持二进制，八进制，十六进制 ​ 这个问题就处在这里了，因为0127在开发者眼中是一个字符串“0127”，但是在springboot看来，这就是一个数字，而且是一个八进制的数字。当后台使用String类型接收数据时，如果配置文件中配置了一个整数值，他是先安装整数进行处理，读取后再转换成字符串。巧了，0127撞上了八进制的格式，所以最终以十进制数字87的结果存在了。 ​ 这里提两个注意点，第一，字符串标准书写加上引号包裹，养成习惯，第二，遇到0开头的数据多注意吧。 总结 yaml文件中对于数字的定义支持进制书写格式，如需使用字符串请使用引号明确标注 KF-3.测试​ 说完bean配置相关的内容，下面要对前面讲过的一个知识做加强了，测试。测试是保障程序正确性的唯一屏障，在企业级开发中更是不可缺少，但是由于测试代码往往不产生实际效益，所以一些小型公司并不是很关注，导致一些开发者从小型公司进入中大型公司后，往往这一块比较短板，所以还是要拿出来把这一块知识好好说说，做一名专业的开发人员。 KF-3-1.加载测试专用属性​ 测试过程本身并不是一个复杂的过程，但是很多情况下测试时需要模拟一些线上情况，或者模拟一些特殊情况。如果当前环境按照线上环境已经设定好了，例如是下面的配置 env: maxMemory: 32GB minMemory: 16GB ​ 但是你现在想测试对应的兼容性，需要测试如下配置 env: maxMemory: 16GB minMemory: 8GB ​ 这个时候我们能不能每次测试的时候都去修改源码application.yml中的配置进行测试呢？显然是不行的。每次测试前改过来，每次测试后改回去，这太麻烦了。于是我们就想，需要在测试环境中创建一组临时属性，去覆盖我们源码中设定的属性，这样测试用例就相当于是一个独立的环境，能够独立测试，这样就方便多了。 临时属性 ​ springboot已经为我们开发者早就想好了这种问题该如何解决，并且提供了对应的功能入口。在测试用例程序中，可以通过对注解@SpringBootTest添加属性来模拟临时属性，具体如下： //properties属性可以为当前测试用例添加临时的属性配置 @SpringBootTest(properties = {\"test.prop=testValue1\"}) public class PropertiesAndArgsTest { @Value(\"${test.prop}\") private String msg; @Test void testProperties(){ System.out.println(msg); } } ​ 使用注解@SpringBootTest的properties属性就可以为当前测试用例添加临时的属性，覆盖源码配置文件中对应的属性值进行测试。 临时参数 ​ 除了上述这种情况，在前面讲解使用命令行启动springboot程序时讲过，通过命令行参数也可以设置属性值。而且线上启动程序时，通常都会添加一些专用的配置信息。作为运维人员他们才不懂java，更不懂这些配置的信息具体格式该怎么写，那如果我们作为开发者提供了对应的书写内容后，能否提前测试一下这些配置信息是否有效呢？当时是可以的，还是通过注解@SpringBootTest的另一个属性来进行设定。 //args属性可以为当前测试用例添加临时的命令行参数 @SpringBootTest(args={\"--test.prop=testValue2\"}) public class PropertiesAndArgsTest { @Value(\"${test.prop}\") private String msg; @Test void testProperties(){ System.out.println(msg); } } ​ 使用注解@SpringBootTest的args属性就可以为当前测试用例模拟命令行参数并进行测试。 ​ 说到这里，好奇宝宝们肯定就有新问题了，如果两者共存呢？其实如果思考一下配置属性与命令行参数的加载优先级，这个结果就不言而喻了。在属性加载的优先级设定中，有明确的优先级设定顺序，还记得下面这个顺序吗？ ​ 在这个属性加载优先级的顺序中，明确规定了命令行参数的优先级排序是11，而配置属性的优先级是3，结果不言而喻了，args属性配置优先于properties属性配置加载。 ​ 到这里我们就掌握了如果在测试用例中去模拟临时属性的设定。 总结 加载测试临时属性可以通过注解@SpringBootTest的properties和args属性进行设定，此设定应用范围仅适用于当前测试用例 思考 ​ 应用于测试环境的临时属性解决了，如果想在测试的时候临时加载一些bean能不做呢？也就是说我测试时，想搞一些独立的bean出来，专门应用于测试环境，能否实现呢？咱们下一节再讲。 KF-3-2.加载测试专用配置​ 上一节提出了临时配置一些专用于测试环境的bean的需求，这一节我们就来解决这个问题。 ​ 学习过Spring的知识，我们都知道，其实一个spring环境中可以设置若干个配置文件或配置类，若干个配置信息可以同时生效。现在我们的需求就是在测试环境中再添加一个配置类，然后启动测试环境时，生效此配置就行了。其实做法和spring环境中加载多个配置信息的方式完全一样。具体操作步骤如下： 步骤①：在测试包test中创建专用的测试环境配置类 @Configuration public class MsgConfig { @Bean public String msg(){ return \"bean msg\"; } } ​ 上述配置仅用于演示当前实验效果，实际开发可不能这么注入String类型的数据 步骤②：在启动测试环境时，导入测试环境专用的配置类，使用@Import注解即可实现 @SpringBootTest @Import({MsgConfig.class}) public class ConfigurationTest { @Autowired private String msg; @Test void testConfiguration(){ System.out.println(msg); } } ​ 到这里就通过@Import属性实现了基于开发环境的配置基础上，对配置进行测试环境的追加操作，实现了1+1的配置环境效果。这样我们就可以实现每一个不同的测试用例加载不同的bean的效果，丰富测试用例的编写，同时不影响开发环境的配置。 总结 定义测试环境专用的配置类，然后通过@Import注解在具体的测试中导入临时的配置，例如测试用例，方便测试过程，且上述配置不影响其他的测试类环境 思考 ​ 当前我们已经可以实现业务层和数据层的测试，并且通过临时配置，控制每个测试用例加载不同的测试数据。但是实际企业开发不仅要保障业务层与数据层的功能安全有效，也要保障表现层的功能正常。但是我们目的对表现层的测试都是通过postman手工测试的，并没有在打包过程中体现表现层功能被测试通过。能否在测试用例中对表现层进行功能测试呢？还真可以，咱们下一节再讲。 KF-3-3.Web环境模拟测试​ 在测试中对表现层功能进行测试需要一个基础和一个功能。所谓的一个基础是运行测试程序时，必须启动web环境，不然没法测试web功能。一个功能是必须在测试程序中具备发送web请求的能力，不然无法实现web功能的测试。所以在测试用例中测试表现层接口这项工作就转换成了两件事，一，如何在测试类中启动web测试，二，如何在测试类中发送web请求。下面一件事一件事进行，先说第一个 测试类中启动web环境 ​ 每一个springboot的测试类上方都会标准@SpringBootTest注解，而注解带有一个属性，叫做webEnvironment。通过该属性就可以设置在测试用例中启动web环境，具体如下： @SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT) public class WebTest { } ​ 测试类中启动web环境时，可以指定启动的Web环境对应的端口，springboot提供了4种设置值，分别如下： MOCK：根据当前设置确认是否启动web环境，例如使用了Servlet的API就启动web环境，属于适配性的配置 DEFINED_PORT：使用自定义的端口作为web服务器端口 RANDOM_PORT：使用随机端口作为web服务器端口 NONE：不启动web环境 ​ 通过上述配置，现在启动测试程序时就可以正常启用web环境了，建议大家测试时使用RANDOM_PORT，避免代码中因为写死设定引发线上功能打包测试时由于端口冲突导致意外现象的出现。就是说你程序中写了用8080端口，结果线上环境8080端口被占用了，结果你代码中所有写的东西都要改，这就是写死代码的代价。现在你用随机端口就可以测试出来你有没有这种问题的隐患了。 ​ 测试环境中的web环境已经搭建好了，下面就可以来解决第二个问题了，如何在程序代码中发送web请求。 测试类中发送请求 ​ 对于测试类中发送请求，其实java的API就提供对应的功能，只不过平时各位小伙伴接触的比较少，所以较为陌生。springboot为了便于开发者进行对应的功能开发，对其又进行了包装，简化了开发步骤，具体操作如下： 步骤①：在测试类中开启web虚拟调用功能，通过注解@AutoConfigureMockMvc实现此功能的开启 @SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT) //开启虚拟MVC调用 @AutoConfigureMockMvc public class WebTest { } 步骤②：定义发起虚拟调用的对象MockMVC，通过自动装配的形式初始化对象 @SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT) //开启虚拟MVC调用 @AutoConfigureMockMvc public class WebTest { @Test void testWeb(@Autowired MockMvc mvc) { } } 步骤③：创建一个虚拟请求对象，封装请求的路径，并使用MockMVC对象发送对应请求 @SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT) //开启虚拟MVC调用 @AutoConfigureMockMvc public class WebTest { @Test void testWeb(@Autowired MockMvc mvc) throws Exception { //http://localhost:8080/books //创建虚拟请求，当前访问/books MockHttpServletRequestBuilder builder = MockMvcRequestBuilders.get(\"/books\"); //执行对应的请求 mvc.perform(builder); } } ​ 执行测试程序，现在就可以正常的发送/books对应的请求了，注意访问路径不要写http://localhost:8080/books，因为前面的服务器IP地址和端口使用的是当前虚拟的web环境，无需指定，仅指定请求的具体路径即可。 总结 在测试类中测试web层接口要保障测试类启动时启动web容器，使用@SpringBootTest注解的webEnvironment属性可以虚拟web环境用于测试 为测试方法注入MockMvc对象，通过MockMvc对象可以发送虚拟请求，模拟web请求调用过程 思考 ​ 目前已经成功的发送了请求，但是还没有起到测试的效果，测试过程必须出现预计值与真实值的比对结果才能确认测试结果是否通过，虚拟请求中能对哪些请求结果进行比对呢？咱们下一节再讲。 web环境请求结果比对 ​ 上一节已经在测试用例中成功的模拟出了web环境，并成功的发送了web请求，本节就来解决发送请求后如何比对发送结果的问题。其实发完请求得到的信息只有一种，就是响应对象。至于响应对象中包含什么，就可以比对什么。常见的比对内容如下： 响应状态匹配 @Test void testStatus(@Autowired MockMvc mvc) throws Exception { MockHttpServletRequestBuilder builder = MockMvcRequestBuilders.get(\"/books\"); ResultActions action = mvc.perform(builder); //设定预期值 与真实值进行比较，成功测试通过，失败测试失败 //定义本次调用的预期值 StatusResultMatchers status = MockMvcResultMatchers.status(); //预计本次调用时成功的：状态200 ResultMatcher ok = status.isOk(); //添加预计值到本次调用过程中进行匹配 action.andExpect(ok); } 响应体匹配（非json数据格式） @Test void testBody(@Autowired MockMvc mvc) throws Exception { MockHttpServletRequestBuilder builder = MockMvcRequestBuilders.get(\"/books\"); ResultActions action = mvc.perform(builder); //设定预期值 与真实值进行比较，成功测试通过，失败测试失败 //定义本次调用的预期值 ContentResultMatchers content = MockMvcResultMatchers.content(); ResultMatcher result = content.string(\"springboot2\"); //添加预计值到本次调用过程中进行匹配 action.andExpect(result); } 响应体匹配（json数据格式，开发中的主流使用方式） @Test void testJson(@Autowired MockMvc mvc) throws Exception { MockHttpServletRequestBuilder builder = MockMvcRequestBuilders.get(\"/books\"); ResultActions action = mvc.perform(builder); //设定预期值 与真实值进行比较，成功测试通过，失败测试失败 //定义本次调用的预期值 ContentResultMatchers content = MockMvcResultMatchers.content(); ResultMatcher result = content.json(\"{\\\"id\\\":1,\\\"name\\\":\\\"springboot2\\\",\\\"type\\\":\\\"springboot\\\"}\"); //添加预计值到本次调用过程中进行匹配 action.andExpect(result); } 响应头信息匹配 @Test void testContentType(@Autowired MockMvc mvc) throws Exception { MockHttpServletRequestBuilder builder = MockMvcRequestBuilders.get(\"/books\"); ResultActions action = mvc.perform(builder); //设定预期值 与真实值进行比较，成功测试通过，失败测试失败 //定义本次调用的预期值 HeaderResultMatchers header = MockMvcResultMatchers.header(); ResultMatcher contentType = header.string(\"Content-Type\", \"application/json\"); //添加预计值到本次调用过程中进行匹配 action.andExpect(contentType); } ​ 基本上齐了，头信息，正文信息，状态信息都有了，就可以组合出一个完美的响应结果比对结果了。以下范例就是三种信息同时进行匹配校验，也是一个完整的信息匹配过程。 @Test void testGetById(@Autowired MockMvc mvc) throws Exception { MockHttpServletRequestBuilder builder = MockMvcRequestBuilders.get(\"/books\"); ResultActions action = mvc.perform(builder); StatusResultMatchers status = MockMvcResultMatchers.status(); ResultMatcher ok = status.isOk(); action.andExpect(ok); HeaderResultMatchers header = MockMvcResultMatchers.header(); ResultMatcher contentType = header.string(\"Content-Type\", \"application/json\"); action.andExpect(contentType); ContentResultMatchers content = MockMvcResultMatchers.content(); ResultMatcher result = content.json(\"{\\\"id\\\":1,\\\"name\\\":\\\"springboot\\\",\\\"type\\\":\\\"springboot\\\"}\"); action.andExpect(result); } 总结 web虚拟调用可以对本地虚拟请求的返回响应信息进行比对，分为响应头信息比对、响应体信息比对、响应状态信息比对 KF-3-4.数据层测试回滚​ 当前我们的测试程序可以完美的进行表现层、业务层、数据层接口对应的功能测试了，但是测试用例开发完成后，在打包的阶段由于test生命周期属于必须被运行的生命周期，如果跳过会给系统带来极高的安全隐患，所以测试用例必须执行。但是新的问题就呈现了，测试用例如果测试时产生了事务提交就会在测试过程中对数据库数据产生影响，进而产生垃圾数据。这个过程不是我们希望发生的，作为开发者测试用例该运行运行，但是过程中产生的数据不要在我的系统中留痕，这样该如何处理呢？ ​ springboot早就为开发者想到了这个问题，并且针对此问题给出了最简解决方案，在原始测试用例中添加注解@Transactional即可实现当前测试用例的事务不提交。当程序运行后，只要注解@Transactional出现的位置存在注解@SpringBootTest，springboot就会认为这是一个测试程序，无需提交事务，所以也就可以避免事务的提交。 @SpringBootTest @Transactional @Rollback(true) public class DaoTest { @Autowired private BookService bookService; @Test void testSave(){ Book book = new Book(); book.setName(\"springboot3\"); book.setType(\"springboot3\"); book.setDescription(\"springboot3\"); bookService.save(book); } } ​ 如果开发者想提交事务，也可以，再添加一个@RollBack的注解，设置回滚状态为false即可正常提交事务，是不是很方便？springboot在辅助开发者日常工作这一块展现出了惊人的能力，实在太贴心了。 总结 在springboot的测试类中通过添加注解@Transactional来阻止测试用例提交事务 通过注解@Rollback控制springboot测试类执行结果是否提交事务，需要配合注解@Transactional使用 思考 ​ 当前测试程序已经近乎完美了，但是由于测试用例中书写的测试数据属于固定数据，往往失去了测试的意义，开发者可以针对测试用例进行针对性开发，这样就有可能出现测试用例不能完美呈现业务逻辑代码是否真实有效的达成业务目标的现象，解决方案其实很容易想，测试用例的数据只要随机产生就可以了，能实现吗？咱们下一节再讲。 KF-3-5.测试用例数据设定​ 对于测试用例的数据固定书写肯定是不合理的，springboot提供了在配置中使用随机值的机制，确保每次运行程序加载的数据都是随机的。具体如下： testcase: book: id: ${random.int} id2: ${random.int(10)} type: ${random.int!5,10!} name: ${random.value} uuid: ${random.uuid} publishTime: ${random.long} ​ 当前配置就可以在每次运行程序时创建一组随机数据，避免每次运行时数据都是固定值的尴尬现象发生，有助于测试功能的进行。数据的加载按照之前加载数据的形式，使用@ConfigurationProperties注解即可 @Component @Data @ConfigurationProperties(prefix = \"testcase.book\") public class BookCase { private int id; private int id2; private int type; private String name; private String uuid; private long publishTime; } ​ 对于随机值的产生，还有一些小的限定规则，比如产生的数值性数据可以设置范围等，具体如下： ${random.int}表示随机整数 ${random.int(10)}表示10以内的随机数 ${random.int(10,20)}表示10到20的随机数 其中()可以是任意字符，例如[]，!!均可 总结 使用随机数据可以替换测试用例中书写的固定数据，提高测试用例中的测试数据有效性 KF-4.数据层解决方案​ 开发实用篇前三章基本上是开胃菜，从第四章开始，开发实用篇进入到了噩梦难度了，从这里开始，不再是单纯的在springboot内部搞事情了，要涉及到很多相关知识。本章节主要内容都是和数据存储与读取相关，前期学习的知识与数据层有关的技术基本上都围绕在数据库这个层面上，所以本章要讲的第一个大的分支就是SQL解决方案相关的内容，除此之外，数据的来源还可以是非SQL技术相关的数据操作，因此第二部分围绕着NOSQL解决方案讲解。至于什么是NOSQL解决方案，讲到了再说吧。下面就从SQL解决方案说起。 KF-4-1.SQL​ 回忆一下之前做SSMP整合的时候数据层解决方案涉及到了哪些技术？MySQL数据库与MyBatisPlus框架，后面又学了Druid数据源的配置，所以现在数据层解决方案可以说是Mysql+Druid+MyBatisPlus。而三个技术分别对应了数据层操作的三个层面： 数据源技术：Druid 持久化技术：MyBatisPlus 数据库技术：MySQL ​ 下面的研究就分为三个层面进行研究，对应上面列出的三个方面，咱们就从第一个数据源技术开始说起。 数据源技术​ 目前我们使用的数据源技术是Druid，运行时可以在日志中看到对应的数据源初始化信息，具体如下： INFO 28600 --- [ main] c.a.d.s.b.a.DruidDataSourceAutoConfigure : Init DruidDataSource INFO 28600 --- [ main] com.alibaba.druid.pool.DruidDataSource : {dataSource-1} inited ​ 如果不使用Druid数据源，程序运行后是什么样子呢？是独立的数据库连接对象还是有其他的连接池技术支持呢？将Druid技术对应的starter去掉再次运行程序可以在日志中找到如下初始化信息： INFO 31820 --- [ main] com.zaxxer.hikari.HikariDataSource : HikariPool-1 - Starting... INFO 31820 --- [ main] com.zaxxer.hikari.HikariDataSource : HikariPool-1 - Start completed. ​ 虽然没有DruidDataSource相关的信息了，但是我们发现日志中有HikariDataSource这个信息，就算不懂这是个什么技术，看名字也能看出来，以DataSource结尾的名称，这一定是一个数据源技术。我们又没有手工添加这个技术，这个技术哪里来的呢？这就是这一节要讲的知识，springboot内嵌数据源。 ​ 数据层技术是每一个企业级应用程序都会用到的，而其中必定会进行数据库连接的管理。springboot根据开发者的习惯出发，开发者提供了数据源技术，就用你提供的，开发者没有提供，那总不能手工管理一个一个的数据库连接对象啊，怎么办？我给你一个默认的就好了，这样省心又省事，大家都方便。 ​ springboot提供了3款内嵌数据源技术，分别如下： HikariCP Tomcat提供DataSource Commons DBCP ​ 第一种，HikartCP，这是springboot官方推荐的数据源技术，作为默认内置数据源使用。啥意思？你不配置数据源，那就用这个。 ​ 第二种，Tomcat提供的DataSource，如果不想用HikartCP，并且使用tomcat作为web服务器进行web程序的开发，使用这个。为什么是Tomcat，不是其他web服务器呢？因为web技术导入starter后，默认使用内嵌tomcat，既然都是默认使用的技术了，那就一用到底，数据源也用它的。有人就提出怎么才能不使用HikartCP用tomcat提供的默认数据源对象呢？把HikartCP技术的坐标排除掉就OK了。 ​ 第三种，DBCP，这个使用的条件就更苛刻了，既不使用HikartCP也不使用tomcat的DataSource时，默认给你用这个。 ​ springboot这心操的，也是稀碎啊，就怕你自己管不好连接对象，给你一顿推荐，真是开发界的最强辅助。既然都给你奶上了，那就受用吧，怎么配置使用这些东西呢？之前我们配置druid时使用druid的starter对应的配置如下： spring: datasource: druid: url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=UTC driver-class-name: com.mysql.cj.jdbc.Driver username: root password: root ​ 换成是默认的数据源HikariCP后，直接吧druid删掉就行了，如下： spring: datasource: url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=UTC driver-class-name: com.mysql.cj.jdbc.Driver username: root password: root ​ 当然，也可以写上是对hikari做的配置，但是url地址要单独配置，如下： spring: datasource: url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=UTC hikari: driver-class-name: com.mysql.cj.jdbc.Driver username: root password: root ​ 这就是配置hikari数据源的方式。如果想对hikari做进一步的配置，可以继续配置其独立的属性。例如： spring: datasource: url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=UTC hikari: driver-class-name: com.mysql.cj.jdbc.Driver username: root password: root maximum-pool-size: 50 ​ 如果不想使用hikari数据源，使用tomcat的数据源或者DBCP配置格式也是一样的。学习到这里，以后我们做数据层时，数据源对象的选择就不再是单一的使用druid数据源技术了，可以根据需要自行选择。 总结 springboot技术提供了3种内置的数据源技术，分别是Hikari、tomcat内置数据源、DBCP 持久化技术​ 说完数据源解决方案，再来说一下持久化解决方案。springboot充分发挥其最强辅助的特征，给开发者提供了一套现成的数据层技术，叫做JdbcTemplate。其实这个技术不能说是springboot提供的，因为不使用springboot技术，一样能使用它，谁提供的呢？spring技术提供的，所以在springboot技术范畴中，这个技术也是存在的，毕竟springboot技术是加速spring程序开发而创建的。 ​ 这个技术其实就是回归到jdbc最原始的编程形式来进行数据层的开发，下面直接上操作步骤： 步骤①：导入jdbc对应的坐标，记得是starter &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency 步骤②：自动装配JdbcTemplate对象 @SpringBootTest class Springboot15SqlApplicationTests { @Test void testJdbcTemplate(@Autowired JdbcTemplate jdbcTemplate){ } } 步骤③：使用JdbcTemplate实现查询操作（非实体类封装数据的查询操作） @Test void testJdbcTemplate(@Autowired JdbcTemplate jdbcTemplate){ String sql = \"select * from tbl_book\"; List&lt;Map&lt;String, Object&gt;&gt; maps = jdbcTemplate.queryForList(sql); System.out.println(maps); } 步骤④：使用JdbcTemplate实现查询操作（实体类封装数据的查询操作） @Test void testJdbcTemplate(@Autowired JdbcTemplate jdbcTemplate){ String sql = \"select * from tbl_book\"; RowMapper&lt;Book&gt; rm = new RowMapper&lt;Book&gt;() { @Override public Book mapRow(ResultSet rs, int rowNum) throws SQLException { Book temp = new Book(); temp.setId(rs.getInt(\"id\")); temp.setName(rs.getString(\"name\")); temp.setType(rs.getString(\"type\")); temp.setDescription(rs.getString(\"description\")); return temp; } }; List&lt;Book&gt; list = jdbcTemplate.query(sql, rm); System.out.println(list); } 步骤⑤：使用JdbcTemplate实现增删改操作 @Test void testJdbcTemplateSave(@Autowired JdbcTemplate jdbcTemplate){ String sql = \"insert into tbl_book values(3,'springboot1','springboot2','springboot3')\"; jdbcTemplate.update(sql); } ​ 如果想对JdbcTemplate对象进行相关配置，可以在yml文件中进行设定，具体如下： spring: jdbc: template: query-timeout: -1 # 查询超时时间 max-rows: 500 # 最大行数 fetch-size: -1 # 缓存行数 总结 SpringBoot内置JdbcTemplate持久化解决方案 使用JdbcTemplate需要导入spring-boot-starter-jdbc的坐标 数据库技术​ 截止到目前，springboot给开发者提供了内置的数据源解决方案和持久化解决方案，在数据层解决方案三件套中还剩下一个数据库，莫非springboot也提供有内置的解决方案？还真有，还不是一个，三个，这一节就来说说内置的数据库解决方案。 ​ springboot提供了3款内置的数据库，分别是 H2 HSQL Derby ​ 以上三款数据库除了可以独立安装之外，还可以像是tomcat服务器一样，采用内嵌的形式运行在spirngboot容器中。内嵌在容器中运行，那必须是java对象啊，对，这三款数据库底层都是使用java语言开发的。 ​ 我们一直使用MySQL数据库就挺好的，为什么有需求用这个呢？原因就在于这三个数据库都可以采用内嵌容器的形式运行，在应用程序运行后，如果我们进行测试工作，此时测试的数据无需存储在磁盘上，但是又要测试使用，内嵌数据库就方便了，运行在内存中，该测试测试，该运行运行，等服务器关闭后，一切烟消云散，多好，省得你维护外部数据库了。这也是内嵌数据库的最大优点，方便进行功能测试。 ​ 下面以H2数据库为例讲解如何使用这些内嵌数据库，操作步骤也非常简单，简单才好用嘛 步骤①：导入H2数据库对应的坐标，一共2个 &lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; 步骤②：将工程设置为web工程，启动工程时启动H2数据库 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; 步骤③：通过配置开启H2数据库控制台访问程序，也可以使用其他的数据库连接软件操作 spring: h2: console: enabled: true path: /h2 ​ web端访问路径/h2，访问密码123456，如果访问失败，先配置下列数据源，启动程序运行后再次访问/h2路径就可以正常访问了 datasource: url: jdbc:h2:~/test hikari: driver-class-name: org.h2.Driver username: sa password: 123456 步骤④：使用JdbcTemplate或MyBatisPlus技术操作数据库 （略） ​ 其实我们只是换了一个数据库而已，其他的东西都不受影响。一个重要提醒，别忘了，上线时，把内存级数据库关闭，采用MySQL数据库作为数据持久化方案，关闭方式就是设置enabled属性为false即可。 总结 H2内嵌式数据库启动方式，添加坐标，添加配置 H2数据库线上运行时请务必关闭 ​ 到这里SQL相关的数据层解决方案就讲完了，现在的可选技术就丰富的多了。 数据源技术：Druid、Hikari、tomcat DataSource、DBCP 持久化技术：MyBatisPlus、MyBatis、JdbcTemplate 数据库技术：MySQL、H2、HSQL、Derby ​ 现在开发程序时就可以在以上技术中任选一种组织成一套数据库解决方案了。 KF-4-2.NoSQL​ SQL数据层解决方案说完了，下面来说收NoSQL数据层解决方案。这个NoSQL是什么意思呢？从字面来看，No表示否定，NoSQL就是非关系型数据库解决方案，意思就是数据该存存该取取，只是这些数据不放在关系型数据库中了，那放在哪里？自然是一些能够存储数据的其他相关技术中了，比如Redis等。本节讲解的内容就是springboot如何整合这些技术，在springboot官方文档中提供了10种相关技术的整合方案，我们将讲解国内市场上最流行的几款NoSQL数据库整合方案，分别是Redis、MongoDB、ES。 ​ 因为每个小伙伴学习这门课程的时候起点不同，为了便于各位学习者更好的学习，每种技术在讲解整合前都会先讲一下安装和基本使用，然后再讲整合。如果对某个技术比较熟悉的小伙伴可以直接跳过安装的学习过程，直接看整合方案即可。此外上述这些技术最佳使用方案都是在Linux服务器上部署，但是考虑到各位小伙伴的学习起点差异过大，所以下面的课程都是以Windows平台作为安装基础讲解，如果想看Linux版软件安装，可以再找到对应技术的学习文档查阅学习。 SpringBoot整合Redis​ Redis是一款采用key-value数据存储格式的内存级NoSQL数据库，重点关注数据存储格式，是key-value格式，也就是键值对的存储形式。与MySQL数据库不同，MySQL数据库有表、有字段、有记录，Redis没有这些东西，就是一个名称对应一个值，并且数据以存储在内存中使用为主。什么叫以存储在内存中为主？其实Redis有它的数据持久化方案，分别是RDB和AOF，但是Redis自身并不是为了数据持久化而生的，主要是在内存中保存数据，加速数据访问的，所以说是一款内存级数据库。 ​ Redis支持多种数据存储格式，比如可以直接存字符串，也可以存一个map集合，list集合，后面会涉及到一些不同格式的数据操作，这个需要先学习一下才能进行整合，所以在基本操作中会介绍一些相关操作。下面就先安装，再操作，最后说整合 安装​ windows版安装包下载地址：https://github.com/tporadowski/redis/releases ​ 下载的安装包有两种形式，一种是一键安装的msi文件，还有一种是解压缩就能使用的zip文件，哪种形式都行，这里就不介绍安装过程了，本课程采用的是msi一键安装的msi文件进行安装的。 ​ 啥是msi，其实就是一个文件安装包，不仅安装软件，还帮你把安装软件时需要的功能关联在一起，打包操作。比如如安装序列、创建和设置安装路径、设置系统依赖项、默认设定安装选项和控制安装过程的属性。说简单点就是一站式服务，安装过程一条龙操作一气呵成，就是为小白用户提供的软件安装程序。 ​ 安装完毕后会得到如下文件，其中有两个文件对应两个命令，是启动Redis的核心命令，需要再CMD命令行模式执行。 启动服务器 redis-server.exe redis.windows.conf ​ 初学者无需调整服务器对外服务端口，默认6379。 启动客户端 redis-cli.exe ​ 如果启动redis服务器失败，可以先启动客户端，然后执行shutdown操作后退出，此时redis服务器就可以正常执行了。 基本操作​ 服务器启动后，使用客户端就可以连接服务器，类似于启动完MySQL数据库，然后启动SQL命令行操作数据库。 ​ 放置一个字符串数据到redis中，先为数据定义一个名称，比如name,age等，然后使用命令set设置数据到redis服务器中即可 set name itheima set age 12 ​ 从redis中取出已经放入的数据，根据名称取，就可以得到对应数据。如果没有对应数据就会得到(nil) get name get age ​ 以上使用的数据存储是一个名称对应一个值，如果要维护的数据过多，可以使用别的数据存储结构。例如hash，它是一种一个名称下可以存储多个数据的存储模型，并且每个数据也可以有自己的二级存储名称。向hash结构中存储数据格式如下： hset a a1 aa1 #对外key名称是a，在名称为a的存储模型中，a1这个key中保存了数据aa1 hset a a2 aa2 ​ 获取hash结构中的数据命令如下 hget a a1 #得到aa1 hget a a2 #得到aa2 ​ 有关redis的基础操作就普及到这里，需要全面掌握redis技术，请参看相关教程学习。 整合​ 在进行整合之前先梳理一下整合的思想，springboot整合任何技术其实就是在springboot中使用对应技术的API。如果两个技术没有交集，就不存在整合的概念了。所谓整合其实就是使用springboot技术去管理其他技术，几个问题是躲不掉的。 ​ 第一，需要先导入对应技术的坐标，而整合之后，这些坐标都有了一些变化 ​ 第二，任何技术通常都会有一些相关的设置信息，整合之后，这些信息如何写，写在哪是一个问题 ​ 第三，没有整合之前操作如果是模式A的话，整合之后如果没有给开发者带来一些便捷操作，那整合将毫无意义，所以整合后操作肯定要简化一些，那对应的操作方式自然也有所不同 ​ 按照上面的三个问题去思考springboot整合所有技术是一种通用思想，在整合的过程中会逐步摸索出整合的套路，而且适用性非常强，经过若干种技术的整合后基本上可以总结出一套固定思维。 ​ 下面就开始springboot整合redis，操作步骤如下： 步骤①：导入springboot整合redis的starter坐标 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; ​ 上述坐标可以在创建模块的时候通过勾选的形式进行选择，归属NoSQL分类中 步骤②：进行基础配置 spring: redis: host: localhost port: 6379 ​ 操作redis，最基本的信息就是操作哪一台redis服务器，所以服务器地址属于基础配置信息，不可缺少。但是即便你不配置，目前也是可以用的。因为以上两组信息都有默认配置，刚好就是上述配置值。 步骤③：使用springboot整合redis的专用客户端接口操作，此处使用的是RedisTemplate @SpringBootTest class Springboot16RedisApplicationTests { @Autowired private RedisTemplate redisTemplate; @Test void set() { ValueOperations ops = redisTemplate.opsForValue(); ops.set(\"age\",41); } @Test void get() { ValueOperations ops = redisTemplate.opsForValue(); Object age = ops.get(\"name\"); System.out.println(age); } @Test void hset() { HashOperations ops = redisTemplate.opsForHash(); ops.put(\"info\",\"b\",\"bb\"); } @Test void hget() { HashOperations ops = redisTemplate.opsForHash(); Object val = ops.get(\"info\", \"b\"); System.out.println(val); } } ​ 在操作redis时，需要先确认操作何种数据，根据数据种类得到操作接口。例如使用opsForValue()获取string类型的数据操作接口，使用opsForHash()获取hash类型的数据操作接口，剩下的就是调用对应api操作了。各种类型的数据操作接口如下： 总结 springboot整合redis步骤 导入springboot整合redis的starter坐标 进行基础配置 使用springboot整合redis的专用客户端接口RedisTemplate操作 StringRedisTemplate ​ 由于redis内部不提供java对象的存储格式，因此当操作的数据以对象的形式存在时，会进行转码，转换成字符串格式后进行操作。为了方便开发者使用基于字符串为数据的操作，springboot整合redis时提供了专用的API接口StringRedisTemplate，你可以理解为这是RedisTemplate的一种指定数据泛型的操作API。 @SpringBootTest public class StringRedisTemplateTest { @Autowired private StringRedisTemplate stringRedisTemplate; @Test void get(){ ValueOperations&lt;String, String&gt; ops = stringRedisTemplate.opsForValue(); String name = ops.get(\"name\"); System.out.println(name); } } redis客户端选择 springboot整合redis技术提供了多种客户端兼容模式，默认提供的是lettucs客户端技术，也可以根据需要切换成指定客户端技术，例如jedis客户端技术，切换成jedis客户端技术操作步骤如下： 步骤①：导入jedis坐标 &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;/dependency&gt; ​ jedis坐标受springboot管理，无需提供版本号 步骤②：配置客户端技术类型，设置为jedis spring: redis: host: localhost port: 6379 client-type: jedis 步骤③：根据需要设置对应的配置 spring: redis: host: localhost port: 6379 client-type: jedis lettuce: pool: max-active: 16 jedis: pool: max-active: 16 lettcus与jedis区别 jedis连接Redis服务器是直连模式，当多线程模式下使用jedis会存在线程安全问题，解决方案可以通过配置连接池使每个连接专用，这样整体性能就大受影响 lettcus基于Netty框架进行与Redis服务器连接，底层设计中采用StatefulRedisConnection。 StatefulRedisConnection自身是线程安全的，可以保障并发访问安全问题，所以一个连接可以被多线程复用。当然lettcus也支持多连接实例一起工作 总结 springboot整合redis提供了StringRedisTemplate对象，以字符串的数据格式操作redis 如果需要切换redis客户端实现技术，可以通过配置的形式进行","categories":[],"tags":[{"name":"SSMP","slug":"SSMP","permalink":"https://gitee.com/yunyd/tags/SSMP/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://gitee.com/yunyd/tags/SpringBoot/"}],"author":"llllz."},{"title":"SpringBoot复习 -1","slug":"SpringBoot复习  -1","date":"2023-08-03T04:01:03.000Z","updated":"2023-08-25T00:22:14.686Z","comments":true,"path":"posts/64bda99a.html","link":"","permalink":"https://gitee.com/yunyd/posts/64bda99a.html","excerpt":"","text":"SpringBoot复习JC-1.SpringBoot简介​ SpringBoot是由Pivotal团队提供的全新框架，其设计目的是用来简化Spring应用的初始搭建以及开发过程。 ​ 都简化了了哪些东西呢？其实就是针对原始的Spring程序制作的两个方面进行了简化： Spring程序缺点 依赖设置繁琐 以前写Spring程序，使用的技术都要自己一个一个的写，现在不需要了，如果做过原始SpringMVC程序的小伙伴应该知道，写SpringMVC程序，最基础的spring-web和spring-webmvc这两个坐标时必须的，就这还不包含你用json啊等等这些坐标，现在呢？一个坐标搞定面 配置繁琐 以前写配置类或者配置文件，然后用什么东西就要自己写加载bean这些东西，现在呢？什么都没写，照样能用 回顾 ​ 通过上面两个方面的定位，我们可以产生两个模糊的概念： SpringBoot开发团队认为原始的Spring程序初始搭建的时候可能有些繁琐，这个过程是可以简化的，那原始的Spring程序初始搭建过程都包含哪些东西了呢？为什么觉得繁琐呢？最基本的Spring程序至少有一个配置文件或配置类，用来描述Spring的配置信息，莫非这个文件都可以不写？此外现在企业级开发使用Spring大部分情况下是做web开发，如果做web开发的话，还要在加载web环境时加载时加载指定的spring配置，这都是最基本的需求了，不写的话怎么知道加载哪个配置文件/配置类呢？那换了SpringBoot技术以后呢，这些还要写吗？谜底稍后揭晓，先卖个关子 SpringBoot开发团队认为原始的Spring程序开发的过程也有些繁琐，这个过程仍然可以简化。开发过程无外乎使用什么技术，导入对应的jar包（或坐标）然后将这个技术的核心对象交给Spring容器管理，也就是配置成Spring容器管控的bean就可以了。这都是基本操作啊，难道这些东西SpringBoot也能帮我们简化？ ​ 再来看看前面提出的两个问题，已经有答案了，都简化了，都不用写了，这就是SpringBoot给我们带来的好处。这些简化操作在SpringBoot中有专业的用语，也是SpringBoot程序的核心功能及优点： 起步依赖（简化依赖配置） 依赖配置的书写简化就是靠这个起步依赖达成的 自动配置（简化常用工程相关配置） 配置过于繁琐，使用自动配置就可以做响应的简化，但是内部还是很复杂的，后面具体展开说 辅助功能（内置服务器，……） 除了上面的功能，其实SpringBoot程序还有其他的一些优势，比如我们没有配置Tomcat服务器，但是能正常运行，这是SpringBoot程序的一个可以感知到的功能，也是SpringBoot的辅助功能之一。一个辅助功能都能做的这么6，太牛了 ​ 下面结合入门程序来说说这些简化操作都在哪些方面进行体现的，一共分为4个方面 parent starter 引导类 内嵌tomcat parent​ SpringBoot关注到开发者在进行开发时，往往对依赖版本的选择具有固定的搭配格式，并且这些依赖版本的选择还不能乱搭配。比如A技术的2.0版与B技术的3.5版可以合作在一起，但是和B技术的3.7版合并使用时就有冲突。其实很多开发者都一直想做一件事情，就是将各种各样的技术配合使用的常见依赖版本进行收集整理，制作出了最合理的依赖版本配置方案，这样使用起来就方便多了。 ​ SpringBoot一看这种情况so easy啊，于是将所有的技术版本的常见使用方案都给开发者整理了出来，以后开发者使用时直接用它提供的版本方案，就不用担心冲突问题了，相当于SpringBoot做了无数个技术版本搭配的列表，这个技术搭配列表的名字叫做parent。 ​ parent自身具有很多个版本，每个parent版本中包含有几百个其他技术的版本号，不同的parent间使用的各种技术的版本号有可能会发生变化。当开发者使用某些技术时，直接使用SpringBoot提供的parent就行了，由parent帮助开发者统一的进行各种技术的版本管理 ​ 比如你现在要使用Spring配合MyBatis开发，没有parent之前怎么做呢？选个Spring的版本，再选个MyBatis的版本，再把这些技术使用时关联的其他技术的版本逐一确定下来。当你Spring的版本发生变化需要切换时，你的MyBatis版本有可能也要跟着切换，关联技术呢？可能都要切换，而且切换后还可能出现问题。现在这一切工作都可以交给parent来做了。你无需关注这些技术间的版本冲突问题，你只需要关注你用什么技术就行了，冲突问题由parent负责处理。 ​ 有人可能会提出来，万一parent给我导入了一些我不想使用的依赖怎么办？记清楚，这一点很关键，parent仅仅帮我们进行版本管理，它不负责帮你导入坐标，说白了用什么还是你自己定，只不过版本不需要你管理了。整体上来说，使用parent可以帮助开发者进行版本的统一管理 ​ 关注：parent定义出来以后，并不是直接使用的，仅仅给了开发者一个说明书，但是并没有实际使用，这个一定要确认清楚 ​ 那SpringBoot又是如何做到这一点的呢？可以查阅SpringBoot的配置源码，看到这些定义 项目中的pom.xml中继承了一个坐标 &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.5.4&lt;/version&gt; &lt;/parent&gt; 打开后可以查阅到其中又继承了一个坐标 &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.5.4&lt;/version&gt; &lt;/parent&gt; 这个坐标中定义了两组信息，第一组是各式各样的依赖版本号属性，下面列出依赖版本属性的局部，可以看的出来，定义了若干个技术的依赖版本号 &lt;properties&gt; &lt;activemq.version&gt;5.16.3&lt;/activemq.version&gt; &lt;aspectj.version&gt;1.9.7&lt;/aspectj.version&gt; &lt;assertj.version&gt;3.19.0&lt;/assertj.version&gt; &lt;commons-codec.version&gt;1.15&lt;/commons-codec.version&gt; &lt;commons-dbcp2.version&gt;2.8.0&lt;/commons-dbcp2.version&gt; &lt;commons-lang3.version&gt;3.12.0&lt;/commons-lang3.version&gt; &lt;commons-pool.version&gt;1.6&lt;/commons-pool.version&gt; &lt;commons-pool2.version&gt;2.9.0&lt;/commons-pool2.version&gt; &lt;h2.version&gt;1.4.200&lt;/h2.version&gt; &lt;hibernate.version&gt;5.4.32.Final&lt;/hibernate.version&gt; &lt;hibernate-validator.version&gt;6.2.0.Final&lt;/hibernate-validator.version&gt; &lt;httpclient.version&gt;4.5.13&lt;/httpclient.version&gt; &lt;jackson-bom.version&gt;2.12.4&lt;/jackson-bom.version&gt; &lt;javax-jms.version&gt;2.0.1&lt;/javax-jms.version&gt; &lt;javax-json.version&gt;1.1.4&lt;/javax-json.version&gt; &lt;javax-websocket.version&gt;1.1&lt;/javax-websocket.version&gt; &lt;jetty-el.version&gt;9.0.48&lt;/jetty-el.version&gt; &lt;junit.version&gt;4.13.2&lt;/junit.version&gt; &lt;/properties&gt; ​ 第二组是各式各样的的依赖坐标信息，可以看出依赖坐标定义中没有具体的依赖版本号，而是引用了第一组信息中定义的依赖版本属性值 &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-core&lt;/artifactId&gt; &lt;version&gt;${hibernate.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;${junit.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 关注：上面的依赖坐标定义是出现在标签中的，其实是对引用坐标的依赖管理，并不是实际使用的坐标。因此当你的项目中继承了这组parent信息后，在不使用对应坐标的情况下，前面的这组定义是不会具体导入某个依赖的 关注：因为在maven中继承机会只有一次，上述继承的格式还可以切换成导入的形式进行，并且在阿里云的starter创建工程时就使用了此种形式 &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-boot.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 总结 开发SpringBoot程序要继承spring-boot-starter-parent spring-boot-starter-parent中定义了若干个依赖管理 继承parent模块可以避免多个依赖使用相同技术时出现依赖版本冲突 继承parent的形式也可以采用引入依赖的形式实现效果 思考 ​ parent中定义了若干个依赖版本管理，但是也没有使用，那这个设定也就不生效啊，究竟谁在使用这些定义呢？ starter​ SpringBoot关注到开发者在实际开发时，对于依赖坐标的使用往往都有一些固定的组合方式，比如使用spring-webmvc就一定要使用spring-web。每次都要固定搭配着写，非常繁琐，而且格式固定，没有任何技术含量。 ​ SpringBoot一看这种情况，看来需要给开发者带来一些帮助了。安排，把所有的技术使用的固定搭配格式都给开发出来，以后你用某个技术，就不用一次写一堆依赖了，还容易写错，我给你做一个东西，代表一堆东西，开发者使用的时候，直接用我做好的这个东西就好了，对于这样的固定技术搭配，SpringBoot给它起了个名字叫做starter。 ​ starter定义了使用某种技术时对于依赖的固定搭配格式，也是一种最佳解决方案，使用starter可以帮助开发者减少依赖配置 ​ 这个东西其实在入门案例里面已经使用过了，入门案例中的web功能就是使用这种方式添加依赖的。可以查阅SpringBoot的配置源码，看到这些定义 项目中的pom.xml定义了使用SpringMVC技术，但是并没有写SpringMVC的坐标，而是添加了一个名字中包含starter的依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; 在spring-boot-starter-web中又定义了若干个具体依赖的坐标 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.5.4&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-json&lt;/artifactId&gt; &lt;version&gt;2.5.4&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;version&gt;2.5.4&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;5.3.9&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.3.9&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; ​ 之前提到过开发SpringMVC程序需要导入spring-webmvc的坐标和spring整合web开发的坐标，就是上面这组坐标中的最后两个了。 ​ 但是我们发现除了这两个还有其他的，比如第二个，叫做spring-boot-starter-json。看名称就知道，这个是与json有关的坐标了，但是看名字发现和最后两个又不太一样，它的名字中也有starter，打开看看里面有什么？ &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.5.4&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;5.3.9&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.12.4&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.datatype&lt;/groupId&gt; &lt;artifactId&gt;jackson-datatype-jdk8&lt;/artifactId&gt; &lt;version&gt;2.12.4&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.datatype&lt;/groupId&gt; &lt;artifactId&gt;jackson-datatype-jsr310&lt;/artifactId&gt; &lt;version&gt;2.12.4&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.module&lt;/groupId&gt; &lt;artifactId&gt;jackson-module-parameter-names&lt;/artifactId&gt; &lt;version&gt;2.12.4&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; ​ 我们可以发现，这个starter中又包含了若干个坐标，其实就是使用SpringMVC开发通常都会使用到Json，使用json又离不开这里面定义的这些坐标，看来还真是方便，SpringBoot把我们开发中使用的东西能用到的都给提前做好了。你仔细看完会发现，里面有一些你没用过的。的确会出现这种过量导入的可能性，没关系，可以通过maven中的排除依赖剔除掉一部分。不过你不管它也没事，大不了就是过量导入呗。 ​ 到这里基本上得到了一个信息，使用starter可以帮开发者快速配置依赖关系。以前写依赖3个坐标的，现在写导入一个就搞定了，就是加速依赖配置的。 starter与parent的区别 ​ 朦朦胧胧中感觉starter与parent好像都是帮助我们简化配置的，但是功能又不一样，梳理一下。 ​ starter是一个坐标中定了若干个坐标，以前写多个的，现在写一个，是用来减少依赖配置的书写量的 ​ parent是定义了几百个依赖版本号，以前写依赖需要自己手工控制版本，现在由SpringBoot统一管理，这样就不存在版本冲突了，是用来减少依赖冲突的 实际开发应用方式 实际开发中如果需要用什么技术，先去找有没有这个技术对应的starter 如果有对应的starter，直接写starter，而且无需指定版本，版本由parent提供 如果没有对应的starter，手写坐标即可 实际开发中如果发现坐标出现了冲突现象，确认你要使用的可行的版本号，使用手工书写的方式添加对应依赖，覆盖SpringBoot提供给我们的配置管理 方式一：直接写坐标 方式二：覆盖中定义的版本号，就是下面这堆东西了，哪个冲突了覆盖哪个就OK了 &lt;properties&gt; &lt;activemq.version&gt;5.16.3&lt;/activemq.version&gt; &lt;aspectj.version&gt;1.9.7&lt;/aspectj.version&gt; &lt;assertj.version&gt;3.19.0&lt;/assertj.version&gt; &lt;commons-codec.version&gt;1.15&lt;/commons-codec.version&gt; &lt;commons-dbcp2.version&gt;2.8.0&lt;/commons-dbcp2.version&gt; &lt;commons-lang3.version&gt;3.12.0&lt;/commons-lang3.version&gt; &lt;commons-pool.version&gt;1.6&lt;/commons-pool.version&gt; &lt;commons-pool2.version&gt;2.9.0&lt;/commons-pool2.version&gt; &lt;h2.version&gt;1.4.200&lt;/h2.version&gt; &lt;hibernate.version&gt;5.4.32.Final&lt;/hibernate.version&gt; &lt;hibernate-validator.version&gt;6.2.0.Final&lt;/hibernate-validator.version&gt; &lt;httpclient.version&gt;4.5.13&lt;/httpclient.version&gt; &lt;jackson-bom.version&gt;2.12.4&lt;/jackson-bom.version&gt; &lt;javax-jms.version&gt;2.0.1&lt;/javax-jms.version&gt; &lt;javax-json.version&gt;1.1.4&lt;/javax-json.version&gt; &lt;javax-websocket.version&gt;1.1&lt;/javax-websocket.version&gt; &lt;jetty-el.version&gt;9.0.48&lt;/jetty-el.version&gt; &lt;junit.version&gt;4.13.2&lt;/junit.version&gt; &lt;/properties&gt; 温馨提示 ​ SpringBoot官方给出了好多个starter的定义，方便我们使用，而且名称都是如下格式 命名规则：spring-boot-starter-技术名称 ​ 所以以后见了spring-boot-starter-aaa这样的名字，这就是SpringBoot官方给出的starter定义。那非官方定义的也有吗？有的，具体命名方式到整合章节再说 总结 开发SpringBoot程序需要导入坐标时通常导入对应的starter 每个不同的starter根据功能不同，通常包含多个依赖坐标 使用starter可以实现快速配置的效果，达到简化配置的目的 引导类​ 配置说完了，我们发现SpringBoot确实帮助我们减少了很多配置工作，下面说一下程序是如何运行的。目前程序运行的入口就是SpringBoot工程创建时自带的那个类了，带有main方法的那个类，运行这个类就可以启动SpringBoot工程的运行 @SpringBootApplication public class Springboot0101QuickstartApplication { public static void main(String[] args) { SpringApplication.run(Springboot0101QuickstartApplication.class, args); } } ​ SpringBoot本身是为了加速Spring程序的开发的，而Spring程序运行的基础是需要创建自己的Spring容器对象（IoC容器）并将所有的对象交给Spring的容器管理，也就是一个一个的Bean。那还了SpringBoot加速开发Spring程序，这个容器还在吗？这个疑问不用说，一定在。当前这个类运行后就会产生一个Spring容器对象，并且可以将这个对象保存起来，通过容器对象直接操作Bean。 @SpringBootApplication public class Springboot0101QuickstartApplication { public static void main(String[] args) { ConfigurableApplicationContext ctx = SpringApplication.run(Springboot0101QuickstartApplication.class, args); BookController bean = ctx.getBean(BookController.class); System.out.println(\"bean======&gt;\" + bean); } } ​ 通过上述操作不难看出，其实SpringBoot程序启动还是创建了一个Spring容器对象。这个类在SpringBoot程序中是所有功能的入口，称这个类为引导类。 ​ 作为一个引导类最典型的特征就是当前类上方声明了一个注解@SpringBootApplication 总结 SpringBoot工程提供引导类用来启动程序 SpringBoot工程启动后创建并初始化Spring容器 思考 ​ 程序现在已经运行了，通过引导类的main方法运行了起来。但是运行java程序不应该是执行完就结束了吗？但是我们现在明显是启动了一个web服务器啊，不然网页怎么能正常访问呢？这个服务器是在哪里写的呢？ 内嵌tomcat​ 当前我们做的SpringBoot入门案例勾选了Spirng-web的功能，并且导入了对应的starter。 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; ​ SpringBoot发现，既然你要做web程序，肯定离不开使用web服务器，这样吧，帮人帮到底，送佛送到西。我帮你搞一个web服务器，你要愿意用的，直接使用就好了，干脆我再多给你几种选择，你随便切换。万一你不想用我给你提供的，也行，你可以自己搞。 ​ 由于这个功能不属于程序的主体功能，可用可不用，于是乎SpringBoot将其定位成辅助功能，别小看这么一个辅助功能，它可是帮我们开发者又减少了好多的设置性工作。 ​ 下面就围绕着这个内置的web服务器，也可以说是内置的tomcat服务器来研究几个问题 这个服务器在什么位置定义的 这个服务器是怎么运行的 这个服务器如果想换怎么换？虽然这个需求很垃圾，搞得开发者会好多web服务器一样，用别人提供好的不香么？非要自己折腾 内嵌Tomcat定义位置 ​ 说到定义的位置，我们就想，如果我们不开发web程序，用的着web服务器吗？肯定用不着啊。那如果这个东西被加入到你的程序中，伴随着什么技术进来的呢？肯定是web相关的功能啊，没错，就是前面导入的web相关的starter做的这件事。 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; ​ 打开查看web的starter导入了哪些东西 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.5.4&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-json&lt;/artifactId&gt; &lt;version&gt;2.5.4&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;version&gt;2.5.4&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;5.3.9&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.3.9&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; ​ 第三个依赖就是这个tomcat对应的东西了，居然也是一个starter，再打开看看 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;jakarta.annotation&lt;/groupId&gt; &lt;artifactId&gt;jakarta.annotation-api&lt;/artifactId&gt; &lt;version&gt;1.3.5&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-core&lt;/artifactId&gt; &lt;version&gt;9.0.52&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;tomcat-annotations-api&lt;/artifactId&gt; &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-el&lt;/artifactId&gt; &lt;version&gt;9.0.52&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-websocket&lt;/artifactId&gt; &lt;version&gt;9.0.52&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;tomcat-annotations-api&lt;/artifactId&gt; &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;/dependencies&gt; ​ 这里面有一个核心的坐标，tomcat-embed-core，叫做tomcat内嵌核心。就是这个东西把tomcat功能引入到了我们的程序中。目前解决了第一个问题，找到根儿了，谁把tomcat引入到程序中的？spring-boot-starter-web中的spring-boot-starter-tomcat做的。之所以你感觉很奇妙的原因就是，这个东西是默认加入到程序中了，所以感觉很神奇，居然什么都不做，就有了web服务器对应的功能，再来说第二个问题，这个服务器是怎么运行的 内嵌Tomcat运行原理 ​ Tomcat服务器是一款软件，而且是一款使用java语言开发的软件，熟悉的小伙伴可能有印象，tomcat安装目录中保存有jar，好多个jar。 ​ 下面的问题来了，既然是使用java语言开发的，运行的时候肯定符合java程序运行的原理，java程序运行靠的是什么？对象呀，一切皆对象，万物皆对象。那tomcat运行起来呢？也是对象。 ​ 如果是对象，那Spring容器是用来管理对象的，这个对象能不能交给Spring容器管理呢？把吗去掉，是个对象都可以交给Spring容器管理，行了，这下通了。tomcat服务器运行其实是以对象的形式在Spring容器中运行的，怪不得我们没有安装这个tomcat，而且还能用。闹了白天这东西最后是以一个对象的形式存在，保存在Spring容器中悄悄运行的。具体运行的是什么呢？其实就是上前面提到的那个tomcat内嵌核心 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-core&lt;/artifactId&gt; &lt;version&gt;9.0.52&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; ​ 那既然是个对象，如果把这个对象从Spring容器中去掉是不是就没有web服务器的功能呢？是这样的，通过依赖排除可以去掉这个web服务器功能 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;/dependencies&gt; ​ 上面对web-starter做了一个操作，使用maven的排除依赖去掉了使用tomcat的starter。这下好了，容器中肯定没有这个对象了，重新启动程序可以观察到程序运行了，但是并没有像之前那样运行后会等着用户发请求，而是直接停掉了，就是这个原因了。 更换内嵌Tomcat ​ 那根据上面的操作我们思考是否可以换个服务器呢？必须的嘛。根据SpringBoot的工作机制，用什么技术，加入什么依赖就行了。SpringBoot提供了3款内置的服务器 tomcat(默认)：apache出品，粉丝多，应用面广，负载了若干较重的组件 jetty：更轻量级，负载性能远不及tomcat undertow：负载性能勉强跑赢tomcat 想用哪个，加个坐标就OK。前提是把tomcat排除掉，因为tomcat是默认加载的。 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; ​ 现在就已经成功替换了web服务器，核心思想就是用什么加入对应坐标就可以了。如果有starter，优先使用starter。 总结 内嵌Tomcat服务器是SpringBoot辅助功能之一 内嵌Tomcat工作原理是将Tomcat服务器作为对象运行，并将该对象交给Spring容器管理 变更内嵌服务器思想是去除现有服务器，添加全新的服务器 ​ 到这里第一章快速上手SpringBoot就结束了，这一章我们学习了两大块知识 使用了4种方式制作了SpringBoot的入门程序，不管是哪一种，其实内部都是一模一样的 学习了入门程序的工作流程，知道什么是parent，什么是starter，这两个东西是怎么配合工作的，以及我们的程序为什么启动起来是一个tomcat服务器等等 ​ 第一章到这里就结束了，再往下学习就要去基于会创建SpringBoot工程的基础上，研究SpringBoot工程的具体细节了。 JC-2.SpringBoot基础配置​ 入门案例做完了，下面就要研究SpringBoot的用法了。通过入门案例，各位小伙伴能够感知到一个信息，SpringBoot没有具体的功能，它在辅助加快Spring程序的开发效率。我们发现现在几乎不用做任何的配置，功能就有了，确实很好用。但是仔细想想，没有做配置意味着什么？意味着配置已经做好了，不用你自己写了。但是新的问题又来了，如果不想用已经写好的默认配置，该如何干预呢？这就是这一章咱们要研究的问题。 ​ 如果我们想修改默认的配置i，这个信息应该写在什么位置呢？目前我们接触的入门案例中一共有3个文件，第一是pom.xml文件，设置项目的依赖的，这个没什么好研究的，相关的高级内容咱们到原理篇再说，第二是引导类，这个是执行SpringBoot程序的入口，也不像是做配置的地方，其实还有一个信息，就是在resources目录下面有一个空白的文件，叫做application.properties。一看就是个配置文件，咱们这一章就来说说配置文件怎么写，能写什么，怎么干预SpringBoot的默认配置，修改成自己的配置。 ​ JC-2-1.属性配置​ SpringBoot通过配置文件application.properties就可以修改默认的配置，那咱们就先找个简单的配置下手，当前访问tomcat的默认端口是8080，好熟悉的味道，但是不便于书写，我们先改成80，通过这个操作来熟悉一下SpringBoot的配置格式是什么样的 ​ 那该如何写呢？properties格式的文件书写规范是key=value name=itheima ​ 这个格式肯定是不能颠覆的，那就尝试性的写就行了，改端口，写port。当你输入port后，神奇的事情就发生了，这玩意儿带提示，太好了 ​ 根据提示敲回车，输入80端口，搞定 server.port=80 ​ 下面就可以直接运行程序，测试效果了。 ​ 我们惊奇的发现SpringBoot这玩意儿狠啊，以前修改端口在哪里改？tomcat服务器的配置文件中改，现在呢？SpringBoot专用的配置文件中改，是不是意味着以后所有的配置都可以写在这一个文件中呢？是的，简化开发者配置的书写位置，集中管理。妙啊，妈妈再也不用担心我找不到配置文件了。 ​ 其实到这里我们应该得到如下三个信息 SpringBoot程序可以在application.properties文件中进行属性配置 application.properties文件中只要输入要配置的属性关键字就可以根据提示进行设置 SpringBoot将配置信息集中在一个文件中写，不管你是服务器的配置，还是数据库的配置，总之都写在一起，逃离一个项目十几种配置文件格式的尴尬局面 总结 SpringBoot默认配置文件是application.properties ​ 做完了端口的配置，趁热打铁，再做几个配置，目前项目启动时会显示一些日志信息，就来改一改这里面的一些设置。 关闭运行日志图表（banner) spring.main.banner-mode=off 设置运行日志的显示级别 logging.level.root=debug ​ 你会发现，现在这么搞配置太爽了，以前你做配置怎么做？不同的技术有自己专用的配置文件，文件不同格式也不统一，现在呢？不用东奔西走的找配置文件写配置了，统一格式了，这就是大秦帝国啊，统一六国。SpringBoot比大秦狠，因为未来出现的技术还没出现呢，但是现在已经确认了，配置都写这个文件里面。 ​ 我们现在配置了3个信息，但是又有新的问题了。这个配置是随便写的吗？什么都能配？有没有一个东西显示所有能配置的项呢？此外这个配置和什么东西有关呢？会不会因为我写了什么东西以后才可以写什么配置呢？比如我现在没有写数据库相关的东西，能否配置数据呢？一个一个来，先说第一个问题，都能配置什么。 ​ 打开SpringBoot的官网，找到SpringBoot官方文档，打开查看附录中的Application Properties就可以获取到对应的配置项了，网址奉上：https://docs.spring.io/spring-boot/docs/current/reference/html/application-properties.html#application-properties ​ 能写什么的问题解决了，再来说第二个问题，这个配置项和什么有关。在pom中注释掉导入的spring-boot-starter-web，然后刷新工程，你会发现配置的提示消失了。闹了半天是设定使用了什么技术才能做什么配置。也合理，不然配置的东西都没有使用对应技术，配了也是白配。 温馨提示 ​ 所有的starter中都会依赖下面这个starter，叫做spring-boot-starter。这个starter是所有的SpringBoot的starter的基础依赖，里面定义了SpringBoot相关的基础配置，关于这个starter我们到开发应用篇和原理篇中再深入讲解。 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.5.4&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; 总结 SpringBoot中导入对应starter后，提供对应配置属性 书写SpringBoot配置采用关键字+提示形式书写 JC-2-2.配置文件分类​ 现在已经能够进行SpringBoot相关的配置了，但是properties格式的配置写起来总是觉得看着不舒服，所以就期望存在一种书写起来更简便的配置格式提供给开发者使用。有吗？还真有，SpringBoot除了支持properties格式的配置文件，还支持另外两种格式的配置文件。分别如下: properties格式 yml格式 yaml格式 一看到全新的文件格式，各位小伙伴肯定想，这下又要学习新的语法格式了。怎么说呢？从知识角度来说，要学，从开发角度来说，不用学。为什么呢？因为SpringBoot的配置在Idea工具下有提示啊，跟着提示走就行了。下面列举三种不同文件格式配置相同的属性范例，先了解一下 application.properties（properties格式） server.port=80 application.yml（yml格式） server: port: 81 application.yaml（yaml格式） server: port: 82 ​ 仔细看会发现yml格式和yaml格式除了文件名后缀不一样，格式完全一样，是这样的，yml和yaml文件格式就是一模一样的，只是文件后缀不同，所以可以合并成一种格式来看。那对于这三种格式来说，以后用哪一种比较多呢？记清楚，以后基本上都是用yml格式的，本课程后面的所有知识都是基于yml格式来制作的，以后在企业开发过程中用这个格式的机会也最多，一定要重点掌握。 总结 SpringBoot提供了3种配置文件的格式 properties（传统格式/默认格式） yml（主流格式） yaml 思考 ​ 现在我们已经知道使用三种格式都可以做配置了，好奇宝宝们就有新的灵魂拷问了，万一我三个都写了，他们三个谁说了算呢？打一架吗？ 配置文件优先级​ 其实三个文件如果共存的话，谁生效说的就是配置文件加载的优先级别。先说一点，虽然以后这种情况很少出现，但是这个知识还是可以学习一下的。我们就让三个配置文件书写同样的信息，比如都配置端口，然后我们让每个文件配置的端口号都不一样，最后启动程序后看启动端口是多少就知道谁的加载优先级比较高了。 application.properties（properties格式） server.port=80 application.yml（yml格式） server: port: 81 application.yaml（yaml格式） server: port: 82 ​ 启动后发现目前的启动端口为80，把80对应的文件删除掉，然后再启动，现在端口又改成了81。现在我们就已经知道了3个文件的加载优先顺序是什么 application.properties &gt; application.yml &gt; application.yaml ​ 虽然得到了一个知识结论，但是我们实际开发的时候还是要看最终的效果为准。也就是你要的最终效果是什么自己是明确的，上述结论只能帮助你分析结论产生的原因。这个知识了解一下就行了，因为以后同时写多种配置文件格式的情况实在是较少。 ​ 最后我们把配置文件内容给修改一下 application.properties（properties格式） server.port=80 spring.main.banner-mode=off application.yml（yml格式） server: port: 81 logging: level: root: debug application.yaml（yaml格式） server: port: 82 ​ 我们发现不仅端口生效了，最终显示80，同时其他两条配置也生效了，看来每个配置文件中的项都会生效，只不过如果多个配置文件中有相同类型的配置会优先级高的文件覆盖优先级的文件中的配置。如果配置项不同的话，那所有的配置项都会生效。 总结 配置文件间的加载优先级 properties（最高）&gt; yml &gt; yaml（最低） 不同配置文件中相同配置按照加载优先级相互覆盖，不同配置文件中不同配置全部保留 教你一招：自动提示功能消失解决方案​ 可能有些小伙伴会基于各种各样的原因导致配置文件中没有提示，这个确实很让人头疼，所以下面给大家说一下如果自动提示功能消失了怎么解决。 ​ 先要明确一个核心，就是自动提示功能不是SpringBoot技术给我们提供的，是我们在Idea工具下编程，这个编程工具给我们提供的。明白了这一点后，再来说为什么会出现这种现象。其实这个自动提示功能消失的原因还是蛮多的，如果想解决这个问题，就要知道为什么会消失，大体原因有如下3种： Idea认为你现在写配置的文件不是个配置文件，所以拒绝给你提供提示功能 Idea认定你是合理的配置文件，但是Idea加载不到对应的提示信息 这里我们主要解决第一个现象，第二种现象到原理篇再讲解。第一种现象的解决方式如下： 步骤①：打开设置，【Files】→【Project Structure…】 步骤②：在弹出窗口中左侧选择【Facets】，右侧选中Spring路径下对应的模块名称，也就是你自动提示功能消失的那个模块 步骤③：点击Customize Spring Boot按钮，此时可以看到当前模块对应的配置文件是哪些了。如果没有你想要称为配置文件的文件格式，就有可能无法弹出提示 步骤④：选择添加配置文件，然后选中要作为配置文件的具体文件就OK了 ​ 到这里就做完了，其实就是Idea的一个小功能 总结 指定SpringBoot配置文件 Setting → Project Structure → Facets 选中对应项目/工程 Customize Spring Boot 选择配置文件 JC-2-3.yaml文件​ SpringBoot的配置以后主要使用yml结尾的这种文件格式，并且在书写时可以通过提示的形式加载正确的格式。但是这种文件还是有严格的书写格式要求的。下面就来说一下具体的语法格式。 ​ YAML（YAML Ain’t Markup Language），一种数据序列化格式。具有容易阅读、容易与脚本语言交互、以数据为核心，重数据轻格式的特点。常见的文件扩展名有两种： .yml格式（主流） .yaml格式 对于文件自身在书写时，具有严格的语法格式要求，具体如下： 大小写敏感 属性层级关系使用多行描述，每行结尾使用冒号结束 使用缩进表示层级关系，同层级左侧对齐，只允许使用空格（不允许使用Tab键） 属性值前面添加空格（属性名与属性值之间使用冒号+空格作为分隔） #号 表示注释 上述规则不要死记硬背，按照书写习惯慢慢适应，并且在Idea下由于具有提示功能，慢慢适应着写格式就行了。核心的一条规则要记住，数据前面要加空格与冒号隔开 ​ 下面列出常见的数据书写格式，熟悉一下 boolean: TRUE #TRUE,true,True,FALSE,false，False均可 float: 3.14 #6.8523015e+5 #支持科学计数法 int: 123 #0b1010_0111_0100_1010_1110 #支持二进制、八进制、十六进制 null: ~ #使用~表示null string: HelloWorld #字符串可以直接书写 string2: \"Hello World\" #可以使用双引号包裹特殊字符 date: 2018-02-17 #日期必须使用yyyy-MM-dd格式 datetime: 2018-02-17T15:02:31+08:00 #时间和日期之间使用T连接，最后使用+代表时区 ​ 此外，yaml格式中也可以表示数组，在属性名书写位置的下方使用减号作为数据开始符号，每行书写一个数据，减号与数据间空格分隔 subject: - Java - 前端 - 大数据 enterprise: name: itcast age: 16 subject: - Java - 前端 - 大数据 likes: [王者荣耀,刺激战场] #数组书写缩略格式 users: #对象数组格式一 - name: Tom age: 4 - name: Jerry age: 5 users: #对象数组格式二 - name: Tom age: 4 - name: Jerry age: 5 users2: [ { name:Tom , age:4 } , { name:Jerry , age:5 } ] #对象数组缩略格式 总结 yaml语法规则 大小写敏感 属性层级关系使用多行描述，每行结尾使用冒号结束 使用缩进表示层级关系，同层级左侧对齐，只允许使用空格（不允许使用Tab键） 属性值前面添加空格（属性名与属性值之间使用冒号+空格作为分隔） #号 表示注释 注意属性名冒号后面与数据之间有一个空格 字面值、对象数据格式、数组数据格式 思考 ​ 现在我们已经知道了yaml具有严格的数据格式要求，并且已经可以正确的书写yaml文件了，那这些文件书写后其实是在定义一些数据。这些数据时给谁用的呢？大部分是SpringBoot框架内部使用，但是如果我们想配置一些数据自己使用，能不能用呢？答案是可以的，那如何读取yaml文件中的数据呢？咱们下一节再说。 JC-2-4.yaml数据读取​ 对于yaml文件中的数据，其实你就可以想象成这就是一个小型的数据库，里面保存有若干数据，每个数据都有一个独立的名字，如果你想读取里面的数据，肯定是支持的，下面就介绍3种读取数据的方式 读取单一数据​ yaml中保存的单个数据，可以使用Spring中的注解直接读取，使用@Value可以读取单个数据，属性名引用方式：${一级属性名.二级属性名……} ​ 记得使用@Value注解时，要将该注入写在某一个指定的Spring管控的bean的属性名上方。现在就可以读取到对应的单一数据行了 总结 使用@Value配合SpEL读取单个数据 如果数据存在多层级，依次书写层级名称即可 读取全部数据​ 读取单一数据可以解决读取数据的问题，但是如果定义的数据量过大，这么一个一个书写肯定会累死人的，SpringBoot提供了一个对象，能够把所有的数据都封装到这一个对象中，这个对象叫做Environment，使用自动装配注解可以将所有的yaml数据封装到这个对象中 ​ 数据封装到了Environment对象中，获取属性时，通过Environment的接口操作进行，具体方法时getProperties（String），参数填写属性名即可 总结 使用Environment对象封装全部配置信息 使用@Autowired自动装配数据到Environment对象中 读取对象数据​ 单一数据读取书写比较繁琐，全数据封装又封装的太厉害了，每次拿数据还要一个一个的getProperties（）,总之用起来都不是很舒服。由于Java是一个面向对象的语言，很多情况下，我们会将一组数据封装成一个对象。SpringBoot也提供了可以将一组yaml对象数据封装一个Java对象的操作 ​ 首先定义一个对象，并将该对象纳入Spring管控的范围，也就是定义成一个bean，然后使用注解@ConfigurationProperties指定该对象加载哪一组yaml中配置的信息。 ​ 这个@ConfigurationProperties必须告诉他加载的数据前缀是什么，这样当前前缀下的所有属性就封装到这个对象中。记得数据属性名要与对象的变量名一一对应啊，不然没法封装。其实以后如果你要定义一组数据自己使用，就可以先写一个对象，然后定义好属性，下面到配置中根据这个格式书写即可。 ​ ​ 温馨提示 ​ 细心的小伙伴会发现一个问题，自定义的这种数据在yaml文件中书写时没有弹出提示，是这样的，咱们到原理篇再揭秘如何弹出提示。 总结 使用@ConfigurationProperties注解绑定配置信息到封装类中 封装类需要定义为Spring管理的bean，否则无法进行属性注入 yaml文件中的数据引用​ 如果你在书写yaml数据时，经常出现如下现象，比如很多个文件都具有相同的目录前缀 center: dataDir: /usr/local/fire/data tmpDir: /usr/local/fire/tmp logDir: /usr/local/fire/log msgDir: /usr/local/fire/msgDir 或者 center: dataDir: D:/usr/local/fire/data tmpDir: D:/usr/local/fire/tmp logDir: D:/usr/local/fire/log msgDir: D:/usr/local/fire/msgDir ​ 这个时候你可以使用引用格式来定义数据，其实就是搞了个变量名，然后引用变量了，格式如下： baseDir: /usr/local/fire center: dataDir: ${baseDir}/data tmpDir: ${baseDir}/tmp logDir: ${baseDir}/log msgDir: ${baseDir}/msgDir ​ 还有一个注意事项，在书写字符串时，如果需要使用转义字符，需要将数据字符串使用双引号包裹起来 lesson: \"Spring\\tboot\\nlesson\" 总结 在配置文件中可以使用${属性名}方式引用属性值 如果属性中出现特殊字符，可以使用双引号包裹起来作为字符解析 ​ 到这里有关yaml文件的基础使用就先告一段落，在实用篇中再继续研究更深入的内容。 JC-3.基于SpringBoot实现SSMP整合​ 重头戏来了，SpringBoot之所以好用，就是它能方便快捷的整合其他技术，这一部分咱们就来聊聊一些技术的整合方式，通过这一章的学习，大家能够感受到SpringBoot到底有多酷炫。这一章咱们学习如下技术的整合方式 整合JUnit 整合MyBatis 整合MyBatis-Plus 整合Druid 上面这些技术都整合完毕后，我们做一个小案例，也算是学有所用吧。涉及的技术比较多，综合运用一下。 JC-3-1.整合JUnit​ SpringBoot技术的定位用于简化开发，再具体点是简化Spring程序的开发。所以在整合任意技术的时候，如果你想直观感触到简化的效果，你必须先知道使用非SpringBoot技术时对应的整合是如何做的，然后再看基于SpringBoot的整合是如何做的，才能比对出来简化在了哪里。 ​ 我们先来看一下不使用SpringBoot技术时，Spring整合JUnit的制作方式 //加载spring整合junit专用的类运行器 @RunWith(SpringJUnit4ClassRunner.class) //指定对应的配置信息 @ContextConfiguration(classes = SpringConfig.class) public class AccountServiceTestCase { //注入你要测试的对象 @Autowired private AccountService accountService; @Test public void testGetById(){ //执行要测试的对象对应的方法 System.out.println(accountService.findById(2)); } } ​ 其中核心代码是前两个注解，第一个注解@RunWith是设置Spring专用于测试的类运行器，简单说就是Spring程序执行程序有自己的一套独立的运行程序的方式，不能使用JUnit提供的类运行方式了，必须指定一下，但是格式是固定的，琢磨一下，每次都指定一样的东西，这个东西写起来没有技术含量啊，第二个注解@ContextConfiguration是用来设置Spring核心配置文件或配置类的，简单说就是加载Spring的环境你要告诉Spring具体的环境配置是在哪里写的，虽然每次加载的文件都有可能不同，但是仔细想想，如果文件名是固定的，这个貌似也是一个固定格式。似然有可能是固定格式，那就有可能每次都写一样的东西，也是一个没有技术含量的内容书写 ​ SpringBoot就抓住上述两条没有技术含量的内容书写进行开发简化，能走默认值的走默认值，能不写的就不写，具体格式如下 @SpringBootTest class Springboot04JunitApplicationTests { //注入你要测试的对象 @Autowired private BookDao bookDao; @Test void contextLoads() { //执行要测试的对象对应的方法 bookDao.save(); System.out.println(\"two...\"); } } ​ 看看这次简化成什么样了，一个注解就搞定了，而且还没有参数，再体会SpringBoot整合其他技术的优势在哪里，就两个字——简化。使用一个注解@SpringBootTest替换了前面两个注解。至于内部是怎么回事？和之前一样，只不过都走默认值。 ​ 这个时候有人就问了，你加载的配置类或者配置文件是哪一个？就是我们前面启动程序使用的引导类。如果想手工指定引导类有两种方式，第一种方式使用属性的形式进行，在注解@SpringBootTest中添加classes属性指定配置类 @SpringBootTest(classes = Springboot04JunitApplication.class) class Springboot04JunitApplicationTests { //注入你要测试的对象 @Autowired private BookDao bookDao; @Test void contextLoads() { //执行要测试的对象对应的方法 bookDao.save(); System.out.println(\"two...\"); } } ​ 第二种方式回归原始配置方式，仍然使用@ContextConfiguration注解进行，效果是一样的 @SpringBootTest @ContextConfiguration(classes = Springboot04JunitApplication.class) class Springboot04JunitApplicationTests { //注入你要测试的对象 @Autowired private BookDao bookDao; @Test void contextLoads() { //执行要测试的对象对应的方法 bookDao.save(); System.out.println(\"two...\"); } } ​ 温馨提示 ​ 使用SpringBoot整合JUnit需要保障导入test对应的starter，由于初始化项目时此项是默认导入的，所以此处没有提及，其实和之前学习的内容一样，用什么技术导入对应的starter即可。 总结 导入测试对应的starter 测试类使用@SpringBootTest修饰 使用自动装配的形式添加要测试的对象 测试类如果存在于引导类所在包或子包中无需指定引导类 测试类如果不存在于引导类所在的包或子包中需要通过classes属性指定引导类 JC-3-2.整合MyBatis​ 整合完JUnit下面再来说一下整合MyBatis，这个技术是大部分公司都要使用的技术，务必掌握。如果对Spring整合MyBatis不熟悉的小伙伴好好复习一下，下面列举出原始整合的全部内容，以配置类的形式为例进行 导入坐标，MyBatis坐标不能少，Spring整合MyBatis还有自己专用的坐标，此外Spring进行数据库操作的jdbc坐标是必须的，剩下还有mysql驱动坐标，本例中使用了Druid数据源，这个倒是可以不要 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.16&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;!--1.导入mybatis与spring整合的jar包--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--导入spring操作数据库必选的包--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; Spring核心配置 @Configuration @ComponentScan(\"com.itheima\") @PropertySource(\"jdbc.properties\") public class SpringConfig { } MyBatis要交给Spring接管的bean //定义mybatis专用的配置类 @Configuration public class MyBatisConfig { // 定义创建SqlSessionFactory对应的bean @Bean public SqlSessionFactoryBean sqlSessionFactory(DataSource dataSource){ //SqlSessionFactoryBean是由mybatis-spring包提供的，专用于整合用的对象 SqlSessionFactoryBean sfb = new SqlSessionFactoryBean(); //设置数据源替代原始配置中的environments的配置 sfb.setDataSource(dataSource); //设置类型别名替代原始配置中的typeAliases的配置 sfb.setTypeAliasesPackage(\"com.itheima.domain\"); return sfb; } // 定义加载所有的映射配置 @Bean public MapperScannerConfigurer mapperScannerConfigurer(){ MapperScannerConfigurer msc = new MapperScannerConfigurer(); msc.setBasePackage(\"com.itheima.dao\"); return msc; } } 数据源对应的bean，此处使用Druid数据源 @Configuration public class JdbcConfig { @Value(\"${jdbc.driver}\") private String driver; @Value(\"${jdbc.url}\") private String url; @Value(\"${jdbc.username}\") private String userName; @Value(\"${jdbc.password}\") private String password; @Bean(\"dataSource\") public DataSource dataSource(){ DruidDataSource ds = new DruidDataSource(); ds.setDriverClassName(driver); ds.setUrl(url); ds.setUsername(userName); ds.setPassword(password); return ds; } } 数据库连接信息（properties格式） jdbc.driver=com.mysql.jdbc.Driver jdbc.url=jdbc:mysql://localhost:3306/spring_db?useSSL=false jdbc.username=root jdbc.password=root 上述格式基本上是简格式了，要写的东西还真不少。下面看看SpringBoot整合MyBaits格式 步骤①：创建模块时勾选要使用的技术，MyBatis，由于要操作数据库，还要勾选对应数据库 ​ 或者手工导入对应技术的starter，和对应数据库的坐标 &lt;dependencies&gt; &lt;!--1.导入对应的starter--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 步骤②：配置数据源相关信息，没有这个信息你连接哪个数据库都不知道 #2.配置相关信息 spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm_db username: root password: root ​ 完了，就这么多，没了。有人就很纳闷，这就结束了？对，这就结束了，SpringBoot把配置中所有可能出现的通用配置都简化了。下面就可以写一下MyBatis程序运行需要的Dao（或者Mapper）就可以运行了 实体类 public class Book { private Integer id; private String type; private String name; private String description; } 映射接口（Dao） @Mapper public interface BookDao { @Select(\"select * from tbl_book where id = #{id}\") public Book getById(Integer id); } 测试类 @SpringBootTest class Springboot05MybatisApplicationTests { @Autowired private BookDao bookDao; @Test void contextLoads() { System.out.println(bookDao.getById(1)); } } ​ 完美，开发从此变的就这么简单。再体会一下SpringBoot如何进行第三方技术整合的，是不是很优秀？具体内部的原理到原理篇再展开讲解 ​ 注意：当前使用的SpringBoot版本是2.5.4，对应的坐标设置中Mysql驱动使用的是8x版本。当SpringBoot2.4.3（不含）版本之前会出现一个小BUG，就是MySQL驱动升级到8以后要求强制配置时区，如果不设置会出问题。解决方案很简单，驱动url上面添加上对应设置就行了 #2.配置相关信息 spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=UTC username: root password: root ​ 这里设置的UTC是全球标准时间，你也可以理解为是英国时间，中国处在东八区，需要在这个基础上加上8小时，这样才能和中国地区的时间对应的，也可以修改配置不写UTC，写Asia/Shanghai也可以解决这个问题。 #2.配置相关信息 spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=Asia/Shanghai username: root password: root ​ 如果不想每次都设置这个东西，也可以去修改mysql中的配置文件mysql.ini，在mysqld项中添加default-time-zone=+8:00也可以解决这个问题。其实方式方法很多，这里就说这么多吧。 ​ 此外在运行程序时还会给出一个提示，说数据库驱动过时的警告，根据提示修改配置即可，弃用com.mysql.jdbc.Driver，换用com.mysql.cj.jdbc.Driver。前面的例子中已经更换了驱动了，在此说明一下。 Loading class `com.mysql.jdbc.Driver'. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver'. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary. 总结 整合操作需要勾选MyBatis技术，也就是导入MyBatis对应的starter 数据库连接相关信息转换成配置 数据库SQL映射需要添加@Mapper被容器识别到 MySQL 8.X驱动强制要求设置时区 修改url，添加serverTimezone设定 修改MySQL数据库配置 驱动类过时，提醒更换为com.mysql.cj.jdbc.Driver JC-3-3.整合MyBatis-Plus​ 做完了两种技术的整合了，各位小伙伴要学会总结，我们做这个整合究竟哪些是核心？总结下来就两句话 导入对应技术的starter坐标 根据对应技术的要求做配置 ​ 虽然看起来有点虚，但是确实是这个理儿，下面趁热打铁，再换一个技术，看看是不是上面这两步。 ​ 接下来在MyBatis的基础上再升级一下，整合MyBaitsPlus（简称MP），国人开发的技术，符合中国人开发习惯，谁用谁知道。来吧，一起做整合 步骤①：导入对应的starter &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.4.3&lt;/version&gt; &lt;/dependency&gt; ​ 关于这个坐标，此处要说明一点，之前我们看的starter都是spring-boot-starter-？？？，也就是说都是下面的格式 Spring-boot-start-*** ​ 而这个坐标的名字书写比较特殊，是第三方技术名称在前，boot和starter在后。此处简单提一下命名规范，后期原理篇会再详细讲解 starter所属 命名规则 示例 官方提供 spring-boot-starter-技术名称 spring-boot-starter-web spring-boot-starter-test 第三方提供 第三方技术名称-spring-boot-starter druid-spring-boot-starter 第三方提供 第三方技术名称-boot-starter（第三方技术名称过长，简化命名） mybatis-plus-boot-starter 温馨提示 ​ 有些小伙伴在创建项目时想通过勾选的形式找到这个名字，别翻了，没有。截止目前，SpringBoot官网还未收录此坐标，而我们Idea创建模块时读取的是SpringBoot官网的Spring Initializr，所以也没有。如果换用阿里云的url创建项目可以找到对应的坐标 步骤②：配置数据源相关信息 #2.配置相关信息 spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm_db username: root password: root ​ 没了，就这么多，剩下的就是写MyBaitsPlus的程序了 映射接口（Dao） @Mapper public interface BookDao extends BaseMapper&lt;Book&gt; { } ​ 核心在于Dao接口继承了一个BaseMapper的接口，这个接口中帮助开发者预定了若干个常用的API接口，简化了通用API接口的开发工作。 ​ 下面就可以写一个测试类进行测试了，此处省略。 温馨提示 ​ 目前数据库的表名定义规则是tbl_模块名称，为了能和实体类相对应，需要做一个配置，相关知识各位小伙伴可以到MyBatisPlus课程中去学习，此处仅给出解决方案。配置application.yml文件，添加如下配置即可，设置所有表名的通用前缀名 mybatis-plus: global-config: db-config: table-prefix: tbl_ #设置所有表的通用前缀名称为tbl_ 总结 手工添加MyBatis-Plus对应的starter 数据层接口使用BaseMapper简化开发 需要使用的第三方技术无法通过勾选确定时，需要手工添加坐标 JC-3-4.整合Druid​ 使用SpringBoot整合了3个技术了，发现套路基本相同，导入对应的starter，然后做配置，各位小伙伴需要一直强化这套思想。下面再整合一个技术，继续深入强化此思想。 ​ 前面整合MyBatis和MP的时候，使用的数据源对象都是SpringBoot默认的数据源对象，下面我们手工控制一下，自己指定了一个数据源对象，Druid。 ​ 在没有指定数据源时，我们的配置如下： #2.配置相关信息 spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=Asia/Shanghai username: root password: root ​ 此时虽然没有指定数据源，但是根据SpringBoot的德行，肯定帮我们选了一个它认为最好的数据源对象，这就是HiKari。通过启动日志可以查看到对应的身影。 2021-11-29 09:39:15.202 INFO 12260 --- [ main] com.zaxxer.hikari.HikariDataSource : HikariPool-1 - Starting... 2021-11-29 09:39:15.208 WARN 12260 --- [ main] com.zaxxer.hikari.util.DriverDataSource : Registered driver with driverClassName=com.mysql.jdbc.Driver was not found, trying direct instantiation. 2021-11-29 09:39:15.551 INFO 12260 --- [ main] com.zaxxer.hikari.HikariDataSource : HikariPool-1 - Start completed. ​ 上述信息中每一行都有HiKari的身影，如果需要更换数据源，其实只需要两步即可。 导入对应的技术坐标 配置使用指定的数据源类型 ​ 下面就切换一下数据源对象 步骤①：导入对应的坐标（注意，是坐标，此处不是starter） &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.16&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 步骤②：修改配置，在数据源配置中有一个type属性，专用于指定数据源类型 spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=UTC username: root password: root type: com.alibaba.druid.pool.DruidDataSource ​ 这里其实要提出一个问题的，目前的数据源配置格式是一个通用格式，不管你换什么数据源都可以用这种形式进行配置。但是新的问题又来了，如果对数据源进行个性化的配置，例如配置数据源对应的连接数量，这个时候就有新的问题了。每个数据源技术对应的配置名称都一样吗？肯定不是啊，各个厂商不可能提前商量好都写一样的名字啊，怎么办？就要使用专用的配置格式了。这个时候上面这种通用格式就不能使用了，怎么办？还能怎么办？按照SpringBoot整合其他技术的通用规则来套啊，导入对应的starter，进行相应的配置即可。 步骤①：导入对应的starter &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.6&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 步骤②：修改配置 spring: datasource: druid: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=UTC username: root password: root ​ 注意观察，配置项中，在datasource下面并不是直接配置url这些属性的，而是先配置了一个druid节点，然后再配置的url这些东西。言外之意，url这个属性时druid下面的属性，那你能想到吗？除了这4个常规配置外，还有druid专用的其他配置。通过提示功能可以打开druid相关的配置查阅 ​ 与druid相关的配置超过200条以上，这就告诉你，如果想做druid相关的配置，使用这种格式就可以了，这里就不展开描述了，太多了。 ​ 这是我们做的第4个技术的整合方案，还是那两句话：导入对应starter，使用对应配置。没了，SpringBoot整合其他技术就这么简单粗暴。 总结 整合Druid需要导入Druid对应的starter 根据Druid提供的配置方式进行配置 整合第三方技术通用方式 导入对应的starter 根据提供的配置格式，配置非默认值对应的配置项 JC-3-5.SSMP整合综合案例​ SpringBoot能够整合的技术太多太多了，对于初学者来说慢慢来，一点点掌握。前面咱们做了4个整合了，下面就通过一个稍微综合一点的案例，将所有知识贯穿起来，同时做一个小功能，体会一下。不过有言在先，这个案例制作的时候，你可能会有这种感觉，说好的SpringBoot整合其他技术的案例，为什么感觉SpringBoot整合其他技术的身影不多呢？因为这东西书写太简单了，简单到瞬间写完，大量的时间做的不是这些整合工作。 ​ 先看一下这个案例的最终效果 主页面 添加 删除 分页 条件查询 ​ 整体案例中需要采用的技术如下，先了解一下，做到哪一个说哪一个 实体类开发————使用Lombok快速制作实体类 Dao开发————整合MyBatisPlus，制作数据层测试 Service开发————基于MyBatisPlus进行增量开发，制作业务层测试类 Controller开发————基于Restful开发，使用PostMan测试接口功能 Controller开发————前后端开发协议制作 页面开发————基于VUE+ElementUI制作，前后端联调，页面数据处理，页面消息处理 列表 新增 修改 删除 分页 查询 项目异常处理 按条件查询————页面功能调整、Controller修正功能、Service修正功能 ​ 可以看的出来，东西还是很多的，希望通过这个案例，各位小伙伴能够完成基础开发的技能训练。整体开发过程采用做一层测一层的形式进行，过程完整，战线较长，希望各位能跟进进度，完成这个小案例的制作。 0.模块创建​ 对于这个案例如果按照企业开发的形式进行应该制作后台微服务，前后端分离的开发。 我知道这个对初学的小伙伴要求太高了，咱们简化一下。后台做单体服务器，前端不使用前后端分离的制作了。 一个服务器即充当后台服务调用，又负责前端页面展示，降低学习的门槛。 下面我们就可以创建一个新的模块，加载要使用的技术对应的starter，修改配置文件格式为yml格式，并把web访问端口先设置成80。 pom.xml &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; application.yml server: port: 80 1.实体类开发​ 本案例对应的模块表结构如下： -- ---------------------------- -- Table structure for tbl_book -- ---------------------------- DROP TABLE IF EXISTS `tbl_book`; CREATE TABLE `tbl_book` ( `id` int(11) NOT NULL AUTO_INCREMENT, `type` varchar(20) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `name` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `description` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, PRIMARY KEY (`id`) USING BTREE ) ENGINE = InnoDB AUTO_INCREMENT = 51 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic; -- ---------------------------- -- Records of tbl_book -- ---------------------------- INSERT INTO `tbl_book` VALUES (1, '计算机理论', 'Spring实战 第5版', 'Spring入门经典教程，深入理解Spring原理技术内幕'); INSERT INTO `tbl_book` VALUES (2, '计算机理论', 'Spring 5核心原理与30个类手写实战', '十年沉淀之作，手写Spring精华思想'); INSERT INTO `tbl_book` VALUES (3, '计算机理论', 'Spring 5 设计模式', '深入Spring源码剖析Spring源码中蕴含的10大设计模式'); INSERT INTO `tbl_book` VALUES (4, '计算机理论', 'Spring MVC+MyBatis开发从入门到项目实战', '全方位解析面向Web应用的轻量级框架，带你成为Spring MVC开发高手'); INSERT INTO `tbl_book` VALUES (5, '计算机理论', '轻量级Java Web企业应用实战', '源码级剖析Spring框架，适合已掌握Java基础的读者'); INSERT INTO `tbl_book` VALUES (6, '计算机理论', 'Java核心技术 卷I 基础知识（原书第11版）', 'Core Java 第11版，Jolt大奖获奖作品，针对Java SE9、10、11全面更新'); INSERT INTO `tbl_book` VALUES (7, '计算机理论', '深入理解Java虚拟机', '5个维度全面剖析JVM，大厂面试知识点全覆盖'); INSERT INTO `tbl_book` VALUES (8, '计算机理论', 'Java编程思想（第4版）', 'Java学习必读经典,殿堂级著作！赢得了全球程序员的广泛赞誉'); INSERT INTO `tbl_book` VALUES (9, '计算机理论', '零基础学Java（全彩版）', '零基础自学编程的入门图书，由浅入深，详解Java语言的编程思想和核心技术'); INSERT INTO `tbl_book` VALUES (10, '市场营销', '直播就该这么做：主播高效沟通实战指南', '李子柒、李佳琦、薇娅成长为网红的秘密都在书中'); INSERT INTO `tbl_book` VALUES (11, '市场营销', '直播销讲实战一本通', '和秋叶一起学系列网络营销书籍'); INSERT INTO `tbl_book` VALUES (12, '市场营销', '直播带货：淘宝、天猫直播从新手到高手', '一本教你如何玩转直播的书，10堂课轻松实现带货月入3W+'); ​ 根据上述表结构，制作对应的实体类 实体类 public class Book { private Integer id; private String type; private String name; private String description; } ​ 实体类的开发可以自动通过工具手工生成get/set方法，然后覆盖toString()方法，方便调试，等等。不过这一套操作书写很繁琐，有对应的工具可以帮助我们简化开发，介绍一个小工具，lombok。 ​ Lombok，一个Java类库，提供了一组注解，简化POJO实体类开发，SpringBoot目前默认集成了lombok技术，并提供了对应的版本控制，所以只需要提供对应的坐标即可，在pom.xml中添加lombok的坐标。 &lt;dependencies&gt; &lt;!--lombok--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; ​ 使用lombok可以通过一个注解@Data完成一个实体类对应的getter，setter，toString，equals，hashCode等操作的快速添加 import lombok.Data; @Data public class Book { private Integer id; private String type; private String name; private String description; } ​ 到这里实体类就做好了，是不是比不使用lombok简化好多，这种工具在Java开发中还有N多，后面课程中遇到了能用的东西时，在不增加各位小伙伴大量的学习时间的情况下，尽量多给大家介绍一些 总结 实体类制作 使用lombok简化开发 导入lombok无需指定版本，由SpringBoot提供版本 @Data注解 2.数据层开发——基础CRUD​ 数据层开发本次使用MyBatisPlus技术，数据源使用前面学习的Druid，学都学了都用上 步骤①：导入MyBatisPlus与Druid对应的starter，当然mysql的驱动不能少 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.4.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 步骤②：配置数据库连接相关的数据源配置 server: port: 80 spring: datasource: druid: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=UTC username: root password: root 步骤③：使用MP的标准通用接口BaseMapper加速开发，别忘了@Mapper和泛型的指定 @Mapper public interface BookDao extends BaseMapper&lt;Book&gt; { } 步骤④：制作测试类测试结果，这个测试类制作是个好习惯，不过在企业开发中往往都为加速开发跳过此步，且行且珍惜吧 package com.itheima.dao; import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper; import com.baomidou.mybatisplus.core.conditions.query.QueryWrapper; import com.baomidou.mybatisplus.core.metadata.IPage; import com.baomidou.mybatisplus.extension.plugins.pagination.Page; import com.itheima.domain.Book; import org.junit.jupiter.api.Test; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; @SpringBootTest public class BookDaoTestCase { @Autowired private BookDao bookDao; @Test void testGetById(){ System.out.println(bookDao.selectById(1)); } @Test void testSave(){ Book book = new Book(); book.setType(\"测试数据123\"); book.setName(\"测试数据123\"); book.setDescription(\"测试数据123\"); bookDao.insert(book); } @Test void testUpdate(){ Book book = new Book(); book.setId(17); book.setType(\"测试数据abcdefg\"); book.setName(\"测试数据123\"); book.setDescription(\"测试数据123\"); bookDao.updateById(book); } @Test void testDelete(){ bookDao.deleteById(16); } @Test void testGetAll(){ bookDao.selectList(null); } } 温馨提示 ​ MP技术默认的主键生成策略为雪花算法，生成的主键ID长度较大，和目前的数据库设定规则不相符，需要配置一下使MP使用数据库的主键生成策略，方式嘛还是老一套，做配置。在application.yml中添加对应配置即可，具体如下 server: port: 80 spring: datasource: druid: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=UTC username: root password: root mybatis-plus: global-config: db-config: table-prefix: tbl_ #设置表名通用前缀 id-type: auto #设置主键id字段的生成策略为参照数据库设定的策略，当前数据库设置id生成策略为自增 查看MP运行日志​ 在进行数据层测试的时候，因为基础的CRUD操作均由MP给我们提供了，所以就出现了一个局面，开发者不需要书写SQL语句了，这样程序运行的时候总有一种感觉，一切的一切都是黑盒的，作为开发者我们啥也不知道就完了。如果程序正常运行还好，如果报错了，这个时候就很崩溃，你甚至都不知道从何下手，因为传递参数、封装SQL语句这些操作完全不是你干预开发出来的，所以查看执行期运行的SQL语句就成为当务之急。 ​ SpringBoot整合MP的时候充分考虑到了这点，通过配置的形式就可以查阅执行期SQL语句，配置如下 mybatis-plus: global-config: db-config: table-prefix: tbl_ id-type: auto configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl ​ 再来看运行结果，此时就显示了运行期执行SQL的情况。 Creating a new SqlSession SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@2c9a6717] was not registered for synchronization because synchronization is not active JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@6ca30b8a] will not be managed by Spring ==&gt; Preparing: SELECT id,type,name,description FROM tbl_book ==&gt; Parameters: &lt;== Columns: id, type, name, description &lt;== Row: 1, 计算机理论, Spring实战 第5版, Spring入门经典教程，深入理解Spring原理技术内幕 &lt;== Row: 2, 计算机理论, Spring 5核心原理与30个类手写实战, 十年沉淀之作，手写Spring精华思想 &lt;== Row: 3, 计算机理论, Spring 5 设计模式, 深入Spring源码剖析Spring源码中蕴含的10大设计模式 &lt;== Row: 4, 计算机理论, Spring MVC+MyBatis开发从入门到项目实战, 全方位解析面向Web应用的轻量级框架，带你成为Spring MVC开发高手 &lt;== Row: 5, 计算机理论, 轻量级Java Web企业应用实战, 源码级剖析Spring框架，适合已掌握Java基础的读者 &lt;== Row: 6, 计算机理论, Java核心技术 卷I 基础知识（原书第11版）, Core Java 第11版，Jolt大奖获奖作品，针对Java SE9、10、11全面更新 &lt;== Row: 7, 计算机理论, 深入理解Java虚拟机, 5个维度全面剖析JVM，大厂面试知识点全覆盖 &lt;== Row: 8, 计算机理论, Java编程思想（第4版）, Java学习必读经典,殿堂级著作！赢得了全球程序员的广泛赞誉 &lt;== Row: 9, 计算机理论, 零基础学Java（全彩版）, 零基础自学编程的入门图书，由浅入深，详解Java语言的编程思想和核心技术 &lt;== Row: 10, 市场营销, 直播就该这么做：主播高效沟通实战指南, 李子柒、李佳琦、薇娅成长为网红的秘密都在书中 &lt;== Row: 11, 市场营销, 直播销讲实战一本通, 和秋叶一起学系列网络营销书籍 &lt;== Row: 12, 市场营销, 直播带货：淘宝、天猫直播从新手到高手, 一本教你如何玩转直播的书，10堂课轻松实现带货月入3W+ &lt;== Row: 13, 测试类型, 测试数据, 测试描述数据 &lt;== Row: 14, 测试数据update, 测试数据update, 测试数据update &lt;== Row: 15, -----------------, 测试数据123, 测试数据123 &lt;== Total: 15 ​ 其中清晰的标注了当前执行的SQL语句是什么，携带了什么参数，对应的执行结果是什么，所有信息应有尽有。 ​ 此处设置的是日志的显示形式，当前配置的是控制台输出，当然还可以由更多的选择，根据需求切换即可 总结 手工导入starter坐标（2个），mysql驱动（1个） 配置数据源与MyBatisPlus对应的配置 开发Dao接口（继承BaseMapper） 制作测试类测试Dao功能是否有效 使用配置方式开启日志，设置日志输出方式为标准输出即可查阅SQL执行日志 3.数据层开发——分页功能制作​ 前面仅仅是使用了MP提供的基础CRUD功能，实际上MP给我们提供了几乎所有的基础操作，这一节说一下如果实现数据库端的分页操作 ​ MP提供的分页操作API如下 @Test void testGetPage(){ IPage page = new Page(2,5); bookDao.selectPage(page, null); System.out.println(page.getCurrent()); System.out.println(page.getSize()); System.out.println(page.getTotal()); System.out.println(page.getPages()); System.out.println(page.getRecords()); } ​ 其中selectPage方法需要传入一个封装分页数据的对象，可以通过new的形式创建这个对象，当然这个对象也是MP提供的，别选错包了。创建此对象时就需要指定分页的两个基本数据 当前显示第几页 每页显示几条数据 ​ 可以通过创建Page对象时利用构造方法初始化这两个数据 IPage page = new Page(2,5); ​ 将该对象传入到查询方法selectPage后，可以得到查询结果，但是我们会发现当前操作查询结果返回值仍然是一个IPage对象，这又是怎么回事？ IPage page = bookDao.selectPage(page, null); ​ 原来这个IPage对象中封装了若干个数据，而查询的结果作为IPage对象封装的一个数据存在的，可以理解为查询结果得到后，又塞到了这个IPage对象中，其实还是为了高度的封装，一个IPage描述了分页所有的信息。下面5个操作就是IPage对象中封装的所有信息了 @Test void testGetPage(){ IPage page = new Page(2,5); bookDao.selectPage(page, null); System.out.println(page.getCurrent()); //当前页码值 System.out.println(page.getSize()); //每页显示数 System.out.println(page.getTotal()); //数据总量 System.out.println(page.getPages()); //总页数 System.out.println(page.getRecords()); //详细数据 } ​ 到这里就知道这些数据如何获取了，但是当你去执行这个操作时，你会发现并不像我们分析的这样，实际上这个分页当前是无效的。为什么这样呢？这个要源于MP的内部机制。 ​ 对于MySQL的分页操作使用limit关键字进行，而并不是所有的数据库都使用limit关键字实现的，这个时候MP为了制作的兼容性强，将分页操作设置为基础查询操作的升级版，你可以理解为IPhone6与IPhone6S-PLUS的关系。 ​ 基础操作中有查询全部的功能，而在这个基础上只需要升级一下（PLUS）就可以得到分页操作。所以MP将分页操作做成了一个开关，你用分页功能就把开关开启，不用就不需要开启这个开关。而我们现在没有开启这个开关，所以分页操作是没有的。这个开关是通过MP的拦截器的形式存在的，其中的原理这里不分析了，有兴趣的小伙伴可以学习MyBatisPlus这门课程进行详细解读。具体设置方式如下 定义MP拦截器并将其设置为Spring管控的bean @Configuration public class MPConfig { @Bean public MybatisPlusInterceptor mybatisPlusInterceptor(){ MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); interceptor.addInnerInterceptor(new PaginationInnerInterceptor()); return interceptor; } } ​ 上述代码第一行是创建MP的拦截器栈，这个时候拦截器栈中没有具体的拦截器，第二行是初始化了分页拦截器，并添加到拦截器栈中。如果后期开发其他功能，需要添加全新的拦截器，按照第二行的格式继续add进去新的拦截器就可以了。 总结 使用IPage封装分页数据 分页操作依赖MyBatisPlus分页拦截器实现功能 借助MyBatisPlus日志查阅执行SQL语句 4.数据层开发——条件查询功能制作​ 除了分页功能，MP还提供有强大的条件查询功能。以往我们写条件查询要自己动态拼写复杂的SQL语句，现在简单了，MP将这些操作都制作成API接口，调用一个又一个的方法就可以实现各种套件的拼装。这里给大家普及一下基本格式，详细的操作还是到MP的课程中查阅吧 ​ 下面的操作就是执行一个模糊匹配对应的操作，由like条件书写变为了like方法的调用 @Test void testGetBy(){ QueryWrapper&lt;Book&gt; qw = new QueryWrapper&lt;&gt;(); qw.like(\"name\",\"Spring\"); bookDao.selectList(qw); } ​ 其中第一句QueryWrapper对象是一个用于封装查询条件的对象，该对象可以动态使用API调用的方法添加条件，最终转化成对应的SQL语句。第二句就是一个条件了，需要什么条件，使用QueryWapper对象直接调用对应操作即可。比如做大于小于关系，就可以使用lt或gt方法，等于使用eq方法，等等，此处不做更多的解释了。 ​ 这组API使用还是比较简单的，但是关于属性字段名的书写存在着安全隐患，比如查询字段name，当前是以字符串的形态书写的，万一写错，编译器还没有办法发现，只能将问题抛到运行器通过异常堆栈告诉开发者，不太友好。 ​ MP针对字段检查进行了功能升级，全面支持Lambda表达式，就有了下面这组API。由QueryWrapper对象升级为LambdaQueryWrapper对象，这下就变了上述问题的出现 @Test void testGetBy2(){ String name = \"1\"; LambdaQueryWrapper&lt;Book&gt; lqw = new LambdaQueryWrapper&lt;Book&gt;(); lqw.like(Book::getName,name); bookDao.selectList(lqw); } ​ 为了便于开发者动态拼写SQL，防止将null数据作为条件使用，MP还提供了动态拼装SQL的快捷书写方式 @Test void testGetBy2(){ String name = \"1\"; LambdaQueryWrapper&lt;Book&gt; lqw = new LambdaQueryWrapper&lt;Book&gt;(); //if(name != null) lqw.like(Book::getName,name); //方式一：JAVA代码控制 lqw.like(name != null,Book::getName,name); //方式二：API接口提供控制开关 bookDao.selectList(lqw); } ​ 其实就是个格式，没有区别。关于MP的基础操作就说到这里吧，如果这一块知识不太熟悉的小伙伴还是去完整的学习一下MP的知识吧，这里只是蜻蜓点水的用了几个操作而已。 总结 使用QueryWrapper对象封装查询条件 推荐使用LambdaQueryWrapper对象 所有查询操作封装成方法调用 查询条件支持动态条件拼装 5.业务层开发​ 数据层开发告一段落，下面进行业务层开发，其实标准业务层开发很多初学者认为就是调用数据层，怎么说呢？这个理解是没有大问题的，更精准的说法应该是组织业务逻辑功能，并根据业务需求，对数据持久层发起调用。有什么差别呢？目标是为了组织出符合需求的业务逻辑功能，至于调不调用数据层还真不好说，有需求就调用，没有需求就不调用。 ​ 一个常识性的知识普及一下，业务层的方法名定义一定要与业务有关，例如登录操作 login(String username,String password); ​ 而数据层的方法名定义一定与业务无关，是一定，不是可能，也不是有可能，例如根据用户名密码查询 selectByUserNameAndPassword(String username,String password); ​ 我们在开发的时候是可以根据完成的工作不同划分成不同职能的开发团队的。比如一个哥们制作数据层，他就可以不知道业务是什么样子，拿到的需求文档要求可能是这样的 接口：传入用户名与密码字段，查询出对应结果，结果是单条数据 接口：传入ID字段，查询出对应结果，结果是单条数据 接口：传入离职字段，查询出对应结果，结果是多条数据 ​ 但是进行业务功能开发的哥们，拿到的需求文档要求差别就很大 接口：传入用户名与密码字段，对用户名字段做长度校验，4-15位，对密码字段做长度校验，8到24位，对喵喵喵字段做特殊字符校验，不允许存在空格，查询结果为对象。如果为null，返回BusinessException，封装消息码INFO_LOGON_USERNAME_PASSWORD_ERROR ​ 你比较一下，能是一回事吗？差别太大了，所以说业务层方法定义与数据层方法定义差异化很大，只不过有些入门级的开发者手懒或者没有使用过公司相关的ISO标准化文档而已。 ​ 多余的话不说了，咱们做案例就简单制作了，业务层接口定义如下： public interface BookService { Boolean save(Book book); Boolean update(Book book); Boolean delete(Integer id); Book getById(Integer id); List&lt;Book&gt; getAll(); IPage&lt;Book&gt; getPage(int currentPage,int pageSize); } ​ 业务层实现类如下，转调数据层即可 @Service public class BookServiceImpl implements BookService { @Autowired private BookDao bookDao; @Override public Boolean save(Book book) { return bookDao.insert(book) &gt; 0; } @Override public Boolean update(Book book) { return bookDao.updateById(book) &gt; 0; } @Override public Boolean delete(Integer id) { return bookDao.deleteById(id) &gt; 0; } @Override public Book getById(Integer id) { return bookDao.selectById(id); } @Override public List&lt;Book&gt; getAll() { return bookDao.selectList(null); } @Override public IPage&lt;Book&gt; getPage(int currentPage, int pageSize) { IPage page = new Page(currentPage,pageSize); bookDao.selectPage(page,null); return page; } } ​ 别忘了对业务层接口进行测试，测试类如下 @SpringBootTest public class BookServiceTest { @Autowired private IBookService bookService; @Test void testGetById(){ System.out.println(bookService.getById(4)); } @Test void testSave(){ Book book = new Book(); book.setType(\"测试数据123\"); book.setName(\"测试数据123\"); book.setDescription(\"测试数据123\"); bookService.save(book); } @Test void testUpdate(){ Book book = new Book(); book.setId(17); book.setType(\"-----------------\"); book.setName(\"测试数据123\"); book.setDescription(\"测试数据123\"); bookService.updateById(book); } @Test void testDelete(){ bookService.removeById(18); } @Test void testGetAll(){ bookService.list(); } @Test void testGetPage(){ IPage&lt;Book&gt; page = new Page&lt;Book&gt;(2,5); bookService.page(page); System.out.println(page.getCurrent()); System.out.println(page.getSize()); System.out.println(page.getTotal()); System.out.println(page.getPages()); System.out.println(page.getRecords()); } } 总结 Service接口名称定义成业务名称，并与Dao接口名称进行区分 制作测试类测试Service功能是否有效 业务层快速开发​ 其实MP技术不仅提供了数据层快速开发方案，业务层MP也给了一个通用接口，个人观点不推荐使用，凑合能用吧，其实就是一个封装+继承的思想，代码给出，实际开发慎用 ​ 业务层接口快速开发 public interface IBookService extends IService&lt;Book&gt; { //添加非通用操作API接口 } ​ 业务层接口实现类快速开发，关注继承的类需要传入两个泛型，一个是数据层接口，另一个是实体类 @Service public class BookServiceImpl extends ServiceImpl&lt;BookDao, Book&gt; implements IBookService { @Autowired private BookDao bookDao; //添加非通用操作API } ​ 如果感觉MP提供的功能不足以支撑你的使用需要，其实是一定不能支撑的，因为需求不可能是通用的，在原始接口基础上接着定义新的API接口就行了，此处不再说太多了，就是自定义自己的操作了，但是不要和已有的API接口名冲突即可。 总结 使用通用接口（ISerivce）快速开发Service 使用通用实现类（ServiceImpl&lt;M,T&gt;）快速开发ServiceImpl 可以在通用接口基础上做功能重载或功能追加 注意重载时不要覆盖原始操作，避免原始提供的功能丢失 6.表现层开发​ 终于做到表现层了，做了这么多都是基础工作。其实你现在回头看看，哪里还有什么SpringBoot的影子？前面1,2步就搞完了。继续完成表现层制作吧，咱们表现层的开发使用基于Restful的表现层接口开发，功能测试通过Postman工具进行 ​ 表现层接口如下: @RestController @RequestMapping(\"/books\") public class BookController2 { @Autowired private IBookService bookService; @GetMapping public List&lt;Book&gt; getAll(){ return bookService.list(); } @PostMapping public Boolean save(@RequestBody Book book){ return bookService.save(book); } @PutMapping public Boolean update(@RequestBody Book book){ return bookService.modify(book); } @DeleteMapping(\"{id}\") public Boolean delete(@PathVariable Integer id){ return bookService.delete(id); } @GetMapping(\"{id}\") public Book getById(@PathVariable Integer id){ return bookService.getById(id); } @GetMapping(\"{currentPage}/{pageSize}\") public IPage&lt;Book&gt; getPage(@PathVariable int currentPage,@PathVariable int pageSize){ return bookService.getPage(currentPage,pageSize, null); } } ​ 在实用Postman测试时关注提交类型，对应上即可，不然就会报405的错误码了 普通GET请求 PUT请求传递json数据，后台实用@RequestBody接收数据 总结 基于Restful制作表现层接口 新增：POST 删除：DELETE 修改：PUT 查询：GET 接收参数 实体数据：@RequestBody 路径变量：@PathVariable 7.表现层消息一致性处理​ 目前我们通过Postman测试后业务层接口功能时通的，但是这样的结果给到前端开发者会出现一个小问题。不同的操作结果所展示的数据格式差异化严重 ​ 增删改操作结果 true ​ 查询单个数据操作结果 { \"id\": 1, \"type\": \"计算机理论\", \"name\": \"Spring实战 第5版\", \"description\": \"Spring入门经典教程\" } ​ 查询全部数据操作结果 [ { \"id\": 1, \"type\": \"计算机理论\", \"name\": \"Spring实战 第5版\", \"description\": \"Spring入门经典教程\" }, { \"id\": 2, \"type\": \"计算机理论\", \"name\": \"Spring 5核心原理与30个类手写实战\", \"description\": \"十年沉淀之作\" } ] ​ 每种不同操作返回的数据格式都不一样，而且还不知道以后还会有什么格式，这样的结果让前端人员看了是很容易让人崩溃的，必须将所有操作的操作结果数据格式统一起来，需要设计表现层返回结果的模型类，用于后端与前端进行数据格式统一，也称为前后端数据协议 @Data public class R { private Boolean flag; private Object data; } ​ 其中flag用于标识操作是否成功，data用于封装操作数据，现在的数据格式就变了 { &nbsp;&nbsp;&nbsp;&nbsp;\"flag\":&nbsp;true, &nbsp;&nbsp;&nbsp;&nbsp;\"data\":{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"id\":&nbsp;1, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"type\":&nbsp;\"计算机理论\", &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"name\":&nbsp;\"Spring实战&nbsp;第5版\", &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"description\":&nbsp;\"Spring入门经典教程\" &nbsp;&nbsp;&nbsp;&nbsp;} } ​ 表现层开发格式也需要转换一下 ​ 结果这么一折腾，全格式统一，现在后端发送给前端的数据格式就统一了，免去了不少前端解析数据的麻烦。 总结 设计统一的返回值结果类型便于前端开发读取数据 返回值结果类型可以根据需求自行设定，没有固定格式 返回值结果模型类用于后端与前端进行数据格式统一，也称为前后端数据协议 8.前后端联通性测试​ 后端的表现层接口开发完毕，就可以进行前端的开发了。 ​ 将前端人员开发的页面保存到lresources目录下的static目录中，建议执行maven的clean生命周期，避免缓存的问题出现。 ​ ​ 在进行具体的功能开发之前，先做联通性的测试，通过页面发送异步提交（axios），这一步调试通过后再进行进一步的功能开发 //列表 getAll() { axios.get(\"/books\").then((res)=&gt;{ console.log(res.data); }); }, ​ 只要后台代码能够正常工作，前端能够在日志中接收到数据，就证明前后端是通的，也就可以进行下一步的功能开发了 总结 单体项目中页面放置在resources/static目录下 created钩子函数用于初始化页面时发起调用 页面使用axios发送异步请求获取数据后确认前后端是否联通 9.页面基础功能开发F-1.列表功能（非分页版）​ 列表功能主要操作就是加载完数据，将数据展示到页面上，此处要利用VUE的数据模型绑定，发送请求得到数据，然后页面上读取指定数据即可 ​ 页面数据模型定义 data:{ dataList: [],//当前页要展示的列表数据 ... }, ​ 异步请求获取数据 //列表 getAll() { axios.get(\"/books\").then((res)=&gt;{ this.dataList = res.data.data; }); }, ​ 这样在页面加载时就可以获取到数据，并且由VUE将数据展示到页面上了 总结： 将查询数据返回到页面，利用前端数据绑定进行数据展示 F-2.添加功能​ 添加功能用于收集数据的表单是通过一个弹窗展示的，因此在添加操作前首先要进行弹窗的展示，添加后隐藏弹窗即可。因为这个弹窗一直存在，因此当页面加载时首先设置这个弹窗为不可显示状态，需要展示，切换状态即可 ​ 默认状态 data:{ dialogFormVisible: false,//添加表单是否可见 ... }, ​ 切换为显示状态 //弹出添加窗口 handleCreate() { this.dialogFormVisible = true; }, ​ 由于每次添加数据都是使用同一个弹窗录入数据，所以每次操作的痕迹将在下一次操作时展示出来，需要在每次操作之前清理掉上次操作的痕迹 ​ 定义清理数据操作 //重置表单 resetForm() { this.formData = {}; }, ​ 切换弹窗状态时清理数据 //弹出添加窗口 handleCreate() { this.dialogFormVisible = true; this.resetForm(); }, ​ 至此准备工作完成，下面就要调用后台完成添加操作了 ​ 添加操作 //添加 handleAdd () { //发送异步请求 axios.post(\"/books\",this.formData).then((res)=&gt;{ //如果操作成功，关闭弹层，显示数据 if(res.data.flag){ this.dialogFormVisible = false; this.$message.success(\"添加成功\"); }else { this.$message.error(\"添加失败\"); } }).finally(()=&gt;{ this.getAll(); }); }, 将要保存的数据传递到后台，通过post请求的第二个参数传递json数据到后台 根据返回的操作结果决定下一步操作 如何是true就关闭添加窗口，显示添加成功的消息 如果是false保留添加窗口，显示添加失败的消息 无论添加是否成功，页面均进行刷新，动态加载数据（对getAll操作发起调用） ​ 取消添加操作 //取消 cancel(){ this.dialogFormVisible = false; this.$message.info(\"操作取消\"); }, 总结 请求方式使用POST调用后台对应操作 添加操作结束后动态刷新页面加载数据 根据操作结果不同，显示对应的提示信息 弹出添加Div时清除表单数据 F-3.删除功能​ 模仿添加操作制作删除功能，差别之处在于删除操作仅传递一个待删除的数据id到后台即可 ​ 删除操作 // 删除 handleDelete(row) { axios.delete(\"/books/\"+row.id).then((res)=&gt;{ if(res.data.flag){ this.$message.success(\"删除成功\"); }else{ this.$message.error(\"删除失败\"); } }).finally(()=&gt;{ this.getAll(); }); }, ​ 删除操作提示信息 // 删除 handleDelete(row) { //1.弹出提示框 this.$confirm(\"此操作永久删除当前数据，是否继续？\",\"提示\",{ type:'info' }).then(()=&gt;{ //2.做删除业务 axios.delete(\"/books/\"+row.id).then((res)=&gt;{ if(res.data.flag){ this.$message.success(\"删除成功\"); }else{ this.$message.error(\"删除失败\"); } }).finally(()=&gt;{ this.getAll(); }); }).catch(()=&gt;{ //3.取消删除 this.$message.info(\"取消删除操作\"); }); }， 总结 请求方式使用Delete调用后台对应操作 删除操作需要传递当前行数据对应的id值到后台 删除操作结束后动态刷新页面加载数据 根据操作结果不同，显示对应的提示信息 删除操作前弹出提示框避免误操作 F-4.修改功能​ 修改功能可以说是列表功能、删除功能与添加功能的合体。几个相似点如下： 页面也需要有一个弹窗用来加载修改的数据，这一点与添加相同，都是要弹窗 弹出窗口中要加载待修改的数据，而数据需要通过查询得到，这一点与查询全部相同，都是要查数据 查询操作需要将要修改的数据id发送到后台，这一点与删除相同，都是传递id到后台 查询得到数据后需要展示到弹窗中，这一点与查询全部相同，都是要通过数据模型绑定展示数据 修改数据时需要将被修改的数据传递到后台，这一点与添加相同，都是要传递数据 所以整体上来看，修改功能就是前面几个功能的大合体 查询并展示数据 //弹出编辑窗口 handleUpdate(row) { axios.get(\"/books/\"+row.id).then((res)=&gt;{ if(res.data.flag){ //展示弹层，加载数据 this.formData = res.data.data; this.dialogFormVisible4Edit = true; }else{ this.$message.error(\"数据同步失败，自动刷新\"); } }); }, ​ 修改操作 //修改 handleEdit() { axios.put(\"/books\",this.formData).then((res)=&gt;{ //如果操作成功，关闭弹层并刷新页面 if(res.data.flag){ this.dialogFormVisible4Edit = false; this.$message.success(\"修改成功\"); }else { this.$message.error(\"修改失败，请重试\"); } }).finally(()=&gt;{ this.getAll(); }); }, 总结 加载要修改数据通过传递当前行数据对应的id值到后台查询数据（同删除与查询全部） 利用前端双向数据绑定将查询到的数据进行回显（同查询全部） 请求方式使用PUT调用后台对应操作（同新增传递数据） 修改操作结束后动态刷新页面加载数据（同新增） 根据操作结果不同，显示对应的提示信息（同新增） ​ 10.业务消息一致性处理​ 目前的功能制作基本上达成了正常使用的情况，什么叫正常使用呢？也就是这个程序不出BUG，如果我们搞一个BUG出来，你会发现程序马上崩溃掉。比如后台手工抛出一个异常，看看前端接收到的数据什么样子 { \"timestamp\": \"2021-09-15T03:27:31.038+00:00\", \"status\": 500, \"error\": \"Internal Server Error\", \"path\": \"/books\" } ​ 面对这种情况，前端的同学又不会了，这又是什么格式？怎么和之前的格式不一样？ { \"flag\": true, \"data\":{ \"id\": 1, \"type\": \"计算机理论\", \"name\": \"Spring实战 第5版\", \"description\": \"Spring入门经典教程\" } } ​ 看来不仅要对正确的操作数据格式做处理，还要对错误的操作数据格式做同样的格式处理 ​ 首先在当前的数据结果中添加消息字段，用来兼容后台出现的操作消息 @Data public class R{ private Boolean flag; private Object data; private String msg; //用于封装消息 } ​ 后台代码也要根据情况做处理，当前是模拟的错误 @PostMapping public R save(@RequestBody Book book) throws IOException { Boolean flag = bookService.insert(book); return new R(flag , flag ? \"添加成功^_^\" : \"添加失败-_-!\"); } ​ 然后在表现层做统一的异常处理，使用SpringMVC提供的异常处理器做统一的异常处理 @RestControllerAdvice public class ProjectExceptionAdvice { @ExceptionHandler(Exception.class) public R doOtherException(Exception ex){ //记录日志 //发送消息给运维 //发送邮件给开发人员,ex对象发送给开发人员 ex.printStackTrace(); return new R(false,null,\"系统错误，请稍后再试！\"); } } ​ 页面上得到数据后，先判定是否有后台传递过来的消息，标志就是当前操作是否成功，如果返回操作结果false，就读取后台传递的消息 //添加 handleAdd () { //发送ajax请求 axios.post(\"/books\",this.formData).then((res)=&gt;{ //如果操作成功，关闭弹层，显示数据 if(res.data.flag){ this.dialogFormVisible = false; this.$message.success(\"添加成功\"); }else { this.$message.error(res.data.msg); //消息来自于后台传递过来，而非固定内容 } }).finally(()=&gt;{ this.getAll(); }); }, 总结 使用注解@RestControllerAdvice定义SpringMVC异常处理器用来处理异常的 异常处理器必须被扫描加载，否则无法生效 表现层返回结果的模型类中添加消息属性用来传递消息到页面 ​ 11.页面功能开发F-5.分页功能​ 分页功能的制作用于替换前面的查询全部，其中要使用到elementUI提供的分页组件 &lt;!--分页组件--&gt; &lt;div class=\"pagination-container\"&gt; &lt;el-pagination class=\"pagiantion\" @current-change=\"handleCurrentChange\" :current-page=\"pagination.currentPage\" :page-size=\"pagination.pageSize\" layout=\"total, prev, pager, next, jumper\" :total=\"pagination.total\"&gt; &lt;/el-pagination&gt; &lt;/div&gt; ​ 为了配合分页组件，封装分页对应的数据模型 data:{ pagination: { //分页相关模型数据 currentPage: 1, //当前页码 pageSize:10, //每页显示的记录数 total:0, //总记录数 } }, ​ 修改查询全部功能为分页查询，通过路径变量传递页码信息参数 getAll() { axios.get(\"/books/\"+this.pagination.currentPage+\"/\"+this.pagination.pageSize).then((res) =&gt; { }); }, ​ 后台提供对应的分页功能 @GetMapping(\"/{currentPage}/{pageSize}\") public R getAll(@PathVariable Integer currentPage,@PathVariable Integer pageSize){ IPage&lt;Book&gt; pageBook = bookService.getPage(currentPage, pageSize); return new R(null != pageBook ,pageBook); } ​ 页面根据分页操作结果读取对应数据，并进行数据模型绑定 getAll() { axios.get(\"/books/\"+this.pagination.currentPage+\"/\"+this.pagination.pageSize).then((res) =&gt; { this.pagination.total = res.data.data.total; this.pagination.currentPage = res.data.data.current; this.pagination.pagesize = res.data.data.size; this.dataList = res.data.data.records; }); }, ​ 对切换页码操作设置调用当前分页操作 //切换页码 handleCurrentChange(currentPage) { this.pagination.currentPage = currentPage; this.getAll(); }, 总结 使用el分页组件 定义分页组件绑定的数据模型 异步调用获取分页数据 分页数据页面回显 F-6.删除功能维护​ 由于使用了分页功能，当最后一页只有一条数据时，删除操作就会出现BUG，最后一页无数据但是独立展示，对分页查询功能进行后台功能维护，如果当前页码值大于最大页码值，重新执行查询。其实这个问题解决方案很多，这里给出比较简单的一种处理方案 @GetMapping(\"{currentPage}/{pageSize}\") public R getPage(@PathVariable int currentPage,@PathVariable int pageSize){ IPage&lt;Book&gt; page = bookService.getPage(currentPage, pageSize); //如果当前页码值大于了总页码值，那么重新执行查询操作，使用最大页码值作为当前页码值 if( currentPage &gt; page.getPages()){ page = bookService.getPage((int)page.getPages(), pageSize); } return new R(true, page); } F-7.条件查询功能​ 最后一个功能来做条件查询，其实条件查询可以理解为分页查询的时候除了携带分页数据再多带几个数据的查询。这些多带的数据就是查询条件。比较一下不带条件的分页查询与带条件的分页查询差别之处，这个功能就好做了 页面封装的数据：带不带条件影响的仅仅是一次性传递到后台的数据总量，由传递2个分页相关的数据转换成2个分页数据加若干个条件 后台查询功能：查询时由不带条件，转换成带条件，反正不带条件的时候查询条件对象使用的是null，现在换成具体条件，差别不大 查询结果：不管带不带条件，出来的数据只是有数量上的差别，其他都差别，这个可以忽略 经过上述分析，看来需要在页面发送请求的格式方面做一定的修改，后台的调用数据层操作时发送修改，其他没有区别 页面发送请求时，两个分页数据仍然使用路径变量，其他条件采用动态拼装url参数的形式传递 页面封装查询条件字段 pagination: { //分页相关模型数据 currentPage: 1, //当前页码 pageSize:10, //每页显示的记录数 total:0, //总记录数 name: \"\", type: \"\", description: \"\" }, 页面添加查询条件字段对应的数据模型绑定名称 &lt;div class=\"filter-container\"&gt; &lt;el-input placeholder=\"图书类别\" v-model=\"pagination.type\" class=\"filter-item\"/&gt; &lt;el-input placeholder=\"图书名称\" v-model=\"pagination.name\" class=\"filter-item\"/&gt; &lt;el-input placeholder=\"图书描述\" v-model=\"pagination.description\" class=\"filter-item\"/&gt; &lt;el-button @click=\"getAll()\" class=\"dalfBut\"&gt;查询&lt;/el-button&gt; &lt;el-button type=\"primary\" class=\"butT\" @click=\"handleCreate()\"&gt;新建&lt;/el-button&gt; &lt;/div&gt; 将查询条件组织成url参数，添加到请求url地址中，这里可以借助其他类库快速开发，当前使用手工形式拼接，降低学习要求 getAll() { //1.获取查询条件,拼接查询条件 param = \"?name=\"+this.pagination.name; param += \"&amp;type=\"+this.pagination.type; param += \"&amp;description=\"+this.pagination.description; console.log(\"-----------------\"+ param); axios.get(\"/books/\"+this.pagination.currentPage+\"/\"+this.pagination.pageSize+param).then((res) =&gt; { this.dataList = res.data.data.records; }); }, 后台代码中定义实体类封查询条件 @GetMapping(\"{currentPage}/{pageSize}\") public R getAll(@PathVariable int currentPage,@PathVariable int pageSize,Book book) { System.out.println(\"参数=====&gt;\"+book); IPage&lt;Book&gt; pageBook = bookService.getPage(currentPage,pageSize); return new R(null != pageBook ,pageBook); } 对应业务层接口与实现类进行修正 public interface IBookService extends IService&lt;Book&gt; { IPage&lt;Book&gt; getPage(Integer currentPage,Integer pageSize,Book queryBook); } @Service public class BookServiceImpl2 extends ServiceImpl&lt;BookDao,Book&gt; implements IBookService { public IPage&lt;Book&gt; getPage(Integer currentPage,Integer pageSize,Book queryBook){ IPage page = new Page(currentPage,pageSize); LambdaQueryWrapper&lt;Book&gt; lqw = new LambdaQueryWrapper&lt;Book&gt;(); lqw.like(Strings.isNotEmpty(queryBook.getName()),Book::getName,queryBook.getName()); lqw.like(Strings.isNotEmpty(queryBook.getType()),Book::getType,queryBook.getType()); lqw.like(Strings.isNotEmpty(queryBook.getDescription()),Book::getDescription,queryBook.getDescription()); return bookDao.selectPage(page,lqw); } } 页面回显数据 getAll() { //1.获取查询条件,拼接查询条件 param = \"?name=\"+this.pagination.name; param += \"&amp;type=\"+this.pagination.type; param += \"&amp;description=\"+this.pagination.description; console.log(\"-----------------\"+ param); axios.get(\"/books/\"+this.pagination.currentPage+\"/\"+this.pagination.pageSize+param).then((res) =&gt; { this.pagination.total = res.data.data.total; this.pagination.currentPage = res.data.data.current; this.pagination.pagesize = res.data.data.size; this.dataList = res.data.data.records; }); }, 总结 定义查询条件数据模型（当前封装到分页数据模型中） 异步调用分页功能并通过请求参数传递数据到后台","categories":[],"tags":[{"name":"SSMP","slug":"SSMP","permalink":"https://gitee.com/yunyd/tags/SSMP/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://gitee.com/yunyd/tags/SpringBoot/"}],"author":"llllz."},{"title":"Mybatis复习","slug":"Mybatis复习","date":"2023-08-01T01:56:16.000Z","updated":"2023-08-25T00:21:17.163Z","comments":true,"path":"posts/54e7bc9e.html","link":"","permalink":"https://gitee.com/yunyd/posts/54e7bc9e.html","excerpt":"","text":"Mybatis复习1.配置文件实现CRUD 如上图所示产品原型，里面包含了品牌数据的 查询 、按条件查询、添加、删除、批量删除、修改 等功能，而这些功能其实就是对数据库表中的数据进行CRUD操作。接下来我们就使用Mybatis完成品牌数据的增删改查操作。以下是我们要完成功能列表： 查询 查询所有数据 查询详情 条件查询 添加 修改 修改全部字段 修改动态字段 删除 删除一个 批量删除 我们先将必要的环境准备一下。 1.1 环境准备 数据库表（tb_brand）及数据准备 -- 删除tb_brand表 drop table if exists tb_brand; -- 创建tb_brand表 create table tb_brand ( -- id 主键 id int primary key auto_increment, -- 品牌名称 brand_name varchar(20), -- 企业名称 company_name varchar(20), -- 排序字段 ordered int, -- 描述信息 description varchar(100), -- 状态：0：禁用 1：启用 status int ); -- 添加数据 insert into tb_brand (brand_name, company_name, ordered, description, status) values ('三只松鼠', '三只松鼠股份有限公司', 5, '好吃不上火', 0), ('华为', '华为技术有限公司', 100, '华为致力于把数字世界带入每个人、每个家庭、每个组织，构建万物互联的智能世界', 1), ('小米', '小米科技有限公司', 50, 'are you ok', 1); 实体类 Brand 在 com.itheima.pojo 包下创建 Brand 实体类。 public class Brand { // id 主键 private Integer id; // 品牌名称 private String brandName; // 企业名称 private String companyName; // 排序字段 private Integer ordered; // 描述信息 private String description; // 状态：0：禁用 1：启用 private Integer status; //省略 setter and getter。自己写时要补全这部分代码 } 编写测试用例 测试代码需要在 test/java 目录下创建包及测试用例。项目结构如下： 安装 MyBatisX 插件 MybatisX 是一款基于 IDEA 的快速开发插件，为效率而生。 主要功能 XML映射配置文件 和 接口方法 间相互跳转 根据接口方法生成 statement 安装方式 点击 file ，选择 settings ，就能看到如下图所示界面 注意：安装完毕后需要重启IDEA 插件效果 红色头绳的表示映射配置文件，蓝色头绳的表示mapper接口。在mapper接口点击红色头绳的小鸟图标会自动跳转到对应的映射配置文件，在映射配置文件中点击蓝色头绳的小鸟图标会自动跳转到对应的mapper接口。也可以在mapper接口中定义方法，自动生成映射配置文件中的 statement ，如图所示 1.2 查询所有数据 如上图所示就页面上展示的数据，而这些数据需要从数据库进行查询。接下来我们就来讲查询所有数据功能，而实现该功能我们分以下步骤进行实现： 编写接口方法：Mapper接口 参数：无 查询所有数据功能是不需要根据任何条件进行查询的，所以此方法不需要参数。 结果：List 我们会将查询出来的每一条数据封装成一个 Brand 对象，而多条数据封装多个 Brand 对象，需要将这些对象封装到List集合中返回。 执行方法、测试 1.2.1 编写接口方法在 com.itheima.mapper 包写创建名为 BrandMapper 的接口。并在该接口中定义 List&lt;Brand&gt; selectAll() 方法。 public interface BrandMapper { /** * 查询所有 */ List&lt;Brand&gt; selectAll(); } 1.2.2 编写SQL语句在 reources 下创建 com/itheima/mapper 目录结构，并在该目录下创建名为 BrandMapper.xml 的映射配置文件 &lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt; &lt;mapper namespace=\"com.itheima.mapper.BrandMapper\"&gt; &lt;select id=\"selectAll\" resultType=\"brand\"&gt; select * from tb_brand; &lt;/select&gt; &lt;/mapper&gt; 1.2.3 编写测试方法在 MybatisTest 类中编写测试查询所有的方法 @Test public void testSelectAll() throws IOException { //1. 获取SqlSessionFactory String resource = \"mybatis-config.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); //2. 获取SqlSession对象 SqlSession sqlSession = sqlSessionFactory.openSession(); //3. 获取Mapper接口的代理对象 BrandMapper brandMapper = sqlSession.getMapper(BrandMapper.class); //4. 执行方法 List&lt;Brand&gt; brands = brandMapper.selectAll(); System.out.println(brands); //5. 释放资源 sqlSession.close(); } 注意：现在我们感觉测试这部分代码写起来特别麻烦，我们可以先忍忍。以后我们只会写上面的第3步的代码，其他的都不需要我们来完成。 执行测试方法结果如下： 从上面结果我们看到了问题，有些数据封装成功了，而有些数据并没有封装成功。为什么这样呢？ 这个问题可以通过两种方式进行解决： 给字段起别名 使用resultMap定义字段和属性的映射关系 1.2.4 起别名解决上述问题从上面结果可以看到 brandName 和 companyName 这两个属性的数据没有封装成功，查询 实体类 和 表中的字段 发现，在实体类中属性名是 brandName 和 companyName ，而表中的字段名为 brand_name 和 company_name，如下图所示 。那么我们只需要保持这两部分的名称一致这个问题就迎刃而解。 我们可以在写sql语句时给这两个字段起别名，将别名定义成和属性名一致即可。 &lt;select id=\"selectAll\" resultType=\"brand\"&gt; select id, brand_name as brandName, company_name as companyName, ordered, description, status from tb_brand; &lt;/select&gt; 而上面的SQL语句中的字段列表书写麻烦，如果表中还有更多的字段，同时其他的功能也需要查询这些字段时就显得我们的代码不够精炼。Mybatis提供了sql 片段可以提高sql的复用性。 SQL片段： 将需要复用的SQL片段抽取到 sql 标签中 &lt;sql id=\"brand_column\"&gt; id, brand_name as brandName, company_name as companyName, ordered, description, status &lt;/sql&gt; id属性值是唯一标识，引用时也是通过该值进行引用。 在原sql语句中进行引用 使用 include 标签引用上述的 SQL 片段，而 refid 指定上述 SQL 片段的id值。 &lt;select id=\"selectAll\" resultType=\"brand\"&gt; select &lt;include refid=\"brand_column\" /&gt; from tb_brand; &lt;/select&gt; 1.2.5 使用resultMap解决上述问题起别名 + sql片段的方式可以解决上述问题，但是它也存在问题。如果还有功能只需要查询部分字段，而不是查询所有字段，那么我们就需要再定义一个 SQL 片段，这就显得不是那么灵活。 那么我们也可以使用resultMap来定义字段和属性的映射关系的方式解决上述问题。 在映射配置文件中使用resultMap定义 字段 和 属性 的映射关系 &lt;resultMap id=\"brandResultMap\" type=\"brand\"&gt; &lt;!-- id：完成主键字段的映射 column：表的列名 property：实体类的属性名 result：完成一般字段的映射 column：表的列名 property：实体类的属性名 --&gt; &lt;result column=\"brand_name\" property=\"brandName\"/&gt; &lt;result column=\"company_name\" property=\"companyName\"/&gt; &lt;/resultMap&gt; 注意：在上面只需要定义 字段名 和 属性名 不一样的映射，而一样的则不需要专门定义出来。 SQL语句正常编写 &lt;select id=\"selectAll\" resultMap=\"brandResultMap\"&gt; select * from tb_brand; &lt;/select&gt; 1.2.6 小结实体类属性名 和 数据库表列名 不一致，不能自动封装数据 ==起别名：==在SQL语句中，对不一样的列名起别名，别名和实体类属性名一样 可以定义 片段，提升复用性 ==resultMap：==定义 完成不一致的属性名和列名的映射 而我们最终选择使用 resultMap的方式。查询映射配置文件中查询所有的 statement 书写如下： &lt;resultMap id=\"brandResultMap\" type=\"brand\"&gt; &lt;!-- id：完成主键字段的映射 column：表的列名 property：实体类的属性名 result：完成一般字段的映射 column：表的列名 property：实体类的属性名 --&gt; &lt;result column=\"brand_name\" property=\"brandName\"/&gt; &lt;result column=\"company_name\" property=\"companyName\"/&gt; &lt;/resultMap&gt; &lt;select id=\"selectAll\" resultMap=\"brandResultMap\"&gt; select * from tb_brand; &lt;/select&gt; 1.3 查询详情 有些数据的属性比较多，在页面表格中无法全部实现，而只会显示部分，而其他属性数据的查询可以通过 查看详情 来进行查询，如上图所示。 查看详情功能实现步骤： 编写接口方法：Mapper接口 参数：id 查看详情就是查询某一行数据，所以需要根据id进行查询。而id以后是由页面传递过来。 结果：Brand 根据id查询出来的数据只要一条，而将一条数据封装成一个Brand对象即可 编写SQL语句：SQL映射文件 执行方法、进行测试 1.3.1 编写接口方法在 BrandMapper 接口中定义根据id查询数据的方法 /** * 查看详情：根据Id查询 */ Brand selectById(int id); 1.3.2 编写SQL语句在 BrandMapper.xml 映射配置文件中编写 statement，使用 resultMap 而不是使用 resultType &lt;select id=\"selectById\" resultMap=\"brandResultMap\"&gt; select * from tb_brand where id = #{id}; &lt;/select&gt; 注意：上述SQL中的 #{id}先这样写，一会我们再详细讲解 1.3.3 编写测试方法在 test/java 下的 com.itheima.mapper 包下的 MybatisTest类中 定义测试方法 @Test public void testSelectById() throws IOException { //接收参数，该id以后需要传递过来 int id = 1; //1. 获取SqlSessionFactory String resource = \"mybatis-config.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); //2. 获取SqlSession对象 SqlSession sqlSession = sqlSessionFactory.openSession(); //3. 获取Mapper接口的代理对象 BrandMapper brandMapper = sqlSession.getMapper(BrandMapper.class); //4. 执行方法 Brand brand = brandMapper.selectById(id); System.out.println(brand); //5. 释放资源 sqlSession.close(); } 执行测试方法结果如下： 1.3.4 参数占位符查询到的结果很好理解就是id为1的这行数据。而这里我们需要看控制台显示的SQL语句，能看到使用？进行占位。说明我们在映射配置文件中的写的 #{id} 最终会被？进行占位。接下来我们就聊聊映射配置文件中的参数占位符。 mybatis提供了两种参数占位符： #{} ：执行SQL时，会将 #{} 占位符替换为？，将来自动设置参数值。从上述例子可以看出使用#{} 底层使用的是 PreparedStatement ${} ：拼接SQL。底层使用的是 Statement，会存在SQL注入问题。如下图将 映射配置文件中的 #{} 替换成 ${} 来看效果 &lt;select id=\"selectById\" resultMap=\"brandResultMap\"&gt; select * from tb_brand where id = ${id}; &lt;/select&gt; 重新运行查看结果如下： ==注意：==从上面两个例子可以看出，以后开发我们使用 #{} 参数占位符。 1.3.5 parameterType使用对于有参数的mapper接口方法，我们在映射配置文件中应该配置 ParameterType 来指定参数类型。只不过该属性都可以省略。如下图： &lt;select id=\"selectById\" parameterType=\"int\" resultMap=\"brandResultMap\"&gt; select * from tb_brand where id = ${id}; &lt;/select&gt; 1.3.6 SQL语句中特殊字段处理以后肯定会在SQL语句中写一下特殊字符，比如某一个字段大于某个值，如下图 可以看出报错了，因为映射配置文件是xml类型的问题，而 &gt; &lt; 等这些字符在xml中有特殊含义，所以此时我们需要将这些符号进行转义，可以使用以下两种方式进行转义 转义字符 下图的 &amp;lt; 就是 &lt; 的转义字符。 1.4 多条件查询 我们经常会遇到如上图所示的多条件查询，将多条件查询的结果展示在下方的数据列表中。而我们做这个功能需要分析最终的SQL语句应该是什么样，思考两个问题 条件表达式 如何连接 条件字段 企业名称 和 品牌名称 需要进行模糊查询，所以条件应该是： 简单的分析后，我们来看功能实现的步骤： 编写接口方法 参数：所有查询条件 结果：List 在映射配置文件中编写SQL语句 编写测试方法并执行 1.4.1 编写接口方法在 BrandMapper 接口中定义多条件查询的方法。 而该功能有三个参数，我们就需要考虑定义接口时，参数应该如何定义。Mybatis针对多参数有多种实现 使用 @Param(\"参数名称\") 标记每一个参数，在映射配置文件中就需要使用 #{参数名称} 进行占位 List&lt;Brand&gt; selectByCondition(@Param(\"status\") int status, @Param(\"companyName\") String companyName,@Param(\"brandName\") String brandName); 将多个参数封装成一个 实体对象 ，将该实体对象作为接口的方法参数。该方式要求在映射配置文件的SQL中使用 #{内容} 时，里面的内容必须和实体类属性名保持一致。 List&lt;Brand&gt; selectByCondition(Brand brand); 将多个参数封装到map集合中，将map集合作为接口的方法参数。该方式要求在映射配置文件的SQL中使用 #{内容} 时，里面的内容必须和map集合中键的名称一致。 List&lt;Brand&gt; selectByCondition(Map map); 1.4.2 编写SQL语句在 BrandMapper.xml 映射配置文件中编写 statement，使用 resultMap 而不是使用 resultType &lt;select id=\"selectByCondition\" resultMap=\"brandResultMap\"&gt; select * from tb_brand where status = #{status} and company_name like #{companyName} and brand_name like #{brandName} &lt;/select&gt; 1.4.3 编写测试方法在 test/java 下的 com.itheima.mapper 包下的 MybatisTest类中 定义测试方法 @Test public void testSelectByCondition() throws IOException { //接收参数 int status = 1; String companyName = \"华为\"; String brandName = \"华为\"; // 处理参数 companyName = \"%\" + companyName + \"%\"; brandName = \"%\" + brandName + \"%\"; //1. 获取SqlSessionFactory String resource = \"mybatis-config.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); //2. 获取SqlSession对象 SqlSession sqlSession = sqlSessionFactory.openSession(); //3. 获取Mapper接口的代理对象 BrandMapper brandMapper = sqlSession.getMapper(BrandMapper.class); //4. 执行方法 //方式一 ：接口方法参数使用 @Param 方式调用的方法 //List&lt;Brand&gt; brands = brandMapper.selectByCondition(status, companyName, brandName); //方式二 ：接口方法参数是 实体类对象 方式调用的方法 //封装对象 /* Brand brand = new Brand(); brand.setStatus(status); brand.setCompanyName(companyName); brand.setBrandName(brandName);*/ //List&lt;Brand&gt; brands = brandMapper.selectByCondition(brand); //方式三 ：接口方法参数是 map集合对象 方式调用的方法 Map map = new HashMap(); map.put(\"status\" , status); map.put(\"companyName\", companyName); map.put(\"brandName\" , brandName); List&lt;Brand&gt; brands = brandMapper.selectByCondition(map); System.out.println(brands); //5. 释放资源 sqlSession.close(); } 1.4.4 动态SQL上述功能实现存在很大的问题。用户在输入条件时，肯定不会所有的条件都填写，这个时候我们的SQL语句就不能那样写的 例如用户只输入 当前状态 时，SQL语句就是 select * from tb_brand where status = #{status} 而用户如果只输入企业名称时，SQL语句就是 select * from tb_brand where company_name like #{companName} 而用户如果输入了 当前状态 和 企业名称 时，SQL语句又不一样 select * from tb_brand where status = #{status} and company_name like #{companName} 针对上述的需要，Mybatis对动态SQL有很强大的支撑： if choose (when, otherwise) trim (where, set) foreach 我们先学习 if 标签和 where 标签： if 标签：条件判断 test 属性：逻辑表达式 &lt;select id=\"selectByCondition\" resultMap=\"brandResultMap\"&gt; select * from tb_brand where &lt;if test=\"status != null\"&gt; and status = #{status} &lt;/if&gt; &lt;if test=\"companyName != null and companyName != '' \"&gt; and company_name like #{companyName} &lt;/if&gt; &lt;if test=\"brandName != null and brandName != '' \"&gt; and brand_name like #{brandName} &lt;/if&gt; &lt;/select&gt; 如上的这种SQL语句就会根据传递的参数值进行动态的拼接。如果此时status和companyName有值那么就会值拼接这两个条件。 执行结果如下： 但是它也存在问题，如果此时给的参数值是 Map map = new HashMap(); // map.put(\"status\" , status); map.put(\"companyName\", companyName); map.put(\"brandName\" , brandName); 拼接的SQL语句就变成了 select * from tb_brand where and company_name like ? and brand_name like ? 而上面的语句中 where 关键后直接跟 and 关键字，这就是一条错误的SQL语句。这个就可以使用 where 标签解决 where 标签 作用： 替换where关键字 会动态的去掉第一个条件前的 and 如果所有的参数没有值则不加where关键字 &lt;select id=\"selectByCondition\" resultMap=\"brandResultMap\"&gt; select * from tb_brand &lt;where&gt; &lt;if test=\"status != null\"&gt; and status = #{status} &lt;/if&gt; &lt;if test=\"companyName != null and companyName != '' \"&gt; and company_name like #{companyName} &lt;/if&gt; &lt;if test=\"brandName != null and brandName != '' \"&gt; and brand_name like #{brandName} &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; 注意：需要给每个条件前都加上 and 关键字。 1.5 单个条件（动态SQL） 如上图所示，在查询时只能选择 品牌名称、当前状态、企业名称 这三个条件中的一个，但是用户到底选择哪儿一个，我们并不能确定。这种就属于单个条件的动态SQL语句。 这种需求需要使用到 choose（when，otherwise）标签 实现， 而 choose 标签类似于Java 中的switch语句。 通过一个案例来使用这些标签 1.5.1 编写接口方法在 BrandMapper 接口中定义单条件查询的方法。 /** * 单条件动态查询 * @param brand * @return */ List&lt;Brand&gt; selectByConditionSingle(Brand brand); 1.5.2 编写SQL语句在 BrandMapper.xml 映射配置文件中编写 statement，使用 resultMap 而不是使用 resultType &lt;select id=\"selectByConditionSingle\" resultMap=\"brandResultMap\"&gt; select * from tb_brand &lt;where&gt; &lt;choose&gt;&lt;!--相当于switch--&gt; &lt;when test=\"status != null\"&gt;&lt;!--相当于case--&gt; status = #{status} &lt;/when&gt; &lt;when test=\"companyName != null and companyName != '' \"&gt;&lt;!--相当于case--&gt; company_name like #{companyName} &lt;/when&gt; &lt;when test=\"brandName != null and brandName != ''\"&gt;&lt;!--相当于case--&gt; brand_name like #{brandName} &lt;/when&gt; &lt;/choose&gt; &lt;/where&gt; &lt;/select&gt; 1.5.3 编写测试方法在 test/java 下的 com.itheima.mapper 包下的 MybatisTest类中 定义测试方法 @Test public void testSelectByConditionSingle() throws IOException { //接收参数 int status = 1; String companyName = \"华为\"; String brandName = \"华为\"; // 处理参数 companyName = \"%\" + companyName + \"%\"; brandName = \"%\" + brandName + \"%\"; //封装对象 Brand brand = new Brand(); //brand.setStatus(status); brand.setCompanyName(companyName); //brand.setBrandName(brandName); //1. 获取SqlSessionFactory String resource = \"mybatis-config.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); //2. 获取SqlSession对象 SqlSession sqlSession = sqlSessionFactory.openSession(); //3. 获取Mapper接口的代理对象 BrandMapper brandMapper = sqlSession.getMapper(BrandMapper.class); //4. 执行方法 List&lt;Brand&gt; brands = brandMapper.selectByConditionSingle(brand); System.out.println(brands); //5. 释放资源 sqlSession.close(); } 执行测试方法结果如下： 1.6 添加数据 如上图是我们平时在添加数据时展示的页面，而我们在该页面输入想要的数据后添加 提交 按钮，就会将这些数据添加到数据库中。接下来我们就来实现添加数据的操作。 编写接口方法 参数：除了id之外的所有的数据。id对应的是表中主键值，而主键我们是 ==自动增长== 生成的。 编写SQL语句 编写测试方法并执行 明确了该功能实现的步骤后，接下来我们进行具体的操作。 1.6.1 编写接口方法在 BrandMapper 接口中定义添加方法。 /** * 添加 */ void add(Brand brand); 1.6.2 编写SQL语句在 BrandMapper.xml 映射配置文件中编写添加数据的 statement &lt;insert id=\"add\"&gt; insert into tb_brand (brand_name, company_name, ordered, description, status) values (#{brandName}, #{companyName}, #{ordered}, #{description}, #{status}); &lt;/insert&gt; 1.6.3 编写测试方法在 test/java 下的 com.itheima.mapper 包下的 MybatisTest类中 定义测试方法 @Test public void testAdd() throws IOException { //接收参数 int status = 1; String companyName = \"波导手机\"; String brandName = \"波导\"; String description = \"手机中的战斗机\"; int ordered = 100; //封装对象 Brand brand = new Brand(); brand.setStatus(status); brand.setCompanyName(companyName); brand.setBrandName(brandName); brand.setDescription(description); brand.setOrdered(ordered); //1. 获取SqlSessionFactory String resource = \"mybatis-config.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); //2. 获取SqlSession对象 SqlSession sqlSession = sqlSessionFactory.openSession(); //SqlSession sqlSession = sqlSessionFactory.openSession(true); //设置自动提交事务，这种情况不需要手动提交事务了 //3. 获取Mapper接口的代理对象 BrandMapper brandMapper = sqlSession.getMapper(BrandMapper.class); //4. 执行方法 brandMapper.add(brand); //提交事务 sqlSession.commit(); //5. 释放资源 sqlSession.close(); } 执行结果如下： 1.6.4 添加-主键返回在数据添加成功后，有时候需要获取插入数据库数据的主键（主键是自增长）。 比如：添加订单和订单项，如下图就是京东上的订单 订单数据存储在订单表中，订单项存储在订单项表中。 添加订单数据 添加订单项数据，订单项中需要设置所属订单的id 明白了什么时候 主键返回 。接下来我们简单模拟一下，在添加完数据后打印id属性值，能打印出来说明已经获取到了。 我们将上面添加品牌数据的案例中映射配置文件里 statement 进行修改，如下 &lt;insert id=\"add\" useGeneratedKeys=\"true\" keyProperty=\"id\"&gt; insert into tb_brand (brand_name, company_name, ordered, description, status) values (#{brandName}, #{companyName}, #{ordered}, #{description}, #{status}); &lt;/insert&gt; 在 insert 标签上添加如下属性： useGeneratedKeys：是够获取自动增长的主键值。true表示获取 keyProperty ：指定将获取到的主键值封装到哪儿个属性里 1.7 修改 如图所示是修改页面，用户在该页面书写需要修改的数据，点击 提交 按钮，就会将数据库中对应的数据进行修改。注意一点，如果哪儿个输入框没有输入内容，我们是将表中数据对应字段值替换为空白还是保留字段之前的值？答案肯定是保留之前的数据。 接下来我们就具体来实现 1.7.1 编写接口方法在 BrandMapper 接口中定义修改方法。 /** * 修改 */ void update(Brand brand); 上述方法参数 Brand 就是封装了需要修改的数据，而id肯定是有数据的，这也是和添加方法的区别。 1.7.2 编写SQL语句在 BrandMapper.xml 映射配置文件中编写修改数据的 statement。 &lt;update id=\"update\"&gt; update tb_brand &lt;set&gt; &lt;if test=\"brandName != null and brandName != ''\"&gt; brand_name = #{brandName}, &lt;/if&gt; &lt;if test=\"companyName != null and companyName != ''\"&gt; company_name = #{companyName}, &lt;/if&gt; &lt;if test=\"ordered != null\"&gt; ordered = #{ordered}, &lt;/if&gt; &lt;if test=\"description != null and description != ''\"&gt; description = #{description}, &lt;/if&gt; &lt;if test=\"status != null\"&gt; status = #{status} &lt;/if&gt; &lt;/set&gt; where id = #{id}; &lt;/update&gt; set 标签可以用于动态包含需要更新的列，忽略其它不更新的列。 1.7.3 编写测试方法在 test/java 下的 com.itheima.mapper 包下的 MybatisTest类中 定义测试方法 @Test public void testUpdate() throws IOException { //接收参数 int status = 0; String companyName = \"波导手机\"; String brandName = \"波导\"; String description = \"波导手机,手机中的战斗机\"; int ordered = 200; int id = 6; //封装对象 Brand brand = new Brand(); brand.setStatus(status); // brand.setCompanyName(companyName); // brand.setBrandName(brandName); // brand.setDescription(description); // brand.setOrdered(ordered); brand.setId(id); //1. 获取SqlSessionFactory String resource = \"mybatis-config.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); //2. 获取SqlSession对象 SqlSession sqlSession = sqlSessionFactory.openSession(); //SqlSession sqlSession = sqlSessionFactory.openSession(true); //3. 获取Mapper接口的代理对象 BrandMapper brandMapper = sqlSession.getMapper(BrandMapper.class); //4. 执行方法 int count = brandMapper.update(brand); System.out.println(count); //提交事务 sqlSession.commit(); //5. 释放资源 sqlSession.close(); } 执行测试方法结果如下： 从结果中SQL语句可以看出，只修改了 status 字段值，因为我们给的数据中只给Brand实体对象的 status 属性设置值了。这就是 set 标签的作用。 1.8 删除一行数据 如上图所示，每行数据后面都有一个 删除 按钮，当用户点击了该按钮，就会将改行数据删除掉。那我们就需要思考，这种删除是根据什么进行删除呢？是通过主键id删除，因为id是表中数据的唯一标识。 接下来就来实现该功能。 1.8.1 编写接口方法在 BrandMapper 接口中定义根据id删除方法。 /** * 根据id删除 */ void deleteById(int id); 1.8.2 编写SQL语句在 BrandMapper.xml 映射配置文件中编写删除一行数据的 statement &lt;delete id=\"deleteById\"&gt; delete from tb_brand where id = #{id}; &lt;/delete&gt; 1.8.3 编写测试方法在 test/java 下的 com.itheima.mapper 包下的 MybatisTest类中 定义测试方法 @Test public void testDeleteById() throws IOException { //接收参数 int id = 6; //1. 获取SqlSessionFactory String resource = \"mybatis-config.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); //2. 获取SqlSession对象 SqlSession sqlSession = sqlSessionFactory.openSession(); //SqlSession sqlSession = sqlSessionFactory.openSession(true); //3. 获取Mapper接口的代理对象 BrandMapper brandMapper = sqlSession.getMapper(BrandMapper.class); //4. 执行方法 brandMapper.deleteById(id); //提交事务 sqlSession.commit(); //5. 释放资源 sqlSession.close(); } 运行过程只要没报错，直接到数据库查询数据是否还存在。 1.9 批量删除 如上图所示，用户可以选择多条数据，然后点击上面的 删除 按钮，就会删除数据库中对应的多行数据。 1.9.1 编写接口方法在 BrandMapper 接口中定义删除多行数据的方法。 /** * 批量删除 */ void deleteByIds(int[] ids); 参数是一个数组，数组中存储的是多条数据的id 1.9.2 编写SQL语句在 BrandMapper.xml 映射配置文件中编写删除多条数据的 statement。 编写SQL时需要遍历数组来拼接SQL语句。Mybatis 提供了 foreach 标签供我们使用 foreach 标签 用来迭代任何可迭代的对象（如数组，集合）。 collection 属性： mybatis会将数组参数，封装为一个Map集合。 默认：array = 数组 使用@Param注解改变map集合的默认key的名称 item 属性：本次迭代获取到的元素。 separator 属性：集合项迭代之间的分隔符。foreach 标签不会错误地添加多余的分隔符。也就是最后一次迭代不会加分隔符。 open 属性：该属性值是在拼接SQL语句之前拼接的语句，只会拼接一次 close 属性：该属性值是在拼接SQL语句拼接后拼接的语句，只会拼接一次 &lt;delete id=\"deleteByIds\"&gt; delete from tb_brand where id in &lt;foreach collection=\"array\" item=\"id\" separator=\",\" open=\"(\" close=\")\"&gt; #{id} &lt;/foreach&gt; ; &lt;/delete&gt; 假如数组中的id数据是{1,2,3}，那么拼接后的sql语句就是： delete from tb_brand where id in (1,2,3); 1.9.3 编写测试方法在 test/java 下的 com.itheima.mapper 包下的 MybatisTest类中 定义测试方法 @Test public void testDeleteByIds() throws IOException { //接收参数 int[] ids = {5,7,8}; //1. 获取SqlSessionFactory String resource = \"mybatis-config.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); //2. 获取SqlSession对象 SqlSession sqlSession = sqlSessionFactory.openSession(); //SqlSession sqlSession = sqlSessionFactory.openSession(true); //3. 获取Mapper接口的代理对象 BrandMapper brandMapper = sqlSession.getMapper(BrandMapper.class); //4. 执行方法 brandMapper.deleteByIds(ids); //提交事务 sqlSession.commit(); //5. 释放资源 sqlSession.close(); } 1.10 Mybatis参数传递Mybatis 接口方法中可以接收各种各样的参数，如下： 多个参数 单个参数：单个参数又可以是如下类型 POJO 类型 Map 集合类型 Collection 集合类型 List 集合类型 Array 类型 其他类型 1.10.1 多个参数如下面的代码，就是接收两个参数，而接收多个参数需要使用 @Param 注解，那么为什么要加该注解呢？这个问题要弄明白就必须来研究Mybatis 底层对于这些参数是如何处理的。 User select(@Param(\"username\") String username,@Param(\"password\") String password); &lt;select id=\"select\" resultType=\"user\"&gt; select * from tb_user where username=#{username} and password=#{password} &lt;/select&gt; 我们在接口方法中定义多个参数，Mybatis 会将这些参数封装成 Map 集合对象，值就是参数值，而键在没有使用 @Param 注解时有以下命名规则： 以 arg 开头 ：第一个参数就叫 arg0，第二个参数就叫 arg1，以此类推。如： map.put(“arg0”，参数值1); map.put(“arg1”，参数值2); 以 param 开头 ： 第一个参数就叫 param1，第二个参数就叫 param2，依次类推。如： map.put(“param1”，参数值1); map.put(“param2”，参数值2); 代码验证： 在 UserMapper 接口中定义如下方法 User select(String username,String password); 在 UserMapper.xml 映射配置文件中定义SQL &lt;select id=\"select\" resultType=\"user\"&gt; select * from tb_user where username=#{arg0} and password=#{arg1} &lt;/select&gt; 或者 &lt;select id=\"select\" resultType=\"user\"&gt; select * from tb_user where username=#{param1} and password=#{param2} &lt;/select&gt; 运行代码结果如下 在映射配合文件的SQL语句中使用用 arg 开头的和 param 书写，代码的可读性会变的特别差，此时可以使用 @Param 注解。 在接口方法参数上使用 @Param 注解，Mybatis 会将 arg 开头的键名替换为对应注解的属性值。 代码验证： 在 UserMapper 接口中定义如下方法，在 username 参数前加上 @Param 注解 User select(@Param(\"username\") String username, String password); Mybatis 在封装 Map 集合时，键名就会变成如下： map.put(“username”，参数值1); map.put(“arg1”，参数值2); map.put(“param1”，参数值1); map.put(“param2”，参数值2); 在 UserMapper.xml 映射配置文件中定义SQL &lt;select id=\"select\" resultType=\"user\"&gt; select * from tb_user where username=#{username} and password=#{param2} &lt;/select&gt; 运行程序结果没有报错。而如果将 #{} 中的 username 还是写成 arg0 &lt;select id=\"select\" resultType=\"user\"&gt; select * from tb_user where username=#{arg0} and password=#{param2} &lt;/select&gt; 运行程序则可以看到错误 ==结论：以后接口参数是多个时，在每个参数上都使用 @Param 注解。这样代码的可读性更高。== 1.10.2 单个参数 POJO 类型 直接使用。要求 属性名 和 参数占位符名称 一致 Map 集合类型 直接使用。要求 map集合的键名 和 参数占位符名称 一致 Collection 集合类型 Mybatis 会将集合封装到 map 集合中，如下： map.put(“arg0”，collection集合); map.put(“collection”，collection集合; ==可以使用 @Param 注解替换map集合中默认的 arg 键名。== List 集合类型 Mybatis 会将集合封装到 map 集合中，如下： map.put(“arg0”，list集合); map.put(“collection”，list集合); map.put(“list”，list集合); ==可以使用 @Param 注解替换map集合中默认的 arg 键名。== Array 类型 Mybatis 会将集合封装到 map 集合中，如下： map.put(“arg0”，数组); map.put(“array”，数组); ==可以使用 @Param 注解替换map集合中默认的 arg 键名。== 其他类型 比如int类型，参数占位符名称 叫什么都可以。尽量做到见名知意 2.注解实现CRUD使用注解开发会比配置文件开发更加方便。如下就是使用注解进行开发 @Select(value = \"select * from tb_user where id = #{id}\") public User select(int id); ==注意：== 注解是用来替换映射配置文件方式配置的，所以使用了注解，就不需要再映射配置文件中书写对应的 statement Mybatis 针对 CURD 操作都提供了对应的注解，已经做到见名知意。如下： 查询 ：@Select 添加 ：@Insert 修改 ：@Update 删除 ：@Delete 接下来我们做一个案例来使用 Mybatis 的注解开发 代码实现： 将之前案例中 UserMapper.xml 中的 根据id查询数据 的 statement 注释掉 在 UserMapper 接口的 selectById 方法上添加注解 运行测试程序也能正常查询到数据 我们课程上只演示这一个查询的注解开发，其他的同学们下来可以自己实现，都是比较简单。 ==注意：==在官方文档中 入门 中有这样的一段话： 所以，==注解完成简单功能，配置文件完成复杂功能。== 而我们之前写的动态 SQL 就是复杂的功能，如果用注解使用的话，就需要使用到 Mybatis 提供的SQL构建器来完成，而对应的代码如下： 上述代码将java代码和SQL语句融到了一块，使得代码的可读性大幅度降低。","categories":[],"tags":[{"name":"SSMP","slug":"SSMP","permalink":"https://gitee.com/yunyd/tags/SSMP/"},{"name":"MyBatis","slug":"MyBatis","permalink":"https://gitee.com/yunyd/tags/MyBatis/"}],"author":"llllz."},{"title":"JUC-说说Java锁事","slug":"JUC-说说Java锁事 -3","date":"2023-08-01T01:12:22.000Z","updated":"2023-08-25T00:20:14.640Z","comments":true,"path":"posts/da3e444a.html","link":"","permalink":"https://gitee.com/yunyd/posts/da3e444a.html","excerpt":"","text":"说说Java”锁”事1.1 从轻松的乐观锁和悲观锁开讲●悲观锁： 认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改，synchronized和Lock的实现类都是悲观锁，适合写操作多的场景，先加锁可以保证写操作时数据正确，显示的锁定之后再操作同步资源—–狼性锁 ●乐观锁： 认为自己在使用数据的时候不会有别的线程修改数据或资源，不会添加锁，Java中使用无锁编程来实现，只是在更新的时候去判断，之前有没有别的线程更新了这个数据，如果这个数据没有被更新，当前线程将自己修改的数据成功写入，如果已经被其他线程更新，则根据不同的实现方式执行不同的操作，比如：放弃修改、重试抢锁等等。判断规则有：版本号机制Version，最常采用的是CAS算法，Java原子类中的递增操作就通过CAS自旋实现的。—–适合读操作多的场景，不加锁的特性能够使其读操作的性能大幅提升，乐观锁则直接去操作同步资源，是一种无锁算法，得之我幸不得我命—佛系锁 1.2 通过8种情况演示锁运行案例，看看锁到底是什么1.2.1 锁相关的8种案例演示code8种案例演示： class Phone { public synchronized void sendEmail() { try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\"------sendEmail\"); } public synchronized void sendSMS() { System.out.println(\"------sendSMS\"); } public void hello() { System.out.println(\"------hello\"); } } /** * 现象描述： * 1 标准访问ab两个线程，请问先打印邮件还是短信？ --------先邮件，后短信 共用一个对象锁 * 2. sendEmail钟加入暂停3秒钟，请问先打印邮件还是短信？---------先邮件，后短信 共用一个对象锁 * 3. 添加一个普通的hello方法，请问先打印普通方法还是邮件？ --------先hello，再邮件 * 4. 有两部手机，请问先打印邮件还是短信？ ----先短信后邮件 资源没有争抢，不是同一个对象锁 * 5. 有两个静态同步方法，一步手机， 请问先打印邮件还是短信？---------先邮件后短信 共用一个类锁 * 6. 有两个静态同步方法，两部手机， 请问先打印邮件还是短信？ ----------先邮件后短信 共用一个类锁 * 7. 有一个静态同步方法 一个普通同步方法，请问先打印邮件还是短信？ ---------先短信后邮件 一个用类锁一个用对象锁 * 8. 有一个静态同步方法，一个普通同步方法，两部手机，请问先打印邮件还是短信？ -------先短信后邮件 一个类锁一个对象锁 */ public class Lock8Demo { public static void main(String[] args) { Phone phone = new Phone(); new Thread(() -&gt; { phone.sendEmail(); }, \"a\").start(); try { TimeUnit.MILLISECONDS.sleep(200); } catch (InterruptedException e) { e.printStackTrace(); } new Thread(() -&gt; { phone.sendSMS(); }, \"b\").start(); } } 结论： 对于普通同步方法，锁的是当前实例对象，通常指this，所有的同步方法用的都是同一把锁—&gt;实例对象本身 对于静态同步方法，锁的时当前类的Class对象 对于同步方法块，锁的时synchronized括号内的对象 1.2.2 synchronized有三种应用方式 作用于实例方法，当前实例加锁，进入同步代码块前要获得当前实例的锁； 作用于代码块，对括号里配置的对象加锁 作用于静态方法，当前类加锁，进去同步代码前要获得当前类对象的锁 1.2.3 从字节码角度分析synchronized实现 javap -c(v附加信息) ***.class 文件反编译 synchronized同步代码块 实现使用的是monitorenter和monitorexit指令 synchronized普通同步方法 调用指令将会检查方法的ACC_SYNCHRONIZED访问标志是否被设置，如果设置了，执行线程会将现持有monitor锁，然后再执行该方法，最后在方法完成（无论是否正常结束）时释放monitor synchronized静态同步方法 ACC_STATIC、ACC_SYNCHRONIZED访问标志区分该方法是否是静态同步方法 1.2.4 反编译synchronized锁的是什么面试题：为什么任何一个对象都可以成为一个锁？ C++源码：ObjectMonitor.java—&gt;ObjectMonitor.cpp—&gt;ObjectMonitor.hpp 每个对象天生都带着一个对象监视器，每一个被锁住的对象都会和Monitor关联起来 总结：指针指向Monitor对象（也称为管程或监视器）的真实地址。每个对象都存在着一个monitor与之关联，当一个monitor被某个线程持有后，它便处于锁定状态。在Java虚拟机（HotSpot）中，monitor是由OnjectMonitor实现的，其主要的数据结构如下（位于HotSpot虚拟机源码ObjectMonitor.hpp文件，C++实现）： 1.2.5 对于Synchronized关键字后面章节详说 1.3 公平锁和非公平锁1.3.1 何为公平锁/非公平锁 公平锁：是指多个线程按照申请锁的顺序来获取锁，这里类似于排队买票，先来的人先买，后来的人再队尾排着，这是公平的—– Lock lock = new ReentrantLock(true)—表示公平锁，先来先得。 非公平锁：是指多个线程获取锁的顺序并不是按照申请的顺序，有可能后申请的线程比先申请的线程优先获取锁，在高并发环境下，有可能造成优先级反转或者饥饿的状态（某个线程一直得不到锁）—- Lock lock = new ReentrantLock(false)—表示非公平锁，后来的也可能先获得锁，默认为非公平锁。 面试题： 为什么会有公平锁/非公平锁的设计？为什么默认非公平？ 恢复挂起的线程到真正锁的获取还是有时间差的，从开发人员来看这个时间微乎其微，但是从CPU的角度来看，这个时间差存在的还是很明显的。所以非公平锁能更充分地利用CPU的时间片，尽量减少CPU空间状态时间。 使用多线程很重要的考量点是线程切换的开销，当采用非公平锁时，当一个线程请求锁获取同步状态，然后释放同步状态，所以刚释放锁的线程在此刻再次获取同步状态的概率就变得很大，所以就减少了线程的开销。 什么时候用公平？什么时候用非公平？ 如果为了更高的吞吐量，很显然非公平锁是比较合适的，因为节省了很多线程切换的时间，吞吐量自然就上去了；否则就用公平锁，大家公平使用。 1.3.2 预埋伏AQS后续深入分析 1.4 可重入锁（递归锁）1.4.1 概念说明是指在同一线程在外层方法获取到锁的时侯，在进入该线程的内层方法会自动获取锁（前提，锁对象的是同一个对象），不会因为之前已经获取过还没释放而阻塞———优点之一就是可一定程度避免死锁。 1.4.2 可重入锁种类 隐式锁（即synchronized关键字使用的锁），默认是可重入锁 在一个synchronized修饰的方法或者代码块的内部调用本类的其他synchronized修饰的方法或者代码块时，是永远可以得到锁。 显式锁（即Lock）也有ReentrantLock这样的可重入锁 隐式和显示可重入锁的演示： public class ReEntryLockDemo { public static void main(String[] args) { final Object o = new Object(); /** * ---------------外层调用 * ---------------中层调用 * ---------------内层调用 */ new Thread(() -&gt; { synchronized (o) { System.out.println(\"---------------外层调用\"); synchronized (o) { System.out.println(\"---------------中层调用\"); synchronized (o) { System.out.println(\"---------------内层调用\"); } } } }, \"t1\").start(); /** * 注意：加锁几次就需要解锁几次 * ---------------外层调用 * ---------------中层调用 * ---------------内层调用 */ Lock lock = new ReentrantLock(); new Thread(() -&gt; { lock.lock(); try { System.out.println(\"---------------外层调用\"); lock.lock(); try { System.out.println(\"---------------中层调用\"); lock.lock(); try { System.out.println(\"---------------内层调用\"); } finally { lock.unlock(); } } finally { lock.unlock(); } } finally { lock.unlock(); } }, \"t2\").start(); } } 1.5 死锁及排查1.5.1 概念死锁是指两个或两个以上的线程在执行过程中，因抢夺资源而造成的一种互相等待的现象，若无外力干涉，则它们无法再继续推进下去。 产生原因： 系统资源不足 进程运行推进顺序不合适 系统资源分配不当 1.5.2 写一个死锁代码case实现死锁： public class DeadLockDemo { static Object a=new Object(); static Object b=new Object(); public static void main(String[] args) { new Thread(() -&gt; { synchronized (a){ System.out.println(\"t1线程持有a锁，试图获取b锁\"); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } synchronized (b){ System.out.println(\"t1线程获取到b锁\"); } } },\"t1\").start(); new Thread(() -&gt; { synchronized (b){ System.out.println(\"t2线程持有a锁，试图获取a锁\"); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } synchronized (a){ System.out.println(\"t2线程获取到a锁\"); } } },\"t2\").start(); } } 1.5.3 如何排查死锁 纯命令 jps -l jstack 进程编号 图形化 jconsole 1.6 写锁（独占锁）/读锁（共享锁）深度源码分析见后面 1.7 自旋锁spinLock深度源码分析见后面 1.8 无锁-&gt;独占锁-&gt;读写锁-&gt;邮戳锁深度源码分析见后面 1.9 无锁-&gt;偏向锁-&gt;轻量锁-&gt;重量锁深度源码分析见后面","categories":[],"tags":[{"name":"JUC并发编程","slug":"JUC并发编程","permalink":"https://gitee.com/yunyd/tags/JUC%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"author":"llllz."},{"title":"JUC-CompletableFuture","slug":"JUC-CompletableFuture -2","date":"2023-07-28T02:12:22.000Z","updated":"2023-08-25T00:19:26.556Z","comments":true,"path":"posts/1fb3c234.html","link":"","permalink":"https://gitee.com/yunyd/posts/1fb3c234.html","excerpt":"","text":"CompletableFuture1.1 Future接口理论知识复习Future接口（FutureTask实现类）定义了操作异步任务执行一些方法，如获取异步任务的执行结果、取消异步任务的执行、判断任务是否被取消、判断任务执行是否完毕等。 举例：比如主线程让一个子线程去执行任务，子线程可能比较耗时，启动子线程开始执行任务后，主线程就去做其他事情了，忙完其他事情或者先执行完，过了一会再才去获取子任务的执行结果或变更的任务状态（老师上课时间想喝水，他继续讲课不结束上课这个主线程，让学生去小卖部帮老师买水完成这个耗时和费力的任务）。 1.2 Future接口常用实现类FutureTask异步任务1.2.1 Future接口能干什么Future是Java5新加的一个接口，它提供一种异步并行计算的功能，如果主线程需要执行一个很耗时的计算任务，我们会就可以通过Future把这个任务放进异步线程中执行，主线程继续处理其他任务或者先行结束，再通过Future获取计算结果。 1.2.2 Future接口相关架构●目的：异步多线程任务执行且返回有结果，三个特点：多线程、有返回、异步任务（班长为老师去买水作为新启动的异步多线程任务且买到水有结果返回） ●代码实现：Runnable接口+Callable接口+Future接口和FutureTask实现类。 FutureTask开启异步任务： public class CompletableFutureDemo { public static void main(String[] args) throws ExecutionException, InterruptedException { FutureTask&lt;String&gt; futureTask = new FutureTask(new MyThread()); Thread t1 = new Thread(futureTask); //开启一个异步线程 t1.start(); System.out.println(futureTask.get()); //有返回hello Callable } } class MyThread implements Callable&lt;String&gt; { @Override public String call() throws Exception { System.out.println(\"--------come in\"); return \"hello Callable\"; } } 1.2.3 Future编码实战和优缺点分析●优点：Future+线程池异步多线程任务配合，能显著提高程序的运行效率。 ●缺点： ​ ○get()阻塞—一旦调用get()方法求结果，一旦调用不见不散，非要等到结果才会离开，不管你是否计算完成，如果没有计算完成容易程序堵塞。 ​ ○isDone()轮询—轮询的方式会耗费无谓的cpu资源，而且也不见得能及时得到计算结果，如果想要异步获取结果，通常会以轮询的方式去获取结果，尽量不要阻塞。 ●结论：Future对于结果的获取不是很友好，只能通过阻塞或轮询的方式得到任务的结果。 Future获取结果get()和轮询： public class FutureApiDemo { public static void main(String[] args) throws ExecutionException, InterruptedException, TimeoutException { FutureTask&lt;String&gt; futureTask = new FutureTask&lt;&gt;(() -&gt; { System.out.println(Thread.currentThread().getName() + \"--------come in\"); try { TimeUnit.SECONDS.sleep(5); } catch (InterruptedException e) { e.printStackTrace(); } return \"task over\"; }); Thread t1 = new Thread(futureTask, \"t1\"); t1.start(); // System.out.println(futureTask.get());//这样会有阻塞的可能，在程序没有计算完毕的情况下。 System.out.println(Thread.currentThread().getName() + \" ------忙其他任务\"); // System.out.println(futureTask.get(3,TimeUnit.SECONDS));//只愿意等待三秒，计算未完成直接抛出异常 while (true) {//轮询 if(futureTask.isDone()){ System.out.println(futureTask.get()); break; }else{ TimeUnit.MILLISECONDS.sleep(500); System.out.println(\"正在处理中，不要催了，越催越慢\"); } } /* 轮询结果 * main ------忙其他任务 t1--------come in 正在处理中，不要催了，越催越慢 正在处理中，不要催了，越催越慢 正在处理中，不要催了，越催越慢 正在处理中，不要催了，越催越慢 正在处理中，不要催了，越催越慢 正在处理中，不要催了，越催越慢 正在处理中，不要催了，越催越慢 正在处理中，不要催了，越催越慢 正在处理中，不要催了，越催越慢 正在处理中，不要催了，越催越慢 task over Process finished with exit code 0 * */ } } 1.2.4 完成一些复杂的任务●对于简单的业务场景使用Future完全ok ●回调通知： ​ ○应对Future的完成时间，完成了可以告诉我，也就是我们的回调通知 ​ ○通过轮询的方式去判断任务是否完成这样非常占cpu并且代码也不优雅 ●创建异步任务：Future+线程池组合 ●多个任务前后依赖可以组合处理（水煮鱼—&gt;买鱼—&gt;调料—&gt;下锅）： ​ ○想将多个异步任务的结果组合起来，后一个异步任务的计算结果需要钱一个异步任务的值 ​ ○想将两个或多个异步计算合并成为一个异步计算，这几个异步计算互相独立，同时后面这个又依赖前一个处理的结果 ●对计算速度选最快的： ​ ○当Future集合中某个任务最快结束时，返回结果，返回第一名处理结果 ●结论： ​ ○使用Future之前提供的那点API就囊中羞涩，处理起来不够优雅，这时候还是让CompletableFuture以声明式的方式优雅的处理这些需求。 ​ ○从i到i++ ​ ○Future能干的，CompletableFuture都能干 1.3 CompletableFuture对Future的改进1.3.1 CompletableFuture为什么会出现●get()方法在Future计算完成之前会一直处在阻塞状态下，阻塞的方式和异步编程的设计理念相违背。 ●isDene()方法容易耗费cpu资源（cpu空转）， ●对于真正的异步处理我们希望是可以通过传入回调函数，在Future结束时自动调用该回调函数，这样，我们就不用等待结果 jdk8设计出CompletableFuture，CompletableFuture提供了一种观察者模式类似的机制，可以让任务执行完成后通知监听的一方。 1.3.2 CompletableFuture和CompletionStage介绍类架构说明： ●接口CompletionStage ​ ○代表异步计算过程中的某一个阶段，一个阶段完成以后可能会触发另外一个阶段。 ​ ○一个阶段的执行可能是被单个阶段的完成触发，也可能是由多个阶段一起触发 ●类CompletableFuture ​ ○提供了非常强大的Future的扩展功能，可以帮助我们简化异步编程的复杂性，并且提供了函数式编程的能力，可以通过回调的方式处理计算结果，也提供了转换和组合CompletableFuture的方法 ​ ○它可能代表一个明确完成的Future，也可能代表一个完成阶段（CompletionStage），它支持在计算完成以后触发一些函数或执行某些动作 1.3.3 核心的四个静态方法，来创建一个异步任务四个静态构造方法 对于上述Executor参数说明：若没有指定，则使用默认的ForkJoinPoolcommonPool（）作为它的线程池执行异步代码，如果指定线程池，则使用我们自定义的或者特别指定的线程池执行异步代码 四个静态方法演示: public class CompletableFutureBuildDemo { public static void main(String[] args) throws ExecutionException, InterruptedException { ExecutorService executorService = Executors.newFixedThreadPool(3); CompletableFuture&lt;Void&gt; completableFuture = CompletableFuture.runAsync(() -&gt; { System.out.println(Thread.currentThread().getName()); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } },executorService); System.out.println(completableFuture.get()); //null CompletableFuture&lt;String&gt; objectCompletableFuture = CompletableFuture.supplyAsync(()-&gt;{ System.out.println(Thread.currentThread().getName()); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } return \"hello supplyAsync\"; },executorService); System.out.println(objectCompletableFuture.get());//hello supplyAsync executorService.shutdown(); } } CompletableFuture减少阻塞和轮询，可以传入回调对象，当异步任务完成或者发生异常时，自动调用回调对象的回调方法。 CompletableFuture使用演示: public class CompletableFutureUseDemo { public static void main(String[] args) throws ExecutionException, InterruptedException { ExecutorService executorService = Executors.newFixedThreadPool(3); CompletableFuture&lt;Integer&gt; completableFuture = CompletableFuture.supplyAsync(() -&gt; { System.out.println(Thread.currentThread().getName() + \"---come in\"); int result = ThreadLocalRandom.current().nextInt(10); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } if (result &gt; 5) { //模拟产生异常情况 int i = 10 / 0; } System.out.println(\"----------1秒钟后出结果\" + result); return result; }, executorService).whenComplete((v, e) -&gt; { if (e == null) { System.out.println(\"计算完成 更新系统\" + v); } }).exceptionally(e -&gt; { e.printStackTrace(); System.out.println(\"异常情况：\" + e.getCause() + \" \" + e.getMessage()); return null; }); System.out.println(Thread.currentThread().getName() + \"先去完成其他任务\"); executorService.shutdown(); } } /** * 无异常情况 * pool-1-thread-1---come in * main先去完成其他任务 * ----------1秒钟后出结果9 * 计算完成 更新系统9 */ /** * 有异常情况 *pool-1-thread-1---come in * main先去完成其他任务 * java.util.concurrent.CompletionException: java.lang.ArithmeticException: / by zero * 异常情况：java.lang.ArithmeticException: / by zero java.lang.ArithmeticException: / by zero */ CompletableFuture优点： ●异步任务结束时，会自动回调某个对象的方法 ●主线程设置好回调后，不用关心异步任务的执行，异步任务之间可以顺序执行 ●异步任务出错时，会自动回调某个对象的方法 1.4 案例精讲-从电商网站的比价需求展开1.4.1 函数式编程已成为主流Lambda表达式+Stream流式调用+Chain链式调用+Java8函数式编程 函数时接口： ●Runnable：无参数、无返回值 ●Function：接受一个参数，并且有返回值 ●Consumer：接受一个参数，没有返回值 ​ ○BiConsumer：接受两个参数，没有返回值 ●Supplier：没有参数，有返回值 小结： chain链式调用： public class CompletableFutureMallDemo { public static void main(String[] args) { Student student = new Student(); student.setId(1).setStudentName(\"z3\").setMajor(\"english\"); //链式调用 } } @AllArgsConstructor @NoArgsConstructor @Data @Accessors(chain = true)//开启链式调用 class Student { private Integer id; private String studentName; private String major; } 1.4.2 大厂业务需求说明切记：功能—&gt;性能（完成—&gt;完美） 电商网站比价需求分析： 1.需求说明： ​ a同一款产品，同时搜索出同款产品在各大电商平台的售价 ​ b同一款产品，同时搜索出本产品在同一个电商平台下，各个入驻卖家售价是多少 2.输出返回： ​ a出来结果希望是同款产品的在不同地方的价格清单列表，返回一个List ​ 例如：《Mysql》 in jd price is 88.05 《Mysql》 in taobao price is 90.43 3.解决方案，对比同一个产品在各个平台上的价格，要求获得一个清单列表 astep by step，按部就班，查完淘宝查京东，查完京东查天猫…. ball in，万箭齐发，一口气多线程异步任务同时查询 1.4.3 一波流Java8函数式编程带走-比价案例实战Case比价实战Case: public class CompletableFutureMallDemo { static List&lt;NetMall&gt; list = Arrays.asList(new NetMall(\"jd\"), new NetMall(\"taobao\"), new NetMall(\"dangdang\")); /** * step by step * @param list * @param productName * @return */ public static List&lt;String&gt; getPrice(List&lt;NetMall&gt; list, String productName) { //《Mysql》 in jd price is 88.05 return list .stream() .map(netMall -&gt; String.format(\"《\" + productName + \"》\" + \"in %s price is %.2f\", netMall.getNetMallName(), netMall.calcPrice(productName))) .collect(Collectors.toList()); } /** * all in * 把list里面的内容映射给CompletableFuture() * @param list * @param productName * @return */ public static List&lt;String&gt; getPriceByCompletableFuture(List&lt;NetMall&gt; list, String productName) { return list.stream().map(netMall -&gt; CompletableFuture.supplyAsync(() -&gt; String.format(\"《\" + productName + \"》\" + \"in %s price is %.2f\", netMall.getNetMallName(), netMall.calcPrice(productName)))) //Stream&lt;CompletableFuture&lt;String&gt;&gt; .collect(Collectors.toList()) //List&lt;CompletableFuture&lt;String&gt;&gt; .stream()//Stream&lt;String&gt; .map(s -&gt; s.join()).collect(Collectors.toList()); //List&lt;String&gt; } public static void main(String[] args) { /** * 采用step by setp方式查询 * 《masql》in jd price is 110.11 * 《masql》in taobao price is 109.32 * 《masql》in dangdang price is 109.24 * ------costTime: 3094 毫秒 */ long StartTime = System.currentTimeMillis(); List&lt;String&gt; list1 = getPrice(list, \"masql\"); for (String element : list1) { System.out.println(element); } long endTime = System.currentTimeMillis(); System.out.println(\"------costTime: \" + (endTime - StartTime) + \" 毫秒\"); /** * 采用 all in三个异步线程方式查询 * 《mysql》in jd price is 109.71 * 《mysql》in taobao price is 110.69 * 《mysql》in dangdang price is 109.28 * ------costTime1009 毫秒 */ long StartTime2 = System.currentTimeMillis(); List&lt;String&gt; list2 = getPriceByCompletableFuture(list, \"mysql\"); for (String element : list2) { System.out.println(element); } long endTime2 = System.currentTimeMillis(); System.out.println(\"------costTime\" + (endTime2 - StartTime2) + \" 毫秒\"); } } @AllArgsConstructor @NoArgsConstructor @Data class NetMall { private String netMallName; public double calcPrice(String productName) { try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } return ThreadLocalRandom.current().nextDouble() * 2 + productName.charAt(0); } } 1.4.4 CompletableFuture常用方法●获得结果和触发计算 ​ ○获取结果 ​ ■public T get() ​ ■public T get(long timeout,TimeUnit unit) ​ ■public T join() —&gt;和get一样的作用，只是不需要抛出异常 ​ ■public T getNow(T valuelfAbsent) —&gt;计算完成就返回正常值，否则返回备胎值（传入的参数），立即获取结果不阻塞 ​ ○主动触发计算 ​ ■public boolean complete(T value) —-&gt;是否打断get方法立即返回括号值 ●对计算结果进行处理 ​ ○thenApply —&gt;计算结果存在依赖关系，这两个线程串行化—-&gt;由于存在依赖关系（当前步错，不走下一步），当前步骤有异常的话就叫停 ​ ○handle —&gt;计算结果存在依赖关系，这两个线程串行化—-&gt;有异常也可以往下走一步 对计算结果进行处理演示: public class CompletableFutureApiDemo { public static void main(String[] args) throws ExecutionException, InterruptedException, TimeoutException { ExecutorService threadPool = Executors.newFixedThreadPool(3); CompletableFuture&lt;Integer&gt; completableFuture = CompletableFuture.supplyAsync(() -&gt; { try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } return 1; }, threadPool).thenApply(f -&gt; { System.out.println(\"222\"); return f + 2; }).handle((f, e) -&gt; { System.out.println(\"3333\"); int i=10/0; return f + 2; // thenApply(f -&gt; { // System.out.println(\"3333\"); // return f + 2; }).whenComplete((v, e) -&gt; { if (e == null) { System.out.println(\"----计算结果\" + v); } }).exceptionally(e -&gt; { e.printStackTrace(); System.out.println(e.getCause()); return null; }); System.out.println(Thread.currentThread().getName() + \"------主线程先去做其他事情\"); } } ●对计算结果进行消费 ​ ○接受任务的处理结果，并消费处理，无返回结果 ​ ○thenAccept thenAccetp演示: public class CompletableFutureApi2Demo { public static void main(String[] args) { ExecutorService threadPool = Executors.newFixedThreadPool(3); CompletableFuture.supplyAsync(() -&gt; { return 1; }, threadPool).thenApply(f -&gt; { return f + 2; }).thenApply(f -&gt; { return f + 2; }).thenAccept(r -&gt; { System.out.println(r);//5 }); } } ​ ○对比补充 ​ ■thenRun(Runnable runnable) :任务A执行完执行B，并且不需要A的结果 ​ ■thenAccept(Consumer action): 任务A执行完执行B，B需要A的结果，但是任务B没有返回值 ​ ■thenApply(Function fn): 任务A执行完执行B，B需要A的结果，同时任务B有返回值 对比补充: public class CompletableFutureApi2Demo { public static void main(String[] args) { System.out.println(CompletableFuture.supplyAsync(() -&gt; \"result\").thenRun(() -&gt; {}).join());//null System.out.println(CompletableFuture.supplyAsync(() -&gt; \"result\").thenAccept(r -&gt; System.out.println(r)).join());//result null System.out.println(CompletableFuture.supplyAsync(() -&gt; \"result\").thenApply(f -&gt; f + 2).join());//result2 } } ​ ○CompletableFuture和线程池说明 ​ ■如果没有传入自定义线程池，都用默认线程池ForkJoinPool ​ ■传入一个线程池，如果你执行第一个任务时，传入了一个自定义线程池 ●调用thenRun方法执行第二个任务时，则第二个任务和第一个任务时共用同一个线程池 ●调用thenRunAsync执行第二个任务时，则第一个任务使用的是你自定义的线程池，第二个任务使用的是ForkJoin线程池 ​ ■备注：可能是线程处理太快，系统优化切换原则， 直接使用main线程处理，thenAccept和thenAcceptAsync，thenApply和thenApplyAsync等，之间的区别同理。 ●对计算速度进行选用 ​ ○谁快用谁 ​ ○applyToEither applyToEither演示: public class CompletableFutureApiDemo { public static void main(String[] args) { ExecutorService threadPool = Executors.newFixedThreadPool(3); CompletableFuture&lt;String&gt; playA = CompletableFuture.supplyAsync(() -&gt; { try { System.out.println(\"A come in\"); TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } return \"playA\"; }, threadPool); CompletableFuture&lt;String&gt; playB = CompletableFuture.supplyAsync(() -&gt; { try { System.out.println(\"B come in\"); TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { e.printStackTrace(); } return \"playB\"; }, threadPool); CompletableFuture&lt;String&gt; result = playA.applyToEither(playB, f -&gt; { return f + \" is winner\"; }); /** * A come in * B come in * main-----------winner:playA is winner */ System.out.println(Thread.currentThread().getName() + \"-----------winner:\" + result.join()); } } ●对计算结果进行合并 ​ ○两个CompletableStage任务都完成后，最终能把两个任务的结果一起交给thenCombine来处理 ​ ○先完成的先等着，等待其他分支任务 thenCombine演示: public class CompletableFutureApi3Demo { public static void main(String[] args) { CompletableFuture&lt;Integer&gt; completableFuture1 = CompletableFuture.supplyAsync(() -&gt; { System.out.println(Thread.currentThread().getName() + \" 启动\"); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } return 10; }); CompletableFuture&lt;Integer&gt; completableFuture2 = CompletableFuture.supplyAsync(() -&gt; { System.out.println(Thread.currentThread().getName() + \" 启动\"); try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } return 20; }); CompletableFuture&lt;Integer&gt; finalResult = completableFuture1.thenCombine(completableFuture2, (x, y) -&gt; { System.out.println(\"----------开始两个结果合并\"); return x + y; }); System.out.println(finalResult.join()); } }","categories":[],"tags":[{"name":"JUC并发编程","slug":"JUC并发编程","permalink":"https://gitee.com/yunyd/tags/JUC%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"author":"llllz."},{"title":"Spring复习 -3","slug":"Spring复习  -3","date":"2023-07-27T11:47:32.000Z","updated":"2023-08-25T00:23:20.944Z","comments":true,"path":"posts/312bf285.html","link":"","permalink":"https://gitee.com/yunyd/posts/312bf285.html","excerpt":"","text":"Spring复习1. AOP简介前面我们在介绍Spring的时候说过，Spring有两个核心的概念，一个是IOC/DI，一个是AOP。 前面已经对IOC/DI进行了系统的学习，接下来要学习它的另一个核心内容，就是==AOP==。 对于AOP,我们前面提过一句话是:==AOP是在不改原有代码的前提下对其进行增强。== 对于下面的内容，我们主要就是围绕着这一句话进行展开学习，主要学习两方面内容AOP核心概念,AOP作用: 1.1 什么是AOP? AOP(Aspect Oriented Programming)面向切面编程，一种编程范式，指导开发者如何组织程序结构。 OOP(Object Oriented Programming)面向对象编程 我们都知道OOP是一种编程思想，那么AOP也是一种编程思想，编程思想主要的内容就是指导程序员该如何编写程序，所以它们两个是不同的编程范式。 1.2 AOP作用 作用:在不惊动原始设计的基础上为其进行功能增强，前面咱们有技术就可以实现这样的功能即代理模式。 前面咱们有技术就可以实现这样的功能即代理模式。 1.3 AOP核心概念为了能更好的理解AOP的相关概念，我们准备了一个环境，整个环境的内容我们暂时可以不用关注，最主要的类为:BookDaoImpl @Repository public class BookDaoImpl implements BookDao { public void save() { //记录程序当前执行执行（开始时间） Long startTime = System.currentTimeMillis(); //业务执行万次 for (int i = 0;i&lt;10000;i++) { System.out.println(\"book dao save ...\"); } //记录程序当前执行时间（结束时间） Long endTime = System.currentTimeMillis(); //计算时间差 Long totalTime = endTime-startTime; //输出信息 System.out.println(\"执行万次消耗时间：\" + totalTime + \"ms\"); } public void update(){ System.out.println(\"book dao update ...\"); } public void delete(){ System.out.println(\"book dao delete ...\"); } public void select(){ System.out.println(\"book dao select ...\"); } } 代码的内容相信大家都能够读懂，对于save方法中有计算万次执行消耗的时间。 当在App类中从容器中获取bookDao对象后，分别执行其save,delete,update和select方法后会有如下的打印结果: 这个时候，我们就应该有些疑问? 对于计算万次执行消耗的时间只有save方法有，为什么delete和update方法也会有呢? delete和update方法有，那什么select方法为什么又没有呢? 这个案例中其实就使用了Spring的AOP，在不惊动(改动)原有设计(代码)的前提下，想给谁添加功能就给谁添加。这个也就是Spring的理念： 无入侵式/无侵入式 说了这么多，Spring到底是如何实现的呢? (1)前面一直在强调，Spring的AOP是对一个类的方法在不进行任何修改的前提下实现增强。对于上面的案例中BookServiceImpl中有save,update,delete和select方法,这些方法我们给起了一个名字叫==连接点== (2)在BookServiceImpl的四个方法中，update和delete只有打印没有计算万次执行消耗时间，但是在运行的时候已经有该功能，那也就是说update和delete方法都已经被增强，所以对于需要增强的方法我们给起了一个名字叫==切入点== (3)执行BookServiceImpl的update和delete方法的时候都被添加了一个计算万次执行消耗时间的功能，将这个功能抽取到一个方法中，换句话说就是存放共性功能的方法，我们给起了个名字叫==通知== (4)通知是要增强的内容，会有多个，切入点是需要被增强的方法，也会有多个，那哪个切入点需要添加哪个通知，就需要提前将它们之间的关系描述清楚，那么对于通知和切入点之间的关系描述，我们给起了个名字叫==切面== (5)通知是一个方法，方法不能独立存在需要被写在一个类中，这个类我们也给起了个名字叫==通知类== 至此AOP中的核心概念就已经介绍完了，总结下: 连接点(JoinPoint)：程序执行过程中的任意位置，粒度为执行方法、抛出异常、设置变量等 在SpringAOP中，理解为方法的执行 切入点(Pointcut):匹配连接点的式子 在SpringAOP中，一个切入点可以描述一个具体方法，也可也匹配多个方法 一个具体的方法:如com.itheima.dao包下的BookDao接口中的无形参无返回值的save方法 匹配多个方法:所有的save方法，所有的get开头的方法，所有以Dao结尾的接口中的任意方法，所有带有一个参数的方法 连接点范围要比切入点范围大，是切入点的方法也一定是连接点，但是是连接点的方法就不一定要被增强，所以可能不是切入点。 通知(Advice):在切入点处执行的操作，也就是共性功能 在SpringAOP中，功能最终以方法的形式呈现 通知类：定义通知的类 切面(Aspect):描述通知与切入点的对应关系。 小结 这一节中主要讲解了AOP的概念与作用，以及AOP中的核心概念，学完以后大家需要能说出: 什么是AOP? AOP的作用是什么? AOP中核心概念分别指的是什么? 连接点 切入点 通知 通知类 切面 2. AOP入门案例2.1 需求分析案例设定：测算接口执行效率，但是这个案例稍微复杂了点，我们对其进行简化。 简化设定：在方法执行前输出当前系统时间。 对于SpringAOP的开发有两种方式，XML 和 ==注解==，我们使用哪个呢? 因为现在注解使用的比较多，所以本次课程就采用注解完成AOP的开发。 总结需求为:使用SpringAOP的注解方式完成在方法执行的前打印出当前系统时间。 2.2 思路分析需求明确后，具体该如何实现，都有哪些步骤，我们先来分析下: 1.导入坐标(pom.xml) 2.制作连接点(原始操作，Dao接口与实现类) 3.制作共性功能(通知类与通知) 4.定义切入点 5.绑定切入点与通知关系(切面) 2.3 环境准备 创建一个Maven项目 pom.xml添加Spring依赖 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 添加BookDao和BookDaoImpl类 public interface BookDao { public void save(); public void update(); } @Repository public class BookDaoImpl implements BookDao { public void save() { System.out.println(System.currentTimeMillis()); System.out.println(\"book dao save ...\"); } public void update(){ System.out.println(\"book dao update ...\"); } } 创建Spring的配置类 @Configuration @ComponentScan(\"com.itheima\") public class SpringConfig { } 编写App运行类 public class App { public static void main(String[] args) { ApplicationContext ctx = new AnnotationConfigApplicationContext(SpringConfig.class); BookDao bookDao = ctx.getBean(BookDao.class); bookDao.save(); } } 最终创建好的项目结构如下: 说明: 目前打印save方法的时候，因为方法中有打印系统时间，所以运行的时候是可以看到系统时间 对于update方法来说，就没有该功能 我们要使用SpringAOP的方式在不改变update方法的前提下让其具有打印系统时间的功能。 2.4 AOP实现步骤步骤1:添加依赖pom.xml &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.9.4&lt;/version&gt; &lt;/dependency&gt; 因为spring-context中已经导入了spring-aop,所以不需要再单独导入spring-aop 导入AspectJ的jar包,AspectJ是AOP思想的一个具体实现，Spring有自己的AOP实现，但是相比于AspectJ来说比较麻烦，所以我们直接采用Spring整合ApsectJ的方式进行AOP开发。 步骤2:定义接口与实现类环境准备的时候，BookDaoImpl已经准备好，不需要做任何修改 步骤3:定义通知类和通知通知就是将共性功能抽取出来后形成的方法，共性功能指的就是当前系统时间的打印。 public class MyAdvice { public void method(){ System.out.println(System.currentTimeMillis()); } } 类名和方法名没有要求，可以任意。 步骤4:定义切入点BookDaoImpl中有两个方法，分别是save和update，我们要增强的是update方法，该如何定义呢? public class MyAdvice { @Pointcut(\"execution(void com.itheima.dao.BookDao.update())\") private void pt(){} public void method(){ System.out.println(System.currentTimeMillis()); } } 说明: 切入点定义依托一个不具有实际意义的方法进行，即无参数、无返回值、方法体无实际逻辑。 execution及后面编写的内容，后面会有章节专门去学习。 步骤5:制作切面切面是用来描述通知和切入点之间的关系，如何进行关系的绑定? public class MyAdvice { @Pointcut(\"execution(void com.itheima.dao.BookDao.update())\") private void pt(){} @Before(\"pt()\") public void method(){ System.out.println(System.currentTimeMillis()); } } 绑定切入点与通知关系，并指定通知添加到原始连接点的具体执行==位置== 说明:@Before翻译过来是之前，也就是说通知会在切入点方法执行之前执行，除此之前还有其他四种类型，后面会讲。 步骤6:将通知类配给容器并标识其为切面类@Component @Aspect public class MyAdvice { @Pointcut(\"execution(void com.itheima.dao.BookDao.update())\") private void pt(){} @Before(\"pt()\") public void method(){ System.out.println(System.currentTimeMillis()); } } 步骤7:开启注解格式AOP功能@Configuration @ComponentScan(\"com.itheima\") @EnableAspectJAutoProxy public class SpringConfig { } 步骤8:运行程序public class App { public static void main(String[] args) { ApplicationContext ctx = new AnnotationConfigApplicationContext(SpringConfig.class); BookDao bookDao = ctx.getBean(BookDao.class); bookDao.update(); } } 看到在执行update方法之前打印了系统时间戳，说明对原始方法进行了增强，AOP编程成功。 知识点1：@EnableAspectJAutoProxy 名称 @EnableAspectJAutoProxy 类型 配置类注解 位置 配置类定义上方 作用 开启注解格式AOP功能 知识点2：@Aspect 名称 @Aspect 类型 类注解 位置 切面类定义上方 作用 设置当前类为AOP切面类 知识点3：@Pointcut 名称 @Pointcut 类型 方法注解 位置 切入点方法定义上方 作用 设置切入点方法 属性 value（默认）：切入点表达式 知识点4：@Before 名称 @Before 类型 方法注解 位置 通知方法定义上方 作用 设置当前通知方法与切入点之间的绑定关系，当前通知方法在原始切入点方法前运行 3. AOP工作流程AOP的入门案例已经完成，对于刚才案例的执行过程，我们就得来分析分析，这一节我们主要讲解两个知识点:AOP工作流程和AOP核心概念。其中核心概念是对前面核心概念的补充。 3.1 AOP工作流程由于AOP是基于Spring容器管理的bean做的增强，所以整个工作过程需要从Spring加载bean说起: 流程1:Spring容器启动 容器启动就需要去加载bean,哪些类需要被加载呢? 需要被增强的类，如:BookServiceImpl 通知类，如:MyAdvice 注意此时bean对象还没有创建成功 流程2:读取所有切面配置中的切入点 上面这个例子中有两个切入点的配置，但是第一个ptx()并没有被使用，所以不会被读取。 流程3:初始化bean，判定bean对应的类中的方法是否匹配到任意切入点 注意第1步在容器启动的时候，bean对象还没有被创建成功。 要被实例化bean对象的类中的方法和切入点进行匹配 匹配失败，创建原始对象,如UserDao 匹配失败说明不需要增强，直接调用原始对象的方法即可。 匹配成功，创建原始对象（==目标对象==）的==代理==对象,如:BookDao 匹配成功说明需要对其进行增强 对哪个类做增强，这个类对应的对象就叫做目标对象 因为要对目标对象进行功能增强，而采用的技术是动态代理，所以会为其创建一个代理对象 最终运行的是代理对象的方法，在该方法中会对原始方法进行功能增强 流程4:获取bean执行方法 获取的bean是原始对象时，调用方法并执行，完成操作 获取的bean是代理对象时，根据代理对象的运行模式运行原始方法与增强的内容，完成操作 验证容器中是否为代理对象为了验证IOC容器中创建的对象和我们刚才所说的结论是否一致，首先先把结论理出来: 如果目标对象中的方法会被增强，那么容器中将存入的是目标对象的代理对象 如果目标对象中的方法不被增强，那么容器中将存入的是目标对象本身。 验证思路 1.要执行的方法，不被定义的切入点包含，即不要增强，打印当前类的getClass()方法 2.要执行的方法，被定义的切入点包含，即要增强，打印出当前类的getClass()方法 3.观察两次打印的结果 步骤1:修改App类,获取类的类型public class App { public static void main(String[] args) { ApplicationContext ctx = new AnnotationConfigApplicationContext(SpringConfig.class); BookDao bookDao = ctx.getBean(BookDao.class); System.out.println(bookDao); System.out.println(bookDao.getClass()); } } 步骤2:修改MyAdvice类，不增强因为定义的切入点中，被修改成update1,所以BookDao中的update方法在执行的时候，就不会被增强， 所以容器中的对象应该是目标对象本身。 @Component @Aspect public class MyAdvice { @Pointcut(\"execution(void com.itheima.dao.BookDao.update1())\") private void pt(){} @Before(\"pt()\") public void method(){ System.out.println(System.currentTimeMillis()); } } 步骤3:运行程序 步骤4:修改MyAdvice类，增强因为定义的切入点中，被修改成update,所以BookDao中的update方法在执行的时候，就会被增强， 所以容器中的对象应该是目标对象的代理对象 @Component @Aspect public class MyAdvice { @Pointcut(\"execution(void com.itheima.dao.BookDao.update())\") private void pt(){} @Before(\"pt()\") public void method(){ System.out.println(System.currentTimeMillis()); } } 步骤5:运行程序 至此对于刚才的结论，我们就得到了验证，这块大家需要注意的是: 不能直接打印对象，从上面两次结果中可以看出，直接打印对象走的是对象的toString方法，不管是不是代理对象打印的结果都是一样的，原因是内部对toString方法进行了重写。 3.2 AOP核心概念在上面介绍AOP的工作流程中，我们提到了两个核心概念，分别是: 目标对象(Target)：原始功能去掉共性功能对应的类产生的对象，这种对象是无法直接完成最终工作的 代理(Proxy)：目标对象无法直接完成工作，需要对其进行功能回填，通过原始对象的代理对象实现 上面这两个概念比较抽象，简单来说， 目标对象就是要增强的类[如:BookServiceImpl类]对应的对象，也叫原始对象，不能说它不能运行，只能说它在运行的过程中对于要增强的内容是缺失的。 SpringAOP是在不改变原有设计(代码)的前提下对其进行增强的，它的底层采用的是代理模式实现的，所以要对原始对象进行增强，就需要对原始对象创建代理对象，在代理对象中的方法把通知[如:MyAdvice中的method方法]内容加进去，就实现了增强,这就是我们所说的代理(Proxy)。 小结 通过这一节中，我们需要掌握的内容有： 能说出AOP的工作流程 AOP的核心概念 目标对象、连接点、切入点 通知类、通知 切面 代理 SpringAOP的本质或者可以说底层实现是通过代理模式。 4. AOP配置管理4.1 AOP切入点表达式前面的案例中，有涉及到如下内容: 对于AOP中切入点表达式，我们总共会学习三个内容，分别是语法格式、通配符和书写技巧。 4.1.1 语法格式首先我们先要明确两个概念: 切入点:要进行增强的方法 切入点表达式:要进行增强的方法的描述方式 对于切入点的描述，我们其实是有两中方式的，先来看下前面的例子 描述方式一：执行com.itheima.dao包下的BookDao接口中的无参数update方法 execution(void com.itheima.dao.BookDao.update()) 描述方式二：执行com.itheima.dao.impl包下的BookDaoImpl类中的无参数update方法 execution(void com.itheima.dao.impl.BookDaoImpl.update()) 因为调用接口方法的时候最终运行的还是其实现类的方法，所以上面两种描述方式都是可以的。 对于切入点表达式的语法为: 切入点表达式标准格式：动作关键字(访问修饰符 返回值 包名.类/接口名.方法名(参数) 异常名） 对于这个格式，我们不需要硬记，通过一个例子，理解它: execution(public User com.itheima.service.UserService.findById(int)) execution：动作关键字，描述切入点的行为动作，例如execution表示执行到指定切入点 public:访问修饰符,还可以是public，private等，可以省略 User：返回值，写返回值类型 com.itheima.service：包名，多级包使用点连接 UserService:类/接口名称 findById：方法名 int:参数，直接写参数的类型，多个类型用逗号隔开 异常名：方法定义中抛出指定异常，可以省略 切入点表达式就是要找到需要增强的方法，所以它就是对一个具体方法的描述，但是方法的定义会有很多，所以如果每一个方法对应一个切入点表达式，想想这块就会觉得将来编写起来会比较麻烦，有没有更简单的方式呢? 就需要用到下面所学习的通配符。 4.1.2 通配符我们使用通配符描述切入点，主要的目的就是简化之前的配置，具体都有哪些通配符可以使用? *:单个独立的任意符号，可以独立出现，也可以作为前缀或者后缀的匹配符出现 execution（public * com.itheima.*.UserService.find*(*)) 匹配com.itheima包下的任意包中的UserService类或接口中所有find开头的带有一个参数的方法 ..：多个连续的任意符号，可以独立出现，常用于简化包名与参数的书写 execution（public User com..UserService.findById(..)) 匹配com包下的任意包中的UserService类或接口中所有名称为findById的方法 +：专用于匹配子类类型 execution(* *..*Service+.*(..)) 这个使用率较低，描述子类的，咱们做JavaEE开发，继承机会就一次，使用都很慎重，所以很少用它。*Service+，表示所有以Service结尾的接口的子类。 接下来，我们把案例中使用到的切入点表达式来分析下: execution(void com.itheima.dao.BookDao.update()) 匹配接口，能匹配到 execution(void com.itheima.dao.impl.BookDaoImpl.update()) 匹配实现类，能匹配到 execution(* com.itheima.dao.impl.BookDaoImpl.update()) 返回值任意，能匹配到 execution(* com.itheima.dao.impl.BookDaoImpl.update(*)) 返回值任意，但是update方法必须要有一个参数，无法匹配，要想匹配需要在update接口和实现类添加参数 execution(void com.*.*.*.*.update()) 返回值为void,com包下的任意包三层包下的任意类的update方法，匹配到的是实现类，能匹配 execution(void com.*.*.*.update()) 返回值为void,com包下的任意两层包下的任意类的update方法，匹配到的是接口，能匹配 execution(void *..update()) 返回值为void，方法名是update的任意包下的任意类，能匹配 execution(* *..*(..)) 匹配项目中任意类的任意方法，能匹配，但是不建议使用这种方式，影响范围广 execution(* *..u*(..)) 匹配项目中任意包任意类下只要以u开头的方法，update方法能满足，能匹配 execution(* *..*e(..)) 匹配项目中任意包任意类下只要以e结尾的方法，update和save方法能满足，能匹配 execution(void com..*()) 返回值为void，com包下的任意包任意类任意方法，能匹配，*代表的是方法 execution(* com.itheima.*.*Service.find*(..)) 将项目中所有业务层方法的以find开头的方法匹配 execution(* com.itheima.*.*Service.save*(..)) 将项目中所有业务层方法的以save开头的方法匹配 后面两种更符合我们平常切入点表达式的编写规则 4.1.3 书写技巧对于切入点表达式的编写其实是很灵活的，那么在编写的时候，有没有什么好的技巧让我们用用: 所有代码按照标准规范开发，否则以下技巧全部失效 描述切入点通**==常描述接口==**，而不描述实现类,如果描述到实现类，就出现紧耦合了 访问控制修饰符针对接口开发均采用public描述（**==可省略访问控制修饰符描述==**） 返回值类型对于增删改类使用精准类型加速匹配，对于查询类使用*通配快速描述 ==包名==**书写==尽量不使用..匹配==*，效率过低，常用\\做单个包描述匹配，或精准匹配 ==接口名/类名==**书写名称与模块相关的==采用*匹配==*，例如UserService书写成\\Service，绑定业务层接口名 ==方法名==**书写以==动词==进行==精准匹配==*，名词采用匹配，例如getById书写成getBy*,selectAll书写成selectAll 参数规则较为复杂，根据业务方法灵活调整 通常**==不使用异常==作为==匹配==**规则 4.2 AOP通知类型前面的案例中，有涉及到如下内容: 它所代表的含义是将通知添加到切入点方法执行的==前面==。 除了这个注解外，还有没有其他的注解，换个问题就是除了可以在前面加，能不能在其他的地方加? 4.2.1 类型介绍我们先来回顾下AOP通知: AOP通知描述了抽取的共性功能，根据共性功能抽取的位置不同，最终运行代码时要将其加入到合理的位置 通知具体要添加到切入点的哪里? 共提供了5种通知类型: 前置通知 后置通知 ==环绕通知(重点)== 返回后通知(了解) 抛出异常后通知(了解) 为了更好的理解这几种通知类型，我们来看一张图 (1)前置通知，追加功能到方法执行前,类似于在代码1或者代码2添加内容 (2)后置通知,追加功能到方法执行后,不管方法执行的过程中有没有抛出异常都会执行，类似于在代码5添加内容 (3)返回后通知,追加功能到方法执行后，只有方法正常执行结束后才进行,类似于在代码3添加内容，如果方法执行抛出异常，返回后通知将不会被添加 (4)抛出异常后通知,追加功能到方法抛出异常后，只有方法执行出异常才进行,类似于在代码4添加内容，只有方法抛出异常后才会被添加 (5)环绕通知,环绕通知功能比较强大，它可以追加功能到方法执行的前后，这也是比较常用的方式，它可以实现其他四种通知类型的功能，具体是如何实现的，需要我们往下学习。 4.2.2 环境准备 创建一个Maven项目 pom.xml添加Spring依赖 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.9.4&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 添加BookDao和BookDaoImpl类 public interface BookDao { public void update(); public int select(); } @Repository public class BookDaoImpl implements BookDao { public void update(){ System.out.println(\"book dao update ...\"); } public int select() { System.out.println(\"book dao select is running ...\"); return 100; } } 创建Spring的配置类 @Configuration @ComponentScan(\"com.itheima\") @EnableAspectJAutoProxy public class SpringConfig { } 创建通知类 @Component @Aspect public class MyAdvice { @Pointcut(\"execution(void com.itheima.dao.BookDao.update())\") private void pt(){} public void before() { System.out.println(\"before advice ...\"); } public void after() { System.out.println(\"after advice ...\"); } public void around(){ System.out.println(\"around before advice ...\"); System.out.println(\"around after advice ...\"); } public void afterReturning() { System.out.println(\"afterReturning advice ...\"); } public void afterThrowing() { System.out.println(\"afterThrowing advice ...\"); } } 编写App运行类 public class App { public static void main(String[] args) { ApplicationContext ctx = new AnnotationConfigApplicationContext(SpringConfig.class); BookDao bookDao = ctx.getBean(BookDao.class); bookDao.update(); } } 最终创建好的项目结构如下: 4.2.3 通知类型的使用前置通知修改MyAdvice,在before方法上添加@Before注解 @Component @Aspect public class MyAdvice { @Pointcut(\"execution(void com.itheima.dao.BookDao.update())\") private void pt(){} @Before(\"pt()\") //此处也可以写成 @Before(\"MyAdvice.pt()\"),不建议 public void before() { System.out.println(\"before advice ...\"); } } 后置通知@Component @Aspect public class MyAdvice { @Pointcut(\"execution(void com.itheima.dao.BookDao.update())\") private void pt(){} @Before(\"pt()\") public void before() { System.out.println(\"before advice ...\"); } @After(\"pt()\") public void after() { System.out.println(\"after advice ...\"); } } 环绕通知基本使用@Component @Aspect public class MyAdvice { @Pointcut(\"execution(void com.itheima.dao.BookDao.update())\") private void pt(){} @Around(\"pt()\") public void around(){ System.out.println(\"around before advice ...\"); System.out.println(\"around after advice ...\"); } } 运行结果中，通知的内容打印出来，但是原始方法的内容却没有被执行。 因为环绕通知需要在原始方法的前后进行增强，所以环绕通知就必须要能对原始操作进行调用，具体如何实现? @Component @Aspect public class MyAdvice { @Pointcut(\"execution(void com.itheima.dao.BookDao.update())\") private void pt(){} @Around(\"pt()\") public void around(ProceedingJoinPoint pjp) throws Throwable{ System.out.println(\"around before advice ...\"); //表示对原始操作的调用 pjp.proceed(); System.out.println(\"around after advice ...\"); } } **说明:**proceed()为什么要抛出异常? 原因很简单，看下源码就知道了 再次运行，程序可以看到原始方法已经被执行了 注意事项(1)原始方法有返回值的处理 修改MyAdvice,对BookDao中的select方法添加环绕通知， @Component @Aspect public class MyAdvice { @Pointcut(\"execution(void com.itheima.dao.BookDao.update())\") private void pt(){} @Pointcut(\"execution(int com.itheima.dao.BookDao.select())\") private void pt2(){} @Around(\"pt2()\") public void aroundSelect(ProceedingJoinPoint pjp) throws Throwable { System.out.println(\"around before advice ...\"); //表示对原始操作的调用 pjp.proceed(); System.out.println(\"around after advice ...\"); } } 修改App类，调用select方法 public class App { public static void main(String[] args) { ApplicationContext ctx = new AnnotationConfigApplicationContext(SpringConfig.class); BookDao bookDao = ctx.getBean(BookDao.class); int num = bookDao.select(); System.out.println(num); } } 运行后会报错，错误内容为: Exception in thread “main” org.springframework.aop.AopInvocationException: ==Null return value from advice does not match primitive return type for: public abstract int com.itheima.dao.BookDao.select()== at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:226) at com.sun.proxy.$Proxy19.select(Unknown Source) at com.itheima.App.main(App.java:12) 错误大概的意思是:空的返回不匹配原始方法的int返回 void就是返回Null 原始方法就是BookDao下的select方法 所以如果我们使用环绕通知的话，要根据原始方法的返回值来设置环绕通知的返回值，具体解决方案为: @Component @Aspect public class MyAdvice { @Pointcut(\"execution(void com.itheima.dao.BookDao.update())\") private void pt(){} @Pointcut(\"execution(int com.itheima.dao.BookDao.select())\") private void pt2(){} @Around(\"pt2()\") public Object aroundSelect(ProceedingJoinPoint pjp) throws Throwable { System.out.println(\"around before advice ...\"); //表示对原始操作的调用 Object ret = pjp.proceed(); System.out.println(\"around after advice ...\"); return ret; } } 说明: ​ 为什么返回的是Object而不是int的主要原因是Object类型更通用。 ​ 在环绕通知中是可以对原始方法返回值就行修改的。 返回后通知@Component @Aspect public class MyAdvice { @Pointcut(\"execution(void com.itheima.dao.BookDao.update())\") private void pt(){} @Pointcut(\"execution(int com.itheima.dao.BookDao.select())\") private void pt2(){} @AfterReturning(\"pt2()\") public void afterReturning() { System.out.println(\"afterReturning advice ...\"); } } 注意：返回后通知是需要在原始方法select正常执行后才会被执行，如果select()方法执行的过程中出现了异常，那么返回后通知是不会被执行。后置通知是不管原始方法有没有抛出异常都会被执行。这个案例大家下去可以自己练习验证下。 异常后通知@Component @Aspect public class MyAdvice { @Pointcut(\"execution(void com.itheima.dao.BookDao.update())\") private void pt(){} @Pointcut(\"execution(int com.itheima.dao.BookDao.select())\") private void pt2(){} @AfterReturning(\"pt2()\") public void afterThrowing() { System.out.println(\"afterThrowing advice ...\"); } } 注意：异常后通知是需要原始方法抛出异常，可以在select()方法中添加一行代码int i = 1/0即可。如果没有抛异常，异常后通知将不会被执行。 学习完这5种通知类型，我们来思考下环绕通知是如何实现其他通知类型的功能的? 因为环绕通知是可以控制原始方法执行的，所以我们把增强的代码写在调用原始方法的不同位置就可以实现不同的通知类型的功能，如: 通知类型总结知识点1：@After 名称 @After 类型 方法注解 位置 通知方法定义上方 作用 设置当前通知方法与切入点之间的绑定关系，当前通知方法在原始切入点方法后运行 知识点2：@AfterReturning 名称 @AfterReturning 类型 方法注解 位置 通知方法定义上方 作用 设置当前通知方法与切入点之间绑定关系，当前通知方法在原始切入点方法正常执行完毕后执行 知识点3：@AfterThrowing 名称 @AfterThrowing 类型 方法注解 位置 通知方法定义上方 作用 设置当前通知方法与切入点之间绑定关系，当前通知方法在原始切入点方法运行抛出异常后执行 知识点4：@Around 名称 @Around 类型 方法注解 位置 通知方法定义上方 作用 设置当前通知方法与切入点之间的绑定关系，当前通知方法在原始切入点方法前后运行 ==环绕通知注意事项== 环绕通知必须依赖形参ProceedingJoinPoint才能实现对原始方法的调用，进而实现原始方法调用前后同时添加通知 通知中如果未使用ProceedingJoinPoint对原始方法进行调用将跳过原始方法的执行 对原始方法的调用可以不接收返回值，通知方法设置成void即可，如果接收返回值，最好设定为Object类型 原始方法的返回值如果是void类型，通知方法的返回值类型可以设置成void,也可以设置成Object 由于无法预知原始方法运行后是否会抛出异常，因此环绕通知方法必须要处理Throwable异常 介绍完这么多种通知类型，具体该选哪一种呢? 我们可以通过一些案例加深下对通知类型的学习。 4.3 业务层接口执行效率4.3.1 需求分析这个需求也比较简单，前面我们在介绍AOP的时候已经演示过: 需求:任意业务层接口执行均可显示其执行效率（执行时长） 这个案例的目的是查看每个业务层执行的时间，这样就可以监控出哪个业务比较耗时，将其查找出来方便优化。 具体实现的思路: (1) 开始执行方法之前记录一个时间 (2) 执行方法 (3) 执行完方法之后记录一个时间 (4) 用后一个时间减去前一个时间的差值，就是我们需要的结果。 所以要在方法执行的前后添加业务，经过分析我们将采用环绕通知。 **说明:**原始方法如果只执行一次，时间太快，两个时间差可能为0，所以我们要执行万次来计算时间差。 4.3.2 环境准备 创建一个Maven项目 pom.xml添加Spring依赖 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.9.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.16&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 添加AccountService、AccountServiceImpl、AccountDao与Account类 public interface AccountService { void save(Account account); void delete(Integer id); void update(Account account); List&lt;Account&gt; findAll(); Account findById(Integer id); } @Service public class AccountServiceImpl implements AccountService { @Autowired private AccountDao accountDao; public void save(Account account) { accountDao.save(account); } public void update(Account account){ accountDao.update(account); } public void delete(Integer id) { accountDao.delete(id); } public Account findById(Integer id) { return accountDao.findById(id); } public List&lt;Account&gt; findAll() { return accountDao.findAll(); } } public interface AccountDao { @Insert(\"insert into tbl_account(name,money)values(#{name},#{money})\") void save(Account account); @Delete(\"delete from tbl_account where id = #{id} \") void delete(Integer id); @Update(\"update tbl_account set name = #{name} , money = #{money} where id = #{id} \") void update(Account account); @Select(\"select * from tbl_account\") List&lt;Account&gt; findAll(); @Select(\"select * from tbl_account where id = #{id} \") Account findById(Integer id); } public class Account implements Serializable { private Integer id; private String name; private Double money; //setter..getter..toString方法省略 } resources下提供一个jdbc.properties jdbc.driver=com.mysql.jdbc.Driver jdbc.url=jdbc:mysql://localhost:3306/spring_db?useSSL=false jdbc.username=root jdbc.password=root 创建相关配置类 //Spring配置类:SpringConfig @Configuration @ComponentScan(\"com.itheima\") @PropertySource(\"classpath:jdbc.properties\") @Import({JdbcConfig.class,MybatisConfig.class}) public class SpringConfig { } //JdbcConfig配置类 public class JdbcConfig { @Value(\"${jdbc.driver}\") private String driver; @Value(\"${jdbc.url}\") private String url; @Value(\"${jdbc.username}\") private String userName; @Value(\"${jdbc.password}\") private String password; @Bean public DataSource dataSource(){ DruidDataSource ds = new DruidDataSource(); ds.setDriverClassName(driver); ds.setUrl(url); ds.setUsername(userName); ds.setPassword(password); return ds; } } //MybatisConfig配置类 public class MybatisConfig { @Bean public SqlSessionFactoryBean sqlSessionFactory(DataSource dataSource){ SqlSessionFactoryBean ssfb = new SqlSessionFactoryBean(); ssfb.setTypeAliasesPackage(\"com.itheima.domain\"); ssfb.setDataSource(dataSource); return ssfb; } @Bean public MapperScannerConfigurer mapperScannerConfigurer(){ MapperScannerConfigurer msc = new MapperScannerConfigurer(); msc.setBasePackage(\"com.itheima.dao\"); return msc; } } 编写Spring整合Junit的测试类 @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(classes = SpringConfig.class) public class AccountServiceTestCase { @Autowired private AccountService accountService; @Test public void testFindById(){ Account ac = accountService.findById(2); } @Test public void testFindAll(){ List&lt;Account&gt; all = accountService.findAll(); } } 最终创建好的项目结构如下: 4.3.3 功能开发步骤1:开启SpringAOP的注解功能在Spring的主配置文件SpringConfig类中添加注解 @EnableAspectJAutoProxy 步骤2:创建AOP的通知类 该类要被Spring管理，需要添加@Component 要标识该类是一个AOP的切面类，需要添加@Aspect 配置切入点表达式，需要添加一个方法，并添加@Pointcut @Component @Aspect public class ProjectAdvice { //配置业务层的所有方法 @Pointcut(\"execution(* com.itheima.service.*Service.*(..))\") private void servicePt(){} public void runSpeed(){ } } 步骤3:添加环绕通知在runSpeed()方法上添加@Around @Component @Aspect public class ProjectAdvice { //配置业务层的所有方法 @Pointcut(\"execution(* com.itheima.service.*Service.*(..))\") private void servicePt(){} //@Around(\"ProjectAdvice.servicePt()\") 可以简写为下面的方式 @Around(\"servicePt()\") public Object runSpeed(ProceedingJoinPoint pjp){ Object ret = pjp.proceed(); return ret; } } **注意:**目前并没有做任何增强 步骤4:完成核心业务，记录万次执行的时间@Component @Aspect public class ProjectAdvice { //配置业务层的所有方法 @Pointcut(\"execution(* com.itheima.service.*Service.*(..))\") private void servicePt(){} //@Around(\"ProjectAdvice.servicePt()\") 可以简写为下面的方式 @Around(\"servicePt()\") public void runSpeed(ProceedingJoinPoint pjp){ long start = System.currentTimeMillis(); for (int i = 0; i &lt; 10000; i++) { pjp.proceed(); } long end = System.currentTimeMillis(); System.out.println(\"业务层接口万次执行时间: \"+(end-start)+\"ms\"); } } 步骤5:运行单元测试类 **注意:**因为程序每次执行的时长是不一样的，所以运行多次最终的结果是不一样的。 步骤6:程序优化目前程序所面临的问题是，多个方法一起执行测试的时候，控制台都打印的是: 业务层接口万次执行时间:xxxms 我们没有办法区分到底是哪个接口的哪个方法执行的具体时间，具体如何优化? @Component @Aspect public class ProjectAdvice { //配置业务层的所有方法 @Pointcut(\"execution(* com.itheima.service.*Service.*(..))\") private void servicePt(){} //@Around(\"ProjectAdvice.servicePt()\") 可以简写为下面的方式 @Around(\"servicePt()\") public void runSpeed(ProceedingJoinPoint pjp){ //获取执行签名信息 Signature signature = pjp.getSignature(); //通过签名获取执行操作名称(接口名) String className = signature.getDeclaringTypeName(); //通过签名获取执行操作名称(方法名) String methodName = signature.getName(); long start = System.currentTimeMillis(); for (int i = 0; i &lt; 10000; i++) { pjp.proceed(); } long end = System.currentTimeMillis(); System.out.println(\"万次执行：\"+ className+\".\"+methodName+\"----&gt;\" +(end-start) + \"ms\"); } } 步骤7:运行单元测试类 ==补充说明== 当前测试的接口执行效率仅仅是一个理论值，并不是一次完整的执行过程。 这块只是通过该案例把AOP的使用进行了学习，具体的实际值是有很多因素共同决定的。 4.4 AOP通知获取数据目前我们写AOP仅仅是在原始方法前后追加一些操作，接下来我们要说说AOP中数据相关的内容，我们将从获取参数、获取返回值和获取异常三个方面来研究切入点的相关信息。 前面我们介绍通知类型的时候总共讲了五种，那么对于这五种类型都会有参数，返回值和异常吗? 我们先来一个个分析下: 获取切入点方法的参数，所有的通知类型都可以获取参数 JoinPoint：适用于前置、后置、返回后、抛出异常后通知 ProceedingJoinPoint：适用于环绕通知 获取切入点方法返回值，前置和抛出异常后通知是没有返回值，后置通知可有可无，所以不做研究 返回后通知 环绕通知 获取切入点方法运行异常信息，前置和返回后通知是不会有，后置通知可有可无，所以不做研究 抛出异常后通知 环绕通知 4.4.1 环境准备 创建一个Maven项目 pom.xml添加Spring依赖 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.9.4&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 添加BookDao和BookDaoImpl类 public interface BookDao { public String findName(int id); } @Repository public class BookDaoImpl implements BookDao { public String findName(int id) { System.out.println(\"id:\"+id); return \"itcast\"; } } 创建Spring的配置类 @Configuration @ComponentScan(\"com.itheima\") @EnableAspectJAutoProxy public class SpringConfig { } 编写通知类 @Component @Aspect public class MyAdvice { @Pointcut(\"execution(* com.itheima.dao.BookDao.findName(..))\") private void pt(){} @Before(\"pt()\") public void before() { System.out.println(\"before advice ...\" ); } @After(\"pt()\") public void after() { System.out.println(\"after advice ...\"); } @Around(\"pt()\") public Object around() throws Throwable{ Object ret = pjp.proceed(); return ret; } @AfterReturning(\"pt()\") public void afterReturning() { System.out.println(\"afterReturning advice ...\"); } @AfterThrowing(\"pt()\") public void afterThrowing() { System.out.println(\"afterThrowing advice ...\"); } } 编写App运行类 public class App { public static void main(String[] args) { ApplicationContext ctx = new AnnotationConfigApplicationContext(SpringConfig.class); BookDao bookDao = ctx.getBean(BookDao.class); String name = bookDao.findName(100); System.out.println(name); } } 最终创建好的项目结构如下: 4.4.2 获取参数非环绕通知获取方式在方法上添加JoinPoint,通过JoinPoint来获取参数 @Component @Aspect public class MyAdvice { @Pointcut(\"execution(* com.itheima.dao.BookDao.findName(..))\") private void pt(){} @Before(\"pt()\") public void before(JoinPoint jp) Object[] args = jp.getArgs(); System.out.println(Arrays.toString(args)); System.out.println(\"before advice ...\" ); } //...其他的略 } 运行App类，可以获取如下内容，说明参数100已经被获取 思考:方法的参数只有一个，为什么获取的是一个数组? 因为参数的个数是不固定的，所以使用数组更通配些。 如果将参数改成两个会是什么效果呢? (1)修改BookDao接口和BookDaoImpl实现类 public interface BookDao { public String findName(int id,String password); } @Repository public class BookDaoImpl implements BookDao { public String findName(int id,String password) { System.out.println(\"id:\"+id); return \"itcast\"; } } (2)修改App类，调用方法传入多个参数 public class App { public static void main(String[] args) { ApplicationContext ctx = new AnnotationConfigApplicationContext(SpringConfig.class); BookDao bookDao = ctx.getBean(BookDao.class); String name = bookDao.findName(100,\"itheima\"); System.out.println(name); } } (3)运行App，查看结果,说明两个参数都已经被获取到 说明: 使用JoinPoint的方式获取参数适用于前置、后置、返回后、抛出异常后通知。剩下的大家自行去验证。 环绕通知获取方式环绕通知使用的是ProceedingJoinPoint，因为ProceedingJoinPoint是JoinPoint类的子类，所以对于ProceedingJoinPoint类中应该也会有对应的getArgs()方法，我们去验证下: @Component @Aspect public class MyAdvice { @Pointcut(\"execution(* com.itheima.dao.BookDao.findName(..))\") private void pt(){} @Around(\"pt()\") public Object around(ProceedingJoinPoint pjp)throws Throwable { Object[] args = pjp.getArgs(); System.out.println(Arrays.toString(args)); Object ret = pjp.proceed(); return ret; } //其他的略 } 运行App后查看运行结果，说明ProceedingJoinPoint也是可以通过getArgs()获取参数 注意: pjp.proceed()方法是有两个构造方法，分别是: 调用无参数的proceed，当原始方法有参数，会在调用的过程中自动传入参数 所以调用这两个方法的任意一个都可以完成功能 但是当需要修改原始方法的参数时，就只能采用带有参数的方法,如下: @Component @Aspect public class MyAdvice { @Pointcut(\"execution(* com.itheima.dao.BookDao.findName(..))\") private void pt(){} @Around(\"pt()\") public Object around(ProceedingJoinPoint pjp) throws Throwable{ Object[] args = pjp.getArgs(); System.out.println(Arrays.toString(args)); args[0] = 666; Object ret = pjp.proceed(args); return ret; } //其他的略 } 有了这个特性后，我们就可以在环绕通知中对原始方法的参数进行拦截过滤，避免由于参数的问题导致程序无法正确运行，保证代码的健壮性。 4.4.3 获取返回值对于返回值，只有返回后AfterReturing和环绕Around这两个通知类型可以获取，具体如何获取? 环绕通知获取返回值@Component @Aspect public class MyAdvice { @Pointcut(\"execution(* com.itheima.dao.BookDao.findName(..))\") private void pt(){} @Around(\"pt()\") public Object around(ProceedingJoinPoint pjp) throws Throwable{ Object[] args = pjp.getArgs(); System.out.println(Arrays.toString(args)); args[0] = 666; Object ret = pjp.proceed(args); return ret; } //其他的略 } 上述代码中，ret就是方法的返回值，我们是可以直接获取，不但可以获取，如果需要还可以进行修改。 返回后通知获取返回值@Component @Aspect public class MyAdvice { @Pointcut(\"execution(* com.itheima.dao.BookDao.findName(..))\") private void pt(){} @AfterReturning(value = \"pt()\",returning = \"ret\") public void afterReturning(Object ret) { System.out.println(\"afterReturning advice ...\"+ret); } //其他的略 } ==注意:== (1)参数名的问题 (2)afterReturning方法参数类型的问题 参数类型可以写成String，但是为了能匹配更多的参数类型，建议写成Object类型 (3)afterReturning方法参数的顺序问题 运行App后查看运行结果，说明返回值已经被获取到 4.4.4 获取异常对于获取抛出的异常，只有抛出异常后AfterThrowing和环绕Around这两个通知类型可以获取，具体如何获取? 环绕通知获取异常这块比较简单，以前我们是抛出异常，现在只需要将异常捕获，就可以获取到原始方法的异常信息了 @Component @Aspect public class MyAdvice { @Pointcut(\"execution(* com.itheima.dao.BookDao.findName(..))\") private void pt(){} @Around(\"pt()\") public Object around(ProceedingJoinPoint pjp){ Object[] args = pjp.getArgs(); System.out.println(Arrays.toString(args)); args[0] = 666; Object ret = null; try{ ret = pjp.proceed(args); }catch(Throwable throwable){ t.printStackTrace(); } return ret; } //其他的略 } 在catch方法中就可以获取到异常，至于获取到异常以后该如何处理，这个就和你的业务需求有关了。 抛出异常后通知获取异常@Component @Aspect public class MyAdvice { @Pointcut(\"execution(* com.itheima.dao.BookDao.findName(..))\") private void pt(){} @AfterThrowing(value = \"pt()\",throwing = \"t\") public void afterThrowing(Throwable t) { System.out.println(\"afterThrowing advice ...\"+t); } //其他的略 } 如何让原始方法抛出异常，方式有很多， @Repository public class BookDaoImpl implements BookDao { public String findName(int id,String password) { System.out.println(\"id:\"+id); if(true){ throw new NullPointerException(); } return \"itcast\"; } } ==注意:== 运行App后，查看控制台，就能看的异常信息被打印到控制台 至此，AOP通知如何获取数据就已经讲解完了，数据中包含参数、返回值、异常(了解)。 4.5 百度网盘密码数据兼容处理4.5.1 需求分析需求: 对百度网盘分享链接输入密码时尾部多输入的空格做兼容处理。 问题描述: 点击链接，会提示，请输入提取码，如下图所示 当我们从别人发给我们的内容中复制提取码的时候，有时候会多复制到一些空格，直接粘贴到百度的提取码输入框 但是百度那边记录的提取码是没有空格的 这个时候如果不做处理，直接对比的话，就会引发提取码不一致，导致无法访问百度盘上的内容 所以多输入一个空格可能会导致项目的功能无法正常使用。 此时我们就想能不能将输入的参数先帮用户去掉空格再操作呢? 答案是可以的，我们只需要在业务方法执行之前对所有的输入参数进行格式处理——trim() 是对所有的参数都需要去除空格么? 也没有必要，一般只需要针对字符串处理即可。 以后涉及到需要去除前后空格的业务可能会有很多，这个去空格的代码是每个业务都写么? 可以考虑使用AOP来统一处理。 AOP有五种通知类型，该使用哪种呢? 我们的需求是将原始方法的参数处理后在参与原始方法的调用，能做这件事的就只有环绕通知。 综上所述，我们需要考虑两件事:①：在业务方法执行之前对所有的输入参数进行格式处理——trim()②：使用处理后的参数调用原始方法——环绕通知中存在对原始方法的调用 4.5.2 环境准备 创建一个Maven项目 pom.xml添加Spring依赖 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.9.4&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 添加ResourcesService，ResourcesServiceImpl,ResourcesDao和ResourcesDaoImpl类 public interface ResourcesDao { boolean readResources(String url, String password); } @Repository public class ResourcesDaoImpl implements ResourcesDao { public boolean readResources(String url, String password) { //模拟校验 return password.equals(\"root\"); } } public interface ResourcesService { public boolean openURL(String url ,String password); } @Service public class ResourcesServiceImpl implements ResourcesService { @Autowired private ResourcesDao resourcesDao; public boolean openURL(String url, String password) { return resourcesDao.readResources(url,password); } } 创建Spring的配置类 @Configuration @ComponentScan(\"com.itheima\") public class SpringConfig { } 编写App运行类 public class App { public static void main(String[] args) { ApplicationContext ctx = new AnnotationConfigApplicationContext(SpringConfig.class); ResourcesService resourcesService = ctx.getBean(ResourcesService.class); boolean flag = resourcesService.openURL(\"http://pan.baidu.com/haha\", \"root\"); System.out.println(flag); } } 最终创建好的项目结构如下: 现在项目的效果是，当输入密码为”root”控制台打印为true,如果密码改为”root “控制台打印的是false 需求是使用AOP将参数进行统一处理，不管输入的密码root前后包含多少个空格，最终控制台打印的都是true。 4.5.3 具体实现步骤1:开启SpringAOP的注解功能@Configuration @ComponentScan(\"com.itheima\") @EnableAspectJAutoProxy public class SpringConfig { } 步骤2:编写通知类@Component @Aspect public class DataAdvice { @Pointcut(\"execution(boolean com.itheima.service.*Service.*(*,*))\") private void servicePt(){} } 步骤3:添加环绕通知@Component @Aspect public class DataAdvice { @Pointcut(\"execution(boolean com.itheima.service.*Service.*(*,*))\") private void servicePt(){} @Around(\"DataAdvice.servicePt()\") // @Around(\"servicePt()\")这两种写法都对 public Object trimStr(ProceedingJoinPoint pjp) throws Throwable { Object ret = pjp.proceed(); return ret; } } 步骤4:完成核心业务，处理参数中的空格@Component @Aspect public class DataAdvice { @Pointcut(\"execution(boolean com.itheima.service.*Service.*(*,*))\") private void servicePt(){} @Around(\"DataAdvice.servicePt()\") // @Around(\"servicePt()\")这两种写法都对 public Object trimStr(ProceedingJoinPoint pjp) throws Throwable { //获取原始方法的参数 Object[] args = pjp.getArgs(); for (int i = 0; i &lt; args.length; i++) { //判断参数是不是字符串 if(args[i].getClass().equals(String.class)){ args[i] = args[i].toString().trim(); } } //将修改后的参数传入到原始方法的执行中 Object ret = pjp.proceed(args); return ret; } } 步骤5:运行程序不管密码root前后是否加空格，最终控制台打印的都是true 步骤6:优化测试为了能更好的看出AOP已经生效，我们可以修改ResourcesImpl类，在方法中将密码的长度进行打印 @Repository public class ResourcesDaoImpl implements ResourcesDao { public boolean readResources(String url, String password) { System.out.println(password.length()); //模拟校验 return password.equals(\"root\"); } } 再次运行成功，就可以根据最终打印的长度来看看，字符串的空格有没有被去除掉。 注意： 5. AOP总结AOP的知识就已经讲解完了，接下来对于AOP的知识进行一个总结: 5.1 AOP的核心概念 概念：AOP(Aspect Oriented Programming)面向切面编程，一种编程范式 作用：在不惊动原始设计的基础上为方法进行功能==增强== 核心概念 代理（Proxy）：SpringAOP的核心本质是采用代理模式实现的 连接点（JoinPoint）：在SpringAOP中，理解为任意方法的执行 切入点（Pointcut）：匹配连接点的式子，也是具有共性功能的方法描述 通知（Advice）：若干个方法的共性功能，在切入点处执行，最终体现为一个方法 切面（Aspect）：描述通知与切入点的对应关系 目标对象（Target）：被代理的原始对象成为目标对象 5.2 切入点表达式 切入点表达式标准格式：动作关键字(访问修饰符 返回值 包名.类/接口名.方法名（参数）异常名) execution(* com.itheima.service.*Service.*(..)) 切入点表达式描述通配符： 作用：用于快速描述，范围描述 *：匹配任意符号（常用） .. ：匹配多个连续的任意符号（常用） +：匹配子类类型 切入点表达式书写技巧 1.按==标准规范==开发2.查询操作的返回值建议使用*匹配3.减少使用..的形式描述包4.==对接口进行描述==，使用*表示模块名，例如UserService的匹配描述为Service5.方法名书写保留动词，例如get，使用\\表示名词，例如getById匹配描述为getBy*6.参数根据实际情况灵活调整 5.3 五种通知类型 前置通知 后置通知 环绕通知（重点） 环绕通知依赖形参ProceedingJoinPoint才能实现对原始方法的调用 环绕通知可以隔离原始方法的调用执行 环绕通知返回值设置为Object类型 环绕通知中可以对原始方法调用过程中出现的异常进行处理 返回后通知 抛出异常后通知 5.4 通知中获取参数 获取切入点方法的参数，所有的通知类型都可以获取参数 JoinPoint：适用于前置、后置、返回后、抛出异常后通知 ProceedingJoinPoint：适用于环绕通知 获取切入点方法返回值，前置和抛出异常后通知是没有返回值，后置通知可有可无，所以不做研究 返回后通知 环绕通知 获取切入点方法运行异常信息，前置和返回后通知是不会有，后置通知可有可无，所以不做研究 抛出异常后通知 环绕通知 6. AOP事务管理6.1 Spring事务简介6.1.1 相关概念介绍 事务作用：在数据层保障一系列的数据库操作同成功同失败 Spring事务作用：在数据层或**==业务层==**保障一系列的数据库操作同成功同失败 数据层有事务我们可以理解，为什么业务层也需要处理事务呢? 举个简单的例子， 转账业务会有两次数据层的调用，一次是加钱一次是减钱 把事务放在数据层，加钱和减钱就有两个事务 没办法保证加钱和减钱同时成功或者同时失败 这个时候就需要将事务放在业务层进行处理。 Spring为了管理事务，提供了一个平台事务管理器PlatformTransactionManager commit是用来提交事务，rollback是用来回滚事务。 PlatformTransactionManager只是一个接口，Spring还为其提供了一个具体的实现: 从名称上可以看出，我们只需要给它一个DataSource对象，它就可以帮你去在业务层管理事务。其内部采用的是JDBC的事务。所以说如果你持久层采用的是JDBC相关的技术，就可以采用这个事务管理器来管理你的事务。而Mybatis内部采用的就是JDBC的事务，所以后期我们Spring整合Mybatis就采用的这个DataSourceTransactionManager事务管理器。 6.1.2 转账案例-需求分析接下来通过一个案例来学习下Spring是如何来管理事务的。 先来分析下需求: 需求: 实现任意两个账户间转账操作 需求微缩: A账户减钱，B账户加钱 为了实现上述的业务需求，我们可以按照下面步骤来实现下:①：数据层提供基础操作，指定账户减钱（outMoney），指定账户加钱（inMoney） ②：业务层提供转账操作（transfer），调用减钱与加钱的操作 ③：提供2个账号和操作金额执行转账操作 ④：基于Spring整合MyBatis环境搭建上述操作 6.1.3 转账案例-环境搭建步骤1:准备数据库表之前我们在整合Mybatis的时候已经创建了这个表,可以直接使用 create database spring_db character set utf8; use spring_db; create table tbl_account( id int primary key auto_increment, name varchar(35), money double ); insert into tbl_account values(1,'Tom',1000); insert into tbl_account values(2,'Jerry',1000); 步骤2:创建项目导入jar包项目的pom.xml添加相关依赖 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.16&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 步骤3:根据表创建模型类public class Account implements Serializable { private Integer id; private String name; private Double money; //setter...getter...toString...方法略 } 步骤4:创建Dao接口public interface AccountDao { @Update(\"update tbl_account set money = money + #{money} where name = #{name}\") void inMoney(@Param(\"name\") String name, @Param(\"money\") Double money); @Update(\"update tbl_account set money = money - #{money} where name = #{name}\") void outMoney(@Param(\"name\") String name, @Param(\"money\") Double money); } 步骤5:创建Service接口和实现类public interface AccountService { /** * 转账操作 * @param out 传出方 * @param in 转入方 * @param money 金额 */ public void transfer(String out,String in ,Double money) ; } @Service public class AccountServiceImpl implements AccountService { @Autowired private AccountDao accountDao; public void transfer(String out,String in ,Double money) { accountDao.outMoney(out,money); accountDao.inMoney(in,money); } } 步骤6:添加jdbc.properties文件jdbc.driver=com.mysql.jdbc.Driver jdbc.url=jdbc:mysql://localhost:3306/spring_db?useSSL=false jdbc.username=root jdbc.password=root 步骤7:创建JdbcConfig配置类public class JdbcConfig { @Value(\"${jdbc.driver}\") private String driver; @Value(\"${jdbc.url}\") private String url; @Value(\"${jdbc.username}\") private String userName; @Value(\"${jdbc.password}\") private String password; @Bean public DataSource dataSource(){ DruidDataSource ds = new DruidDataSource(); ds.setDriverClassName(driver); ds.setUrl(url); ds.setUsername(userName); ds.setPassword(password); return ds; } } 步骤8:创建MybatisConfig配置类public class MybatisConfig { @Bean public SqlSessionFactoryBean sqlSessionFactory(DataSource dataSource){ SqlSessionFactoryBean ssfb = new SqlSessionFactoryBean(); ssfb.setTypeAliasesPackage(\"com.itheima.domain\"); ssfb.setDataSource(dataSource); return ssfb; } @Bean public MapperScannerConfigurer mapperScannerConfigurer(){ MapperScannerConfigurer msc = new MapperScannerConfigurer(); msc.setBasePackage(\"com.itheima.dao\"); return msc; } } 步骤9:创建SpringConfig配置类@Configuration @ComponentScan(\"com.itheima\") @PropertySource(\"classpath:jdbc.properties\") @Import({JdbcConfig.class,MybatisConfig.class}) public class SpringConfig { } 步骤10:编写测试类@RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(classes = SpringConfig.class) public class AccountServiceTest { @Autowired private AccountService accountService; @Test public void testTransfer() throws IOException { accountService.transfer(\"Tom\",\"Jerry\",100D); } } 最终创建好的项目结构如下: 6.1.4 事务管理上述环境，运行单元测试类，会执行转账操作，Tom的账户会减少100，Jerry的账户会加100。 这是正常情况下的运行结果，但是如果在转账的过程中出现了异常，如: @Service public class AccountServiceImpl implements AccountService { @Autowired private AccountDao accountDao; public void transfer(String out,String in ,Double money) { accountDao.outMoney(out,money); int i = 1/0; accountDao.inMoney(in,money); } } 这个时候就模拟了转账过程中出现异常的情况，正确的操作应该是转账出问题了，Tom应该还是900，Jerry应该还是1100，但是真正运行后会发现，并没有像我们想象的那样，Tom账户为800而Jerry还是1100,100块钱凭空消息了，银行乐疯了。如果把转账换个顺序，银行就该哭了。 不管哪种情况，都是不允许出现的，对刚才的结果我们做一个分析: ①：程序正常执行时，账户金额A减B加，没有问题 ②：程序出现异常后，转账失败，但是异常之前操作成功，异常之后操作失败，整体业务失败 当程序出问题后，我们需要让事务进行回滚，而且这个事务应该是加在业务层上，而Spring的事务管理就是用来解决这类问题的。 Spring事务管理具体的实现步骤为: 步骤1:在需要被事务管理的方法上添加注解public interface AccountService { /** * 转账操作 * @param out 传出方 * @param in 转入方 * @param money 金额 */ //配置当前接口方法具有事务 public void transfer(String out,String in ,Double money) ; } @Service public class AccountServiceImpl implements AccountService { @Autowired private AccountDao accountDao; @Transactional public void transfer(String out,String in ,Double money) { accountDao.outMoney(out,money); int i = 1/0; accountDao.inMoney(in,money); } } ==注意:== @Transactional可以写在接口类上、接口方法上、实现类上和实现类方法上 写在接口类上，该接口的所有实现类的所有方法都会有事务 写在接口方法上，该接口的所有实现类的该方法都会有事务 写在实现类上，该类中的所有方法都会有事务 写在实现类方法上，该方法上有事务 ==建议写在实现类或实现类的方法上== 步骤2:在JdbcConfig类中配置事务管理器public class JdbcConfig { @Value(\"${jdbc.driver}\") private String driver; @Value(\"${jdbc.url}\") private String url; @Value(\"${jdbc.username}\") private String userName; @Value(\"${jdbc.password}\") private String password; @Bean public DataSource dataSource(){ DruidDataSource ds = new DruidDataSource(); ds.setDriverClassName(driver); ds.setUrl(url); ds.setUsername(userName); ds.setPassword(password); return ds; } //配置事务管理器，mybatis使用的是jdbc事务 @Bean public PlatformTransactionManager transactionManager(DataSource dataSource){ DataSourceTransactionManager transactionManager = new DataSourceTransactionManager(); transactionManager.setDataSource(dataSource); return transactionManager; } } 注意：事务管理器要根据使用技术进行选择，Mybatis框架使用的是JDBC事务，可以直接使用DataSourceTransactionManager 步骤3：开启事务注解在SpringConfig的配置类中开启 @Configuration @ComponentScan(\"com.itheima\") @PropertySource(\"classpath:jdbc.properties\") @Import({JdbcConfig.class,MybatisConfig.class //开启注解式事务驱动 @EnableTransactionManagement public class SpringConfig { } 步骤4:运行测试类会发现在转换的业务出现错误后，事务就可以控制回顾，保证数据的正确性。 知识点1：@EnableTransactionManagement 名称 @EnableTransactionManagement 类型 配置类注解 位置 配置类定义上方 作用 设置当前Spring环境中开启注解式事务支持 知识点2：@Transactional 名称 @Transactional 类型 接口注解 类注解 方法注解 位置 业务层接口上方 业务层实现类上方 业务方法上方 作用 为当前业务层方法添加事务（如果设置在类或接口上方则类或接口中所有方法均添加事务） 6.2 Spring事务角色这节中我们重点要理解两个概念，分别是事务管理员和事务协调员。 未开启Spring事务之前: AccountDao的outMoney因为是修改操作，会开启一个事务T1 AccountDao的inMoney因为是修改操作，会开启一个事务T2 AccountService的transfer没有事务， 运行过程中如果没有抛出异常，则T1和T2都正常提交，数据正确 如果在两个方法中间抛出异常，T1因为执行成功提交事务，T2因为抛异常不会被执行 就会导致数据出现错误 开启Spring的事务管理后 transfer上添加了@Transactional注解，在该方法上就会有一个事务T AccountDao的outMoney方法的事务T1加入到transfer的事务T中 AccountDao的inMoney方法的事务T2加入到transfer的事务T中 这样就保证他们在同一个事务中，当业务层中出现异常，整个事务就会回滚，保证数据的准确性。 通过上面例子的分析，我们就可以得到如下概念: 事务管理员：发起事务方，在Spring中通常指代业务层开启事务的方法 事务协调员：加入事务方，在Spring中通常指代数据层方法，也可以是业务层方法 ==注意:== 目前的事务管理是基于DataSourceTransactionManager和SqlSessionFactoryBean使用的是同一个数据源。 6.3 Spring事务属性上一节我们介绍了两个概念，事务的管理员和事务的协同员，对于这两个概念具体做什么的，我们待会通过案例来使用下。除了这两个概念，还有就是事务的其他相关配置都有哪些，就是我们接下来要学习的内容。 在这一节中，我们主要学习三部分内容事务配置、转账业务追加日志、事务传播行为。 6.3.1 事务配置 上面这些属性都可以在@Transactional注解的参数上进行设置。 readOnly：true只读事务，false读写事务，增删改要设为false,查询设为true。 timeout:设置超时时间单位秒，在多长时间之内事务没有提交成功就自动回滚，-1表示不设置超时时间。 rollbackFor:当出现指定异常进行事务回滚 noRollbackFor:当出现指定异常不进行事务回滚 思考:出现异常事务会自动回滚，这个是我们之前就已经知道的 noRollbackFor是设定对于指定的异常不回滚，这个好理解 rollbackFor是指定回滚异常，对于异常事务不应该都回滚么，为什么还要指定? 这块需要更正一个知识点，并不是所有的异常都会回滚事务，比如下面的代码就不会回滚 public interface AccountService { /** * 转账操作 * @param out 传出方 * @param in 转入方 * @param money 金额 */ //配置当前接口方法具有事务 public void transfer(String out,String in ,Double money) throws IOException; } @Service public class AccountServiceImpl implements AccountService { @Autowired private AccountDao accountDao; @Transactional public void transfer(String out,String in ,Double money) throws IOException{ accountDao.outMoney(out,money); //int i = 1/0; //这个异常事务会回滚 if(true){ throw new IOException(); //这个异常事务就不会回滚 } accountDao.inMoney(in,money); } } 出现这个问题的原因是，Spring的事务只会对Error异常和RuntimeException异常及其子类进行事务回顾，其他的异常类型是不会回滚的，对应IOException不符合上述条件所以不回滚 此时就可以使用rollbackFor属性来设置出现IOException异常不回滚 @Service public class AccountServiceImpl implements AccountService { @Autowired private AccountDao accountDao; @Transactional(rollbackFor = {IOException.class}) public void transfer(String out,String in ,Double money) throws IOException{ accountDao.outMoney(out,money); //int i = 1/0; //这个异常事务会回滚 if(true){ throw new IOException(); //这个异常事务就不会回滚 } accountDao.inMoney(in,money); } } rollbackForClassName等同于rollbackFor,只不过属性为异常的类全名字符串 noRollbackForClassName等同于noRollbackFor，只不过属性为异常的类全名字符串 isolation设置事务的隔离级别 DEFAULT :默认隔离级别, 会采用数据库的隔离级别 READ_UNCOMMITTED : 读未提交 READ_COMMITTED : 读已提交 REPEATABLE_READ : 重复读取 SERIALIZABLE: 串行化 介绍完上述属性后，还有最后一个事务的传播行为，为了讲解该属性的设置，我们需要完成下面的案例。 6.3.2 转账业务追加日志案例6.3.2.1 需求分析在前面的转案例的基础上添加新的需求，完成转账后记录日志。 需求：实现任意两个账户间转账操作，并对每次转账操作在数据库进行留痕 需求微缩：A账户减钱，B账户加钱，数据库记录日志 基于上述的业务需求，我们来分析下该如何实现: ①：基于转账操作案例添加日志模块，实现数据库中记录日志 ②：业务层转账操作（transfer），调用减钱、加钱与记录日志功能 需要注意一点就是，我们这个案例的预期效果为: ==无论转账操作是否成功，均进行转账操作的日志留痕== 6.3.2.2 环境准备该环境是基于转账环境来完成的，所以环境的准备可以参考6.1.3的环境搭建步骤，在其基础上，我们继续往下写 步骤1:创建日志表create table tbl_log( id int primary key auto_increment, info varchar(255), createDate datetime ) 步骤2:添加LogDao接口public interface LogDao { @Insert(\"insert into tbl_log (info,createDate) values(#{info},now())\") void log(String info); } 步骤3:添加LogService接口与实现类public interface LogService { void log(String out, String in, Double money); } @Service public class LogServiceImpl implements LogService { @Autowired private LogDao logDao; @Transactional public void log(String out,String in,Double money ) { logDao.log(\"转账操作由\"+out+\"到\"+in+\",金额：\"+money); } } 步骤4:在转账的业务中添加记录日志public interface AccountService { /** * 转账操作 * @param out 传出方 * @param in 转入方 * @param money 金额 */ //配置当前接口方法具有事务 public void transfer(String out,String in ,Double money)throws IOException ; } @Service public class AccountServiceImpl implements AccountService { @Autowired private AccountDao accountDao; @Autowired private LogService logService; @Transactional public void transfer(String out,String in ,Double money) { try{ accountDao.outMoney(out,money); accountDao.inMoney(in,money); }finally { logService.log(out,in,money); } } } 步骤5:运行程序 当程序正常运行，tbl_account表中转账成功，tbl_log表中日志记录成功 当转账业务之间出现异常(int i =1/0),转账失败，tbl_account成功回滚，但是tbl_log表未添加数据 这个结果和我们想要的不一样，什么原因?该如何解决? 失败原因:日志的记录与转账操作隶属同一个事务，同成功同失败 最终效果:无论转账操作是否成功，日志必须保留 6.3.3 事务传播行为 对于上述案例的分析: log方法、inMoney方法和outMoney方法都属于增删改，分别有事务T1,T2,T3 transfer因为加了@Transactional注解，也开启了事务T 前面我们讲过Spring事务会把T1,T2,T3都加入到事务T中 所以当转账失败后，所有的事务都回滚，导致日志没有记录下来 这和我们的需求不符，这个时候我们就想能不能让log方法单独是一个事务呢? 要想解决这个问题，就需要用到事务传播行为，所谓的事务传播行为指的是: 事务传播行为：事务协调员对事务管理员所携带事务的处理态度。 具体如何解决，就需要用到之前我们没有说的propagation属性。 1.修改logService改变事务的传播行为@Service public class LogServiceImpl implements LogService { @Autowired private LogDao logDao; //propagation设置事务属性：传播行为设置为当前操作需要新事务 @Transactional(propagation = Propagation.REQUIRES_NEW) public void log(String out,String in,Double money ) { logDao.log(\"转账操作由\"+out+\"到\"+in+\",金额：\"+money); } } 运行后，就能实现我们想要的结果，不管转账是否成功，都会记录日志。 2.事务传播行为的可选值 对于我们开发实际中使用的话，因为默认值需要事务是常态的。根据开发过程选择其他的就可以了，例如案例中需要新事务就需要手工配置。其实入账和出账操作上也有事务，采用的就是默认值。","categories":[],"tags":[{"name":"SSMP","slug":"SSMP","permalink":"https://gitee.com/yunyd/tags/SSMP/"},{"name":"Spring","slug":"Spring","permalink":"https://gitee.com/yunyd/tags/Spring/"}],"author":"llllz."},{"title":"JUC-线程基础知识复习","slug":"JUC-线程基础知识复习 -1","date":"2023-07-26T05:12:22.000Z","updated":"2023-08-25T00:20:21.970Z","comments":true,"path":"posts/5e115804.html","link":"","permalink":"https://gitee.com/yunyd/posts/5e115804.html","excerpt":"","text":"线程基础知识复习 1把锁：synchronized（后面细讲） 2个并： 并发（concurrent）：是在同一实体上的多个事件，是在一台机器上“同时”处理多个任务，同一时刻，其实是只有一个事情再发生。 并行（parallel）：是在不同实体上的多个事件，是在多台处理器上同时处理多个任务，同一时刻，大家都在做事情，你做你的，我做我的，各干各的。 3个程： 进程：在系统中运行的一个应用程序，每个进程都有它自己的内存空间和系统资源 线程：也被称为轻量级进程，在同一个进程内会有1个或多个线程，是大多数操作系统进行时序调度的基本单元。 管程：Monitor（锁），也就是我们平时所说的锁。Monitor其实是一种同步机制，它的义务是保证（同一时间）只有一个线程可以访问被保护的数据和代码，JVM中同步是基于进入和退出监视器（Monitor管程对象）来实现的，每个对象实例都会有一个Monitor对象，Monitor对象和Java对象一同创建并销毁，底层由C++语言实现。 线程分类（一般不做特别说明配置，默认都是用户线程）： 用户线程：是系统的工作线程，它会完成这个程序需要完成的业务操作。 守护线程：是一种特殊的线程为其他线程服务的，在后台默默地完成一些系统性的任务，比如垃圾回收线程就是最典型的例子。守护线程作为一个服务线程，没有服务对象就没有必要继续运行了，如果用户线程全部结束了，意味着程序需要完成的业务操作已经结束了，系统可以退出了。所以假如当系统只剩下守护线程的时候，守护线程伴随着JVM一同结束工作。 守护线程代码实操 Java 代码 public class DaemonDemo { public static void main(String[] args) { Thread t1 = new Thread(() -&gt; { System.out.println(Thread.currentThread().getName() + \" 开始运行,\" + (Thread.currentThread().isDaemon() ? \"守护线程\" : \"用户线程\")); while (true) { } }, \"t1\"); t1.setDaemon(true);//通过设置属性Daemon来设置当前线程是否为守护线程 t1.start(); try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + \" 主线程结束\"); } } 输出：t1 开始运行,守护线程 main 主线程结束---&gt;在main主线程结束后，守护线程会伴随着JVM一同结束工作，即使还有循环没有结束 JUC 三大辅助类JUC 中提供了三种常用的辅助类，通过这些辅助类可以很好的解决线程数量过 多时 Lock 锁的频繁操作。这三种辅助类为： CountDownLatch: 减少计数 CyclicBarrier: 循环栅栏 Semaphore: 信号灯 1 减少计数 CountDownLatchCountDownLatch 类可以设置一个计数器，然后通过 countDown 方法来进行减 1 的操作，使用 await 方法等待计数器不大于 0，然后继续执行 await 方法之后的语句。 CountDownLatch 主要有两个方法，当一个或多个线程调用 await 方法时，这 些线程会阻塞 其它线程调用 countDown 方法会将计数器减 1(调用 countDown 方法的线程不会阻塞) 当计数器的值变为 0 时，因 await 方法阻塞的线程会被唤醒，继续执行 场景: 6 个同学陆续离开教室后值班同学才可以关门。 public class CountDownLatchDemo { /** \\* 6 个同学陆续离开教室后值班同学才可以关门 \\* @param args */ public static void main(String[] args) throws Exception{ //定义一个数值为 6 的计数器 CountDownLatch countDownLatch = new CountDownLatch(6); //创建 6 个同学 for (int i = 1; i &lt;= 6; i++) { new Thread(() -&gt;{ try{ if(Thread.currentThread().getName().equals(\"同学 6\")){ Thread.sleep(2000); } System.out.println(Thread.currentThread().getName() + \"离开了\"); //计数器减一,不会阻塞 countDownLatch.countDown(); }catch (Exception e){ e.printStackTrace(); } }, \"同学\" + i).start(); } //主线程 await 休息 System.out.println(\"主线程睡觉\"); countDownLatch.await(); //全部离开后自动唤醒主线程 System.out.println(\"全部离开了,现在的计数器为\" +countDownLatch.getCount()); } } 2 循环栅栏 CyclicBarrierCyclicBarrier 看英文单词可以看出大概就是循环阻塞的意思，在使用中CyclicBarrier 的构造方法第一个参数是目标障碍数，每次执行 CyclicBarrier 一次障碍数会加一，如果达到了目标障碍数，才会执行 cyclicBarrier.await()之后的语句。可以将 CyclicBarrier 理解为加 1 操作 场景: 集齐 7 颗龙珠就可以召唤神龙 public class CyclicBarrierDemo { //定义神龙召唤需要的龙珠总数 private final static int NUMBER = 7; /** \\* 集齐 7 颗龙珠就可以召唤神龙 \\* @param args */ public static void main(String[] args) { //定义循环栅栏 CyclicBarrier cyclicBarrier = new CyclicBarrier(NUMBER, () -&gt;{ System.out.println(\"集齐\" + NUMBER + \"颗龙珠,现在召唤神龙!!!!!!!!!\"); }); //定义 7 个线程分别去收集龙珠 for (int i = 1; i &lt;= 7; i++) { new Thread(()-&gt;{ try { if(Thread.currentThread().getName().equals(\"龙珠 3 号\")){ System.out.println(\"龙珠 3 号抢夺战开始,孙悟空开启超级赛亚人模式!\"); Thread.sleep(5000); System.out.println(\"龙珠 3 号抢夺战结束,孙悟空打赢了,拿到了龙珠 3 号!\"); }else{ System.out.println(Thread.currentThread().getName() + \"收集到了!!!!\"); } cyclicBarrier.await(); }catch (Exception e){ e.printStackTrace(); } }, \"龙珠\" + i + \"号\").start(); } } } 3 信号灯 SemaphoreSemaphore 的构造方法中传入的第一个参数是最大信号量（可以看成最大线程池），每个信号量初始化为一个最多只能分发一个许可证。使用 acquire 方法获得许可证，release 方法释放许可 场景: 抢车位, 6 部汽车 3 个停车位 public class SemaphoreDemo { /** * 抢车位, 10 部汽车 1 个停车位 * @param args */ public static void main(String[] args) throws Exception { //定义 3 个停车位 Semaphore semaphore = new Semaphore(1); //模拟 6 辆汽车停车 for (int i = 1; i &lt;= 10; i++) { Thread.sleep(100); //停车 new Thread(() -&gt; { try { System.out.println(Thread.currentThread().getName() + \"找车位 ing\"); semaphore.acquire(); System.out.println(Thread.currentThread().getName() + \"汽车停车成功 !\"); Thread.sleep(10000); } catch (Exception e) { e.printStackTrace(); } finally { System.out.println(Thread.currentThread().getName() + \"溜了溜了\"); semaphore.release(); } }, \"汽车\" + i).start(); } } } 阻塞队列1.1 BlockingQueue 简介Concurrent 包中，BlockingQueue 很好的解决了多线程中，如何高效安全“传输”数据的问题。通过这些高效并且线程安全的队列类，为我们快速搭建高质量的多线程程序带来极大的便利。本文详细介绍了 BlockingQueue 家庭中的所有成员，包括他们各自的功能以及常见使用场景。阻塞队列，顾名思义，首先它是一个队列, 通过一个共享的队列，可以使得数据由队列的一端输入，从另外一端输出； 当队列是空的，从队列中获取元素的操作将会被阻塞 当队列是满的，从队列中添加元素的操作将会被阻塞 试图从空的队列中获取元素的线程将会被阻塞，直到其他线程往空的队列插入新的元素 试图向已满的队列中添加新元素的线程将会被阻塞，直到其他线程从队列中移除一个或多 个元素或者完全清空，使队列变得空闲起来并后续新增 常用的队列主要有以下两种： 先进先出（FIFO）：先插入的队列的元素也最先出队列，类似于排队的功能。从某种程度上来说这种队列也体现了一种公平性 后进先出（LIFO）：后插入队列的元素最先出队列，这种队列优先处理最近发生的事件(栈) 在多线程领域：所谓阻塞，在某些情况下会挂起线程（即阻塞），一旦条件满足，被挂起的线程又会自动被唤起 为什么需要 BlockingQueue 好处是我们不需要关心什么时候需要阻塞线程，什么时候需要唤醒线程，因为这一切BlockingQueue 都给你一手包办了 在 concurrent 包发布以前，在多线程环境下，我们每个程序员都必须去自己控制这些细节，尤其还要兼顾效率和线程安全，而这会给我们的程序带来不小的复杂度。 ​ 多线程环境中，通过队列可以很容易实现数据共享，比如经典的“生产者”和“消费者”模型中，通过队列可以很便利地实现两者之间的数据共享。假设我们有若干生产者线程，另外又有若干个消费者线程。如果生产者线程需要把准备好的数据共享给消费者线程，利用队列的方式来传递数据，就可以很方便地解决他们之间的数据共享问题。但如果生产者和消费者在某个时间段内，万一发生数据处理速度不匹配的情况呢？理想情况下，如果生产者产出数据的速度大于消费者消费的速度，并且当生产出来的数据累积到一定程度的时候，那么生产者必须暂停等待一下（阻塞生产者线程），以便等待消费者线程把累积的数据处理完毕，反之亦然 当队列中没有数据的情况下，消费者端的所有线程都会被自动阻塞（挂起），直到有数据放入队列 当队列中填满数据的情况下，生产者端的所有线程都会被自动阻塞（挂起），直到队列中有空的位置，线程被自动唤醒 1.2 BlockingQueue 核心方法 BlockingQueue 的核心方法： 放入数据• offer(anObject):表示如果可能的话,将 anObject 加到 BlockingQueue 里,即如果 BlockingQueue 可以容纳,则返回 true,否则返回 false.（本方法不阻塞当前执行方法的线程） offer(E o, long timeout, TimeUnit unit)：可以设定等待的时间，如果在指定的时间内，还不能往队列中加入 BlockingQueue，则返回失败 put(anObject):把 anObject 加到 BlockingQueue 里,如果 BlockQueue 没有空间,则调用此方法的线程被阻断直到 BlockingQueue 里面有空间再继续 获取数据 poll(time): 取走 BlockingQueue 里排在首位的对象,若不能立即取出,则可以等time 参数规定的时间,取不到时返回 null poll(long timeout, TimeUnit unit)：从 BlockingQueue 取出一个队首的对象，如果在指定时间内，队列一旦有数据可取，则立即返回队列中的数据。否则知道时间超时还没有数据可取，返回失败。 take(): 取走 BlockingQueue 里排在首位的对象,若 BlockingQueue 为空,阻断进入等待状态直到 BlockingQueue 有新的数据被加入 drainTo(): 一次性从 BlockingQueue 获取所有可用的数据对象（还可以指定获取数据的个数），通过该方法，可以提升获取数据效率；不需要多次分批加锁或释放锁。 1.3 入门案例/** * 阻塞队列 */ public class BlockingQueueDemo { public static void main(String[] args) throws InterruptedException { // List list = new ArrayList(); BlockingQueue&lt;String&gt; blockingQueue = new ArrayBlockingQueue&lt;&gt;(3); //第一组 // System.out.println(blockingQueue.add(\"a\")); // System.out.println(blockingQueue.add(\"b\")); // System.out.println(blockingQueue.add(\"c\")); // System.out.println(blockingQueue.element()); //System.out.println(blockingQueue.add(\"x\")); // System.out.println(blockingQueue.remove()); // System.out.println(blockingQueue.remove()); // System.out.println(blockingQueue.remove()); // System.out.println(blockingQueue.remove()); // 第二组 // System.out.println(blockingQueue.offer(\"a\")); // System.out.println(blockingQueue.offer(\"b\")); // System.out.println(blockingQueue.offer(\"c\")); // System.out.println(blockingQueue.offer(\"x\")); // System.out.println(blockingQueue.poll()); // System.out.println(blockingQueue.poll()); // System.out.println(blockingQueue.poll()); // System.out.println(blockingQueue.poll()); // 第三组 // blockingQueue.put(\"a\"); // blockingQueue.put(\"b\"); // blockingQueue.put(\"c\"); // //blockingQueue.put(\"x\"); // System.out.println(blockingQueue.take()); // System.out.println(blockingQueue.take()); // System.out.println(blockingQueue.take()); // System.out.println(blockingQueue.take()); // 第四组 System.out.println(blockingQueue.offer(\"a\")); System.out.println(blockingQueue.offer(\"b\")); System.out.println(blockingQueue.offer(\"c\")); System.out.println(blockingQueue.offer(\"a\",3L, TimeUnit.SECONDS)); } } 1.4 常见的 BlockingQueue1.4.1 ArrayBlockingQueue(常用)基于数组的阻塞队列实现，在 ArrayBlockingQueue 内部，维护了一个定长数组，以便缓存队列中的数据对象，这是一个常用的阻塞队列，除了一个定长数组外，ArrayBlockingQueue 内部还保存着两个整形变量，分别标识着队列的头部和尾部在数组中的位置。ArrayBlockingQueue 在生产者放入数据和消费者获取数据，都是共用同一个锁对象，由此也意味着两者无法真正并行运行，这点尤其不同于LinkedBlockingQueue；按照实现原理来分析，ArrayBlockingQueue 完全可以采用分离锁，从而实现生产者和消费者操作的完全并行运行。Doug Lea 之所以没这样去做，也许是因为 ArrayBlockingQueue 的数据写入和获取操作已经足够轻巧，以至于引入独立的锁机制，除了给代码带来额外的复杂性外，其在性能上完全占不到任何便宜。 ArrayBlockingQueue 和LinkedBlockingQueue 间还有一个明显的不同之处在于，前者在插入或删除元素时不会产生或销毁任何额外的对象实例，而后者则会生成一个额外的Node 对象。这在长时间内需要高效并发地处理大批量数据的系统中，其对于GC 的影响还是存在一定的区别。而在创建 ArrayBlockingQueue 时，我们还可以控制对象的内部锁是否采用公平锁，默认采用非公平锁。 ==一句话总结: 由数组结构组成的有界阻塞队列。== 1**.4.2 LinkedBlockingQueue(常用)**基于链表的阻塞队列，同 ArrayListBlockingQueue 类似，其内部也维持着一个数据缓冲队列（该队列由一个链表构成），当生产者往队列中放入一个数据时，队列会从生产者手中获取数据，并缓存在队列内部，而生产者立即返回；只有当队列缓冲区达到最大值缓存容量时（LinkedBlockingQueue 可以通过构造函数指定该值），才会阻塞生产者队列，直到消费者从队列中消费掉一份数据，生产者线程会被唤醒，反之对于消费者这端的处理也基于同样的原理。而 LinkedBlockingQueue 之所以能够高效的处理并发数据，还因为其对于生产者端和消费者端分别采用了独立的锁来控制数据同步，这也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。 ArrayBlockingQueue 和 LinkedBlockingQueue 是两个最普通也是最常用的阻塞队列，一般情况下，在处理多线程间的生产者消费者问题，使用这两个类足以。 ==一句话总结: 由链表结构组成的有界（但大小默认值为integer.MAX_VALUE）阻塞队列。== 1.4.3 DelayQueueDelayQueue 中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素。DelayQueue 是一个没有大小限制的队列，因此往队列中插入数据的操作（生产者）永远不会被阻塞，而只有获取数据的操作（消费者）才会被阻塞。 ==一句话总结: 使用优先级队列实现的延迟无界阻塞队列。== 1.4.4 PriorityBlockingQueue基于优先级的阻塞队列（优先级的判断通过构造函数传入的 Compator 对象来决定），但需要注意的是 PriorityBlockingQueue 并不会阻塞数据生产者，而只会在没有可消费的数据时，阻塞数据的消费者。因此使用的时候要特别注意，生产者生产数据的速度绝对不能快于消费者消费数据的速度，否则时间一长，会最终耗尽所有的可用堆内存空间。在实现 PriorityBlockingQueue 时，内部控制线程同步的锁采用的是公平锁。 ==一句话总结: 支持优先级排序的无界阻塞队列。== 1.4.5 SynchronousQueue一种无缓冲的等待队列，类似于无中介的直接交易，有点像原始社会中的生产者和消费者，生产者拿着产品去集市销售给产品的最终消费者，而消费者必须亲自去集市找到所要商品的直接生产者，如果一方没有找到合适的目标，那么对不起，大家都在集市等待。相对于有缓冲的 BlockingQueue 来说，少了一个中间经销商的环节（缓冲区），如果有经销商，生产者直接把产品批发给经 销商，而无需在意经销商最终会将这些产品卖给那些消费者，由于经销商可以库存一部分商品，因此相对于直接交易模式，总体来说采用中间经销商的模式会吞吐量高一些（可以批量买卖）；但另一方面，又因为经销商的引入，使得产品从生产者到消费者中间增加了额外的交易环节，单个产品的及时响应性能可能会降低。声明一个 SynchronousQueue 有两种不同的方式，它们之间有着不太一样的行为。 公平模式和非公平模式的区别: 公平模式：SynchronousQueue 会采用公平锁，并配合一个 FIFO 队列来阻塞多余的生产者和消费者，从而体系整体的公平策略； 非公平模式（SynchronousQueue 默认）：SynchronousQueue 采用非公平锁，同时配合一个 LIFO 队列来管理多余的生产者和消费者，而后一种模式，如果生产者和消费者的处理速度有差距，则很容易出现饥渴的情况，即可能有某些生产者或者是消费者的数据永远都得不到处理。 ==一句话总结: 不存储元素的阻塞队列，也即单个元素的队列。== 1.4.6 LinkedTransferQueueLinkedTransferQueue 是一个由链表结构组成的无界阻塞 TransferQueue 队列。相对于其他阻塞队列，LinkedTransferQueue 多了 tryTransfer 和transfer 方法。LinkedTransferQueue 采用一种预占模式。意思就是消费者线程取元素时，如果队列不为空，则直接取走数据，若队列为空，那就生成一个节点（节点元素为 null）入队，然后消费者线程被等待在这个节点上，后面生产者线程入队时发现有一个元素为 null 的节点，生产者线程就不入队了，直接就将元素填充到该节点，并唤醒该节点等待的线程，被唤醒的消费者线程取走元素，从调用的方法返回。 ==一句话总结: 由链表组成的无界阻塞队列。== 1.4.7 LinkedBlockingDequeLinkedBlockingDeque 是一个由链表结构组成的双向阻塞队列，即可以从队列的两端插入和移除元素。对于一些指定的操作，在插入或者获取队列元素时如果队列状态不允许该操作可能会阻塞住该线程直到队列状态变更为允许操作，这里的阻塞一般有两种情况 插入元素时: 如果当前队列已满将会进入阻塞状态，一直等到队列有空的位置时再讲该元素插入，该操作可以通过设置超时参数，超时后返回 false 表示操作失败，也可以不设置超时参数一直阻塞，中断后抛出 InterruptedException 异常 读取元素时: 如果当前队列为空会阻塞住直到队列不为空然后返回元素，同样可以通过设置超时参数 ==一句话总结: 由链表组成的双向阻塞队列== 1.5 小结 在多线程领域：所谓阻塞，在某些情况下会挂起线程（即阻塞），一旦条件满足，被挂起的线程又会自动被唤起 为什么需要 BlockingQueue? 在 concurrent 包发布以前，在多线程环境下，我们每个程序员都必须去自己控制这些细节，尤其还要兼顾效率和线程安全，而这会给我们的程序带来不小的复杂度。使用后我们不需要关心什么时候需要阻塞线程，什么时候需要唤醒线程，因为这一切 BlockingQueue 都给你一手包办了 ThreadPool 线程池1.1 线程池简介线程池（英语：thread pool）：一种线程使用模式。线程过多会带来调度开销，进而影响缓存局部性和整体性能。而线程池维护着多个线程，等待着监督管理者分配可并发执行的任务。这避免了在处理短时间任务时创建与销毁线程的代价。线程池不仅能够保证内核的充分利用，还能防止过分调度。例子： 10 年前单核 CPU 电脑，假的多线程，像马戏团小丑玩多个球，CPU 需要来回切换。 现在是多核电脑，多个线程各自跑在独立的 CPU 上，不用切换效率高。 线程池的优势： 线程池做的工作只要是控制运行的线程数量，处理过程中将任务放入队列，然后在线程创建后启动这些任务，如果线程数量超过了最大数量，超出数量的线程排队等候，等其他线程执行完毕，再从队列中取出任务来执行。 它的主要特点为： 降低资源消耗: 通过重复利用已创建的线程降低线程创建和销毁造成的销耗。 提高响应速度: 当任务到达时，任务可以不需要等待线程创建就能立即执行。 提高线程的可管理性: 线程是稀缺资源，如果无限制的创建，不仅会销耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 Java 中的线程池是通过 Executor 框架实现的，该框架中用到了 Executor，Executors，ExecutorService，ThreadPoolExecutor 这几个类 1.2 线程池参数说明本次介绍 5 种类型的线程池 1.2.1 常用参数(重点) corePoolSize 线程池的核心线程数 maximumPoolSize 能容纳的最大线程数 keepAliveTime 空闲线程存活时间 unit 存活的时间单位 workQueue 存放提交但未执行任务的队列 threadFactory 创建线程的工厂类 handler 等待队列满后的拒绝策略 线程池中，有三个重要的参数，决定影响了拒绝策略：corePoolSize - 核心线程数，也即最小的线程数。workQueue - 阻塞队列 。 maximumPoolSize -最大线程数当提交任务数大于 corePoolSize 的时候，会优先将任务放到 workQueue 阻塞队列中。当阻塞队列饱和后，会扩充线程池中线程数，直到达到maximumPoolSize 最大线程数配置。此时，再多余的任务，则会触发线程池的拒绝策略了。总结起来，也就是一句话，当提交的任务数大于（workQueue.size() + maximumPoolSize ），就会触发线程池的拒绝策略。 1.2.2 拒绝策略(重点)CallerRunsPolicy: 当触发拒绝策略，只要线程池没有关闭的话，则使用调用线程直接运行任务。一般并发比较小，性能要求不高，不允许失败。但是，由于调用者自己运行任务，如果任务提交速度过快，可能导致程序阻塞，性能效率上必然的损失较大 AbortPolicy: 丢弃任务，并抛出拒绝执行 RejectedExecutionException 异常信息。线程池默认的拒绝策略。必须处理好抛出的异常，否则会打断当前的执行流程，影响后续的任务执行。 DiscardPolicy: 直接丢弃，其他啥都没有DiscardOldestPolicy: 当触发拒绝策略，只要线程池没有关闭的话，丢弃阻塞队列 workQueue 中最老的一个任务，并将新任务加入 1.3 线程池的种类与创建1.3.1 newCachedThreadPool(常用)作用：创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空 闲线程，若无可回收，则新建线程. 特点: 线程池中数量没有固定，可达到最大值（Interger. MAX_VALUE） 线程池中的线程可进行缓存重复利用和回收（回收默认时间为 1 分钟） 当线程池中，没有可用线程，会重新创建一个线程 创建方式: /** * 可缓存线程池 * @return */ public static ExecutorService newCachedThreadPool(){ /** * corePoolSize 线程池的核心线程数 * maximumPoolSize 能容纳的最大线程数 * keepAliveTime 空闲线程存活时间 * unit 存活的时间单位 * workQueue 存放提交但未执行任务的队列 * threadFactory 创建线程的工厂类:可以省略 * handler 等待队列满后的拒绝策略:可以省略 */ return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;&gt;(), Executors.defaultThreadFactory(), new ThreadPoolExecutor.AbortPolicy()); } 场景: 适用于创建一个可无限扩大的线程池，服务器负载压力较轻，执行时间较短，任务多的场景 1.3.2 newFixedThreadPool(常用)作用：创建一个可重用固定线程数的线程池，以共享的无界队列方式来运行这些线程。在任意点，在大多数线程会处于处理任务的活动状态。如果在所有线程处于活动状态时提交附加任务，则在有可用线程之前，附加任务将在队列中等待。如果在关闭前的执行期间由于失败而导致任何线程终止，那么一个新线程将代替它执行后续的任务（如果需要）。在某个线程被显式地关闭之前，池中的线程将一直存在。 特征： 线程池中的线程处于一定的量，可以很好的控制线程的并发量 线程可以重复被使用，在显示关闭之前，都将一直存在 超出一定量的线程被提交时候需在队列中等待 创建方式： /** * 固定长度线程池 * @return */ public static ExecutorService newFixedThreadPool(){ /** * corePoolSize 线程池的核心线程数 * maximumPoolSize 能容纳的最大线程数 * keepAliveTime 空闲线程存活时间 * unit 存活的时间单位 * workQueue 存放提交但未执行任务的队列 * threadFactory 创建线程的工厂类:可以省略 * handler 等待队列满后的拒绝策略:可以省略 */ return new ThreadPoolExecutor(10, 10, 0L, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(), Executors.defaultThreadFactory(), new ThreadPoolExecutor.AbortPolicy()); } 场景: 适用于可以预测线程数量的业务中，或者服务器负载较重，对线程数有严格限制的场景 1.3.3 newSingleThreadExecutor(常用)作用：创建一个使用单个 worker 线程的 Executor，以无界队列方式来运行该线程。（注意，如果因为在关闭前的执行期间出现失败而终止了此单个线程，那么如果需要，一个新线程将代替它执行后续的任务）。可保证顺序地执行各个任务，并且在任意给定的时间不会有多个线程是活动的。与其他等效的newFixedThreadPool 不同，可保证无需重新配置此方法所返回的执行程序即可使用其他的线程。 特征： 线程池中最多执行 1 个线程，之后提交的线程活动将会排在队列中以此执行 创建方式： /** * 单一线程池 * @return */ public static ExecutorService newSingleThreadExecutor(){ /** * corePoolSize 线程池的核心线程数 * maximumPoolSize 能容纳的最大线程数 * keepAliveTime 空闲线程存活时间 * unit 存活的时间单位 * workQueue 存放提交但未执行任务的队列 * threadFactory 创建线程的工厂类:可以省略 * handler 等待队列满后的拒绝策略:可以省略 */ return new ThreadPoolExecutor(1, 1, 0L, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(), Executors.defaultThreadFactory(), new ThreadPoolExecutor.AbortPolicy()); } 场景: 适用于需要保证顺序执行各个任务，并且在任意时间点，不会同时有多个线程的场景 1.3.4 newScheduleThreadPool(了解)作用: 线程池支持定时以及周期性执行任务，创建一个 corePoolSize 为传入参数，最大线程数为整形的最大数的线程池 特征: 线程池中具有指定数量的线程，即便是空线程也将保留 可定时或者延迟执行线程活动 创建方式: public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize, ThreadFactory threadFactory) { return new ScheduledThreadPoolExecutor(corePoolSize, threadFactory); } 场景: 适用于需要多个后台线程执行周期任务的场景 1.3.5 newWorkStealingPooljdk1.8 提供的线程池，底层使用的是 ForkJoinPool 实现，创建一个拥有多个任务队列的线程池，可以减少连接数，创建当前可用 cpu 核数的线程来并行执行任务 创建方式: public static ExecutorService newWorkStealingPool(int parallelism) { /** * parallelism：并行级别，通常默认为 JVM 可用的处理器个数 * factory：用于创建 ForkJoinPool 中使用的线程。 * handler：用于处理工作线程未处理的异常，默认为 null * asyncMode：用于控制 WorkQueue 的工作模式:队列---反队列 */ return new ForkJoinPool(parallelism, ForkJoinPool.defaultForkJoinWorkerThreadFactory, null, true); } 场景: 适用于大耗时，可并行执行的场景 1.4 线程池入门案例场景: 火车站 3 个售票口, 10 个用户买票 /** * 火车站 3 个售票口, 10 个用户买票 * * @param args */ public static void main(String[] args) { //定时线程次:线程数量为 3---窗口数为 3 ExecutorService threadService = new ThreadPoolExecutor(3, 3, 60L, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(), Executors.defaultThreadFactory(), new ThreadPoolExecutor.DiscardOldestPolicy()); try { //10 个人买票 for (int i = 1; i &lt;= 10; i++) { threadService.execute(() -&gt; { try { System.out.println(Thread.currentThread().getName() + \" 窗口, 开始卖票\"); Thread.sleep(5000); System.out.println(Thread.currentThread().getName() + \" 窗口买票结束\"); } catch (Exception e) { e.printStackTrace(); } }); } } catch (Exception e) { e.printStackTrace(); } finally { //完成后结束 threadService.shutdown(); } } 1.5 线程池底层工作原理(重要) 在创建了线程池后，线程池中的线程数为零 当调用 execute()方法添加一个请求任务时，线程池会做出如下判断： 如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入 队列 如果这个时候队列满了且正在运行的线程数量还小于maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务 如果队列满了且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会启动饱和拒绝策略来执行。 当一个线程完成任务时，它会从队列中取下一个任务来执行 当一个线程无事可做超过一定的时间（keepAliveTime）时，线程会判断： 如果当前运行的线程数大于 corePoolSize，那么这个线程就被停掉。 所以线程池的所有任务完成后，它最终会收缩到 corePoolSize 的大小。 1.6 注意事项(重要) 项目中创建多线程时，使用常见的三种线程池创建方式，单一、可变、定长都有一定问题，原因是 FixedThreadPool 和 SingleThreadExecutor 底层都是用LinkedBlockingQueue 实现的，这个队列最大长度为 Integer.MAX_VALUE，容易导致 OOM。所以实际生产一般自己通过 ThreadPoolExecutor 的 7 个参数，自定义线程池 创建线程池推荐适用 ThreadPoolExecutor 及其 7 个参数手动创建 corePoolSize 线程池的核心线程数 maximumPoolSize 能容纳的最大线程数 keepAliveTime 空闲线程存活时间 unit 存活的时间单位 workQueue 存放提交但未执行任务的队列 threadFactory 创建线程的工厂类 handler 等待队列满后的拒绝策略 为什么不允许适用不允许 Executors.的方式手动创建线程池,如下图","categories":[],"tags":[{"name":"JUC并发编程","slug":"JUC并发编程","permalink":"https://gitee.com/yunyd/tags/JUC%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"author":"llllz."},{"title":"Linux","slug":"Linux","date":"2023-07-26T03:00:36.000Z","updated":"2023-08-28T01:10:09.245Z","comments":true,"path":"posts/53d0684b.html","link":"","permalink":"https://gitee.com/yunyd/posts/53d0684b.html","excerpt":"","text":"Linux基础命令Linux的目录结构 /，根目录是最顶级的目录了 Linux只有一个顶级目录：/ 路径描述的层次关系同样适用/来表示 /home/itheima/a.txt，表示根目录下的home文件夹内有itheima文件夹，内有a.txt 开放端口 开放80端口 firewall-cmd –zone=public –add-port=80/tcp –permanent 重启firewall firewall-cmd –reload 查看开放的端口 firewall-cmd –list-ports 返回刚才的目录 cd - 图形化界面与命令行模式的切换 systemctl set-default graphical.target //设置开机启动自动由命令行模式更改为图形界面模式 systemctl set-default multi-user.target //设置开机启动自动由图形界面模式更改为命令行模式 init 0 //关机 init 3 //由图形化界面切换到命令行界面 init 5 //由命令行界面切换到图形化界面 init 6 或 reboot //重启 防火墙 systemctl status firewalld 查看当前防火墙状态 systemctl stop firewalld.service 关闭防火墙 systemctl disable firewalld.service 禁止开机自启防火墙 systemctl start firewalld.service 打开防火墙 Linux命令行上面查看命令的用法命令 –help ls命令功能：列出文件夹信息 语法：ls [-l -h -a] [参数] 参数：被查看的文件夹，不提供参数，表示查看当前工作目录 -l，以列表形式查看 -h，配合-l，以更加人性化的方式显示文件大小 -a，显示隐藏文件 隐藏文件、文件夹在Linux中以.开头的，均是隐藏的。 默认不显示出来，需要-a选项才可查看到。 pwd命令功能：展示当前工作目录 语法：pwd cd命令功能：切换工作目录 语法：cd [目标目录] 参数：目标目录，要切换去的地方，不提供默认切换到当前登录用户HOME目录 HOME目录每一个用户在Linux系统中都有自己的专属工作目录，称之为HOME目录。 普通用户的HOME目录，默认在：/home/用户名 root用户的HOME目录，在：/root FinalShell登陆终端后，默认的工作目录就是用户的HOME目录 相对路径、绝对路径 相对路径，==非==/开头的称之为相对路径 相对路径表示以当前目录作为起点，去描述路径，如test/a.txt，表示当前工作目录内的test文件夹内的a.txt文件 绝对路径，==以==/开头的称之为绝对路径 绝对路径从根开始描述路径 特殊路径符 .，表示当前，比如./a.txt，表示当前文件夹内的a.txt文件 ..，表示上级目录，比如../表示上级目录，../../表示上级的上级目录 ~，表示用户的HOME目录，比如cd ~，即可切回用户HOME目录 nohup命令英文全称：no hang up（不挂起），用于不挂断地运行指定命令，退出终端不会影响程序的运行； 语法格式：nohup Command [Arg …] [&amp;] 参数说明： Command：要执行的命令 Arg：一些参数，可以指定输出文件 &amp;：让命令在后台运行 举例： nohup java -jar boot工程.jar &amp;&gt; hello.log &amp; 后台运行java -jar命令，并将日志输出到hello.log文件,hello.log文件会在当前目录下面生成 mkdir命令功能：创建文件夹 语法：mkdir [-p] 参数 参数：被创建文件夹的路径（相对、绝对、特殊路径符都可以使用） mkdir /home/test mkdir test01 选项：-p，可选，表示创建前置路径（表示自动创建不存在的父目录，适用于创建连续多层级的目录） mkdir -p itliu/good/666（如果不用-p的话，会报错，因为没有itliu和good的文件夹） 注意：如果是普通用户的话，创建文件夹需要修改权限，只能在HOME目录内才可以创建文件夹，在HOME目录外创建文件夹需要权限，root用户才可以 touch命令功能：创建文件 语法：touch 参数 touch test 参数：被创建的文件路径（相对、绝对、特殊路径符都可以使用） cat命令功能：查看文件内容 语法：cat 参数 参数：被查看的文件路径（相对、绝对、特殊路径符都可以使用） more命令功能：查看文件，可以支持翻页查看 语法：more 参数 参数：被查看的文件路径（相对、绝对、特殊路径符都可以使用） 在查看过程中： 空格键翻页 q退出查看 cp命令功能：复制文件、文件夹 语法：cp [-r] 参数1 参数2 参数1，被复制的 参数2，要复制去的地方 选项：-r，可选，复制文件夹使用 示例： cp a.txt b.txt，复制当前目录下a.txt为b.txt cp a.txt test/，复制当前目录a.txt到test文件夹内 cp -r test test2，复制文件夹test及test下面的所有文件到当前文件夹内为test2存在 cp -r test/. test2 表示将test下的文件复制到test2,不包括test目录 mv命令功能：移动文件、文件夹 语法：mv 参数1 参数2 参数1：Linux路径，被移动的文件或者文件夹 参数2：Linux路径，要移动去的地方，参数2如果不存在，则会进行改名 mv test01.txt test02.txt(将test01.txt改名为test02.txt) rm命令功能：删除文件、文件夹 语法：rm [-r -f] 参数1 参数2....参数N 参数：支持多个，每一个表示被删除的，空格进行分隔(可以用绝对，相对，特殊路径)（/root/test） 选项：-r，删除文件夹使用 选项：-f，强制删除，不会给出确认提示，一般root用户会用到 rm命令支持通配符*，用来做模糊匹配 符号*表示通配符， 即匹配任意内容（包含空），示例： test*，表示匹配任何以test开头 的内容 *test，表示匹配任何以test结尾的内容 *test *，表示匹配任何包含test的内容 rm命令很危险，一定要注意，特别是切换到root用户的时候。 which命令功能：查看命令的程序本体文件路径，前面学习的Linux命令，其实它们的本体就是一个个的二进制可执行程序，和Windows系统中的.exe文件，是一个意思。可以通过which命令，查看所使用的一系列命令的程序文件存放在哪里 语法：which 参数 参数：被查看的命令 例： [itliu@bogon ~]which cd /usr/bin/cd [itliu@bogon ~]which pwd /usr/bin/pwd find命令功能：按名称搜索文件 语法1按文件名搜索：find 路径 -name 参数(“被查找的文件名或者目录”) 路径，搜索的起始路径 参数，搜索的关键字，支持通配符*， 比如：*test表示搜索任意以test结尾的文件 功能：按文件大小查找文件 语法：find 其实路径 -size +|-n[kMG] +、-表示大于和小于 n表示大小数字 kMG表示大单位，k（小写字母）表示kb，M表示MB，G表示GB 示例： 查找小于10KB的文件：find / -size -10k 查找大于100MB的文件: find /-size +100M 查找大于1GB的文件: fing / -size +1G grep命令功能：过滤关键字 语法：grep [-n] 关键字 文件路径 选项-n，可选，表示在结果中显示匹配的行的行号。 参数，关键字，必填，表示过滤的关键字，带有空格或其它特殊符号，建议使用””将关键字包围起来 参数，文件路径，必填，表示要过滤内容的文件路径，可作为内容输入端口 grep “itheima” test.txt grep -n “itheima” test.txt 参数文件路径，可以作为管道符的输入 wc命令功能：统计 语法：wc [-c -m -l -w] 文件路径 选项，-c，统计bytes数量 选项，-m，统计字符数量 选项，-l，统计行数 选项，-w，统计单词数量 参数，文件路径，被统计的文件，可作为内容输入端口 wc test.txt 参数文件路径，可作为管道符的输入 管道符|写法：| 功能：将符号左边命令的结果，作为符号右边命令的输入 示例： cat a.txt | grep itheima，将cat a.txt的结果，作为grep命令的输入，用来过滤itheima关键字 cat a.txt | grep itheima 等同于 grep itheima a.txt cat a.txt | wc -l 等同于 wc -l a.txt 可以支持嵌套： cat a.txt | grep itheima | grep itcast 执行流程：首先cat a.txt | grep itheima ，然后将cat a.txt | grep itheima的结果作为grep itcast命令的输入 管道符左边的命令不一定只能是cat，只要是能产生内容输出的命令，都可以跟管道符做配合。比如ls命令，也有输出 例如： ls | grep test 这样就可以在当前目录里面的所有文件夹过滤出test的文件夹 ls /usr/bin | grep gtf 可以在/usr/bin目录下面，只输出gtf，过滤掉出gtf外所有的文件 ls -l /usr/bin | grep gtf ls -l /usr/bin | wc -l 统计出/usr/bin目录下面共计多少行 echo命令功能：输出内容 语法：echo 参数 参数：被输出的内容,带有空格或者\\等特殊符号，建议使用双引号包围（因为不包围的话，空格后很容易被识别为参数2，尽管 echo不受影响，但是要养成习惯 echo “Hello World” `反引号功能：被两个反引号包围的内容，会作为命令执行 ``这个符号位于Esc下面与~符号在一起 示例： echo `pwd`，会输出当前工作目录 重定向符 &gt;,将左侧命令的结果，覆盖写入到符号右侧指定的文件中 &gt;&gt;,将左侧命令的结果，追加写入到符号右侧指定的文件中 演示： 先执行echo “Hello Linux” &gt; itheima.txt 再执行echo “Hello itheima” &gt;itheima.txt，覆盖新内容 再次执行echo “Hello itcast” &gt;&gt; itheima.txt，使用&gt;&gt;追加新内容 &gt;和&gt;&gt;的使用，只要是左面产生结果的，可以将符号左面命令的结果，直接覆盖或追加到右面的文件中 tail命令功能：查看文件尾部内容 语法：tail [-f -num] 参数 参数：Linux路径，表示被查看的文件 选项：-f，持续跟踪文件修改 选项: -num,表示查看尾部多少行，不填默认10行 tail test.txt(默认查看尾部10的内容) tail -5 test.txt(查看尾部5行的内容) tail -f test.txt(默认查看尾部10行的内容，并且程序继续运行，此时对当前finalshell右键，复制一个标签，相当于新连接一个窗口，在那个窗口继续使用命令例如：echo “hello dajiahao” &gt;&gt; test.txt,这个命令执行完毕后，此时再打开之前那个标签窗口，会新显示你刚写的内容)如果想停止的话直接ctrl+c head命令功能：查看文件头部内容 语法：head [-n] 参数 参数：被查看的文件 选项：-n，查看的行数 vi编辑器命令模式快捷键 退出搜索模式：noh 底线命令快捷键 命令的选项我们学习的一系列Linux命令，它们所拥有的选项都是非常多的。 比如，简单的ls命令就有：-a -A -b -c -C -d -D -f -F -g -G -h -H -i -I -k -l -L -m -n -N -o -p -q -Q -r-R -s -S -t -T -u -U -v -w -x -X -1等选项，可以发现选项是极其多的。 课程中， 并不会将全部的选项都进行讲解，否则，一个ls命令就可能讲解2小时之久。 课程中，会对常见的选项进行讲解， 足够满足绝大多数的学习、工作场景。 查看命令的帮助可以通过：命令 --help查看命令的帮助手册 查看命令的详细手册可以通过：man 命令查看某命令的详细手册 Linux常用操作软件安装 CentOS系统使用： yum [install remove search] [-y] 软件名称 install 安装 remove 卸载 search 搜索 -y，自动确认 Ubuntu系统使用 apt [install remove search] [-y] 软件名称 install 安装 remove 卸载 search 搜索 -y，自动确认 yum 和 apt 均需要root权限 systemctl功能：控制系统服务的启动关闭等 语法：systemctl start | stop | restart | disable | enable | status 服务名 start，启动 stop，停止 status，查看状态 disable，关闭开机自启 enable，开启开机自启 restart，重启 软链接功能：创建文件、文件夹软链接（快捷方式） 语法：ln -s 参数1 参数2 参数1：被链接的（需要使用绝对路径） 参数2：要链接去的地方（快捷方式的名称和存放位置） 日期语法：date [-d] [+格式化字符串] -d 按照给定的字符串显示日期，一般用于日期计算 格式化字符串：通过特定的字符串标记，来控制显示的日期格式 %Y 年%y 年份后两位数字 (00..99) %m 月份 (01..12) %d 日 (01..31) %H 小时 (00..23) %M 分钟 (00..59) %S 秒 (00..60) %s 自 1970-01-01 00:00:00 UTC 到现在的秒数 示例： 按照2022-01-01的格式显示日期 按照2022-01-01 10:00:00的格式显示日期 -d选项日期计算 支持的时间标记为： 时区修改时区为中国时区 ntp功能：同步时间 安装：yum install -y ntp 启动管理：systemctl start | stop | restart | status | disable | enable ntpd 手动校准时间：ntpdate -u ntp.aliyun.com ip地址格式：a.b.c.d abcd为0~255的数字 特殊IP： 127.0.0.1，表示本机 0.0.0.0 可以表示本机 也可以表示任意IP（看使用场景） 查看ip：ifconfig 主机名功能：Linux系统的名称 查看：hostname 设置：hostnamectl set-hostname 主机名 配置VMware固定IP 修改VMware网络，参阅PPT，图太多 设置Linux内部固定IP 修改文件：/etc/sysconfig/network-scripts/ifcfg-ens33 示例文件内容： TYPE=\"Ethernet\" PROXY_METHOD=\"none\" BROWSER_ONLY=\"no\" BOOTPROTO=\"static\" # 改为static，固定IP DEFROUTE=\"yes\" IPV4_FAILURE_FATAL=\"no\" IPV6INIT=\"yes\" IPV6_AUTOCONF=\"yes\" IPV6_DEFROUTE=\"yes\" IPV6_FAILURE_FATAL=\"no\" IPV6_ADDR_GEN_MODE=\"stable-privacy\" NAME=\"ens33\" UUID=\"1b0011cb-0d2e-4eaa-8a11-af7d50ebc876\" DEVICE=\"ens33\" ONBOOT=\"yes\" IPADDR=\"192.168.88.131\" # IP地址，自己设置，要匹配网络范围 NETMASK=\"255.255.255.0\" # 子网掩码，固定写法255.255.255.0 GATEWAY=\"192.168.88.2\" # 网关，要和VMware中配置的一致 DNS1=\"192.168.88.2\" # DNS1服务器，和网关一致即可 ps命令功能：查看进程信息 语法：ps -ef，查看全部进程信息，可以搭配grep做过滤：ps -ef | grep xxx kill命令 nmap命令 netstat命令功能：查看端口占用，或者进程占用哪个端口 用法：netstat -anp | grep xxx netstat -anp | grep 12345 (如果命令执行完毕后，没有任何结果，就说明没有12345这个进程，并且12345这个端口也没有人占用) ping命令测试网络是否联通 语法：ping [-c num] 参数 wget命令 curl命令 top命令功能：查看主机运行状态 语法：top，查看基础信息 可用选项： 交互式模式中，可用快捷键： df命令查看磁盘占用 iostat命令查看CPU、磁盘的相关信息 sar命令查看网络统计 环境变量 临时设置：export 变量名=变量值 永久设置： 针对用户，设置用户HOME目录内：.bashrc文件 针对全局，设置/etc/profile PATH变量记录了执行程序的搜索路径 可以将自定义路径加入PATH内，实现自定义命令在任意地方均可执行的效果 $符号可以取出指定的环境变量的值 语法：$变量名 示例： echo $PATH，输出PATH环境变量的值 echo ${PATH}ABC，输出PATH环境变量的值以及ABC 如果变量名和其它内容混淆在一起，可以使用${} rz、sz命令rz、sz命令需要安装。可以通过：yum -y install lrzsz，即可安装 rz命令，进行上传，语法：直接输入rz即可 sz命令进行下载，语法：sz 要下载的文件 文件会自动下载到桌面的fsdownload文件夹中 压缩解压Linux和Mac系统常用有2种压缩格式，后缀名分别是： .tar 称之为tarball，归档文件，即简单的将文件组装到一个.tar的文件内，并没有太多文件体积的减少，仅仅是简单的封装 .gz，也常见为.tar.gz，gzip格式压缩文件，即使用gzip压缩算法将文件解压到一个文件内，可以极大地减少压缩后的体积 针对这两种格式，使用tar命令均可以进行压缩和解压缩的操作 语法： tar [-c -v -x- f- z- C] 参数1 参数2 … 参数N -c，创建压缩文件，用于压缩模式 -v，显示压缩、解压过程，用于查看进度 -x，解压模式 -f，要创建的文件，或要解压的文件，-f选项必须在所有选项中位置处于最后一个 -z，gzip模式，不使用-z就是普通的tarball格式 -C，选择解压的目的地，用于解压模式 压缩tar -zcvf 压缩包 被压缩1...被压缩2...被压缩N -z表示使用gzip，可以不写 tar -cvf test.tar 1.txt 2.txt 3.txt 将1.txt 2.txt 3.txt压缩到test.tar文件内 tar -zcvf test.tar 1.txt 2.txt 3.txt 将1.txt 2.txt 3.txt压缩到test.tar.gz文件内,使用gzip模式 zip [-r] 参数1 参数2 参数N 解压tar -zxvf 被解压的文件 -C 要解压去的地方 -z表示使用gzip，可以省略 -C，可以省略，指定要解压去的地方，不写解压到当前目录 unzip [-d] 参数 su命令切换用户 语法：su [-] [用户] sudo命令 比如： itheima ALL=(ALL) NOPASSWD: ALL 在visudo内配置如上内容，可以让itheima用户，无需密码直接使用sudo 查看权限控制信息 序号1，表示文件、文件夹的权限控制信息 序号2，表示文件、文件夹所属用户 序号3，表示文件、文件夹所属用户组 权限信息共十位 第1位 第二位内容（-或d或l） -表示文件 d表示文件夹 l表示软链接 第2-4位 第2位内容（r或-） 第3位内容（w或-） 第4位内容（x或-） -表示无此权限 第5-7位 第5位内容（r或-） 第6位内容（w或-） 第7位内容（x或-） -表示无此权限 第8-10位 第8位内容（r或-） 第9位内容（w或-） 第10位内容（x或-） -表示无此权限 rwx分别代表什么 r,针对文件可以查看文件内容 针对文件夹，可以查看文件夹内容，如ls命令 w，针对文件表示可以修改此文件 针对文件夹，可以在文件夹内：创建、删除、改名等操作 x，针对文件表示可以将文件作为程序执行 针对文件夹，表示可以更改目录到此文件夹，即cd进入 chmod命令修改文件、文件夹权限 语法：chmod [-R] 权限 参数 权限，要设置的权限，比如755，表示：rwxr-xr-x 参数，被修改的文件、文件夹 选项-R，设置文件夹和其内部全部内容一样生效 chmod u=rwx,g=rx,o=x hello.txt，将文件权限修改为：rwxr-x–x 其中：u表示user所属用户权限，g表示group组权限，o表示other其它用户权限 chmod-R u=rwx，g=rx,o=x test，将文件夹test以及文件夹内全部内容权限设置为:rwxr-x–x chown命令修改文件、文件夹所属用户、组 语法：chown [-R] [用户][:][用户组] 文件或文件夹 用户组管理 用户管理 getent命令 getent group，查看系统全部的用户组 getent passwd，查看系统全部的用户 env命令查看系统全部的环境变量 语法：env 常用快捷命令 ctrl + c 强制退出 ctrl + d 退出或登出 （不能用于vi/vim） history查看历史输入过的命令 history | grep ls （过滤出历史输入过的ls命令） ctrl + r 输入内容去匹配历史命令 如果搜索到的内容是你需要的，那么： 回车键可以直接执行 键盘左键或者右键，可以得到此命令（不执行） 光标移动快捷键 ctrl + a 跳到命令开头 ctrl + e 跳到命令结尾 ctrl + 键盘左键，向左跳一个单词 ctrl + 键盘右键，向右跳一个单词 清屏 通过快捷键ctrl + l 可以清空终端内容 或通过命令clear得到同样的效果","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://gitee.com/yunyd/tags/Linux/"}],"author":"llllz."},{"title":"Spring复习 -2","slug":"Spring复习  -2","date":"2023-07-24T11:43:06.000Z","updated":"2023-08-25T00:23:05.987Z","comments":true,"path":"posts/462cc213.html","link":"","permalink":"https://gitee.com/yunyd/posts/462cc213.html","excerpt":"","text":"Spring复习1. IOC/DI配置管理第三方bean前面所讲的知识点都是基于我们自己写的类，现在如果有需求让我们去管理第三方jar包中的类，该如何管理? 1.1 案例:数据源对象管理在这一节中，我们将通过一个案例来学习下对于第三方bean该如何进行配置管理。 以后我们会用到很多第三方的bean,本次案例将使用咱们前面提到过的数据源Druid(德鲁伊)和C3P0来配置学习下。 1.1.1 环境准备学习之前，先来准备下案例环境: 创建一个Maven项目 pom.xml添加依赖 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; resources下添加spring的配置文件applicationContext.xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;/beans&gt; 编写一个运行类App public class App { public static void main(String[] args) { ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); } } 1.1.2 思路分析在上述环境下，我们来对数据源进行配置管理，先来分析下思路: 需求:使用Spring的IOC容器来管理Druid连接池对象 1.使用第三方的技术，需要在pom.xml添加依赖 2.在配置文件中将【第三方的类】制作成一个bean，让IOC容器进行管理 3.数据库连接需要基础的四要素驱动、连接、用户名和密码，【如何注入】到对应的bean中 4.从IOC容器中获取对应的bean对象，将其打印到控制台查看结果 思考: 第三方的类指的是什么? 如何注入数据库连接四要素? 1.1.3 实现Druid管理带着这两个问题，把下面的案例实现下: 步骤1:导入druid的依赖pom.xml中添加依赖 &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.16&lt;/version&gt; &lt;/dependency&gt; 步骤2:配置第三方bean在applicationContext.xml配置文件中添加DruidDataSource的配置 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!--管理DruidDataSource对象--&gt; &lt;bean class=\"com.alibaba.druid.pool.DruidDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/spring_db\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"root\"/&gt; &lt;/bean&gt; &lt;/beans&gt; 说明: driverClassName:数据库驱动 url:数据库连接地址 username:数据库连接用户名 password:数据库连接密码 数据库连接的四要素要和自己使用的数据库信息一致。 步骤3:从IOC容器中获取对应的bean对象public class App { public static void main(String[] args) { ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); DataSource dataSource = (DataSource) ctx.getBean(\"dataSource\"); System.out.println(dataSource); } } 步骤4:运行程序打印如下结果: 说明第三方bean对象已经被spring的IOC容器进行管理 做完案例后，我们可以将刚才思考的两个问题答案说下: 第三方的类指的是什么? DruidDataSource 如何注入数据库连接四要素? setter注入 1.1.4 实现C3P0管理完成了DruidDataSource的管理，接下来我们再来加深下练习，这次我们来管理C3P0数据源，具体的实现步骤是什么呢? 需求:使用Spring的IOC容器来管理C3P0连接池对象 实现方案和上面基本一致，重点要关注管理的是哪个bean对象`? 步骤1:导入C3P0的依赖pom.xml中添加依赖 &lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.1.2&lt;/version&gt; &lt;/dependency&gt; 对于新的技术，不知道具体的坐标该如何查找? 直接百度搜索 从mvn的仓库https://mvnrepository.com/中进行搜索 步骤2:配置第三方bean在applicationContext.xml配置文件中添加配置 &lt;bean id=\"dataSource\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\"&gt; &lt;property name=\"driverClass\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"jdbcUrl\" value=\"jdbc:mysql://localhost:3306/spring_db\"/&gt; &lt;property name=\"user\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"root\"/&gt; &lt;property name=\"maxPoolSize\" value=\"1000\"/&gt; &lt;/bean&gt; ==注意:== ComboPooledDataSource的属性是通过setter方式进行注入 想注入属性就需要在ComboPooledDataSource类或其上层类中有提供属性对应的setter方法 C3P0的四个属性和Druid的四个属性是不一样的 步骤3:运行程序程序会报错，错误如下 报的错为==ClassNotFoundException==,翻译出来是类没有发现的异常，具体的类为com.mysql.jdbc.Driver。错误的原因是缺少mysql的驱动包。 分析出错误的原因，具体的解决方案就比较简单，只需要在pom.xml把驱动包引入即可。 &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; 添加完mysql的驱动包以后，再次运行App,就可以打印出结果: 注意： 数据连接池在配置属性的时候，除了可以注入数据库连接四要素外还可以配置很多其他的属性，具体都有哪些属性用到的时候再去查，一般配置基础的四个，其他都有自己的默认值 Druid和C3P0在没有导入mysql驱动包的前提下，一个没报错一个报错，说明Druid在初始化的时候没有去加载驱动，而C3P0刚好相反 Druid程序运行虽然没有报错，但是当调用DruidDataSource的getConnection()方法获取连接的时候，也会报找不到驱动类的错误 1.2 加载properties文件上节中我们已经完成两个数据源druid和C3P0的配置，但是其中包含了一些问题，我们来分析下: 这两个数据源中都使用到了一些固定的常量如数据库连接四要素，把这些值写在Spring的配置文件中不利于后期维护 需要将这些值提取到一个外部的properties配置文件中 Spring框架如何从配置文件中读取属性值来配置就是接下来要解决的问题。 问题提出来后，具体该如何实现? 1.2.1 第三方bean属性优化1.2.1.1 实现思路 需求:将数据库连接四要素提取到properties配置文件，spring来加载配置信息并使用这些信息来完成属性注入。 1.在resources下创建一个jdbc.properties(文件的名称可以任意) 2.将数据库连接四要素配置到配置文件中 3.在Spring的配置文件中加载properties文件 4.使用加载到的值实现属性注入 其中第3，4步骤是需要大家重点关注，具体是如何实现。 1.2.1.2 实现步骤步骤1:准备properties配置文件resources下创建一个jdbc.properties文件,并添加对应的属性键值对 jdbc.driver=com.mysql.jdbc.Driver jdbc.url=jdbc:mysql://127.0.0.1:3306/spring_db jdbc.username=root jdbc.password=root 步骤2:开启context命名空间在applicationContext.xml中开context命名空间 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;/beans&gt; 步骤3:加载properties配置文件在配置文件中使用context命名空间下的标签来加载properties配置文件 &lt;context:property-placeholder location=\"jdbc.properties\"/&gt; 步骤4:完成属性注入使用${key}来读取properties配置文件中的内容并完成属性注入 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;context:property-placeholder location=\"jdbc.properties\"/&gt; &lt;bean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"${jdbc.driver}\"/&gt; &lt;property name=\"url\" value=\"${jdbc.url}\"/&gt; &lt;property name=\"username\" value=\"${jdbc.username}\"/&gt; &lt;property name=\"password\" value=\"${jdbc.password}\"/&gt; &lt;/bean&gt; &lt;/beans&gt; 至此，读取外部properties配置文件中的内容就已经完成。 1.2.2 读取单个属性1.2.2.1 实现思路对于上面的案例，效果不是很明显，我们可以换个案例来演示下: 需求:从properties配置文件中读取key为name的值，并将其注入到BookDao中并在save方法中进行打印。 1.在项目中添加BookDao和BookDaoImpl类 2.为BookDaoImpl添加一个name属性并提供setter方法 3.在jdbc.properties中添加数据注入到bookDao中打印方便查询结果 4.在applicationContext.xml添加配置完成配置文件加载、属性注入(${key}) 1.2.2.2 实现步骤步骤1:在项目中添对应的类BookDao和BookDaoImpl类，并在BookDaoImpl类中添加name属性与setter方法 public interface BookDao { public void save(); } public class BookDaoImpl implements BookDao { private String name; public void setName(String name) { this.name = name; } public void save() { System.out.println(\"book dao save ...\" + name); } } 步骤2:完成配置文件的读取与注入在applicationContext.xml添加配置，bean的配置管理、读取外部properties、依赖注入: &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;context:property-placeholder location=\"jdbc.properties\"/&gt; &lt;bean id=\"bookDao\" class=\"com.itheima.dao.impl.BookDaoImpl\"&gt; &lt;property name=\"name\" value=\"${jdbc.driver}\"/&gt; &lt;/bean&gt; &lt;/beans&gt; 步骤3:运行程序在App类中，从IOC容器中获取bookDao对象，调用方法，查看值是否已经被获取到并打印控制台 public class App { public static void main(String[] args) throws Exception{ ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); BookDao bookDao = (BookDao) ctx.getBean(\"bookDao\"); bookDao.save(); } } 1.2.2.3 注意事项至此，读取properties配置文件中的内容就已经完成，但是在使用的时候，有些注意事项: 问题一:键值对的key为username引发的问题 1.在properties中配置键值对的时候，如果key设置为username username=root666 2.在applicationContext.xml注入该属性 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;context:property-placeholder location=\"jdbc.properties\"/&gt; &lt;bean id=\"bookDao\" class=\"com.itheima.dao.impl.BookDaoImpl\"&gt; &lt;property name=\"name\" value=\"${username}\"/&gt; &lt;/bean&gt; &lt;/beans&gt; 3.运行后，在控制台打印的却不是root666，而是自己电脑的用户名 4.出现问题的原因是&lt;context:property-placeholder/&gt;标签会加载系统的环境变量，而且环境变量的值会被优先加载，如何查看系统的环境变量? public static void main(String[] args) throws Exception{ Map&lt;String, String&gt; env = System.getenv(); System.out.println(env); } 大家可以自行运行，在打印出来的结果中会有一个USERNAME=XXX[自己电脑的用户名称] 5.解决方案 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;context:property-placeholder location=\"jdbc.properties\" system-properties-mode=\"NEVER\"/&gt; &lt;/beans&gt; system-properties-mode:设置为NEVER,表示不加载系统属性，就可以解决上述问题。 当然还有一个解决方案就是避免使用username作为属性的key。 问题二:当有多个properties配置文件需要被加载，该如何配置? 1.调整下配置文件的内容，在resources下添加jdbc.properties,jdbc2.properties,内容如下: jdbc.properties jdbc.driver=com.mysql.jdbc.Driver jdbc.url=jdbc:mysql://127.0.0.1:3306/spring_db jdbc.username=root jdbc.password=root jdbc2.properties username=root666 2.修改applicationContext.xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!--方式一 --&gt; &lt;context:property-placeholder location=\"jdbc.properties,jdbc2.properties\" system-properties-mode=\"NEVER\"/&gt; &lt;!--方式二--&gt; &lt;context:property-placeholder location=\"*.properties\" system-properties-mode=\"NEVER\"/&gt; &lt;!--方式三 --&gt; &lt;context:property-placeholder location=\"classpath:*.properties\" system-properties-mode=\"NEVER\"/&gt; &lt;!--方式四--&gt; &lt;context:property-placeholder location=\"classpath*:*.properties\" system-properties-mode=\"NEVER\"/&gt; &lt;/beans&gt; 说明: 方式一:可以实现，如果配置文件多的话，每个都需要配置 方式二:*.properties代表所有以properties结尾的文件都会被加载，可以解决方式一的问题，但是不标准 方式三:标准的写法，classpath:代表的是从根路径下开始查找，但是只能查询当前项目的根路径 方式四:不仅可以加载当前项目还可以加载当前项目所依赖的所有项目的根路径下的properties配置文件 1.2.3 加载properties文件小结 本节主要讲解的是properties配置文件的加载，需要掌握的内容有: 如何开启context命名空间 如何加载properties配置文件 &lt;context:property-placeholder location=\"\" system-properties-mode=\"NEVER\"/&gt; 如何在applicationContext.xml引入properties配置文件中的值 ${key} 2. 核心容器前面已经完成bean与依赖注入的相关知识学习，接下来我们主要学习的是IOC容器中的==核心容器==。 这里所说的核心容器，大家可以把它简单的理解为ApplicationContext，前面虽然已经用到过，但是并没有系统的学习，接下来咱们从以下几个问题入手来学习下容器的相关知识: 如何创建容器? 创建好容器后，如何从容器中获取bean对象? 容器类的层次结构是什么? BeanFactory是什么? 2.1 环境准备在学习和解决上述问题之前，先来准备下案例环境: 创建一个Maven项目 pom.xml添加Spring的依赖 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; resources下添加applicationContext.xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"bookDao\" class=\"com.itheima.dao.impl.BookDaoImpl\"/&gt; &lt;/beans&gt; 添加BookDao和BookDaoImpl类 public interface BookDao { public void save(); } public class BookDaoImpl implements BookDao { public void save() { System.out.println(\"book dao save ...\" ); } } 创建运行类App public class App { public static void main(String[] args) { ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); BookDao bookDao = (BookDao) ctx.getBean(\"bookDao\"); bookDao.save(); } } 最终创建好的项目结构如下: 2.2 容器2.2.1 容器的创建方式案例中创建ApplicationContext的方式为: ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); 这种方式翻译为:==类路径下的XML配置文件== 除了上面这种方式，Spring还提供了另外一种创建方式为: ApplicationContext ctx = new FileSystemXmlApplicationContext(\"applicationContext.xml\"); 这种方式翻译为:==文件系统下的XML配置文件== 使用这种方式，运行，会出现如下错误: 从错误信息中能发现，这种方式是从项目路径下开始查找applicationContext.xml配置文件的，所以需要将其修改为: ApplicationContext ctx = new FileSystemXmlApplicationContext(\"D:\\\\workspace\\\\spring\\\\spring_10_container\\\\src\\\\main\\\\resources\\\\applicationContext.xml\"); **说明:**大家练习的时候，写自己的具体路径。 这种方式虽能实现，但是当项目的位置发生变化后,代码也需要跟着改,耦合度较高,不推荐使用。 2.2.2 Bean的三种获取方式方式一，就是目前案例中获取的方式: BookDao bookDao = (BookDao) ctx.getBean(\"bookDao\"); 这种方式存在的问题是每次获取的时候都需要进行类型转换，有没有更简单的方式呢? 方式二： BookDao bookDao = ctx.getBean(\"bookDao\"，BookDao.class); 这种方式可以解决类型强转问题，但是参数又多加了一个，相对来说没有简化多少。 方式三: BookDao bookDao = ctx.getBean(BookDao.class); 这种方式就类似我们之前所学习依赖注入中的按类型注入。必须要确保IOC容器中该类型对应的bean对象只能有一个。 2.2.3 容器类层次结构(1)在IDEA中双击shift,输入BeanFactory (2)点击进入BeanFactory类，ctrl+h,就能查看到如下结构的层次关系 从图中可以看出，容器类也是从无到有根据需要一层层叠加上来的，大家重点理解下这种设计思想。 2.2.4 BeanFactory的使用使用BeanFactory来创建IOC容器的具体实现方式为: public class AppForBeanFactory { public static void main(String[] args) { Resource resources = new ClassPathResource(\"applicationContext.xml\"); BeanFactory bf = new XmlBeanFactory(resources); BookDao bookDao = bf.getBean(BookDao.class); bookDao.save(); } } 为了更好的看出BeanFactory和ApplicationContext之间的区别，在BookDaoImpl添加如下构造函数: public class BookDaoImpl implements BookDao { public BookDaoImpl() { System.out.println(\"constructor\"); } public void save() { System.out.println(\"book dao save ...\" ); } } 如果不去获取bean对象，打印会发现： BeanFactory是延迟加载，只有在获取bean对象的时候才会去创建 ApplicationContext是立即加载，容器加载的时候就会创建bean对象 ApplicationContext要想成为延迟加载，只需要按照如下方式进行配置 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"bookDao\" class=\"com.itheima.dao.impl.BookDaoImpl\" lazy-init=\"true\"/&gt; &lt;/beans&gt; 小结 这一节中所讲的知识点包括: 容器创建的两种方式 ClassPathXmlApplicationContext[掌握] FileSystemXmlApplicationContext[知道即可] 获取Bean的三种方式 getBean(“名称”):需要类型转换 getBean(“名称”,类型.class):多了一个参数 getBean(类型.class):容器中不能有多个该类的bean对象 上述三种方式，各有各的优缺点，用哪个都可以。 容器类层次结构 只需要知晓容器的最上级的父接口为 BeanFactory即可 BeanFactory 使用BeanFactory创建的容器是延迟加载 使用ApplicationContext创建的容器是立即加载 具体BeanFactory如何创建只需要了解即可。 2.2 核心容器总结这节中没有新的知识点，只是对前面知识的一个大总结，共包含如下内容: 2.2.1 容器相关 BeanFactory是IoC容器的顶层接口，初始化BeanFactory对象时，加载的bean延迟加载 ApplicationContext接口是Spring容器的核心接口，初始化时bean立即加载 ApplicationContext接口提供基础的bean操作相关方法，通过其他接口扩展其功能 ApplicationContext接口常用初始化类 ==ClassPathXmlApplicationContext(常用)== FileSystemXmlApplicationContext 2.2.2 bean相关 其实整个配置中最常用的就两个属性==id==和==class==。 把scope、init-method、destroy-method框起来的原因是，后面注解在讲解的时候还会用到，所以大家对这三个属性关注下。 2.2.3 依赖注入相关 3. IOC/DI注解开发Spring的IOC/DI对应的配置开发就已经讲解完成，但是使用起来相对来说还是比较复杂的，复杂的地方在==配置文件==。 前面咱们聊Spring的时候说过，Spring可以简化代码的开发，到现在并没有体会到。 所以Spring到底是如何简化代码开发的呢? 要想真正简化开发，就需要用到Spring的注解开发，Spring对注解支持的版本历程: 2.0版开始支持注解 2.5版注解功能趋于完善 3.0版支持纯注解开发 关于注解开发，我们会讲解两块内容注解开发定义bean和纯注解开发。 注解开发定义bean用的是2.5版提供的注解，纯注解开发用的是3.0版提供的注解。 3.1 环境准备在学习注解开发之前，先来准备下案例环境: 创建一个Maven项目 pom.xml添加Spring的依赖 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; resources下添加applicationContext.xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"bookDao\" class=\"com.itheima.dao.impl.BookDaoImpl\"/&gt; &lt;/beans&gt; 添加BookDao、BookDaoImpl、BookService、BookServiceImpl类 public interface BookDao { public void save(); } public class BookDaoImpl implements BookDao { public void save() { System.out.println(\"book dao save ...\" ); } } public interface BookService { public void save(); } public class BookServiceImpl implements BookService { public void save() { System.out.println(\"book service save ...\"); } } 创建运行类App public class App { public static void main(String[] args) { ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); BookDao bookDao = (BookDao) ctx.getBean(\"bookDao\"); bookDao.save(); } } 最终创建好的项目结构如下: 3.2 注解开发定义bean在上述环境的基础上，我们来学一学Spring是如何通过注解实现bean的定义开发? 步骤1:删除原XML配置将配置文件中的&lt;bean&gt;标签删除掉 &lt;bean id=\"bookDao\" class=\"com.itheima.dao.impl.BookDaoImpl\"/&gt; 步骤2:Dao上添加注解在BookDaoImpl类上添加@Component注解 @Component(\"bookDao\") public class BookDaoImpl implements BookDao { public void save() { System.out.println(\"book dao save ...\" ); } } ==注意:@Component注解不可以添加在接口上，因为接口是无法创建对象的。== XML与注解配置的对应关系: 步骤3:配置Spring的注解包扫描为了让Spring框架能够扫描到写在类上的注解，需要在配置文件上进行包扫描 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;context:component-scan base-package=\"com.itheima\"/&gt; &lt;/beans&gt; 说明: component-scan component:组件,Spring将管理的bean视作自己的一个组件 scan:扫描 base-package指定Spring框架扫描的包路径，它会扫描指定包及其子包中的所有类上的注解。 包路径越多[如:com.itheima.dao.impl]，扫描的范围越小速度越快 包路径越少[如:com.itheima],扫描的范围越大速度越慢 一般扫描到项目的组织名称即Maven的groupId下[如:com.itheima]即可。 步骤4：运行程序运行App类查看打印结果 步骤5:Service上添加注解在BookServiceImpl类上也添加@Component交给Spring框架管理 @Component public class BookServiceImpl implements BookService { private BookDao bookDao; public void setBookDao(BookDao bookDao) { this.bookDao = bookDao; } public void save() { System.out.println(\"book service save ...\"); bookDao.save(); } } 步骤6:运行程序在App类中，从IOC容器中获取BookServiceImpl对应的bean对象，打印 public class App { public static void main(String[] args) { ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); BookDao bookDao = (BookDao) ctx.getBean(\"bookDao\"); System.out.println(bookDao); //按类型获取bean BookService bookService = ctx.getBean(BookService.class); System.out.println(bookService); } } 打印观察结果，两个bean对象都已经打印到控制台 说明: BookServiceImpl类没有起名称，所以在App中是按照类型来获取bean对象 @Component注解如果不起名称，会有一个默认值就是当前类名首字母小写，所以也可以按照名称获取，如 BookService bookService = (BookService)ctx.getBean(\"bookServiceImpl\"); System.out.println(bookService); 对于@Component注解，还衍生出了其他三个注解@Controller、@Service、@Repository 通过查看源码会发现: 这三个注解和@Component注解的作用是一样的，为什么要衍生出这三个呢? 方便我们后期在编写类的时候能很好的区分出这个类是属于表现层、业务层还是数据层的类。 知识点1:@Component等 名称 @Component/@Controller/@Service/@Repository 类型 类注解 位置 类定义上方 作用 设置该类为spring管理的bean 属性 value（默认）：定义bean的id 3.2 纯注解开发模式上面已经可以使用注解来配置bean,但是依然有用到配置文件，在配置文件中对包进行了扫描，Spring在3.0版已经支持纯注解开发 Spring3.0开启了纯注解开发模式，使用Java类替代配置文件，开启了Spring快速开发赛道 具体如何实现? 3.2.1 思路分析实现思路为: 将配置文件applicationContext.xml删除掉，使用类来替换。 3.2.2 实现步骤步骤1:创建配置类创建一个配置类SpringConfig public class SpringConfig { } 步骤2:标识该类为配置类在配置类上添加@Configuration注解，将其标识为一个配置类,替换applicationContext.xml @Configuration public class SpringConfig { } 步骤3:用注解替换包扫描配置在配置类上添加包扫描注解@ComponentScan替换&lt;context:component-scan base-package=\"\"/&gt; @Configuration @ComponentScan(\"com.itheima\") public class SpringConfig { } 步骤4:创建运行类并执行创建一个新的运行类AppForAnnotation public class AppForAnnotation { public static void main(String[] args) { ApplicationContext ctx = new AnnotationConfigApplicationContext(SpringConfig.class); BookDao bookDao = (BookDao) ctx.getBean(\"bookDao\"); System.out.println(bookDao); BookService bookService = ctx.getBean(BookService.class); System.out.println(bookService); } } 运行AppForAnnotation,可以看到两个对象依然被获取成功 至此，纯注解开发的方式就已经完成了，主要内容包括: Java类替换Spring核心配置文件 @Configuration注解用于设定当前类为配置类 @ComponentScan注解用于设定扫描路径，此注解只能添加一次，多个数据请用数组格式 @ComponentScan({com.itheima.service\",\"com.itheima.dao\"}) 读取Spring核心配置文件初始化容器对象切换为读取Java配置类初始化容器对象 //加载配置文件初始化容器 ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); //加载配置类初始化容器 ApplicationContext ctx = new AnnotationConfigApplicationContext(SpringConfig.class); 知识点1：@Configuration 名称 @Configuration 类型 类注解 位置 类定义上方 作用 设置该类为spring配置类 属性 value（默认）：定义bean的id 知识点2：@ComponentScan 名称 @ComponentScan 类型 类注解 位置 类定义上方 作用 设置spring配置类扫描路径，用于加载使用注解格式定义的bean 属性 value（默认）：扫描路径，此路径可以逐层向下扫描 小结: 这一节重点掌握的是使用注解完成Spring的bean管理，需要掌握的内容为: 记住@Component、@Controller、@Service、@Repository这四个注解 applicationContext.xml中&lt;context:component-san/&gt;的作用是指定扫描包路径，注解为@ComponentScan @Configuration标识该类为配置类，使用类替换applicationContext.xml文件 ClassPathXmlApplicationContext是加载XML配置文件 AnnotationConfigApplicationContext是加载配置类 3.3 注解开发bean作用范围与生命周期管理使用注解已经完成了bean的管理，接下来按照前面所学习的内容，将通过配置实现的内容都换成对应的注解实现，包含两部分内容:bean作用范围和bean生命周期。 3.3.1 环境准备老规矩，学习之前先来准备环境: 创建一个Maven项目 pom.xml添加Spring的依赖 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 添加一个配置类SpringConfig @Configuration @ComponentScan(\"com.itheima\") public class SpringConfig { } 添加BookDao、BookDaoImpl类 public interface BookDao { public void save(); } @Repository public class BookDaoImpl implements BookDao { public void save() { System.out.println(\"book dao save ...\" ); } } 创建运行类App public class App { public static void main(String[] args) { AnnotationConfigApplicationContext ctx = new AnnotationConfigApplicationContext(SpringConfig.class); BookDao bookDao1 = ctx.getBean(BookDao.class); BookDao bookDao2 = ctx.getBean(BookDao.class); System.out.println(bookDao1); System.out.println(bookDao2); } } 最终创建好的项目结构如下: 3.3.2 Bean的作用范围(1)先运行App类,在控制台打印两个一摸一样的地址，说明默认情况下bean是单例 (2)要想将BookDaoImpl变成非单例，只需要在其类上添加@scope注解 @Repository //@Scope设置bean的作用范围 @Scope(\"prototype\") public class BookDaoImpl implements BookDao { public void save() { System.out.println(\"book dao save ...\"); } } 再次执行App类，打印结果: 知识点1：@Scope 名称 @Scope 类型 类注解 位置 类定义上方 作用 设置该类创建对象的作用范围可用于设置创建出的bean是否为单例对象 属性 value（默认）：定义bean作用范围，==默认值singleton（单例），可选值prototype（非单例）== 3.3.3 Bean的生命周期(1)在BookDaoImpl中添加两个方法，init和destroy,方法名可以任意 @Repository public class BookDaoImpl implements BookDao { public void save() { System.out.println(\"book dao save ...\"); } public void init() { System.out.println(\"init ...\"); } public void destroy() { System.out.println(\"destroy ...\"); } } (2)如何对方法进行标识，哪个是初始化方法，哪个是销毁方法? 只需要在对应的方法上添加@PostConstruct和@PreDestroy注解即可。 @Repository public class BookDaoImpl implements BookDao { public void save() { System.out.println(\"book dao save ...\"); } @PostConstruct //在构造方法之后执行，替换 init-method public void init() { System.out.println(\"init ...\"); } @PreDestroy //在销毁方法之前执行,替换 destroy-method public void destroy() { System.out.println(\"destroy ...\"); } } (3)要想看到两个方法执行，需要注意的是destroy只有在容器关闭的时候，才会执行，所以需要修改App的类 public class App { public static void main(String[] args) { AnnotationConfigApplicationContext ctx = new AnnotationConfigApplicationContext(SpringConfig.class); BookDao bookDao1 = ctx.getBean(BookDao.class); BookDao bookDao2 = ctx.getBean(BookDao.class); System.out.println(bookDao1); System.out.println(bookDao2); ctx.close(); //关闭容器 } } (4)运行App,类查看打印结果，证明init和destroy方法都被执行了。 ==注意:@PostConstruct和@PreDestroy注解如果找不到，需要导入下面的jar包== &lt;dependency&gt; &lt;groupId&gt;javax.annotation&lt;/groupId&gt; &lt;artifactId&gt;javax.annotation-api&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; 找不到的原因是，从JDK9以后jdk中的javax.annotation包被移除了，这两个注解刚好就在这个包中。 知识点1：@PostConstruct 名称 @PostConstruct 类型 方法注解 位置 方法上 作用 设置该方法为初始化方法 属性 无 知识点2：@PreDestroy 名称 @PreDestroy 类型 方法注解 位置 方法上 作用 设置该方法为销毁方法 属性 无 小结 3.4 注解开发依赖注入Spring为了使用注解简化开发，并没有提供构造函数注入、setter注入对应的注解，只提供了自动装配的注解实现。 3.4.1 环境准备在学习之前，把案例环境介绍下: 创建一个Maven项目 pom.xml添加Spring的依赖 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 添加一个配置类SpringConfig @Configuration @ComponentScan(\"com.itheima\") public class SpringConfig { } 添加BookDao、BookDaoImpl、BookService、BookServiceImpl类 public interface BookDao { public void save(); } @Repository public class BookDaoImpl implements BookDao { public void save() { System.out.println(\"book dao save ...\" ); } } public interface BookService { public void save(); } @Service public class BookServiceImpl implements BookService { private BookDao bookDao; public void setBookDao(BookDao bookDao) { this.bookDao = bookDao; } public void save() { System.out.println(\"book service save ...\"); bookDao.save(); } } 创建运行类App public class App { public static void main(String[] args) { AnnotationConfigApplicationContext ctx = new AnnotationConfigApplicationContext(SpringConfig.class); BookService bookService = ctx.getBean(BookService.class); bookService.save(); } } 最终创建好的项目结构如下: 环境准备好后，运行后会发现有问题 出现问题的原因是，在BookServiceImpl类中添加了BookDao的属性，并提供了setter方法，但是目前是没有提供配置注入BookDao的，所以bookDao对象为Null,调用其save方法就会报控指针异常。 3.4.2 注解实现按照类型注入对于这个问题使用注解该如何解决? (1) 在BookServiceImpl类的bookDao属性上添加@Autowired注解 @Service public class BookServiceImpl implements BookService { @Autowired private BookDao bookDao; // public void setBookDao(BookDao bookDao) { // this.bookDao = bookDao; // } public void save() { System.out.println(\"book service save ...\"); bookDao.save(); } } 注意: @Autowired可以写在属性上，也可也写在setter方法上，最简单的处理方式是写在属性上并将setter方法删除掉 为什么setter方法可以删除呢? 自动装配基于反射设计创建对象并通过暴力反射为私有属性进行设值 普通反射只能获取public修饰的内容 暴力反射除了获取public修饰的内容还可以获取private修改的内容 所以此处无需提供setter方法 (2)@Autowired是按照类型注入，那么对应BookDao接口如果有多个实现类，比如添加BookDaoImpl2 @Repository public class BookDaoImpl2 implements BookDao { public void save() { System.out.println(\"book dao save ...2\"); } } 这个时候再次运行App，就会报错 此时，按照类型注入就无法区分到底注入哪个对象，解决方案:按照名称注入 先给两个Dao类分别起个名称 @Repository(\"bookDao\") public class BookDaoImpl implements BookDao { public void save() { System.out.println(\"book dao save ...\" ); } } @Repository(\"bookDao2\") public class BookDaoImpl2 implements BookDao { public void save() { System.out.println(\"book dao save ...2\" ); } } 此时就可以注入成功，但是得思考个问题: @Autowired是按照类型注入的，给BookDao的两个实现起了名称，它还是有两个bean对象，为什么不报错? @Autowired默认按照类型自动装配，如果IOC容器中同类的Bean找到多个，就按照变量名和Bean的名称匹配。因为变量名叫bookDao而容器中也有一个booDao，所以可以成功注入。 分析下面这种情况是否能完成注入呢? 不行，因为按照类型会找到多个bean对象，此时会按照bookDao名称去找，因为IOC容器只有名称叫bookDao1和bookDao2,所以找不到，会报NoUniqueBeanDefinitionException 3.4.3 注解实现按照名称注入当根据类型在容器中找到多个bean,注入参数的属性名又和容器中bean的名称不一致，这个时候该如何解决，就需要使用到@Qualifier来指定注入哪个名称的bean对象。 @Service public class BookServiceImpl implements BookService { @Autowired @Qualifier(\"bookDao1\") private BookDao bookDao; public void save() { System.out.println(\"book service save ...\"); bookDao.save(); } } @Qualifier注解后的值就是需要注入的bean的名称。 ==注意:@Qualifier不能独立使用，必须和@Autowired一起使用== 3.4.4 简单数据类型注入引用类型看完，简单类型注入就比较容易懂了。简单类型注入的是基本数据类型或者字符串类型，下面在BookDaoImpl类中添加一个name属性，用其进行简单类型注入 @Repository(\"bookDao\") public class BookDaoImpl implements BookDao { private String name; public void save() { System.out.println(\"book dao save ...\" + name); } } 数据类型换了，对应的注解也要跟着换，这次使用@Value注解，将值写入注解的参数中就行了 @Repository(\"bookDao\") public class BookDaoImpl implements BookDao { @Value(\"itheima\") private String name; public void save() { System.out.println(\"book dao save ...\" + name); } } 注意数据格式要匹配，如将”abc”注入给int值，这样程序就会报错。 介绍完后，会有一种感觉就是这个注解好像没什么用，跟直接赋值是一个效果，还没有直接赋值简单，所以这个注解存在的意义是什么? 3.4.5 注解读取properties配置文件@Value一般会被用在从properties配置文件中读取内容进行使用，具体如何实现? 步骤1：resource下准备properties文件jdbc.properties name=itheima888 步骤2: 使用注解加载properties配置文件在配置类上添加@PropertySource注解 @Configuration @ComponentScan(\"com.itheima\") @PropertySource(\"jdbc.properties\") public class SpringConfig { } 步骤3：使用@Value读取配置文件中的内容@Repository(\"bookDao\") public class BookDaoImpl implements BookDao { @Value(\"${name}\") private String name; public void save() { System.out.println(\"book dao save ...\" + name); } } 步骤4:运行程序 运行App类，查看运行结果，说明配置文件中的内容已经被加载到 注意: 如果读取的properties配置文件有多个，可以使用@PropertySource的属性来指定多个 @PropertySource({\"jdbc.properties\",\"xxx.properties\"}) @PropertySource注解属性中不支持使用通配符*,运行会报错 @PropertySource({\"*.properties\"}) @PropertySource注解属性中可以把classpath:加上,代表从当前项目的根路径找文件 @PropertySource({\"classpath:jdbc.properties\"}) 知识点1：@Autowired 名称 @Autowired 类型 属性注解 或 方法注解（了解） 或 方法形参注解（了解） 位置 属性定义上方 或 标准set方法上方 或 类set方法上方 或 方法形参前面 作用 为引用类型属性设置值 属性 required：true/false，定义该属性是否允许为null 知识点2：@Qualifier 名称 @Qualifier 类型 属性注解 或 方法注解（了解） 位置 属性定义上方 或 标准set方法上方 或 类set方法上方 作用 为引用类型属性指定注入的beanId 属性 value（默认）：设置注入的beanId 知识点3：@Value 名称 @Value 类型 属性注解 或 方法注解（了解） 位置 属性定义上方 或 标准set方法上方 或 类set方法上方 作用 为 基本数据类型 或 字符串类型 属性设置值 属性 value（默认）：要注入的属性值 知识点4：@PropertySource 名称 @PropertySource 类型 类注解 位置 类定义上方 作用 加载properties文件中的属性值 属性 value（默认）：设置加载的properties文件对应的文件名或文件名组成的数组 4. IOC/DI注解开发管理第三方bean前面定义bean的时候都是在自己开发的类上面写个注解就完成了，但如果是第三方的类，这些类都是在jar包中，我们没有办法在类上面添加注解，这个时候该怎么办? 遇到上述问题，我们就需要有一种更加灵活的方式来定义bean,这种方式不能在原始代码上面书写注解，一样能定义bean,这就用到了一个全新的注解==@Bean==。 这个注解该如何使用呢? 咱们把之前使用配置方式管理的数据源使用注解再来一遍，通过这个案例来学习下@Bean的使用。 4.1 环境准备学习@Bean注解之前先来准备环境: 创建一个Maven项目 pom.xml添加Spring的依赖 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 添加一个配置类SpringConfig @Configuration public class SpringConfig { } 添加BookDao、BookDaoImpl类 public interface BookDao { public void save(); } @Repository public class BookDaoImpl implements BookDao { public void save() { System.out.println(\"book dao save ...\" ); } } 创建运行类App public class App { public static void main(String[] args) { AnnotationConfigApplicationContext ctx = new AnnotationConfigApplicationContext(SpringConfig.class); } } 最终创建好的项目结构如下: 4.2 注解开发管理第三方bean在上述环境中完成对Druid数据源的管理，具体的实现步骤为: 步骤1:导入对应的jar包&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.16&lt;/version&gt; &lt;/dependency&gt; 步骤2:在配置类中添加一个方法注意该方法的返回值就是要创建的Bean对象类型 @Configuration public class SpringConfig { public DataSource dataSource(){ DruidDataSource ds = new DruidDataSource(); ds.setDriverClassName(\"com.mysql.jdbc.Driver\"); ds.setUrl(\"jdbc:mysql://localhost:3306/spring_db\"); ds.setUsername(\"root\"); ds.setPassword(\"root\"); return ds; } } 步骤3:在方法上添加@Bean注解@Bean注解的作用是将方法的返回值制作为Spring管理的一个bean对象 @Configuration public class SpringConfig { @Bean public DataSource dataSource(){ DruidDataSource ds = new DruidDataSource(); ds.setDriverClassName(\"com.mysql.jdbc.Driver\"); ds.setUrl(\"jdbc:mysql://localhost:3306/spring_db\"); ds.setUsername(\"root\"); ds.setPassword(\"root\"); return ds; } } 注意:不能使用DataSource ds = new DruidDataSource() 因为DataSource接口中没有对应的setter方法来设置属性。 步骤4:从IOC容器中获取对象并打印public class App { public static void main(String[] args) { AnnotationConfigApplicationContext ctx = new AnnotationConfigApplicationContext(SpringConfig.class); DataSource dataSource = ctx.getBean(DataSource.class); System.out.println(dataSource); } } 至此使用@Bean来管理第三方bean的案例就已经完成。 如果有多个bean要被Spring管理，直接在配置类中多些几个方法，方法上添加@Bean注解即可。 4.3 引入外部配置类如果把所有的第三方bean都配置到Spring的配置类SpringConfig中，虽然可以，但是不利于代码阅读和分类管理，所有我们就想能不能按照类别将这些bean配置到不同的配置类中? 对于数据源的bean,我们新建一个JdbcConfig配置类，并把数据源配置到该类下。 public class JdbcConfig { @Bean public DataSource dataSource(){ DruidDataSource ds = new DruidDataSource(); ds.setDriverClassName(\"com.mysql.jdbc.Driver\"); ds.setUrl(\"jdbc:mysql://localhost:3306/spring_db\"); ds.setUsername(\"root\"); ds.setPassword(\"root\"); return ds; } } 现在的问题是，这个配置类如何能被Spring配置类加载到，并创建DataSource对象在IOC容器中? 针对这个问题，有两个解决方案: 4.3.1 使用包扫描引入步骤1:在Spring的配置类上添加包扫描@Configuration @ComponentScan(\"com.itheima.config\") public class SpringConfig { } 步骤2:在JdbcConfig上添加配置注解JdbcConfig类要放入到com.itheima.config包下，需要被Spring的配置类扫描到即可 @Configuration public class JdbcConfig { @Bean public DataSource dataSource(){ DruidDataSource ds = new DruidDataSource(); ds.setDriverClassName(\"com.mysql.jdbc.Driver\"); ds.setUrl(\"jdbc:mysql://localhost:3306/spring_db\"); ds.setUsername(\"root\"); ds.setPassword(\"root\"); return ds; } } 步骤3:运行程序依然能获取到bean对象并打印控制台。 这种方式虽然能够扫描到，但是不能很快的知晓都引入了哪些配置类，所有这种方式不推荐使用。 4.3.2 使用@Import引入方案一实现起来有点小复杂，Spring早就想到了这一点，于是又给我们提供了第二种方案。 这种方案可以不用加@Configuration注解，但是必须在Spring配置类上使用@Import注解手动引入需要加载的配置类 步骤1:去除JdbcConfig类上的注解public class JdbcConfig { @Bean public DataSource dataSource(){ DruidDataSource ds = new DruidDataSource(); ds.setDriverClassName(\"com.mysql.jdbc.Driver\"); ds.setUrl(\"jdbc:mysql://localhost:3306/spring_db\"); ds.setUsername(\"root\"); ds.setPassword(\"root\"); return ds; } } 步骤2:在Spring配置类中引入@Configuration //@ComponentScan(\"com.itheima.config\") @Import({JdbcConfig.class}) public class SpringConfig { } 注意: 扫描注解可以移除 @Import参数需要的是一个数组，可以引入多个配置类。 @Import注解在配置类中只能写一次，下面的方式是==不允许的== @Configuration //@ComponentScan(\"com.itheima.config\") @Import(JdbcConfig.class) @Import(Xxx.class) public class SpringConfig { } 步骤3:运行程序依然能获取到bean对象并打印控制台 知识点1：@Bean 名称 @Bean 类型 方法注解 位置 方法定义上方 作用 设置该方法的返回值作为spring管理的bean 属性 value（默认）：定义bean的id 知识点2：@Import 名称 @Import 类型 类注解 位置 类定义上方 作用 导入配置类 属性 value（默认）：定义导入的配置类类名，当配置类有多个时使用数组格式一次性导入多个配置类 4.4 注解开发实现为第三方bean注入资源在使用@Bean创建bean对象的时候，如果方法在创建的过程中需要其他资源该怎么办? 这些资源会有两大类，分别是简单数据类型 和引用数据类型。 4.4.1 简单数据类型4.4.1.1 需求分析对于下面代码关于数据库的四要素不应该写死在代码中，应该是从properties配置文件中读取。如何来优化下面的代码? public class JdbcConfig { @Bean public DataSource dataSource(){ DruidDataSource ds = new DruidDataSource(); ds.setDriverClassName(\"com.mysql.jdbc.Driver\"); ds.setUrl(\"jdbc:mysql://localhost:3306/spring_db\"); ds.setUsername(\"root\"); ds.setPassword(\"root\"); return ds; } } 4.4.1.2 注入简单数据类型步骤步骤1:类中提供四个属性public class JdbcConfig { private String driver; private String url; private String userName; private String password; @Bean public DataSource dataSource(){ DruidDataSource ds = new DruidDataSource(); ds.setDriverClassName(\"com.mysql.jdbc.Driver\"); ds.setUrl(\"jdbc:mysql://localhost:3306/spring_db\"); ds.setUsername(\"root\"); ds.setPassword(\"root\"); return ds; } } 步骤2:使用@Value注解引入值public class JdbcConfig { @Value(\"com.mysql.jdbc.Driver\") private String driver; @Value(\"jdbc:mysql://localhost:3306/spring_db\") private String url; @Value(\"root\") private String userName; @Value(\"password\") private String password; @Bean public DataSource dataSource(){ DruidDataSource ds = new DruidDataSource(); ds.setDriverClassName(driver); ds.setUrl(url); ds.setUsername(userName); ds.setPassword(password); return ds; } } 扩展现在的数据库连接四要素还是写在代码中，需要做的是将这些内容提 取到jdbc.properties配置文件，大家思考下该如何实现? 1.resources目录下添加jdbc.properties 2.配置文件中提供四个键值对分别是数据库的四要素 3.使用@PropertySource加载jdbc.properties配置文件 4.修改@Value注解属性的值，将其修改为${key}，key就是键值对中的键的值 具体的实现就交由大家自行实现下。 4.4.2 引用数据类型4.4.2.1 需求分析假设在构建DataSource对象的时候，需要用到BookDao对象，该如何把BookDao对象注入进方法内让其使用呢? public class JdbcConfig { @Bean public DataSource dataSource(){ DruidDataSource ds = new DruidDataSource(); ds.setDriverClassName(\"com.mysql.jdbc.Driver\"); ds.setUrl(\"jdbc:mysql://localhost:3306/spring_db\"); ds.setUsername(\"root\"); ds.setPassword(\"root\"); return ds; } } 4.4.2.2 注入引用数据类型步骤步骤1:在SpringConfig中扫描BookDao扫描的目的是让Spring能管理到BookDao,也就是说要让IOC容器中有一个bookDao对象 @Configuration @ComponentScan(\"com.itheima.dao\") @Import({JdbcConfig.class}) public class SpringConfig { } 步骤2:在JdbcConfig类的方法上添加参数@Bean public DataSource dataSource(BookDao bookDao){ System.out.println(bookDao); DruidDataSource ds = new DruidDataSource(); ds.setDriverClassName(driver); ds.setUrl(url); ds.setUsername(userName); ds.setPassword(password); return ds; } ==引用类型注入只需要为bean定义方法设置形参即可，容器会根据类型自动装配对象。== 步骤3:运行程序 5. 注解开发总结前面我们已经完成了XML配置和注解的开发实现，至于两者之间的差异，咱们放在一块去对比回顾下: 6. Spring整合课程学习到这里，已经对Spring有一个简单的认识了，Spring有一个容器，叫做IoC容器，里面保存bean。在进行企业级开发的时候，其实除了将自己写的类让Spring管理之外，还有一部分重要的工作就是使用第三方的技术。前面已经讲了如何管理第三方bean了，下面结合IoC和DI，整合2个常用技术，进一步加深对Spring的使用理解。 6.1 Spring整合Mybatis思路分析6.1.1 环境准备在准备环境的过程中，我们也来回顾下Mybatis开发的相关内容: 步骤1:准备数据库表Mybatis是来操作数据库表，所以先创建一个数据库及表 create database spring_db character set utf8; use spring_db; create table tbl_account( id int primary key auto_increment, name varchar(35), money double ); 步骤2:创建项目导入jar包项目的pom.xml添加相关依赖 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.16&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 步骤3:根据表创建模型类public class Account implements Serializable { private Integer id; private String name; private Double money; //setter...getter...toString...方法略 } 步骤4:创建Dao接口public interface AccountDao { @Insert(\"insert into tbl_account(name,money)values(#{name},#{money})\") void save(Account account); @Delete(\"delete from tbl_account where id = #{id} \") void delete(Integer id); @Update(\"update tbl_account set name = #{name} , money = #{money} where id = #{id} \") void update(Account account); @Select(\"select * from tbl_account\") List&lt;Account&gt; findAll(); @Select(\"select * from tbl_account where id = #{id} \") Account findById(Integer id); } 步骤5:创建Service接口和实现类public interface AccountService { void save(Account account); void delete(Integer id); void update(Account account); List&lt;Account&gt; findAll(); Account findById(Integer id); } @Service public class AccountServiceImpl implements AccountService { @Autowired private AccountDao accountDao; public void save(Account account) { accountDao.save(account); } public void update(Account account){ accountDao.update(account); } public void delete(Integer id) { accountDao.delete(id); } public Account findById(Integer id) { return accountDao.findById(id); } public List&lt;Account&gt; findAll() { return accountDao.findAll(); } } 步骤6:添加jdbc.properties文件resources目录下添加，用于配置数据库连接四要素 jdbc.driver=com.mysql.jdbc.Driver jdbc.url=jdbc:mysql://localhost:3306/spring_db?useSSL=false jdbc.username=root jdbc.password=root useSSL:关闭MySQL的SSL连接 步骤7:添加Mybatis核心配置文件&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt; &lt;configuration&gt; &lt;!--读取外部properties配置文件--&gt; &lt;properties resource=\"jdbc.properties\"&gt;&lt;/properties&gt; &lt;!--别名扫描的包路径--&gt; &lt;typeAliases&gt; &lt;package name=\"com.itheima.domain\"/&gt; &lt;/typeAliases&gt; &lt;!--数据源--&gt; &lt;environments default=\"mysql\"&gt; &lt;environment id=\"mysql\"&gt; &lt;transactionManager type=\"JDBC\"&gt;&lt;/transactionManager&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"${jdbc.driver}\"&gt;&lt;/property&gt; &lt;property name=\"url\" value=\"${jdbc.url}\"&gt;&lt;/property&gt; &lt;property name=\"username\" value=\"${jdbc.username}\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"${jdbc.password}\"&gt;&lt;/property&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!--映射文件扫描包路径--&gt; &lt;mappers&gt; &lt;package name=\"com.itheima.dao\"&gt;&lt;/package&gt; &lt;/mappers&gt; &lt;/configuration&gt; 步骤8:编写应用程序public class App { public static void main(String[] args) throws IOException { // 1. 创建SqlSessionFactoryBuilder对象 SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder(); // 2. 加载SqlMapConfig.xml配置文件 InputStream inputStream = Resources.getResourceAsStream(\"SqlMapConfig.xml.bak\"); // 3. 创建SqlSessionFactory对象 SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBuilder.build(inputStream); // 4. 获取SqlSession SqlSession sqlSession = sqlSessionFactory.openSession(); // 5. 执行SqlSession对象执行查询，获取结果User AccountDao accountDao = sqlSession.getMapper(AccountDao.class); Account ac = accountDao.findById(1); System.out.println(ac); // 6. 释放资源 sqlSession.close(); } } 步骤9:运行程序 6.1.2 整合思路分析Mybatis的基础环境我们已经准备好了，接下来就得分析下在上述的内容中，哪些对象可以交给Spring来管理? Mybatis程序核心对象分析 从图中可以获取到，真正需要交给Spring管理的是==SqlSessionFactory== 整合Mybatis，就是将Mybatis用到的内容交给Spring管理，分析下配置文件 说明: 第一行读取外部properties配置文件，Spring有提供具体的解决方案@PropertySource,需要交给Spring 第二行起别名包扫描，为SqlSessionFactory服务的，需要交给Spring 第三行主要用于做连接池，Spring之前我们已经整合了Druid连接池，这块也需要交给Spring 前面三行一起都是为了创建SqlSession对象用的，那么用Spring管理SqlSession对象吗?回忆下SqlSession是由SqlSessionFactory创建出来的，所以只需要将SqlSessionFactory交给Spring管理即可。 第四行是Mapper接口和映射文件[如果使用注解就没有该映射文件]，这个是在获取到SqlSession以后执行具体操作的时候用，所以它和SqlSessionFactory创建的时机都不在同一个时间，可能需要单独管理。 6.2 Spring整合Mybatis前面我们已经分析了Spring与Mybatis的整合，大体需要做两件事， 第一件事是:Spring要管理MyBatis中的SqlSessionFactory 第二件事是:Spring要管理Mapper接口的扫描 具体该如何实现，具体的步骤为: 步骤1:项目中导入整合需要的jar包&lt;dependency&gt; &lt;!--Spring操作数据库需要该jar包--&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;!-- Spring与Mybatis整合的jar包 这个jar包mybatis在前面，是Mybatis提供的 --&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; 步骤2:创建Spring的主配置类//配置类注解 @Configuration //包扫描，主要扫描的是项目中的AccountServiceImpl类 @ComponentScan(\"com.itheima\") public class SpringConfig { } 步骤3:创建数据源的配置类在配置类中完成数据源的创建 public class JdbcConfig { @Value(\"${jdbc.driver}\") private String driver; @Value(\"${jdbc.url}\") private String url; @Value(\"${jdbc.username}\") private String userName; @Value(\"${jdbc.password}\") private String password; @Bean public DataSource dataSource(){ DruidDataSource ds = new DruidDataSource(); ds.setDriverClassName(driver); ds.setUrl(url); ds.setUsername(userName); ds.setPassword(password); return ds; } } 步骤4:主配置类中读properties并引入数据源配置类@Configuration @ComponentScan(\"com.itheima\") @PropertySource(\"classpath:jdbc.properties\") @Import(JdbcConfig.class) public class SpringConfig { } 步骤5:创建Mybatis配置类并配置SqlSessionFactorypublic class MybatisConfig { //定义bean，SqlSessionFactoryBean，用于产生SqlSessionFactory对象 @Bean public SqlSessionFactoryBean sqlSessionFactory(DataSource dataSource){ SqlSessionFactoryBean ssfb = new SqlSessionFactoryBean(); //设置模型类的别名扫描 ssfb.setTypeAliasesPackage(\"com.itheima.domain\"); //设置数据源 ssfb.setDataSource(dataSource); return ssfb; } //定义bean，返回MapperScannerConfigurer对象 @Bean public MapperScannerConfigurer mapperScannerConfigurer(){ MapperScannerConfigurer msc = new MapperScannerConfigurer(); msc.setBasePackage(\"com.itheima.dao\"); return msc; } } 说明: 使用SqlSessionFactoryBean封装SqlSessionFactory需要的环境信息 SqlSessionFactoryBean是前面我们讲解FactoryBean的一个子类，在该类中将SqlSessionFactory的创建进行了封装，简化对象的创建，我们只需要将其需要的内容设置即可。 方法中有一个参数为dataSource,当前Spring容器中已经创建了Druid数据源，类型刚好是DataSource类型，此时在初始化SqlSessionFactoryBean这个对象的时候，发现需要使用DataSource对象，而容器中刚好有这么一个对象，就自动加载了DruidDataSource对象。 使用MapperScannerConfigurer加载Dao接口，创建代理对象保存到IOC容器中 这个MapperScannerConfigurer对象也是MyBatis提供的专用于整合的jar包中的类，用来处理原始配置文件中的mappers相关配置，加载数据层的Mapper接口类 MapperScannerConfigurer有一个核心属性basePackage，就是用来设置所扫描的包路径 步骤6:主配置类中引入Mybatis配置类@Configuration @ComponentScan(\"com.itheima\") @PropertySource(\"classpath:jdbc.properties\") @Import({JdbcConfig.class,MybatisConfig.class}) public class SpringConfig { } 步骤7:编写运行类在运行类中，从IOC容器中获取Service对象，调用方法获取结果 public class App2 { public static void main(String[] args) { ApplicationContext ctx = new AnnotationConfigApplicationContext(SpringConfig.class); AccountService accountService = ctx.getBean(AccountService.class); Account ac = accountService.findById(1); System.out.println(ac); } } 步骤8:运行程序 支持Spring与Mybatis的整合就已经完成了，其中主要用到的两个类分别是: ==SqlSessionFactoryBean== ==MapperScannerConfigurer== 6.3 Spring整合Junit整合Junit与整合Druid和MyBatis差异比较大，为什么呢？Junit是一个搞单元测试用的工具，它不是我们程序的主体，也不会参加最终程序的运行，从作用上来说就和之前的东西不一样，它不是做功能的，看做是一个辅助工具就可以了。 6.3.1 环境准备这块环境，大家可以直接使用Spring与Mybatis整合的环境即可。当然也可以重新创建一个，因为内容是一模一样，所以我们直接来看下项目结构即可: 6.3.2 整合Junit步骤在上述环境的基础上，我们来对Junit进行整合。 步骤1:引入依赖pom.xml &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; 步骤2:编写测试类在test\\java下创建一个AccountServiceTest,这个名字任意 //设置类运行器 @RunWith(SpringJUnit4ClassRunner.class) //设置Spring环境对应的配置类 @ContextConfiguration(classes = {SpringConfiguration.class}) //加载配置类 //@ContextConfiguration(locations={\"classpath:applicationContext.xml\"})//加载配置文件 public class AccountServiceTest { //支持自动装配注入bean @Autowired private AccountService accountService; @Test public void testFindById(){ System.out.println(accountService.findById(1)); } @Test public void testFindAll(){ System.out.println(accountService.findAll()); } } 注意: 单元测试，如果测试的是注解配置类，则使用@ContextConfiguration(classes = 配置类.class) 单元测试，如果测试的是配置文件，则使用@ContextConfiguration(locations={配置文件名,...}) Junit运行后是基于Spring环境运行的，所以Spring提供了一个专用的类运行器，这个务必要设置，这个类运行器就在Spring的测试专用包中提供的，导入的坐标就是这个东西SpringJUnit4ClassRunner 上面两个配置都是固定格式，当需要测试哪个bean时，使用自动装配加载对应的对象，下面的工作就和以前做Junit单元测试完全一样了 知识点1：@RunWith 名称 @RunWith 类型 测试类注解 位置 测试类定义上方 作用 设置JUnit运行器 属性 value（默认）：运行所使用的运行期 知识点2：@ContextConfiguration 名称 @ContextConfiguration 类型 测试类注解 位置 测试类定义上方 作用 设置JUnit加载的Spring核心配置 属性 classes：核心配置类，可以使用数组的格式设定加载多个配置类locations:配置文件，可以使用数组的格式设定加载多个配置文件名称","categories":[],"tags":[{"name":"SSMP","slug":"SSMP","permalink":"https://gitee.com/yunyd/tags/SSMP/"},{"name":"Spring","slug":"Spring","permalink":"https://gitee.com/yunyd/tags/Spring/"}],"author":"llllz."},{"title":"SpringMVC复习 -2","slug":"SpringMVC复习  -2","date":"2023-07-24T01:05:17.000Z","updated":"2023-08-25T00:22:47.903Z","comments":true,"path":"posts/d4bfee3c.html","link":"","permalink":"https://gitee.com/yunyd/posts/d4bfee3c.html","excerpt":"","text":"SpringMVC复习1. SSM整合前面我们已经把Mybatis、Spring和SpringMVC三个框架进行了学习，今天主要的内容就是把这三个框架整合在一起完成我们的业务功能开发，具体如何来整合，我们一步步来学习。 1.1 流程分析(1) 创建工程 创建一个Maven的web工程 pom.xml添加SSM需要的依赖jar包 编写Web项目的入口配置类，实现AbstractAnnotationConfigDispatcherServletInitializer重写以下方法 getRootConfigClasses() ：返回Spring的配置类-&gt;需要==SpringConfig==配置类 getServletConfigClasses() ：返回SpringMVC的配置类-&gt;需要==SpringMvcConfig==配置类 getServletMappings() : 设置SpringMVC请求拦截路径规则 getServletFilters() ：设置过滤器，解决POST请求中文乱码问题 (2)SSM整合[==重点是各个配置的编写==] SpringConfig 标识该类为配置类 @Configuration 扫描Service所在的包 @ComponentScan 在Service层要管理事务 @EnableTransactionManagement 读取外部的properties配置文件 @PropertySource 整合Mybatis需要引入Mybatis相关配置类 @Import 第三方数据源配置类 JdbcConfig 构建DataSource数据源，DruidDataSouroce,需要注入数据库连接四要素， @Bean @Value 构建平台事务管理器，DataSourceTransactionManager,@Bean Mybatis配置类 MybatisConfig 构建SqlSessionFactoryBean并设置别名扫描与数据源，@Bean 构建MapperScannerConfigurer并设置DAO层的包扫描 SpringMvcConfig 标识该类为配置类 @Configuration 扫描Controller所在的包 @ComponentScan 开启SpringMVC注解支持 @EnableWebMvc (3)功能模块[与具体的业务模块有关] 创建数据库表 根据数据库表创建对应的模型类 通过Dao层完成数据库表的增删改查(接口+自动代理) 编写Service层[Service接口+实现类] @Service @Transactional 整合Junit对业务层进行单元测试 @RunWith @ContextConfiguration @Test 编写Controller层 接收请求 @RequestMapping @GetMapping @PostMapping @PutMapping @DeleteMapping 接收数据 简单、POJO、嵌套POJO、集合、数组、JSON数据类型 @RequestParam @PathVariable @RequestBody 转发业务层 @Autowired 响应结果 @ResponseBody 1.2 整合配置掌握上述的知识点后，接下来，我们就可以按照上述的步骤一步步的来完成SSM的整合。 步骤1：创建Maven的web项目可以使用Maven的骨架创建 步骤2:添加依赖pom.xml添加SSM所需要的依赖jar包 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;springmvc_08_ssm&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.16&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;80&lt;/port&gt; &lt;path&gt;/&lt;/path&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 步骤3:创建项目包结构 config目录存放的是相关的配置类 controller编写的是Controller类 dao存放的是Dao接口，因为使用的是Mapper接口代理方式，所以没有实现类包 service存的是Service接口，impl存放的是Service实现类 resources:存入的是配置文件，如Jdbc.properties webapp:目录可以存放静态资源 test/java:存放的是测试类 步骤4:创建SpringConfig配置类@Configuration @ComponentScan({\"com.itheima.service\"}) @PropertySource(\"classpath:jdbc.properties\") @Import({JdbcConfig.class,MyBatisConfig.class}) @EnableTransactionManagement public class SpringConfig { } 步骤5:创建JdbcConfig配置类public class JdbcConfig { @Value(\"${jdbc.driver}\") private String driver; @Value(\"${jdbc.url}\") private String url; @Value(\"${jdbc.username}\") private String username; @Value(\"${jdbc.password}\") private String password; @Bean public DataSource dataSource(){ DruidDataSource dataSource = new DruidDataSource(); dataSource.setDriverClassName(driver); dataSource.setUrl(url); dataSource.setUsername(username); dataSource.setPassword(password); return dataSource; } @Bean public PlatformTransactionManager transactionManager(DataSource dataSource){ DataSourceTransactionManager ds = new DataSourceTransactionManager(); ds.setDataSource(dataSource); return ds; } } 步骤6:创建MybatisConfig配置类public class MyBatisConfig { @Bean public SqlSessionFactoryBean sqlSessionFactory(DataSource dataSource){ SqlSessionFactoryBean factoryBean = new SqlSessionFactoryBean(); factoryBean.setDataSource(dataSource); factoryBean.setTypeAliasesPackage(\"com.itheima.domain\"); return factoryBean; } @Bean public MapperScannerConfigurer mapperScannerConfigurer(){ MapperScannerConfigurer msc = new MapperScannerConfigurer(); msc.setBasePackage(\"com.itheima.dao\"); return msc; } } 步骤7:创建jdbc.properties在resources下提供jdbc.properties,设置数据库连接四要素 jdbc.driver=com.mysql.jdbc.Driver jdbc.url=jdbc:mysql://localhost:3306/ssm_db jdbc.username=root jdbc.password=root 步骤8:创建SpringMVC配置类@Configuration @ComponentScan(\"com.itheima.controller\") @EnableWebMvc public class SpringMvcConfig { } 步骤9:创建Web项目入口配置类public class ServletConfig extends AbstractAnnotationConfigDispatcherServletInitializer { //加载Spring配置类 protected Class&lt;?&gt;[] getRootConfigClasses() { return new Class[]{SpringConfig.class}; } //加载SpringMVC配置类 protected Class&lt;?&gt;[] getServletConfigClasses() { return new Class[]{SpringMvcConfig.class}; } //设置SpringMVC请求地址拦截规则 protected String[] getServletMappings() { return new String[]{\"/\"}; } //设置post请求中文乱码过滤器 @Override protected Filter[] getServletFilters() { CharacterEncodingFilter filter = new CharacterEncodingFilter(); filter.setEncoding(\"utf-8\"); return new Filter[]{filter}; } } 至此SSM整合的环境就已经搭建好了。在这个环境上，我们如何进行功能模块的开发呢? 1.3 功能模块开发 需求:对表tbl_book进行新增、修改、删除、根据ID查询和查询所有 步骤1:创建数据库及表create database ssm_db character set utf8; use ssm_db; create table tbl_book( id int primary key auto_increment, type varchar(20), name varchar(50), description varchar(255) ) insert into `tbl_book`(`id`,`type`,`name`,`description`) values (1,'计算机理论','Spring实战 第五版','Spring入门经典教程，深入理解Spring原理技术内幕'),(2,'计算机理论','Spring 5核心原理与30个类手写实践','十年沉淀之作，手写Spring精华思想'),(3,'计算机理论','Spring 5设计模式','深入Spring源码刨析Spring源码中蕴含的10大设计模式'),(4,'计算机理论','Spring MVC+Mybatis开发从入门到项目实战','全方位解析面向Web应用的轻量级框架，带你成为Spring MVC开发高手'),(5,'计算机理论','轻量级Java Web企业应用实战','源码级刨析Spring框架，适合已掌握Java基础的读者'),(6,'计算机理论','Java核心技术 卷Ⅰ 基础知识(原书第11版)','Core Java第11版，Jolt大奖获奖作品，针对Java SE9、10、11全面更新'),(7,'计算机理论','深入理解Java虚拟机','5个纬度全面刨析JVM,大厂面试知识点全覆盖'),(8,'计算机理论','Java编程思想(第4版)','Java学习必读经典，殿堂级著作！赢得了全球程序员的广泛赞誉'),(9,'计算机理论','零基础学Java(全彩版)','零基础自学编程的入门图书，由浅入深，详解Java语言的编程思想和核心技术'),(10,'市场营销','直播就这么做:主播高效沟通实战指南','李子柒、李佳奇、薇娅成长为网红的秘密都在书中'),(11,'市场营销','直播销讲实战一本通','和秋叶一起学系列网络营销书籍'),(12,'市场营销','直播带货:淘宝、天猫直播从新手到高手','一本教你如何玩转直播的书，10堂课轻松实现带货月入3W+'); 步骤2:编写模型类public class Book { private Integer id; private String type; private String name; private String description; //getter...setter...toString省略 } 步骤3:编写Dao接口public interface BookDao { // @Insert(\"insert into tbl_book values(null,#{type},#{name},#{description})\") @Insert(\"insert into tbl_book (type,name,description) values(#{type},#{name},#{description})\") public void save(Book book); @Update(\"update tbl_book set type = #{type}, name = #{name}, description = #{description} where id = #{id}\") public void update(Book book); @Delete(\"delete from tbl_book where id = #{id}\") public void delete(Integer id); @Select(\"select * from tbl_book where id = #{id}\") public Book getById(Integer id); @Select(\"select * from tbl_book\") public List&lt;Book&gt; getAll(); } 步骤4:编写Service接口和实现类@Transactional public interface BookService { /** * 保存 * @param book * @return */ public boolean save(Book book); /** * 修改 * @param book * @return */ public boolean update(Book book); /** * 按id删除 * @param id * @return */ public boolean delete(Integer id); /** * 按id查询 * @param id * @return */ public Book getById(Integer id); /** * 查询全部 * @return */ public List&lt;Book&gt; getAll(); } @Service public class BookServiceImpl implements BookService { @Autowired private BookDao bookDao; public boolean save(Book book) { bookDao.save(book); return true; } public boolean update(Book book) { bookDao.update(book); return true; } public boolean delete(Integer id) { bookDao.delete(id); return true; } public Book getById(Integer id) { return bookDao.getById(id); } public List&lt;Book&gt; getAll() { return bookDao.getAll(); } } 说明: bookDao在Service中注入的会提示一个红线提示，为什么呢? BookDao是一个接口，没有实现类，接口是不能创建对象的，所以最终注入的应该是代理对象 代理对象是由Spring的IOC容器来创建管理的 IOC容器又是在Web服务器启动的时候才会创建 IDEA在检测依赖关系的时候，没有找到适合的类注入，所以会提示错误提示 但是程序运行的时候，代理对象就会被创建，框架会使用DI进行注入，所以程序运行无影响。 如何解决上述问题? 可以不用理会，因为运行是正常的 设置错误提示级别 步骤5:编写Contorller类@RestController @RequestMapping(\"/books\") public class BookController { @Autowired private BookService bookService; @PostMapping public boolean save(@RequestBody Book book) { return bookService.save(book); } @PutMapping public boolean update(@RequestBody Book book) { return bookService.update(book); } @DeleteMapping(\"/{id}\") public boolean delete(@PathVariable Integer id) { return bookService.delete(id); } @GetMapping(\"/{id}\") public Book getById(@PathVariable Integer id) { return bookService.getById(id); } @GetMapping public List&lt;Book&gt; getAll() { return bookService.getAll(); } } 对于图书模块的增删改查就已经完成了编写，我们可以从后往前写也可以从前往后写，最终只需要能把功能实现即可。 接下来我们就先把业务层的代码使用Spring整合Junit的知识点进行单元测试: 1.4 单元测试步骤1:新建测试类@RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(classes = SpringConfig.class) public class BookServiceTest { } 步骤2:注入Service类@RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(classes = SpringConfig.class) public class BookServiceTest { @Autowired private BookService bookService; } 步骤3:编写测试方法我们先来对查询进行单元测试。 @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(classes = SpringConfig.class) public class BookServiceTest { @Autowired private BookService bookService; @Test public void testGetById(){ Book book = bookService.getById(1); System.out.println(book); } @Test public void testGetAll(){ List&lt;Book&gt; all = bookService.getAll(); System.out.println(all); } } 根据ID查询，测试的结果为: 查询所有，测试的结果为: 1.5 PostMan测试新增http://localhost/books { \"type\":\"类别测试数据\", \"name\":\"书名测试数据\", \"description\":\"描述测试数据\" } 修改http://localhost/books { \"id\":13, \"type\":\"类别测试数据\", \"name\":\"书名测试数据\", \"description\":\"描述测试数据\" } 删除http://localhost/books/14 查询单个http://localhost/books/1 查询所有http://localhost/books 2. 统一结果封装2.1 表现层与前端数据传输协议定义SSM整合以及功能模块开发完成后，接下来，我们在上述案例的基础上分析下有哪些问题需要我们去解决下。首先第一个问题是: 在Controller层增删改返回给前端的是boolean类型数据 在Controller层查询单个返回给前端的是对象 在Controller层查询所有返回给前端的是集合对象 目前我们就已经有三种数据类型返回给前端，如果随着业务的增长，我们需要返回的数据类型会越来越多。对于前端开发人员在解析数据的时候就比较凌乱了，所以对于前端来说，如果后台能够返回一个统一的数据结果，前端在解析的时候就可以按照一种方式进行解析。开发就会变得更加简单。 所以我们就想能不能将返回结果的数据进行统一，具体如何来做，大体的思路为: 为了封装返回的结果数据:==创建结果模型类，封装数据到data属性中== 为了封装返回的数据是何种操作及是否操作成功:==封装操作结果到code属性中== 操作失败后为了封装返回的错误信息:==封装特殊消息到message(msg)属性中== 根据分析，我们可以设置统一数据返回结果类 public class Result{ private Object data; private Integer code; private String msg; } **注意:**Result类名及类中的字段并不是固定的，可以根据需要自行增减提供若干个构造方法，方便操作。 2.2 表现层与前端数据传输协议实现前面我们已经分析了如何封装返回结果数据，具体在项目中该如何实现，我们通过个例子来操作一把 2.2.1 环境准备 创建一个Web的Maven项目 pom.xml添加SSM整合所需jar包 创建对应的配置类 编写Controller、Service接口、Service实现类、Dao接口和模型类 resources下提供jdbc.properties配置文件 因为这个项目环境的内容和SSM整合的内容是一致的，所以我们就不在把代码粘出来了，大家在练习的时候可以在前面整合的例子案例环境下，进行本节内容的开发。 最终创建好的项目结构如下: 2.2.2 结果封装对于结果封装，我们应该是在表现层进行处理，所以我们把结果类放在controller包下，当然你也可以放在domain包，这个都是可以的，具体如何实现结果封装，具体的步骤为: 步骤1:创建Result类public class Result { //描述统一格式中的数据 private Object data; //描述统一格式中的编码，用于区分操作，可以简化配置0或1表示成功失败 private Integer code; //描述统一格式中的消息，可选属性 private String msg; public Result() { } //构造方法是方便对象的创建 public Result(Integer code,Object data) { this.data = data; this.code = code; } //构造方法是方便对象的创建 public Result(Integer code, Object data, String msg) { this.data = data; this.code = code; this.msg = msg; } //setter...getter...省略 } 步骤2:定义返回码Code类//状态码 public class Code { public static final Integer SAVE_OK = 20011; public static final Integer DELETE_OK = 20021; public static final Integer UPDATE_OK = 20031; public static final Integer GET_OK = 20041; public static final Integer SAVE_ERR = 20010; public static final Integer DELETE_ERR = 20020; public static final Integer UPDATE_ERR = 20030; public static final Integer GET_ERR = 20040; } **注意:**code类中的常量设计也不是固定的，可以根据需要自行增减，例如将查询再进行细分为GET_OK,GET_ALL_OK,GET_PAGE_OK等。 步骤3:修改Controller类的返回值//统一每一个控制器方法返回值 @RestController @RequestMapping(\"/books\") public class BookController { @Autowired private BookService bookService; @PostMapping public Result save(@RequestBody Book book) { boolean flag = bookService.save(book); return new Result(flag ? Code.SAVE_OK:Code.SAVE_ERR,flag); } @PutMapping public Result update(@RequestBody Book book) { boolean flag = bookService.update(book); return new Result(flag ? Code.UPDATE_OK:Code.UPDATE_ERR,flag); } @DeleteMapping(\"/{id}\") public Result delete(@PathVariable Integer id) { boolean flag = bookService.delete(id); return new Result(flag ? Code.DELETE_OK:Code.DELETE_ERR,flag); } @GetMapping(\"/{id}\") public Result getById(@PathVariable Integer id) { Book book = bookService.getById(id); Integer code = book != null ? Code.GET_OK : Code.GET_ERR; String msg = book != null ? \"\" : \"数据查询失败，请重试！\"; return new Result(code,book,msg); } @GetMapping public Result getAll() { List&lt;Book&gt; bookList = bookService.getAll(); Integer code = bookList != null ? Code.GET_OK : Code.GET_ERR; String msg = bookList != null ? \"\" : \"数据查询失败，请重试！\"; return new Result(code,bookList,msg); } } 步骤4:启动服务测试至此，我们的返回结果就已经能以一种统一的格式返回给前端。前端根据返回的结果，先从中获取code,根据code判断，如果成功则取data属性的值，如果失败，则取msg中的值做提示。 3. 统一异常处理3.1 问题描述在讲解这一部分知识点之前，我们先来演示个效果，修改BookController类的getById方法 @GetMapping(\"/{id}\") public Result getById(@PathVariable Integer id) { //手动添加一个错误信息 if(id==1){ int i = 1/0; } Book book = bookService.getById(id); Integer code = book != null ? Code.GET_OK : Code.GET_ERR; String msg = book != null ? \"\" : \"数据查询失败，请重试！\"; return new Result(code,book,msg); } 重新启动运行项目，使用PostMan发送请求，当传入的id为1，则会出现如下效果： 前端接收到这个信息后和之前我们约定的格式不一致，这个问题该如何解决? 在解决问题之前，我们先来看下异常的种类及出现异常的原因: 框架内部抛出的异常：因使用不合规导致 数据层抛出的异常：因外部服务器故障导致（例如：服务器访问超时） 业务层抛出的异常：因业务逻辑书写错误导致（例如：遍历业务书写操作，导致索引异常等） 表现层抛出的异常：因数据收集、校验等规则导致（例如：不匹配的数据类型间导致异常） 工具类抛出的异常：因工具类书写不严谨不够健壮导致（例如：必要释放的连接长期未释放等） 看完上面这些出现异常的位置，你会发现，在我们开发的任何一个位置都有可能出现异常，而且这些异常是不能避免的。所以我们就得将异常进行处理。 思考 各个层级均出现异常，异常处理代码书写在哪一层? ==所有的异常均抛出到表现层进行处理== 异常的种类很多，表现层如何将所有的异常都处理到呢? ==异常分类== 表现层处理异常，每个方法中单独书写，代码书写量巨大且意义不强，如何解决? ==AOP== 对于上面这些问题及解决方案，SpringMVC已经为我们提供了一套解决方案: 异常处理器: 集中的、统一的处理项目中出现的异常。 3.2 异常处理器的使用3.2.1 环境准备 创建一个Web的Maven项目 pom.xml添加SSM整合所需jar包 创建对应的配置类 编写Controller、Service接口、Service实现类、Dao接口和模型类 resources下提供jdbc.properties配置文件 内容参考前面的项目或者直接使用前面的项目进行本节内容的学习。 最终创建好的项目结构如下: 3.2.2 使用步骤步骤1:创建异常处理器类//@RestControllerAdvice用于标识当前类为REST风格对应的异常处理器 @RestControllerAdvice public class ProjectExceptionAdvice { //除了自定义的异常处理器，保留对Exception类型的异常处理，用于处理非预期的异常 @ExceptionHandler(Exception.class) public void doException(Exception ex){ System.out.println(\"嘿嘿,异常你哪里跑！\") } } ==确保SpringMvcConfig能够扫描到异常处理器类== 步骤2:让程序抛出异常修改BookController的getById方法，添加int i = 1/0. @GetMapping(\"/{id}\") public Result getById(@PathVariable Integer id) { int i = 1/0; Book book = bookService.getById(id); Integer code = book != null ? Code.GET_OK : Code.GET_ERR; String msg = book != null ? \"\" : \"数据查询失败，请重试！\"; return new Result(code,book,msg); } 步骤3:运行程序，测试 说明异常已经被拦截并执行了doException方法。 异常处理器类返回结果给前端//@RestControllerAdvice用于标识当前类为REST风格对应的异常处理器 @RestControllerAdvice public class ProjectExceptionAdvice { //除了自定义的异常处理器，保留对Exception类型的异常处理，用于处理非预期的异常 @ExceptionHandler(Exception.class) public Result doException(Exception ex){ System.out.println(\"嘿嘿,异常你哪里跑！\") return new Result(666,null,\"嘿嘿,异常你哪里跑！\"); } } 启动运行程序，测试 至此，就算后台执行的过程中抛出异常，最终也能按照我们和前端约定好的格式返回给前端。 知识点1：@RestControllerAdvice 名称 @RestControllerAdvice 类型 ==类注解== 位置 Rest风格开发的控制器增强类定义上方 作用 为Rest风格开发的控制器类做增强 **说明:**此注解自带@ResponseBody注解与@Component注解，具备对应的功能 知识点2：@ExceptionHandler 名称 @ExceptionHandler 类型 ==方法注解== 位置 专用于异常处理的控制器方法上方 作用 设置指定异常的处理方案，功能等同于控制器方法，出现异常后终止原始控制器执行,并转入当前方法执行 说明：此类方法可以根据处理的异常不同，制作多个方法分别处理对应的异常 3.3 项目异常处理方案3.3.1 异常分类异常处理器我们已经能够使用了，那么在咱们的项目中该如何来处理异常呢? 因为异常的种类有很多，如果每一个异常都对应一个@ExceptionHandler，那得写多少个方法来处理各自的异常，所以我们在处理异常之前，需要对异常进行一个分类: 业务异常（BusinessException） 规范的用户行为产生的异常 用户在页面输入内容的时候未按照指定格式进行数据填写，如在年龄框输入的是字符串 不规范的用户行为操作产生的异常 如用户故意传递错误数据 系统异常（SystemException） 项目运行过程中可预计但无法避免的异常 比如数据库或服务器宕机 其他异常（Exception） 编程人员未预期到的异常，如:用到的文件不存在 将异常分类以后，针对不同类型的异常，要提供具体的解决方案: 3.3.2 异常解决方案 业务异常（BusinessException） 发送对应消息传递给用户，提醒规范操作 大家常见的就是提示用户名已存在或密码格式不正确等 系统异常（SystemException） 发送固定消息传递给用户，安抚用户 系统繁忙，请稍后再试 系统正在维护升级，请稍后再试 系统出问题，请联系系统管理员等 发送特定消息给运维人员，提醒维护 可以发送短信、邮箱或者是公司内部通信软件 记录日志 发消息和记录日志对用户来说是不可见的，属于后台程序 其他异常（Exception） 发送固定消息传递给用户，安抚用户 发送特定消息给编程人员，提醒维护（纳入预期范围内） 一般是程序没有考虑全，比如未做非空校验等 记录日志 3.3.3 异常解决方案的具体实现 思路: 1.先通过自定义异常，完成BusinessException和SystemException的定义 2.将其他异常包装成自定义异常类型 3.在异常处理器类中对不同的异常进行处理 步骤1:自定义异常类//自定义异常处理器，用于封装异常信息，对异常进行分类 public class SystemException extends RuntimeException{ private Integer code; public Integer getCode() { return code; } public void setCode(Integer code) { this.code = code; } public SystemException(Integer code, String message) { super(message); this.code = code; } public SystemException(Integer code, String message, Throwable cause) { super(message, cause); this.code = code; } } //自定义异常处理器，用于封装异常信息，对异常进行分类 public class BusinessException extends RuntimeException{ private Integer code; public Integer getCode() { return code; } public void setCode(Integer code) { this.code = code; } public BusinessException(Integer code, String message) { super(message); this.code = code; } public BusinessException(Integer code, String message, Throwable cause) { super(message, cause); this.code = code; } } 说明: 让自定义异常类继承RuntimeException的好处是，后期在抛出这两个异常的时候，就不用在try…catch…或throws了 自定义异常类中添加code属性的原因是为了更好的区分异常是来自哪个业务的 步骤2:将其他异常包成自定义异常假如在BookServiceImpl的getById方法抛异常了，该如何来包装呢? public Book getById(Integer id) { //模拟业务异常，包装成自定义异常 if(id == 1){ throw new BusinessException(Code.BUSINESS_ERR,\"请不要使用你的技术挑战我的耐性!\"); } //模拟系统异常，将可能出现的异常进行包装，转换成自定义异常 try{ int i = 1/0; }catch (Exception e){ throw new SystemException(Code.SYSTEM_TIMEOUT_ERR,\"服务器访问超时，请重试!\",e); } return bookDao.getById(id); } 具体的包装方式有： 方式一:try{}catch(){}在catch中重新throw我们自定义异常即可。 方式二:直接throw自定义异常即可 上面为了使code看着更专业些，我们在Code类中再新增需要的属性 //状态码 public class Code { public static final Integer SAVE_OK = 20011; public static final Integer DELETE_OK = 20021; public static final Integer UPDATE_OK = 20031; public static final Integer GET_OK = 20041; public static final Integer SAVE_ERR = 20010; public static final Integer DELETE_ERR = 20020; public static final Integer UPDATE_ERR = 20030; public static final Integer GET_ERR = 20040; public static final Integer SYSTEM_ERR = 50001; public static final Integer SYSTEM_TIMEOUT_ERR = 50002; public static final Integer SYSTEM_UNKNOW_ERR = 59999; public static final Integer BUSINESS_ERR = 60002; } 步骤3:处理器类中处理自定义异常//@RestControllerAdvice用于标识当前类为REST风格对应的异常处理器 @RestControllerAdvice public class ProjectExceptionAdvice { //@ExceptionHandler用于设置当前处理器类对应的异常类型 @ExceptionHandler(SystemException.class) public Result doSystemException(SystemException ex){ //记录日志 //发送消息给运维 //发送邮件给开发人员,ex对象发送给开发人员 return new Result(ex.getCode(),null,ex.getMessage()); } @ExceptionHandler(BusinessException.class) public Result doBusinessException(BusinessException ex){ return new Result(ex.getCode(),null,ex.getMessage()); } //除了自定义的异常处理器，保留对Exception类型的异常处理，用于处理非预期的异常 @ExceptionHandler(Exception.class) public Result doOtherException(Exception ex){ //记录日志 //发送消息给运维 //发送邮件给开发人员,ex对象发送给开发人员 return new Result(Code.SYSTEM_UNKNOW_ERR,null,\"系统繁忙，请稍后再试！\"); } } 步骤4:运行程序根据ID查询， 如果传入的参数为1，会报BusinessException 如果传入的是其他参数，会报SystemException 对于异常我们就已经处理完成了，不管后台哪一层抛出异常，都会以我们与前端约定好的方式进行返回，前端只需要把信息获取到，根据返回的正确与否来展示不同的内容即可。 小结 以后项目中的异常处理方式为: 4. 前后台协议联调4.1 环境准备 创建一个Web的Maven项目 pom.xml添加SSM整合所需jar包 创建对应的配置类 编写Controller、Service接口、Service实现类、Dao接口和模型类 resources下提供jdbc.properties配置文件 内容参考前面的项目或者直接使用前面的项目进行本节内容的学习。 最终创建好的项目结构如下: 将静态资源拷贝到webapp下。 因为添加了静态资源，SpringMVC会拦截，所有需要在SpringConfig的配置类中将静态资源进行放行。 新建SpringMvcSupport @Configuration public class SpringMvcSupport extends WebMvcConfigurationSupport { @Override protected void addResourceHandlers(ResourceHandlerRegistry registry) { registry.addResourceHandler(\"/pages/**\").addResourceLocations(\"/pages/\"); registry.addResourceHandler(\"/css/**\").addResourceLocations(\"/css/\"); registry.addResourceHandler(\"/js/**\").addResourceLocations(\"/js/\"); registry.addResourceHandler(\"/plugins/**\").addResourceLocations(\"/plugins/\"); } } 在SpringMvcConfig中扫描SpringMvcSupport @Configuration @ComponentScan({\"com.itheima.controller\",\"com.itheima.config\"}) @EnableWebMvc public class SpringMvcConfig { } 接下来我们就需要将所有的列表查询、新增、修改、删除等功能一个个来实现下。 4.2 列表功能 需求:页面加载完后发送异步请求到后台获取列表数据进行展示。 1.找到页面的钩子函数，created() 2.created()方法中调用了this.getAll()方法 3.在getAll()方法中使用axios发送异步请求从后台获取数据 4.访问的路径为http://localhost/books 5.返回数据 返回数据res.data的内容如下: { \"data\": [ { \"id\": 1, \"type\": \"计算机理论\", \"name\": \"Spring实战 第五版\", \"description\": \"Spring入门经典教程，深入理解Spring原理技术内幕\" }, { \"id\": 2, \"type\": \"计算机理论\", \"name\": \"Spring 5核心原理与30个类手写实践\", \"description\": \"十年沉淀之作，手写Spring精华思想\" },... ], \"code\": 20041, \"msg\": \"\" } 发送方式: getAll() { //发送ajax请求 axios.get(\"/books\").then((res)=&gt;{ this.dataList = res.data.data; }); } 4.3 添加功能 需求:完成图片的新增功能模块 1.找到页面上的新建按钮，按钮上绑定了@click=\"handleCreate()\"方法 2.在method中找到handleCreate方法，方法中打开新增面板 3.新增面板中找到确定按钮,按钮上绑定了@click=\"handleAdd()\"方法 4.在method中找到handleAdd方法 5.在方法中发送请求和数据，响应成功后将新增面板关闭并重新查询数据 handleCreate打开新增面板 handleCreate() { this.dialogFormVisible = true; }, handleAdd方法发送异步请求并携带数据 handleAdd () { //发送ajax请求 //this.formData是表单中的数据，最后是一个json数据 axios.post(\"/books\",this.formData).then((res)=&gt;{ this.dialogFormVisible = false; this.getAll(); }); } 4.4 添加功能状态处理基础的新增功能已经完成，但是还有一些问题需要解决下: 需求:新增成功是关闭面板，重新查询数据，那么新增失败以后该如何处理? 1.在handlerAdd方法中根据后台返回的数据来进行不同的处理 2.如果后台返回的是成功，则提示成功信息，并关闭面板 3.如果后台返回的是失败，则提示错误信息 (1)修改前端页面 handleAdd () { //发送ajax请求 axios.post(\"/books\",this.formData).then((res)=&gt;{ //如果操作成功，关闭弹层，显示数据 if(res.data.code == 20011){ this.dialogFormVisible = false; this.$message.success(\"添加成功\"); }else if(res.data.code == 20010){ this.$message.error(\"添加失败\"); }else{ this.$message.error(res.data.msg); } }).finally(()=&gt;{ this.getAll(); }); } (2)后台返回操作结果，将Dao层的增删改方法返回值从void改成int public interface BookDao { // @Insert(\"insert into tbl_book values(null,#{type},#{name},#{description})\") @Insert(\"insert into tbl_book (type,name,description) values(#{type},#{name},#{description})\") public int save(Book book); @Update(\"update tbl_book set type = #{type}, name = #{name}, description = #{description} where id = #{id}\") public int update(Book book); @Delete(\"delete from tbl_book where id = #{id}\") public int delete(Integer id); @Select(\"select * from tbl_book where id = #{id}\") public Book getById(Integer id); @Select(\"select * from tbl_book\") public List&lt;Book&gt; getAll(); } (3)在BookServiceImpl中，增删改方法根据DAO的返回值来决定返回true/false @Service public class BookServiceImpl implements BookService { @Autowired private BookDao bookDao; public boolean save(Book book) { return bookDao.save(book) &gt; 0; } public boolean update(Book book) { return bookDao.update(book) &gt; 0; } public boolean delete(Integer id) { return bookDao.delete(id) &gt; 0; } public Book getById(Integer id) { if(id == 1){ throw new BusinessException(Code.BUSINESS_ERR,\"请不要使用你的技术挑战我的耐性!\"); } // //将可能出现的异常进行包装，转换成自定义异常 // try{ // int i = 1/0; // }catch (Exception e){ // throw new SystemException(Code.SYSTEM_TIMEOUT_ERR,\"服务器访问超时，请重试!\",e); // } return bookDao.getById(id); } public List&lt;Book&gt; getAll() { return bookDao.getAll(); } } (4)测试错误情况，将图书类别长度设置超出范围即可 处理完新增后，会发现新增还存在一个问题， 新增成功后，再次点击新增按钮会发现之前的数据还存在，这个时候就需要在新增的时候将表单内容清空。 resetForm(){ this.formData = {}; } handleCreate() { this.dialogFormVisible = true; this.resetForm(); } 4.5 修改功能 需求:完成图书信息的修改功能 1.找到页面中的编辑按钮，该按钮绑定了@click=\"handleUpdate(scope.row)\" 2.在method的handleUpdate方法中发送异步请求根据ID查询图书信息 3.根据后台返回的结果，判断是否查询成功 ​ 如果查询成功打开修改面板回显数据，如果失败提示错误信息 4.修改完成后找到修改面板的确定按钮，该按钮绑定了@click=\"handleEdit()\" 5.在method的handleEdit方法中发送异步请求提交修改数据 6.根据后台返回的结果，判断是否修改成功 ​ 如果成功提示错误信息，关闭修改面板，重新查询数据，如果失败提示错误信息 scope.row代表的是当前行的行数据，也就是说,scope.row就是选中行对应的json数据，如下: { \"id\": 1, \"type\": \"计算机理论\", \"name\": \"Spring实战 第五版\", \"description\": \"Spring入门经典教程，深入理解Spring原理技术内幕\" } 修改handleUpdate方法 //弹出编辑窗口 handleUpdate(row) { // console.log(row); //row.id 查询条件 //查询数据，根据id查询 axios.get(\"/books/\"+row.id).then((res)=&gt;{ if(res.data.code == 20041){ //展示弹层，加载数据 this.formData = res.data.data; this.dialogFormVisible4Edit = true; }else{ this.$message.error(res.data.msg); } }); } 修改handleEdit方法 handleEdit() { //发送ajax请求 axios.put(\"/books\",this.formData).then((res)=&gt;{ //如果操作成功，关闭弹层，显示数据 if(res.data.code == 20031){ this.dialogFormVisible4Edit = false; this.$message.success(\"修改成功\"); }else if(res.data.code == 20030){ this.$message.error(\"修改失败\"); }else{ this.$message.error(res.data.msg); } }).finally(()=&gt;{ this.getAll(); }); } 至此修改功能就已经完成。 4.6 删除功能 需求:完成页面的删除功能。 1.找到页面的删除按钮，按钮上绑定了@click=\"handleDelete(scope.row)\" 2.method的handleDelete方法弹出提示框 3.用户点击取消,提示操作已经被取消。 4.用户点击确定，发送异步请求并携带需要删除数据的主键ID 5.根据后台返回结果做不同的操作 ​ 如果返回成功，提示成功信息，并重新查询数据 ​ 如果返回失败，提示错误信息，并重新查询数据 修改handleDelete方法 handleDelete(row) { //1.弹出提示框 this.$confirm(\"此操作永久删除当前数据，是否继续？\",\"提示\",{ type:'info' }).then(()=&gt;{ //2.做删除业务 axios.delete(\"/books/\"+row.id).then((res)=&gt;{ if(res.data.code == 20021){ this.$message.success(\"删除成功\"); }else{ this.$message.error(\"删除失败\"); } }).finally(()=&gt;{ this.getAll(); }); }).catch(()=&gt;{ //3.取消删除 this.$message.info(\"取消删除操作\"); }); } 接下来，下面是一个完整页面 &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;!-- 页面meta --&gt; &lt;meta charset=\"utf-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;title&gt;SpringMVC案例&lt;/title&gt; &lt;meta content=\"width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no\" name=\"viewport\"&gt; &lt;!-- 引入样式 --&gt; &lt;link rel=\"stylesheet\" href=\"../plugins/elementui/index.css\"&gt; &lt;link rel=\"stylesheet\" href=\"../plugins/font-awesome/css/font-awesome.min.css\"&gt; &lt;link rel=\"stylesheet\" href=\"../css/style.css\"&gt; &lt;/head&gt; &lt;body class=\"hold-transition\"&gt; &lt;div id=\"app\"&gt; &lt;div class=\"content-header\"&gt; &lt;h1&gt;图书管理&lt;/h1&gt; &lt;/div&gt; &lt;div class=\"app-container\"&gt; &lt;div class=\"box\"&gt; &lt;div class=\"filter-container\"&gt; &lt;el-input placeholder=\"图书名称\" v-model=\"pagination.queryString\" style=\"width: 200px;\" class=\"filter-item\"&gt;&lt;/el-input&gt; &lt;el-button @click=\"getAll()\" class=\"dalfBut\"&gt;查询&lt;/el-button&gt; &lt;el-button type=\"primary\" class=\"butT\" @click=\"handleCreate()\"&gt;新建&lt;/el-button&gt; &lt;/div&gt; &lt;el-table size=\"small\" current-row-key=\"id\" :data=\"dataList\" stripe highlight-current-row&gt; &lt;el-table-column type=\"index\" align=\"center\" label=\"序号\"&gt;&lt;/el-table-column&gt; &lt;el-table-column prop=\"type\" label=\"图书类别\" align=\"center\"&gt;&lt;/el-table-column&gt; &lt;el-table-column prop=\"name\" label=\"图书名称\" align=\"center\"&gt;&lt;/el-table-column&gt; &lt;el-table-column prop=\"description\" label=\"描述\" align=\"center\"&gt;&lt;/el-table-column&gt; &lt;el-table-column label=\"操作\" align=\"center\"&gt; &lt;template slot-scope=\"scope\"&gt; &lt;el-button type=\"primary\" size=\"mini\" @click=\"handleUpdate(scope.row)\"&gt;编辑&lt;/el-button&gt; &lt;el-button type=\"danger\" size=\"mini\" @click=\"handleDelete(scope.row)\"&gt;删除&lt;/el-button&gt; &lt;/template&gt; &lt;/el-table-column&gt; &lt;/el-table&gt; &lt;!-- 新增标签弹层 --&gt; &lt;div class=\"add-form\"&gt; &lt;el-dialog title=\"新增图书\" :visible.sync=\"dialogFormVisible\"&gt; &lt;el-form ref=\"dataAddForm\" :model=\"formData\" :rules=\"rules\" label-position=\"right\" label-width=\"100px\"&gt; &lt;el-row&gt; &lt;el-col :span=\"12\"&gt; &lt;el-form-item label=\"图书类别\" prop=\"type\"&gt; &lt;el-input v-model=\"formData.type\"/&gt; &lt;/el-form-item&gt; &lt;/el-col&gt; &lt;el-col :span=\"12\"&gt; &lt;el-form-item label=\"图书名称\" prop=\"name\"&gt; &lt;el-input v-model=\"formData.name\"/&gt; &lt;/el-form-item&gt; &lt;/el-col&gt; &lt;/el-row&gt; &lt;el-row&gt; &lt;el-col :span=\"24\"&gt; &lt;el-form-item label=\"描述\"&gt; &lt;el-input v-model=\"formData.description\" type=\"textarea\"&gt;&lt;/el-input&gt; &lt;/el-form-item&gt; &lt;/el-col&gt; &lt;/el-row&gt; &lt;/el-form&gt; &lt;div slot=\"footer\" class=\"dialog-footer\"&gt; &lt;el-button @click=\"dialogFormVisible = false\"&gt;取消&lt;/el-button&gt; &lt;el-button type=\"primary\" @click=\"handleAdd()\"&gt;确定&lt;/el-button&gt; &lt;/div&gt; &lt;/el-dialog&gt; &lt;/div&gt; &lt;!-- 编辑标签弹层 --&gt; &lt;div class=\"add-form\"&gt; &lt;el-dialog title=\"编辑检查项\" :visible.sync=\"dialogFormVisible4Edit\"&gt; &lt;el-form ref=\"dataEditForm\" :model=\"formData\" :rules=\"rules\" label-position=\"right\" label-width=\"100px\"&gt; &lt;el-row&gt; &lt;el-col :span=\"12\"&gt; &lt;el-form-item label=\"图书类别\" prop=\"type\"&gt; &lt;el-input v-model=\"formData.type\"/&gt; &lt;/el-form-item&gt; &lt;/el-col&gt; &lt;el-col :span=\"12\"&gt; &lt;el-form-item label=\"图书名称\" prop=\"name\"&gt; &lt;el-input v-model=\"formData.name\"/&gt; &lt;/el-form-item&gt; &lt;/el-col&gt; &lt;/el-row&gt; &lt;el-row&gt; &lt;el-col :span=\"24\"&gt; &lt;el-form-item label=\"描述\"&gt; &lt;el-input v-model=\"formData.description\" type=\"textarea\"&gt;&lt;/el-input&gt; &lt;/el-form-item&gt; &lt;/el-col&gt; &lt;/el-row&gt; &lt;/el-form&gt; &lt;div slot=\"footer\" class=\"dialog-footer\"&gt; &lt;el-button @click=\"dialogFormVisible4Edit = false\"&gt;取消&lt;/el-button&gt; &lt;el-button type=\"primary\" @click=\"handleEdit()\"&gt;确定&lt;/el-button&gt; &lt;/div&gt; &lt;/el-dialog&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;!-- 引入组件库 --&gt; &lt;script src=\"../js/vue.js\"&gt;&lt;/script&gt; &lt;script src=\"../plugins/elementui/index.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\" src=\"../js/jquery.min.js\"&gt;&lt;/script&gt; &lt;script src=\"../js/axios-0.18.0.js\"&gt;&lt;/script&gt; &lt;script&gt; var vue = new Vue({ el: '#app', data:{ pagination: {}, dataList: [],//当前页要展示的列表数据 formData: {},//表单数据 dialogFormVisible: false,//控制表单是否可见 dialogFormVisible4Edit:false,//编辑表单是否可见 rules: {//校验规则 type: [{ required: true, message: '图书类别为必填项', trigger: 'blur' }], name: [{ required: true, message: '图书名称为必填项', trigger: 'blur' }] } }, //钩子函数，VUE对象初始化完成后自动执行 created() { this.getAll(); }, methods: { //列表 getAll() { //发送ajax请求 axios.get(\"/books\").then((res)=&gt;{ this.dataList = res.data.data; }); }, //弹出添加窗口 handleCreate() { this.dialogFormVisible = true; this.resetForm(); }, //重置表单 resetForm() { this.formData = {}; }, //添加 handleAdd () { //发送ajax请求 axios.post(\"/books\",this.formData).then((res)=&gt;{ console.log(res.data); //如果操作成功，关闭弹层，显示数据 if(res.data.code == 20011){ this.dialogFormVisible = false; this.$message.success(\"添加成功\"); }else if(res.data.code == 20010){ this.$message.error(\"添加失败\"); }else{ this.$message.error(res.data.msg); } }).finally(()=&gt;{ this.getAll(); }); }, //弹出编辑窗口 handleUpdate(row) { // console.log(row); //row.id 查询条件 //查询数据，根据id查询 axios.get(\"/books/\"+row.id).then((res)=&gt;{ // console.log(res.data.data); if(res.data.code == 20041){ //展示弹层，加载数据 this.formData = res.data.data; this.dialogFormVisible4Edit = true; }else{ this.$message.error(res.data.msg); } }); }, //编辑 handleEdit() { //发送ajax请求 axios.put(\"/books\",this.formData).then((res)=&gt;{ //如果操作成功，关闭弹层，显示数据 if(res.data.code == 20031){ this.dialogFormVisible4Edit = false; this.$message.success(\"修改成功\"); }else if(res.data.code == 20030){ this.$message.error(\"修改失败\"); }else{ this.$message.error(res.data.msg); } }).finally(()=&gt;{ this.getAll(); }); }, // 删除 handleDelete(row) { //1.弹出提示框 this.$confirm(\"此操作永久删除当前数据，是否继续？\",\"提示\",{ type:'info' }).then(()=&gt;{ //2.做删除业务 axios.delete(\"/books/\"+row.id).then((res)=&gt;{ if(res.data.code == 20021){ this.$message.success(\"删除成功\"); }else{ this.$message.error(\"删除失败\"); } }).finally(()=&gt;{ this.getAll(); }); }).catch(()=&gt;{ //3.取消删除 this.$message.info(\"取消删除操作\"); }); } } }) &lt;/script&gt; &lt;/html&gt; 5. 拦截器对于拦截器这节的知识，我们需要学习如下内容: 拦截器概念 入门案例 拦截器参数 拦截器工作流程分析 5.1 拦截器概念讲解拦截器的概念之前，我们先看一张图: (1)浏览器发送一个请求会先到Tomcat的web服务器 (2)Tomcat服务器接收到请求以后，会去判断请求的是静态资源还是动态资源 (3)如果是静态资源，会直接到Tomcat的项目部署目录下去直接访问 (4)如果是动态资源，就需要交给项目的后台代码进行处理 (5)在找到具体的方法之前，我们可以去配置过滤器(可以配置多个)，按照顺序进行执行 (6)然后进入到到中央处理器(SpringMVC中的内容)，SpringMVC会根据配置的规则进行拦截 (7)如果满足规则，则进行处理，找到其对应的controller类中的方法进行执行,完成后返回结果 (8)如果不满足规则，则不进行处理 (9)这个时候，如果我们需要在每个Controller方法执行的前后添加业务，具体该如何来实现? 这个就是拦截器要做的事。 拦截器（Interceptor）是一种动态拦截方法调用的机制，在SpringMVC中动态拦截控制器方法的执行 作用: 在指定的方法调用前后执行预先设定的代码 阻止原始方法的执行 总结：拦截器就是用来做增强 看完以后，大家会发现 拦截器和过滤器在作用和执行顺序上也很相似 所以这个时候，就有一个问题需要思考:拦截器和过滤器之间的区别是什么? 归属不同：Filter属于Servlet技术，Interceptor属于SpringMVC技术 拦截内容不同：Filter对所有访问进行增强，Interceptor仅针对SpringMVC的访问进行增强 5.2 拦截器入门案例5.2.1 环境准备 创建一个Web的Maven项目 pom.xml添加SSM整合所需jar包 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;springmvc_12_interceptor&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;80&lt;/port&gt; &lt;path&gt;/&lt;/path&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;8&lt;/source&gt; &lt;target&gt;8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 创建对应的配置类 public class ServletContainersInitConfig extends AbstractAnnotationConfigDispatcherServletInitializer { protected Class&lt;?&gt;[] getRootConfigClasses() { return new Class[0]; } protected Class&lt;?&gt;[] getServletConfigClasses() { return new Class[]{SpringMvcConfig.class}; } protected String[] getServletMappings() { return new String[]{\"/\"}; } //乱码处理 @Override protected Filter[] getServletFilters() { CharacterEncodingFilter filter = new CharacterEncodingFilter(); filter.setEncoding(\"UTF-8\"); return new Filter[]{filter}; } } @Configuration @ComponentScan({\"com.itheima.controller\"}) @EnableWebMvc public class SpringMvcConfig{ } 创建模型类Book public class Book { private String name; private double price; public String getName() { return name; } public void setName(String name) { this.name = name; } public double getPrice() { return price; } public void setPrice(double price) { this.price = price; } @Override public String toString() { return \"Book{\" + \"书名='\" + name + '\\'' + \", 价格=\" + price + '}'; } } 编写Controller @RestController @RequestMapping(\"/books\") public class BookController { @PostMapping public String save(@RequestBody Book book){ System.out.println(\"book save...\" + book); return \"{'module':'book save'}\"; } @DeleteMapping(\"/{id}\") public String delete(@PathVariable Integer id){ System.out.println(\"book delete...\" + id); return \"{'module':'book delete'}\"; } @PutMapping public String update(@RequestBody Book book){ System.out.println(\"book update...\"+book); return \"{'module':'book update'}\"; } @GetMapping(\"/{id}\") public String getById(@PathVariable Integer id){ System.out.println(\"book getById...\"+id); return \"{'module':'book getById'}\"; } @GetMapping public String getAll(){ System.out.println(\"book getAll...\"); return \"{'module':'book getAll'}\"; } } 最终创建好的项目结构如下: 5.2.2 拦截器开发步骤1:创建拦截器类让类实现HandlerInterceptor接口，重写接口中的三个方法。 @Component //定义拦截器类，实现HandlerInterceptor接口 //注意当前类必须受Spring容器控制 public class ProjectInterceptor implements HandlerInterceptor { @Override //原始方法调用前执行的内容 public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { System.out.println(\"preHandle...\"); return true; } @Override //原始方法调用后执行的内容 public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { System.out.println(\"postHandle...\"); } @Override //原始方法调用完成后执行的内容 public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { System.out.println(\"afterCompletion...\"); } } **注意:**拦截器类要被SpringMVC容器扫描到。 步骤2:配置拦截器类@Configuration public class SpringMvcSupport extends WebMvcConfigurationSupport { @Autowired private ProjectInterceptor projectInterceptor; @Override protected void addResourceHandlers(ResourceHandlerRegistry registry) { registry.addResourceHandler(\"/pages/**\").addResourceLocations(\"/pages/\"); } @Override protected void addInterceptors(InterceptorRegistry registry) { //配置拦截器 registry.addInterceptor(projectInterceptor).addPathPatterns(\"/books\" ); } } 步骤3:SpringMVC添加SpringMvcSupport包扫描@Configuration @ComponentScan({\"com.itheima.controller\",\"com.itheima.config\"}) @EnableWebMvc public class SpringMvcConfig{ } 步骤4:运行程序测试使用PostMan发送http://localhost/books 如果发送http://localhost/books/100会发现拦截器没有被执行，原因是拦截器的addPathPatterns方法配置的拦截路径是/books,我们现在发送的是/books/100，所以没有匹配上，因此没有拦截，拦截器就不会执行。 步骤5:修改拦截器拦截规则@Configuration public class SpringMvcSupport extends WebMvcConfigurationSupport { @Autowired private ProjectInterceptor projectInterceptor; @Override protected void addResourceHandlers(ResourceHandlerRegistry registry) { registry.addResourceHandler(\"/pages/**\").addResourceLocations(\"/pages/\"); } @Override protected void addInterceptors(InterceptorRegistry registry) { //配置拦截器 registry.addInterceptor(projectInterceptor).addPathPatterns(\"/books\",\"/books/*\" ); } } 这个时候，如果再次访问http://localhost/books/100，拦截器就会被执行。 最后说一件事，就是拦截器中的preHandler方法，如果返回true,则代表放行，会执行原始Controller类中要请求的方法，如果返回false，则代表拦截，后面的就不会再执行了。 步骤6:简化SpringMvcSupport的编写@Configuration @ComponentScan({\"com.itheima.controller\"}) @EnableWebMvc //实现WebMvcConfigurer接口可以简化开发，但具有一定的侵入性 public class SpringMvcConfig implements WebMvcConfigurer { @Autowired private ProjectInterceptor projectInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) { //配置多拦截器 registry.addInterceptor(projectInterceptor).addPathPatterns(\"/books\",\"/books/*\"); } } 此后咱们就不用再写SpringMvcSupport类了。 最后我们来看下拦截器的执行流程: 当有拦截器后，请求会先进入preHandle方法， ​ 如果方法返回true，则放行继续执行后面的handle[controller的方法]和后面的方法 ​ 如果返回false，则直接跳过后面方法的执行。 5.3 拦截器参数5.3.1 前置处理方法原始方法之前运行preHandle public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { System.out.println(\"preHandle\"); return true; } request:请求对象 response:响应对象 handler:被调用的处理器对象，本质上是一个方法对象，对反射中的Method对象进行了再包装 使用request对象可以获取请求数据中的内容，如获取请求头的Content-Type public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { String contentType = request.getHeader(\"Content-Type\"); System.out.println(\"preHandle...\"+contentType); return true; } 使用handler参数，可以获取方法的相关信息 public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { HandlerMethod hm = (HandlerMethod)handler; String methodName = hm.getMethod().getName();//可以获取方法的名称 System.out.println(\"preHandle...\"+methodName); return true; } 5.3.2 后置处理方法原始方法运行后运行，如果原始方法被拦截，则不执行 public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { System.out.println(\"postHandle\"); } 前三个参数和上面的是一致的。 modelAndView:如果处理器执行完成具有返回结果，可以读取到对应数据与页面信息，并进行调整 因为咱们现在都是返回json数据，所以该参数的使用率不高。 5.3.3 完成处理方法拦截器最后执行的方法，无论原始方法是否执行 public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { System.out.println(\"afterCompletion\"); } 前三个参数与上面的是一致的。 ex:如果处理器执行过程中出现异常对象，可以针对异常情况进行单独处理 因为我们现在已经有全局异常处理器类，所以该参数的使用率也不高。 这三个方法中，最常用的是==preHandle==,在这个方法中可以通过返回值来决定是否要进行放行，我们可以把业务逻辑放在该方法中，如果满足业务则返回true放行，不满足则返回false拦截。 5.4 拦截器链配置目前，我们在项目中只添加了一个拦截器，如果有多个，该如何配置?配置多个后，执行顺序是什么? 5.4.1 配置多个拦截器步骤1:创建拦截器类实现接口，并重写接口中的方法 @Component public class ProjectInterceptor2 implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { System.out.println(\"preHandle...222\"); return false; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { System.out.println(\"postHandle...222\"); } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { System.out.println(\"afterCompletion...222\"); } } 步骤2:配置拦截器类@Configuration @ComponentScan({\"com.itheima.controller\"}) @EnableWebMvc //实现WebMvcConfigurer接口可以简化开发，但具有一定的侵入性 public class SpringMvcConfig implements WebMvcConfigurer { @Autowired private ProjectInterceptor projectInterceptor; @Autowired private ProjectInterceptor2 projectInterceptor2; @Override public void addInterceptors(InterceptorRegistry registry) { //配置多拦截器 registry.addInterceptor(projectInterceptor).addPathPatterns(\"/books\",\"/books/*\"); registry.addInterceptor(projectInterceptor2).addPathPatterns(\"/books\",\"/books/*\"); } } 步骤3:运行程序，观察顺序 拦截器执行的顺序是和配置顺序有关。就和前面所提到的运维人员进入机房的案例，先进后出。 当配置多个拦截器时，形成拦截器链 拦截器链的运行顺序参照拦截器添加顺序为准 当拦截器中出现对原始处理器的拦截，后面的拦截器均终止运行 当拦截器运行中断，仅运行配置在前面的拦截器的afterCompletion操作 preHandle：与配置顺序相同，必定运行 postHandle:与配置顺序相反，可能不运行 afterCompletion:与配置顺序相反，可能不运行。 这个顺序不太好记，最终只需要把握住一个原则即可:==以最终的运行结果为准==","categories":[],"tags":[{"name":"SSMP","slug":"SSMP","permalink":"https://gitee.com/yunyd/tags/SSMP/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://gitee.com/yunyd/tags/SpringMVC/"}],"author":"llllz."},{"title":"SpringMVC复习 -1","slug":"SpringMVC复习  -1","date":"2023-07-23T23:04:40.000Z","updated":"2023-08-25T00:22:39.282Z","comments":true,"path":"posts/4db6bf86.html","link":"","permalink":"https://gitee.com/yunyd/posts/4db6bf86.html","excerpt":"","text":"SpringMVC复习1. SpringMVC概述学习SpringMVC我们先来回顾下现在web程序是如何做的，咱们现在web程序大都基于三层架构来实现。 三层架构 浏览器发送一个请求给后端服务器，后端服务器现在是使用Servlet来接收请求和数据 如果所有的处理都交给Servlet来处理的话，所有的东西都耦合在一起，对后期的维护和扩展极为不利 将后端服务器Servlet拆分成三层，分别是web、service和dao web层主要由servlet来处理，负责页面请求和数据的收集以及响应结果给前端 service层主要负责业务逻辑的处理 dao层主要负责数据的增删改查操作 servlet处理请求和数据的时候，存在的问题是一个servlet只能处理一个请求 针对web层进行了优化，采用了MVC设计模式，将其设计为controller、view和Model controller负责请求和数据的接收，接收后将其转发给service进行业务处理 service根据需要会调用dao对数据进行增删改查 dao把数据处理完后将结果交给service,service再交给controller controller根据需求组装成Model和View,Model和View组合起来生成页面转发给前端浏览器 这样做的好处就是controller可以处理多个请求，并对请求进行分发，执行不同的业务操作。 随着互联网的发展，上面的模式因为是同步调用，性能慢慢的跟不是需求，所以异步调用慢慢的走到了前台，是现在比较流行的一种处理方式。 因为是异步调用，所以后端不需要返回view视图，将其去除 前端如果通过异步调用的方式进行交互，后台就需要将返回的数据转换成json格式进行返回 SpringMVC==主要==负责的就是 controller如何接收请求和数据 如何将请求和数据转发给业务层 如何将响应数据转换成json发回到前端 介绍了这么多，对SpringMVC进行一个定义 SpringMVC是一种基于Java实现MVC模型的轻量级Web框架 优点 使用简单、开发便捷(相比于Servlet) 灵活性强 这里所说的优点，就需要我们在使用的过程中慢慢体会。 2. SpringMVC入门案例因为SpringMVC是一个Web框架，将来是要替换Servlet,所以先来回顾下以前Servlet是如何进行开发的? 1.创建web工程(Maven结构) 2.设置tomcat服务器，加载web工程(tomcat插件) 3.导入坐标(Servlet) 4.定义处理请求的功能类(UserServlet) 5.设置请求映射(配置映射关系) SpringMVC的制作过程和上述流程几乎是一致的，具体的实现流程是什么? 1.创建web工程(Maven结构) 2.设置tomcat服务器，加载web工程(tomcat插件) 3.导入坐标(==SpringMVC==+Servlet) 4.定义处理请求的功能类(==UserController==) 5.==设置请求映射(配置映射关系)== 6.==将SpringMVC设定加载到Tomcat容器中== 2.1 需求分析2.2 案例制作步骤1:创建Maven项目打开IDEA,创建一个新的web项目 步骤2:补全目录结构因为使用骨架创建的项目结构不完整，需要手动补全 步骤3:导入jar包将pom.xml中多余的内容删除掉，再添加SpringMVC需要的依赖 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;springmvc_01_quickstart&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;80&lt;/port&gt; &lt;path&gt;/&lt;/path&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; **说明:**servlet的坐标为什么需要添加&lt;scope&gt;provided&lt;/scope&gt;? scope是maven中jar包依赖作用范围的描述， 如果不设置默认是compile在在编译、运行、测试时均有效 如果运行有效的话就会和tomcat中的servlet-api包发生冲突，导致启动报错 provided代表的是该包只在编译和测试的时候用，运行的时候无效直接使用tomcat中的，就避免冲突 步骤4:创建配置类@Configuration @ComponentScan(\"com.itheima.controller\") public class SpringMvcConfig { } 步骤5:创建Controller类@Controller public class UserController { @RequestMapping(\"/save\") public void save(){ System.out.println(\"user save ...\"); } } 步骤6:使用配置类替换web.xml将web.xml删除，换成ServletContainersInitConfig public class ServletContainersInitConfig extends AbstractDispatcherServletInitializer { //加载springmvc配置类 protected WebApplicationContext createServletApplicationContext() { //初始化WebApplicationContext对象 AnnotationConfigWebApplicationContext ctx = new AnnotationConfigWebApplicationContext(); //加载指定配置类 ctx.register(SpringMvcConfig.class); return ctx; } //设置由springmvc控制器处理的请求映射路径 protected String[] getServletMappings() { return new String[]{\"/\"}; } //加载spring配置类 protected WebApplicationContext createRootApplicationContext() { return null; } } 步骤7:配置Tomcat环境 步骤8:启动运行项目 步骤9:浏览器访问浏览器输入http://localhost/save进行访问，会报如下错误: 页面报错的原因是后台没有指定返回的页面，目前只需要关注控制台看user save ...有没有被执行即可。 步骤10:修改Controller返回值解决上述问题前面我们说过现在主要的是前端发送异步请求，后台响应json数据，所以接下来我们把Controller类的save方法进行修改 @Controller public class UserController { @RequestMapping(\"/save\") public String save(){ System.out.println(\"user save ...\"); return \"{'info':'springmvc'}\"; } } 再次重启tomcat服务器，然后重新通过浏览器测试访问,会发现还是会报错，这次的错是404 出错的原因是，如果方法直接返回字符串，springmvc会把字符串当成页面的名称在项目中进行查找返回，因为不存在对应返回值名称的页面，所以会报404错误，找不到资源。 而我们其实是想要直接返回的是json数据，具体如何修改呢? 步骤11:设置返回数据为json@Controller public class UserController { @RequestMapping(\"/save\") @ResponseBody public String save(){ System.out.println(\"user save ...\"); return \"{'info':'springmvc'}\"; } } 再次重启tomcat服务器，然后重新通过浏览器测试访问，就能看到返回的结果数据 至此SpringMVC的入门案例就已经完成。 注意事项 SpringMVC是基于Spring的，在pom.xml只导入了spring-webmvcjar包的原因是它会自动依赖spring相关坐标 AbstractDispatcherServletInitializer类是SpringMVC提供的快速初始化Web3.0容器的抽象类 AbstractDispatcherServletInitializer提供了三个接口方法供用户实现 createServletApplicationContext方法，创建Servlet容器时，加载SpringMVC对应的bean并放入WebApplicationContext对象范围中，而WebApplicationContext的作用范围为ServletContext范围，即整个web容器范围 getServletMappings方法，设定SpringMVC对应的请求映射路径，即SpringMVC拦截哪些请求 createRootApplicationContext方法，如果创建Servlet容器时需要加载非SpringMVC对应的bean,使用当前方法进行，使用方式和createServletApplicationContext相同。 createServletApplicationContext用来加载SpringMVC环境 createRootApplicationContext用来加载Spring环境 知识点1：@Controller 名称 @Controller 类型 类注解 位置 SpringMVC控制器类定义上方 作用 设定SpringMVC的核心控制器bean 知识点2：@RequestMapping 名称 @RequestMapping 类型 类注解或方法注解 位置 SpringMVC控制器类或方法定义上方 作用 设置当前控制器方法请求访问路径 相关属性 value(默认)，请求访问路径 知识点3：@ResponseBody 名称 @ResponseBody 类型 类注解或方法注解 位置 SpringMVC控制器类或方法定义上方 作用 设置当前控制器方法响应内容为当前返回值，无需解析 2.3 入门案例总结 一次性工作 创建工程，设置服务器，加载工程 导入坐标 创建web容器启动类，加载SpringMVC配置，并设置SpringMVC请求拦截路径 SpringMVC核心配置类（设置配置类，扫描controller包，加载Controller控制器bean） 多次工作 定义处理请求的控制器类 定义处理请求的控制器方法，并配置映射路径（@RequestMapping）与返回json数据（@ResponseBody） 2.4 工作流程解析为了更好的使用SpringMVC,我们将SpringMVC的使用过程总共分两个阶段来分析，分别是启动服务器初始化过程和单次请求过程 2.4.1 启动服务器初始化过程 服务器启动，执行ServletContainersInitConfig类，初始化web容器 功能类似于以前的web.xml 执行createServletApplicationContext方法，创建了WebApplicationContext对象 该方法加载SpringMVC的配置类SpringMvcConfig来初始化SpringMVC的容器 加载SpringMvcConfig配置类 执行@ComponentScan加载对应的bean 扫描指定包及其子包下所有类上的注解，如Controller类上的@Controller注解 加载UserController，每个@RequestMapping的名称对应一个具体的方法 此时就建立了 /save 和 save方法的对应关系 执行getServletMappings方法，设定SpringMVC拦截请求的路径规则 /代表所拦截请求的路径规则，只有被拦截后才能交给SpringMVC来处理请求 2.4.2 单次请求过程 发送请求http://localhost/save web容器发现该请求满足SpringMVC拦截规则，将请求交给SpringMVC处理 解析请求路径/save 由/save匹配执行对应的方法save(） 上面的第五步已经将请求路径和方法建立了对应关系，通过/save就能找到对应的save方法 执行save() 检测到有@ResponseBody直接将save()方法的返回值作为响应体返回给请求方 2.5 bean加载控制2.5.1 问题分析入门案例的内容已经做完了，在入门案例中我们创建过一个SpringMvcConfig的配置类，再回想前面咱们学习Spring的时候也创建过一个配置类SpringConfig。这两个配置类都需要加载资源，那么它们分别都需要加载哪些内容? 我们先来看下目前我们的项目目录结构: config目录存入的是配置类,写过的配置类有: ServletContainersInitConfig SpringConfig SpringMvcConfig JdbcConfig MybatisConfig controller目录存放的是SpringMVC的controller类 service目录存放的是service接口和实现类 dao目录存放的是dao/Mapper接口 controller、service和dao这些类都需要被容器管理成bean对象，那么到底是该让SpringMVC加载还是让Spring加载呢? SpringMVC加载其相关bean(表现层bean),也就是controller包下的类 Spring控制的bean 业务bean(Service) 功能bean(DataSource,SqlSessionFactoryBean,MapperScannerConfigurer等) 分析清楚谁该管哪些bean以后，接下来要解决的问题是如何让Spring和SpringMVC分开加载各自的内容。 在SpringMVC的配置类SpringMvcConfig中使用注解@ComponentScan，我们只需要将其扫描范围设置到controller即可，如 在Spring的配置类SpringConfig中使用注解@ComponentScan,当时扫描的范围中其实是已经包含了controller,如: 从包结构来看的话，Spring已经多把SpringMVC的controller类也给扫描到，所以针对这个问题该如何解决，就是咱们接下来要学习的内容。 概括的描述下咱们现在的问题就是==因为功能不同，如何避免Spring错误加载到SpringMVC的bean?== 2.5.2 思路分析针对上面的问题，解决方案也比较简单，就是: 加载Spring控制的bean的时候排除掉SpringMVC控制的bean 具体该如何排除： 方式一:Spring加载的bean设定扫描范围为精准范围，例如service包、dao包等 方式二:Spring加载的bean设定扫描范围为com.itheima,排除掉controller包中的bean 方式三:不区分Spring与SpringMVC的环境，加载到同一个环境中[了解即可] 2.5.4 环境准备 创建一个Web的Maven项目 pom.xml添加Spring依赖 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;springmvc_02_bean_load&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.16&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;80&lt;/port&gt; &lt;path&gt;/&lt;/path&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 创建对应的配置类 public class ServletContainersInitConfig extends AbstractDispatcherServletInitializer { protected WebApplicationContext createServletApplicationContext() { AnnotationConfigWebApplicationContext ctx = new AnnotationConfigWebApplicationContext(); ctx.register(SpringMvcConfig.class); return ctx; } protected String[] getServletMappings() { return new String[]{\"/\"}; } protected WebApplicationContext createRootApplicationContext() { return null; } } @Configuration @ComponentScan(\"com.itheima.controller\") public class SpringMvcConfig { } @Configuration @ComponentScan(\"com.itheima\") public class SpringConfig { } 编写Controller，Service，Dao，Domain类 @Controller public class UserController { @RequestMapping(\"/save\") @ResponseBody public String save(){ System.out.println(\"user save ...\"); return \"{'info':'springmvc'}\"; } } public interface UserService { public void save(User user); } @Service public class UserServiceImpl implements UserService { public void save(User user) { System.out.println(\"user service ...\"); } } public interface UserDao { @Insert(\"insert into tbl_user(name,age)values(#{name},#{age})\") public void save(User user); } public class User { private Integer id; private String name; private Integer age; //setter..getter..toString略 } 最终创建好的项目结构如下: 2.5.5 设置bean加载控制方式一:修改Spring配置类，设定扫描范围为精准范围。 @Configuration @ComponentScan({\"com.itheima.service\",\"comitheima.dao\"}) public class SpringConfig { } 说明: 上述只是通过例子说明可以精确指定让Spring扫描对应的包结构，真正在做开发的时候，因为Dao最终是交给MapperScannerConfigurer对象来进行扫描处理的，我们只需要将其扫描到service包即可。 方式二:修改Spring配置类，设定扫描范围为com.itheima,排除掉controller包中的bean @Configuration @ComponentScan(value=\"com.itheima\", excludeFilters=@ComponentScan.Filter( type = FilterType.ANNOTATION, classes = Controller.class ) ) public class SpringConfig { } excludeFilters属性：设置扫描加载bean时，排除的过滤规则 type属性：设置排除规则，当前使用按照bean定义时的注解类型进行排除 ANNOTATION：按照注解排除 ASSIGNABLE_TYPE:按照指定的类型过滤 ASPECTJ:按照Aspectj表达式排除，基本上不会用 REGEX:按照正则表达式排除 CUSTOM:按照自定义规则排除 大家只需要知道第一种ANNOTATION即可 classes属性：设置排除的具体注解类，当前设置排除@Controller定义的bean 如何测试controller类已经被排除掉了? public class App{ public static void main (String[] args){ AnnotationConfigApplicationContext ctx = new AnnotationConfigApplicationContext(SpringConfig.class); System.out.println(ctx.getBean(UserController.class)); } } 如果被排除了，该方法执行就会报bean未被定义的错误 ==注意:测试的时候，需要把SpringMvcConfig配置类上的@ComponentScan注解注释掉，否则不会报错== 出现问题的原因是， Spring配置类扫描的包是com.itheima SpringMVC的配置类，SpringMvcConfig上有一个@Configuration注解，也会被Spring扫描到 SpringMvcConfig上又有一个@ComponentScan，把controller类又给扫描进来了 所以如果不把@ComponentScan注释掉，Spring配置类将Controller排除，但是因为扫描到SpringMVC的配置类，又将其加载回来，演示的效果就出不来 解决方案，也简单，把SpringMVC的配置类移出Spring配置类的扫描范围即可。 最后一个问题，有了Spring的配置类，要想在tomcat服务器启动将其加载，我们需要修改ServletContainersInitConfig public class ServletContainersInitConfig extends AbstractDispatcherServletInitializer { protected WebApplicationContext createServletApplicationContext() { AnnotationConfigWebApplicationContext ctx = new AnnotationConfigWebApplicationContext(); ctx.register(SpringMvcConfig.class); return ctx; } protected String[] getServletMappings() { return new String[]{\"/\"}; } protected WebApplicationContext createRootApplicationContext() { AnnotationConfigWebApplicationContext ctx = new AnnotationConfigWebApplicationContext(); ctx.register(SpringConfig.class); return ctx; } } 对于上述的配置方式，Spring还提供了一种更简单的配置方式，可以不用再去创建AnnotationConfigWebApplicationContext对象，不用手动register对应的配置类，如何实现? public class ServletContainersInitConfig extends AbstractAnnotationConfigDispatcherServletInitializer { protected Class&lt;?&gt;[] getRootConfigClasses() { return new Class[]{SpringConfig.class}; } protected Class&lt;?&gt;[] getServletConfigClasses() { return new Class[]{SpringMvcConfig.class}; } protected String[] getServletMappings() { return new String[]{\"/\"}; } } 知识点1：@ComponentScan 名称 @ComponentScan 类型 类注解 位置 类定义上方 作用 设置spring配置类扫描路径，用于加载使用注解格式定义的bean 相关属性 excludeFilters:排除扫描路径中加载的bean,需要指定类别(type)和具体项(classes)includeFilters:加载指定的bean，需要指定类别(type)和具体项(classes) 3. PostMan工具的使用3.1 PostMan简介代码编写完后，我们要想测试，只需要打开浏览器直接输入地址发送请求即可。发送的是GET请求可以直接使用浏览器，但是如果要发送的是POST请求呢? 如果要求发送的是post请求，我们就得准备页面在页面上准备form表单，测试起来比较麻烦。所以我们就需要借助一些第三方工具，如PostMan. PostMan是一款功能强大的网页调试与发送网页HTTP请求的Chrome插件。 作用：常用于进行接口测试 特征 简单 实用 美观 大方 3.2 PostMan安装双击\\Postman-win64-8.3.1-Setup.exe即可自动安装， 安装完成后，如果需要注册，可以按照提示进行注册，如果底部有跳过测试的链接也可以点击跳过注册 看到如下界面，就说明已经安装成功。 3.3 PostMan使用3.3.1 创建WorkSpace工作空间 3.3.2 发送请求 3.3.3 保存当前请求 **注意:**第一次请求需要创建一个新的目录，后面就不需要创建新目录，直接保存到已经创建好的目录即可。 4. 请求与响应前面我们已经完成了入门案例相关的知识学习，接来了我们就需要针对SpringMVC相关的知识点进行系统的学习，之前我们提到过，SpringMVC是web层的框架，主要的作用是接收请求、接收数据、响应结果，所以这一章节是学习SpringMVC的==重点==内容，我们主要会讲解四部分内容: 请求映射路径 请求参数 日期类型参数传递 响应json数据 4.1 设置请求映射路径4.1.1 环境准备 创建一个Web的Maven项目 pom.xml添加Spring依赖 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;springmvc_03_request_mapping&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;80&lt;/port&gt; &lt;path&gt;/&lt;/path&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 创建对应的配置类 public class ServletContainersInitConfig extends AbstractAnnotationConfigDispatcherServletInitializer { protected Class&lt;?&gt;[] getServletConfigClasses() { return new Class[]{SpringMvcConfig.class}; } protected String[] getServletMappings() { return new String[]{\"/\"}; } protected Class&lt;?&gt;[] getRootConfigClasses() { return new Class[0]; } } @Configuration @ComponentScan(\"com.itheima.controller\") public class SpringMvcConfig { } 编写BookController和UserController @Controller public class UserController { @RequestMapping(\"/save\") @ResponseBody public String save(){ System.out.println(\"user save ...\"); return \"{'module':'user save'}\"; } @RequestMapping(\"/delete\") @ResponseBody public String save(){ System.out.println(\"user delete ...\"); return \"{'module':'user delete'}\"; } } @Controller public class BookController { @RequestMapping(\"/save\") @ResponseBody public String save(){ System.out.println(\"book save ...\"); return \"{'module':'book save'}\"; } } 最终创建好的项目结构如下: 把环境准备好后，启动Tomcat服务器，后台会报错: 从错误信息可以看出: UserController有一个save方法，访问路径为http://localhost/save BookController也有一个save方法，访问路径为http://localhost/save 当访问http://localhost/saved的时候，到底是访问UserController还是BookController? 4.1.2 问题分析团队多人开发，每人设置不同的请求路径，冲突问题该如何解决? 解决思路:为不同模块设置模块名作为请求路径前置 对于Book模块的save,将其访问路径设置http://localhost/book/save 对于User模块的save,将其访问路径设置http://localhost/user/save 这样在同一个模块中出现命名冲突的情况就比较少了。 4.1.3 设置映射路径步骤1:修改Controller@Controller public class UserController { @RequestMapping(\"/user/save\") @ResponseBody public String save(){ System.out.println(\"user save ...\"); return \"{'module':'user save'}\"; } @RequestMapping(\"/user/delete\") @ResponseBody public String save(){ System.out.println(\"user delete ...\"); return \"{'module':'user delete'}\"; } } @Controller public class BookController { @RequestMapping(\"/book/save\") @ResponseBody public String save(){ System.out.println(\"book save ...\"); return \"{'module':'book save'}\"; } } 问题是解决了，但是每个方法前面都需要进行修改，写起来比较麻烦而且还有很多重复代码，如果/user后期发生变化，所有的方法都需要改，耦合度太高。 步骤2:优化路径配置优化方案: @Controller @RequestMapping(\"/user\") public class UserController { @RequestMapping(\"/save\") @ResponseBody public String save(){ System.out.println(\"user save ...\"); return \"{'module':'user save'}\"; } @RequestMapping(\"/delete\") @ResponseBody public String save(){ System.out.println(\"user delete ...\"); return \"{'module':'user delete'}\"; } } @Controller @RequestMapping(\"/book\") public class BookController { @RequestMapping(\"/save\") @ResponseBody public String save(){ System.out.println(\"book save ...\"); return \"{'module':'book save'}\"; } } 注意: 当类上和方法上都添加了@RequestMapping注解，前端发送请求的时候，要和两个注解的value值相加匹配才能访问到。 @RequestMapping注解value属性前面加不加/都可以 扩展小知识: 对于PostMan如何觉得字小不好看，可以使用ctrl+=调大，ctrl+-调小。 4.2 请求参数请求路径设置好后，只要确保页面发送请求地址和后台Controller类中配置的路径一致，就可以接收到前端的请求，接收到请求后，如何接收页面传递的参数? 关于请求参数的传递与接收是和请求方式有关系的，目前比较常见的两种请求方式为： GET POST 针对于不同的请求前端如何发送，后端如何接收? 4.2.1 环境准备 创建一个Web的Maven项目 pom.xml添加Spring依赖 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;springmvc_03_request_mapping&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;80&lt;/port&gt; &lt;path&gt;/&lt;/path&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 创建对应的配置类 public class ServletContainersInitConfig extends AbstractAnnotationConfigDispatcherServletInitializer { protected Class&lt;?&gt;[] getServletConfigClasses() { return new Class[]{SpringMvcConfig.class}; } protected String[] getServletMappings() { return new String[]{\"/\"}; } protected Class&lt;?&gt;[] getRootConfigClasses() { return new Class[0]; } } @Configuration @ComponentScan(\"com.itheima.controller\") public class SpringMvcConfig { } 编写UserController @Controller public class UserController { @RequestMapping(\"/commonParam\") @ResponseBody public String commonParam(){ return \"{'module':'commonParam'}\"; } } 编写模型类，User和Address public class Address { private String province; private String city; //setter...getter...略 } public class User { private String name; private int age; //setter...getter...略 } 最终创建好的项目结构如下: 4.2.2 参数传递GET发送单个参数发送请求与参数: http://localhost/commonParam?name=itcast 接收参数： @Controller public class UserController { @RequestMapping(\"/commonParam\") @ResponseBody public String commonParam(String name){ System.out.println(\"普通参数传递 name ==&gt; \"+name); return \"{'module':'commonParam'}\"; } } GET发送多个参数发送请求与参数: http://localhost/commonParam?name=itcast&amp;age=15 接收参数： @Controller public class UserController { @RequestMapping(\"/commonParam\") @ResponseBody public String commonParam(String name,int age){ System.out.println(\"普通参数传递 name ==&gt; \"+name); System.out.println(\"普通参数传递 age ==&gt; \"+age); return \"{'module':'commonParam'}\"; } } GET请求中文乱码如果我们传递的参数中有中文，你会发现接收到的参数会出现中文乱码问题。 发送请求:http://localhost/commonParam?name=张三&amp;age=18 控制台: 出现乱码的原因相信大家都清楚，Tomcat8.5以后的版本已经处理了中文乱码的问题，但是IDEA中的Tomcat插件目前只到Tomcat7，所以需要修改pom.xml来解决GET请求中文乱码问题 &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;80&lt;/port&gt;&lt;!--tomcat端口号--&gt; &lt;path&gt;/&lt;/path&gt; &lt;!--虚拟目录--&gt; &lt;uriEncoding&gt;UTF-8&lt;/uriEncoding&gt;&lt;!--访问路径编解码字符集--&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; POST发送参数发送请求与参数: 接收参数： 和GET一致，不用做任何修改 @Controller public class UserController { @RequestMapping(\"/commonParam\") @ResponseBody public String commonParam(String name,int age){ System.out.println(\"普通参数传递 name ==&gt; \"+name); System.out.println(\"普通参数传递 age ==&gt; \"+age); return \"{'module':'commonParam'}\"; } } POST请求中文乱码发送请求与参数: 接收参数: 控制台打印，会发现有中文乱码问题。 解决方案:配置过滤器 public class ServletContainersInitConfig extends AbstractAnnotationConfigDispatcherServletInitializer { protected Class&lt;?&gt;[] getRootConfigClasses() { return new Class[0]; } protected Class&lt;?&gt;[] getServletConfigClasses() { return new Class[]{SpringMvcConfig.class}; } protected String[] getServletMappings() { return new String[]{\"/\"}; } //乱码处理 @Override protected Filter[] getServletFilters() { CharacterEncodingFilter filter = new CharacterEncodingFilter(); filter.setEncoding(\"UTF-8\"); return new Filter[]{filter}; } } CharacterEncodingFilter是在spring-web包中，所以用之前需要导入对应的jar包。 4.3 五种类型参数传递前面我们已经能够使用GET或POST来发送请求和数据，所携带的数据都是比较简单的数据，接下来在这个基础上，我们来研究一些比较复杂的参数传递，常见的参数种类有: 普通参数 POJO类型参数 嵌套POJO类型参数 数组类型参数 集合类型参数 这些参数如何发送，后台改如何接收?我们一个个来学习。 4.3.1 普通参数 普通参数:url地址传参，地址参数名与形参变量名相同，定义形参即可接收参数。 如果形参与地址参数名不一致该如何解决? 发送请求与参数: http://localhost/commonParamDifferentName?name=张三&amp;age=18 后台接收参数: @RequestMapping(\"/commonParamDifferentName\") @ResponseBody public String commonParamDifferentName(String userName , int age){ System.out.println(\"普通参数传递 userName ==&gt; \"+userName); System.out.println(\"普通参数传递 age ==&gt; \"+age); return \"{'module':'common param different name'}\"; } 因为前端给的是name,后台接收使用的是userName,两个名称对不上，导致接收数据失败: 解决方案:使用@RequestParam注解 @RequestMapping(\"/commonParamDifferentName\") @ResponseBody public String commonParamDifferentName(@RequestPaam(\"name\") String userName , int age){ System.out.println(\"普通参数传递 userName ==&gt; \"+userName); System.out.println(\"普通参数传递 age ==&gt; \"+age); return \"{'module':'common param different name'}\"; } 注意:写上@RequestParam注解框架就不需要自己去解析注入，能提升框架处理性能 4.3.2 POJO数据类型简单数据类型一般处理的是参数个数比较少的请求，如果参数比较多，那么后台接收参数的时候就比较复杂，这个时候我们可以考虑使用POJO数据类型。 POJO参数：请求参数名与形参对象属性名相同，定义POJO类型形参即可接收参数 此时需要使用前面准备好的POJO类，先来看下User public class User { private String name; private int age; //setter...getter...略 } 发送请求和参数: 后台接收参数: //POJO参数：请求参数与形参对象中的属性对应即可完成参数传递 @RequestMapping(\"/pojoParam\") @ResponseBody public String pojoParam(User user){ System.out.println(\"pojo参数传递 user ==&gt; \"+user); return \"{'module':'pojo param'}\"; } 注意: POJO参数接收，前端GET和POST发送请求数据的方式不变。 ==请求参数key的名称要和POJO中属性的名称一致，否则无法封装。== 4.3.3 嵌套POJO类型参数如果POJO对象中嵌套了其他的POJO类，如 public class Address { private String province; private String city; //setter...getter...略 } public class User { private String name; private int age; private Address address; //setter...getter...略 } 嵌套POJO参数：请求参数名与形参对象属性名相同，按照对象层次结构关系即可接收嵌套POJO属性参数 发送请求和参数: 后台接收参数: //POJO参数：请求参数与形参对象中的属性对应即可完成参数传递 @RequestMapping(\"/pojoParam\") @ResponseBody public String pojoParam(User user){ System.out.println(\"pojo参数传递 user ==&gt; \"+user); return \"{'module':'pojo param'}\"; } 注意: ==请求参数key的名称要和POJO中属性的名称一致，否则无法封装== 4.3.4 数组类型参数举个简单的例子，如果前端需要获取用户的爱好，爱好绝大多数情况下都是多个，如何发送请求数据和接收数据呢? 数组参数：请求参数名与形参对象属性名相同且请求参数为多个，定义数组类型即可接收参数 发送请求和参数: 后台接收参数: //数组参数：同名请求参数可以直接映射到对应名称的形参数组对象中 @RequestMapping(\"/arrayParam\") @ResponseBody public String arrayParam(String[] likes){ System.out.println(\"数组参数传递 likes ==&gt; \"+ Arrays.toString(likes)); return \"{'module':'array param'}\"; } 4.3.5 集合类型参数数组能接收多个值，那么集合是否也可以实现这个功能呢? 发送请求和参数: 后台接收参数: //集合参数：同名请求参数可以使用@RequestParam注解映射到对应名称的集合对象中作为数据 @RequestMapping(\"/listParam\") @ResponseBody public String listParam(List&lt;String&gt; likes){ System.out.println(\"集合参数传递 likes ==&gt; \"+ likes); return \"{'module':'list param'}\"; } 运行会报错， 错误的原因是:SpringMVC将List看做是一个POJO对象来处理，将其创建一个对象并准备把前端的数据封装到对象中，但是List是一个接口无法创建对象，所以报错。 解决方案是:使用@RequestParam注解 //集合参数：同名请求参数可以使用@RequestParam注解映射到对应名称的集合对象中作为数据 @RequestMapping(\"/listParam\") @ResponseBody public String listParam(@RequestParam List&lt;String&gt; likes){ System.out.println(\"集合参数传递 likes ==&gt; \"+ likes); return \"{'module':'list param'}\"; } 集合保存普通参数：请求参数名与形参集合对象名相同且请求参数为多个，@RequestParam绑定参数关系 对于简单数据类型使用数组会比集合更简单些。 知识点1：@RequestParam 名称 @RequestParam 类型 形参注解 位置 SpringMVC控制器方法形参定义前面 作用 绑定请求参数与处理器方法形参间的关系 相关参数 required：是否为必传参数 defaultValue：参数默认值 4.4 JSON数据传输参数前面我们说过，现在比较流行的开发方式为异步调用。前后台以异步方式进行交换，传输的数据使用的是==JSON==,所以前端如果发送的是JSON数据，后端该如何接收? 对于JSON数据类型，我们常见的有三种: json普通数组（[“value1”,”value2”,”value3”,…]） json对象（{key1:value1,key2:value2,…}） json对象数组（[{key1:value1,…},{key2:value2,…}]） 对于上述数据，前端如何发送，后端如何接收? JSON普通数组步骤1:pom.xml添加依赖SpringMVC默认使用的是jackson来处理json的转换，所以需要在pom.xml添加jackson依赖 &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;/dependency&gt; 步骤2:PostMan发送JSON数据 步骤3:开启SpringMVC注解支持在SpringMVC的配置类中开启SpringMVC的注解支持，这里面就包含了将JSON转换成对象的功能。 @Configuration @ComponentScan(\"com.itheima.controller\") //开启json数据类型自动转换 @EnableWebMvc public class SpringMvcConfig { } 步骤4:参数前添加@RequestBody//使用@RequestBody注解将外部传递的json数组数据映射到形参的集合对象中作为数据 @RequestMapping(\"/listParamForJson\") @ResponseBody public String listParamForJson(@RequestBody List&lt;String&gt; likes){ System.out.println(\"list common(json)参数传递 list ==&gt; \"+likes); return \"{'module':'list common for json param'}\"; } 步骤5:启动运行程序 JSON普通数组的数据就已经传递完成，下面针对JSON对象数据和JSON对象数组的数据该如何传递呢? JSON对象数据我们会发现，只需要关注请求和数据如何发送?后端数据如何接收? 请求和数据的发送: { \"name\":\"itcast\", \"age\":15 } 后端接收数据： @RequestMapping(\"/pojoParamForJson\") @ResponseBody public String pojoParamForJson(@RequestBody User user){ System.out.println(\"pojo(json)参数传递 user ==&gt; \"+user); return \"{'module':'pojo for json param'}\"; } 启动程序访问测试 说明: address为null的原因是前端没有传递数据给后端。 如果想要address也有数据，我们需求修改前端传递的数据内容: { \"name\":\"itcast\", \"age\":15, \"address\":{ \"province\":\"beijing\", \"city\":\"beijing\" } } 再次发送请求，就能看到address中的数据 JSON对象数组集合中保存多个POJO该如何实现? 请求和数据的发送: [ {\"name\":\"itcast\",\"age\":15}, {\"name\":\"itheima\",\"age\":12} ] 后端接收数据: @RequestMapping(\"/listPojoParamForJson\") @ResponseBody public String listPojoParamForJson(@RequestBody List&lt;User&gt; list){ System.out.println(\"list pojo(json)参数传递 list ==&gt; \"+list); return \"{'module':'list pojo for json param'}\"; } 启动程序访问测试 小结 SpringMVC接收JSON数据的实现步骤为: (1)导入jackson包 (2)使用PostMan发送JSON数据 (3)开启SpringMVC注解驱动，在配置类上添加@EnableWebMvc注解 (4)Controller方法的参数前添加@RequestBody注解 知识点1：@EnableWebMvc 名称 @EnableWebMvc 类型 ==配置类注解== 位置 SpringMVC配置类定义上方 作用 开启SpringMVC多项辅助功能 知识点2：@RequestBody 名称 @RequestBody 类型 ==形参注解== 位置 SpringMVC控制器方法形参定义前面 作用 将请求中请求体所包含的数据传递给请求参数，此注解一个处理器方法只能使用一次 @RequestBody与@RequestParam区别 区别 @RequestParam用于接收url地址传参，表单传参【application/x-www-form-urlencoded】 @RequestBody用于接收json数据【application/json】 应用 后期开发中，发送json格式数据为主，@RequestBody应用较广 如果发送非json格式数据，选用@RequestParam接收请求参数 4.5 日期类型参数传递前面我们处理过简单数据类型、POJO数据类型、数组和集合数据类型以及JSON数据类型，接下来我们还得处理一种开发中比较常见的一种数据类型，日期类型 日期类型比较特殊，因为对于日期的格式有N多中输入方式，比如: 2088-08-18 2088/08/18 08/18/2088 …… 针对这么多日期格式，SpringMVC该如何接收，它能很好的处理日期类型数据么? 步骤1:编写方法接收日期数据在UserController类中添加方法，把参数设置为日期类型 @RequestMapping(\"/dataParam\") @ResponseBody public String dataParam(Date date) System.out.println(\"参数传递 date ==&gt; \"+date); return \"{'module':'data param'}\"; } 步骤2:启动Tomcat服务器查看控制台是否报错，如果有错误，先解决错误。 步骤3:使用PostMan发送请求使用PostMan发送GET请求，并设置date参数 http://localhost/dataParam?date=2088/08/08 步骤4:查看控制台 通过打印，我们发现SpringMVC可以接收日期数据类型，并将其打印在控制台。 这个时候，我们就想如果把日期参数的格式改成其他的，SpringMVC还能处理么? 步骤5:更换日期格式为了能更好的看到程序运行的结果，我们在方法中多添加一个日期参数 @RequestMapping(\"/dataParam\") @ResponseBody public String dataParam(Date date,Date date1) System.out.println(\"参数传递 date ==&gt; \"+date); return \"{'module':'data param'}\"; } 使用PostMan发送请求，携带两个不同的日期格式， http://localhost/dataParam?date=2088/08/08&amp;date1=2088-08-08 发送请求和数据后，页面会报400，控制台会报出一个错误 Resolved [org.springframework.web.method.annotation.==MethodArgumentTypeMismatchException==: Failed to convert value of type ‘java.lang.String’ to required type ‘java.util.Date’; nested exception is org.springframework.core.convert.==ConversionFailedException==: Failed to convert from type [java.lang.String] to type [java.util.Date] for value ‘2088-08-08’; nested exception is java.lang.IllegalArgumentException] 从错误信息可以看出，错误的原因是在将2088-08-08转换成日期类型的时候失败了，原因是SpringMVC默认支持的字符串转日期的格式为yyyy/MM/dd,而我们现在传递的不符合其默认格式，SpringMVC就无法进行格式转换，所以报错。 解决方案也比较简单，需要使用@DateTimeFormat @RequestMapping(\"/dataParam\") @ResponseBody public String dataParam(Date date, @DateTimeFormat(pattern=\"yyyy-MM-dd\") Date date1) System.out.println(\"参数传递 date ==&gt; \"+date); System.out.println(\"参数传递 date1(yyyy-MM-dd) ==&gt; \"+date1); return \"{'module':'data param'}\"; } 重新启动服务器，重新发送请求测试，SpringMVC就可以正确的进行日期转换了 步骤6:携带时间的日期接下来我们再来发送一个携带时间的日期，看下SpringMVC该如何处理? 先修改UserController类，添加第三个参数 @RequestMapping(\"/dataParam\") @ResponseBody public String dataParam(Date date, @DateTimeFormat(pattern=\"yyyy-MM-dd\") Date date1, @DateTimeFormat(pattern=\"yyyy/MM/dd HH:mm:ss\") Date date2) System.out.println(\"参数传递 date ==&gt; \"+date); System.out.println(\"参数传递 date1(yyyy-MM-dd) ==&gt; \"+date1); System.out.println(\"参数传递 date2(yyyy/MM/dd HH:mm:ss) ==&gt; \"+date2); return \"{'module':'data param'}\"; } 使用PostMan发送请求，携带两个不同的日期格式， http://localhost/dataParam?date=2088/08/08&amp;date1=2088-08-08&amp;date2=2088/08/08 8:08:08 重新启动服务器，重新发送请求测试，SpringMVC就可以将日期时间的数据进行转换 知识点1：@DateTimeFormat 名称 @DateTimeFormat 类型 ==形参注解== 位置 SpringMVC控制器方法形参前面 作用 设定日期时间型数据格式 相关属性 pattern：指定日期时间格式字符串 内部实现原理讲解内部原理之前，我们需要先思考个问题: 前端传递字符串，后端使用日期Date接收 前端传递JSON数据，后端使用对象接收 前端传递字符串，后端使用Integer接收 后台需要的数据类型有很多中 在数据的传递过程中存在很多类型的转换 问:谁来做这个类型转换? 答:SpringMVC 问:SpringMVC是如何实现类型转换的? 答:SpringMVC中提供了很多类型转换接口和实现类 在框架中，有一些类型转换接口，其中有: (1) Converter接口 /** * S: the source type * T: the target type */ public interface Converter&lt;S, T&gt; { @Nullable //该方法就是将从页面上接收的数据(S)转换成我们想要的数据类型(T)返回 T convert(S source); } 注意:Converter所属的包为org.springframework.core.convert.converter Converter接口的实现类 框架中有提供很多对应Converter接口的实现类，用来实现不同数据类型之间的转换,如: 请求参数年龄数据（String→Integer） 日期格式转换（String → Date） (2) HttpMessageConverter接口 该接口是实现对象与JSON之间的转换工作 ==注意:SpringMVC的配置类把@EnableWebMvc当做标配配置上去，不要省略== 4.6 响应SpringMVC接收到请求和数据后，进行一些了的处理，当然这个处理可以是转发给Service，Service层再调用Dao层完成的，不管怎样，处理完以后，都需要将结果告知给用户。 比如:根据用户ID查询用户信息、查询用户列表、新增用户等。 对于响应，主要就包含两部分内容： 响应页面 响应数据 文本数据 json数据 因为异步调用是目前常用的主流方式，所以我们需要更关注的就是如何返回JSON数据，对于其他只需要认识了解即可。 4.6.1 环境准备 创建一个Web的Maven项目 pom.xml添加Spring依赖 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;springmvc_05_response&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;80&lt;/port&gt; &lt;path&gt;/&lt;/path&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 创建对应的配置类 public class ServletContainersInitConfig extends AbstractAnnotationConfigDispatcherServletInitializer { protected Class&lt;?&gt;[] getRootConfigClasses() { return new Class[0]; } protected Class&lt;?&gt;[] getServletConfigClasses() { return new Class[]{SpringMvcConfig.class}; } protected String[] getServletMappings() { return new String[]{\"/\"}; } //乱码处理 @Override protected Filter[] getServletFilters() { CharacterEncodingFilter filter = new CharacterEncodingFilter(); filter.setEncoding(\"UTF-8\"); return new Filter[]{filter}; } } @Configuration @ComponentScan(\"com.itheima.controller\") //开启json数据类型自动转换 @EnableWebMvc public class SpringMvcConfig { } 编写模型类User public class User { private String name; private int age; //getter...setter...toString省略 } webapp下创建page.jsp &lt;html&gt; &lt;body&gt; &lt;h2&gt;Hello Spring MVC!&lt;/h2&gt; &lt;/body&gt; &lt;/html&gt; 编写UserController @Controller public class UserController { } 最终创建好的项目结构如下: 4.6.2 响应页面[了解]步骤1:设置返回页面@Controller public class UserController { @RequestMapping(\"/toJumpPage\") //注意 //1.此处不能添加@ResponseBody,如果加了该注入，会直接将page.jsp当字符串返回前端 //2.方法需要返回String public String toJumpPage(){ System.out.println(\"跳转页面\"); return \"page.jsp\"; } } 步骤2:启动程序测试此处涉及到页面跳转，所以不适合采用PostMan进行测试，直接打开浏览器，输入 http://localhost/toJumpPage 4.6.3 返回文本数据[了解]步骤1:设置返回文本内容@Controller public class UserController { @RequestMapping(\"/toText\") //注意此处该注解就不能省略，如果省略了,会把response text当前页面名称去查找，如果没有回报404错误 @ResponseBody public String toText(){ System.out.println(\"返回纯文本数据\"); return \"response text\"; } } 步骤2:启动程序测试此处不涉及到页面跳转，因为我们现在发送的是GET请求，可以使用浏览器也可以使用PostMan进行测试，输入地址http://localhost/toText访问 4.6.4 响应JSON数据响应POJO对象@Controller public class UserController { @RequestMapping(\"/toJsonPOJO\") @ResponseBody public User toJsonPOJO(){ System.out.println(\"返回json对象数据\"); User user = new User(); user.setName(\"itcast\"); user.setAge(15); return user; } } 返回值为实体类对象，设置返回值为实体类类型，即可实现返回对应对象的json数据，需要依赖==@ResponseBody==注解和==@EnableWebMvc==注解 重新启动服务器，访问http://localhost/toJsonPOJO 响应POJO集合对象@Controller public class UserController { @RequestMapping(\"/toJsonList\") @ResponseBody public List&lt;User&gt; toJsonList(){ System.out.println(\"返回json集合数据\"); User user1 = new User(); user1.setName(\"传智播客\"); user1.setAge(15); User user2 = new User(); user2.setName(\"黑马程序员\"); user2.setAge(12); List&lt;User&gt; userList = new ArrayList&lt;User&gt;(); userList.add(user1); userList.add(user2); return userList; } } 重新启动服务器，访问http://localhost/toJsonList 知识点1：@ResponseBody 名称 @ResponseBody 类型 ==方法\\类注解== 位置 SpringMVC控制器方法定义上方和控制类上 作用 设置当前控制器返回值作为响应体,写在类上，该类的所有方法都有该注解功能 相关属性 pattern：指定日期时间格式字符串 说明: 该注解可以写在类上或者方法上 写在类上就是该类下的所有方法都有@ReponseBody功能 当方法上有@ReponseBody注解后 方法的返回值为字符串，会将其作为文本内容直接响应给前端 方法的返回值为对象，会将对象转换成JSON响应给前端 此处又使用到了类型转换，内部还是通过Converter接口的实现类完成的，所以Converter除了前面所说的功能外，它还可以实现: 对象转Json数据(POJO -&gt; json) 集合转Json数据(Collection -&gt; json) 5. Rest风格对于Rest风格，我们需要学习的内容包括: REST简介 REST入门案例 REST快速开发 案例:基于RESTful页面数据交互 5.1 REST简介 ==REST==（Representational State Transfer），表现形式状态转换,它是一种软件架构==风格== 当我们想表示一个网络资源的时候，可以使用两种方式: 传统风格资源描述形式 http://localhost/user/getById?id=1 查询id为1的用户信息 http://localhost/user/saveUser 保存用户信息 REST风格描述形式 http://localhost/user/1 http://localhost/user 传统方式一般是一个请求url对应一种操作，这样做不仅麻烦，也不安全，因为会程序的人读取了你的请求url地址，就大概知道该url实现的是一个什么样的操作。 查看REST风格的描述，你会发现请求地址变的简单了，并且光看请求URL并不是很能猜出来该URL的具体功能 所以REST的优点有: 隐藏资源的访问行为，无法通过地址得知对资源是何种操作 书写简化 但是我们的问题也随之而来了，一个相同的url地址即可以是新增也可以是修改或者查询，那么到底我们该如何区分该请求到底是什么操作呢? 按照REST风格访问资源时使用==行为动作==区分对资源进行了何种操作 http://localhost/users 查询全部用户信息 GET（查询） http://localhost/users/1 查询指定用户信息 GET（查询） http://localhost/users 添加用户信息 POST（新增/保存） http://localhost/users 修改用户信息 PUT（修改/更新） http://localhost/users/1 删除用户信息 DELETE（删除） 请求的方式比较多，但是比较常用的就4种，分别是GET,POST,PUT,DELETE。 按照不同的请求方式代表不同的操作类型。 发送GET请求是用来做查询 发送POST请求是用来做新增 发送PUT请求是用来做修改 发送DELETE请求是用来做删除 但是==注意==: 上述行为是约定方式，约定不是规范，可以打破，所以称REST风格，而不是REST规范 REST提供了对应的架构方式，按照这种架构设计项目可以降低开发的复杂性，提高系统的可伸缩性 REST中规定GET/POST/PUT/DELETE针对的是查询/新增/修改/删除，但是我们如果非要用GET请求做删除，这点在程序上运行是可以实现的 但是如果绝大多数人都遵循这种风格，你写的代码让别人读起来就有点莫名其妙了。 描述模块的名称通常使用复数，也就是加s的格式描述，表示此类资源，而非单个资源，例如:users、books、accounts…… 清楚了什么是REST风格后，我们后期会经常提到一个概念叫RESTful，那什么又是RESTful呢? 根据REST风格对资源进行访问称为==RESTful==。 后期我们在进行开发的过程中，大多是都是遵从REST风格来访问我们的后台服务，所以可以说咱们以后都是基于RESTful来进行开发的。 5.2 RESTful入门案例5.2.1 环境准备 创建一个Web的Maven项目 pom.xml添加Spring依赖 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;springmvc_06_rest&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;80&lt;/port&gt; &lt;path&gt;/&lt;/path&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 创建对应的配置类 public class ServletContainersInitConfig extends AbstractAnnotationConfigDispatcherServletInitializer { protected Class&lt;?&gt;[] getRootConfigClasses() { return new Class[0]; } protected Class&lt;?&gt;[] getServletConfigClasses() { return new Class[]{SpringMvcConfig.class}; } protected String[] getServletMappings() { return new String[]{\"/\"}; } //乱码处理 @Override protected Filter[] getServletFilters() { CharacterEncodingFilter filter = new CharacterEncodingFilter(); filter.setEncoding(\"UTF-8\"); return new Filter[]{filter}; } } @Configuration @ComponentScan(\"com.itheima.controller\") //开启json数据类型自动转换 @EnableWebMvc public class SpringMvcConfig { } 编写模型类User和Book public class User { private String name; private int age; //getter...setter...toString省略 } public class Book { private String name; private double price; //getter...setter...toString省略 } 编写UserController和BookController @Controller public class UserController { @RequestMapping(\"/save\") @ResponseBody public String save(@RequestBody User user) { System.out.println(\"user save...\"+user); return \"{'module':'user save'}\"; } @RequestMapping(\"/delete\") @ResponseBody public String delete(Integer id) { System.out.println(\"user delete...\" + id); return \"{'module':'user delete'}\"; } @RequestMapping(\"/update\") @ResponseBody public String update(@RequestBody User user) { System.out.println(\"user update...\" + user); return \"{'module':'user update'}\"; } @RequestMapping(\"/getById\") @ResponseBody public String getById(Integer id) { System.out.println(\"user getById...\" + id); return \"{'module':'user getById'}\"; } @RequestMapping(\"/findAll\") @ResponseBody public String getAll() { System.out.println(\"user getAll...\"); return \"{'module':'user getAll'}\"; } } @Controller public class BookController { @RequestMapping(value = \"/books\",method = RequestMethod.POST) @ResponseBody public String save(@RequestBody Book book){ System.out.println(\"book save...\" + book); return \"{'module':'book save'}\"; } @RequestMapping(value = \"/books/{id}\",method = RequestMethod.DELETE) @ResponseBody public String delete(@PathVariable Integer id){ System.out.println(\"book delete...\" + id); return \"{'module':'book delete'}\"; } @RequestMapping(value = \"/books\",method = RequestMethod.PUT) @ResponseBody public String update(@RequestBody Book book){ System.out.println(\"book update...\" + book); return \"{'module':'book update'}\"; } @RequestMapping(value = \"/books/{id}\",method = RequestMethod.GET) @ResponseBody public String getById(@PathVariable Integer id){ System.out.println(\"book getById...\" + id); return \"{'module':'book getById'}\"; } @RequestMapping(value = \"/books\",method = RequestMethod.GET) @ResponseBody public String getAll(){ System.out.println(\"book getAll...\"); return \"{'module':'book getAll'}\"; } } 最终创建好的项目结构如下: 5.2.2 思路分析 需求:将之前的增删改查替换成RESTful的开发方式。 1.之前不同的请求有不同的路径,现在要将其修改为统一的请求路径 修改前: 新增: /save ,修改: /update,删除 /delete… 修改后: 增删改查: /users 2.根据GET查询、POST新增、PUT修改、DELETE删除对方法的请求方式进行限定 3.发送请求的过程中如何设置请求参数? 5.2.3 修改RESTful风格新增@Controller public class UserController { //设置当前请求方法为POST，表示REST风格中的添加操作 @RequestMapping(value = \"/users\",method = RequestMethod.POST) @ResponseBody public String save() { System.out.println(\"user save...\"); return \"{'module':'user save'}\"; } } 将请求路径更改为/users 访问该方法使用 POST: http://localhost/users 使用method属性限定该方法的访问方式为POST 如果发送的不是POST请求，比如发送GET请求，则会报错 删除@Controller public class UserController { //设置当前请求方法为DELETE，表示REST风格中的删除操作 @RequestMapping(value = \"/users\",method = RequestMethod.DELETE) @ResponseBody public String delete(Integer id) { System.out.println(\"user delete...\" + id); return \"{'module':'user delete'}\"; } } 将请求路径更改为/users 访问该方法使用 DELETE: http://localhost/users 访问成功，但是删除方法没有携带所要删除数据的id,所以针对RESTful的开发，如何携带数据参数? 传递路径参数前端发送请求的时候使用:http://localhost/users/1,路径中的1就是我们想要传递的参数。 后端获取参数，需要做如下修改: 修改@RequestMapping的value属性，将其中修改为/users/{id}，目的是和路径匹配 在方法的形参前添加@PathVariable注解 @Controller public class UserController { //设置当前请求方法为DELETE，表示REST风格中的删除操作 @RequestMapping(value = \"/users/{id}\",method = RequestMethod.DELETE) @ResponseBody public String delete(@PathVariable Integer id) { System.out.println(\"user delete...\" + id); return \"{'module':'user delete'}\"; } } 思考如下两个问题: (1)如果方法形参的名称和路径{}中的值不一致，该怎么办? (2)如果有多个参数需要传递该如何编写? 前端发送请求的时候使用:http://localhost/users/1/tom,路径中的1和tom就是我们想要传递的两个参数。 后端获取参数，需要做如下修改: @Controller public class UserController { //设置当前请求方法为DELETE，表示REST风格中的删除操作 @RequestMapping(value = \"/users/{id}/{name}\",method = RequestMethod.DELETE) @ResponseBody public String delete(@PathVariable Integer id,@PathVariable String name) { System.out.println(\"user delete...\" + id+\",\"+name); return \"{'module':'user delete'}\"; } } 修改@Controller public class UserController { //设置当前请求方法为PUT，表示REST风格中的修改操作 @RequestMapping(value = \"/users\",method = RequestMethod.PUT) @ResponseBody public String update(@RequestBody User user) { System.out.println(\"user update...\" + user); return \"{'module':'user update'}\"; } } 将请求路径更改为/users 访问该方法使用 PUT: http://localhost/users 访问并携带参数: 根据ID查询@Controller public class UserController { //设置当前请求方法为GET，表示REST风格中的查询操作 @RequestMapping(value = \"/users/{id}\" ,method = RequestMethod.GET) @ResponseBody public String getById(@PathVariable Integer id){ System.out.println(\"user getById...\"+id); return \"{'module':'user getById'}\"; } } 将请求路径更改为/users 访问该方法使用 GET: http://localhost/users/666 查询所有@Controller public class UserController { //设置当前请求方法为GET，表示REST风格中的查询操作 @RequestMapping(value = \"/users\" ,method = RequestMethod.GET) @ResponseBody public String getAll() { System.out.println(\"user getAll...\"); return \"{'module':'user getAll'}\"; } } 将请求路径更改为/users 访问该方法使用 GET: http://localhost/users 小结 RESTful入门案例，我们需要学习的内容如下: (1)设定Http请求动作(动词) @RequestMapping(value=””,==method== = RequestMethod.==POST|GET|PUT|DELETE==) (2)设定请求参数(路径变量) @RequestMapping(value=”/users/=={id}==”,method = RequestMethod.DELETE) @ReponseBody public String delete(==@PathVariable== Integer ==id==){ } 知识点1：@PathVariable 名称 @PathVariable 类型 ==形参注解== 位置 SpringMVC控制器方法形参定义前面 作用 绑定路径参数与处理器方法形参间的关系，要求路径参数名与形参名一一对应 关于接收参数，我们学过三个注解@RequestBody、@RequestParam、@PathVariable,这三个注解之间的区别和应用分别是什么? 区别 @RequestParam用于接收url地址传参或表单传参 @RequestBody用于接收json数据 @PathVariable用于接收路径参数，使用{参数名称}描述路径参数 应用 后期开发中，发送请求参数超过1个时，以json格式为主，@RequestBody应用较广 如果发送非json格式数据，选用@RequestParam接收请求参数 采用RESTful进行开发，当参数数量较少时，例如1个，可以采用@PathVariable接收请求路径变量，通常用于传递id值 5.3 RESTful快速开发做完了RESTful的开发，你会发现==好麻烦==，麻烦在哪? 问题1：每个方法的@RequestMapping注解中都定义了访问路径/books，重复性太高。 问题2：每个方法的@RequestMapping注解中都要使用method属性定义请求方式，重复性太高。 问题3：每个方法响应json都需要加上@ResponseBody注解，重复性太高。 对于上面所提的这三个问题，具体该如何解决? @RestController //@Controller + ReponseBody @RequestMapping(\"/books\") public class BookController { //@RequestMapping(method = RequestMethod.POST) @PostMapping public String save(@RequestBody Book book){ System.out.println(\"book save...\" + book); return \"{'module':'book save'}\"; } //@RequestMapping(value = \"/{id}\",method = RequestMethod.DELETE) @DeleteMapping(\"/{id}\") public String delete(@PathVariable Integer id){ System.out.println(\"book delete...\" + id); return \"{'module':'book delete'}\"; } //@RequestMapping(method = RequestMethod.PUT) @PutMapping public String update(@RequestBody Book book){ System.out.println(\"book update...\" + book); return \"{'module':'book update'}\"; } //@RequestMapping(value = \"/{id}\",method = RequestMethod.GET) @GetMapping(\"/{id}\") public String getById(@PathVariable Integer id){ System.out.println(\"book getById...\" + id); return \"{'module':'book getById'}\"; } //@RequestMapping(method = RequestMethod.GET) @GetMapping public String getAll(){ System.out.println(\"book getAll...\"); return \"{'module':'book getAll'}\"; } } 对于刚才的问题，我们都有对应的解决方案： 问题1：每个方法的@RequestMapping注解中都定义了访问路径/books，重复性太高。 将@RequestMapping提到类上面，用来定义所有方法共同的访问路径。 问题2：每个方法的@RequestMapping注解中都要使用method属性定义请求方式，重复性太高。 使用@GetMapping @PostMapping @PutMapping @DeleteMapping代替 问题3：每个方法响应json都需要加上@ResponseBody注解，重复性太高。 1.将ResponseBody提到类上面，让所有的方法都有@ResponseBody的功能 2.使用@RestController注解替换@Controller与@ResponseBody注解，简化书写 知识点1：@RestController 名称 @RestController 类型 ==类注解== 位置 基于SpringMVC的RESTful开发控制器类定义上方 作用 设置当前控制器类为RESTful风格，等同于@Controller与@ResponseBody两个注解组合功能 知识点2：@GetMapping @PostMapping @PutMapping @DeleteMapping 名称 @GetMapping @PostMapping @PutMapping @DeleteMapping 类型 ==方法注解== 位置 基于SpringMVC的RESTful开发控制器方法定义上方 作用 设置当前控制器方法请求访问路径与请求动作，每种对应一个请求动作，例如@GetMapping对应GET请求 相关属性 value（默认）：请求访问路径 5.4 RESTful案例5.4.1 需求分析需求一:图片列表查询，从后台返回数据，将数据展示在页面上 需求二:新增图片，将新增图书的数据传递到后台，并在控制台打印 **说明:**此次案例的重点是在SpringMVC中如何使用RESTful实现前后台交互，所以本案例并没有和数据库进行交互，所有数据使用假数据来完成开发。 步骤分析: 1.搭建项目导入jar包 2.编写Controller类，提供两个方法，一个用来做列表查询，一个用来做新增 3.在方法上使用RESTful进行路径设置 4.完成请求、参数的接收和结果的响应 5.使用PostMan进行测试 6.将前端页面拷贝到项目中 7.页面发送ajax请求 8.完成页面数据的展示 5.4.2 环境准备 创建一个Web的Maven项目 pom.xml添加Spring依赖 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;springmvc_07_rest_case&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;80&lt;/port&gt; &lt;path&gt;/&lt;/path&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 创建对应的配置类 public class ServletContainersInitConfig extends AbstractAnnotationConfigDispatcherServletInitializer { protected Class&lt;?&gt;[] getRootConfigClasses() { return new Class[0]; } protected Class&lt;?&gt;[] getServletConfigClasses() { return new Class[]{SpringMvcConfig.class}; } protected String[] getServletMappings() { return new String[]{\"/\"}; } //乱码处理 @Override protected Filter[] getServletFilters() { CharacterEncodingFilter filter = new CharacterEncodingFilter(); filter.setEncoding(\"UTF-8\"); return new Filter[]{filter}; } } @Configuration @ComponentScan(\"com.itheima.controller\") //开启json数据类型自动转换 @EnableWebMvc public class SpringMvcConfig { } 编写模型类Book public class Book { private Integer id; private String type; private String name; private String description; //setter...getter...toString略 } 编写BookController @Controller public class BookController { } 最终创建好的项目结构如下: 5.4.2 后台接口开发步骤1:编写Controller类并使用RESTful进行配置@RestController @RequestMapping(\"/books\") public class BookController { @PostMapping public String save(@RequestBody Book book){ System.out.println(\"book save ==&gt; \"+ book); return \"{'module':'book save success'}\"; } @GetMapping public List&lt;Book&gt; getAll(){ System.out.println(\"book getAll is running ...\"); List&lt;Book&gt; bookList = new ArrayList&lt;Book&gt;(); Book book1 = new Book(); book1.setType(\"计算机\"); book1.setName(\"SpringMVC入门教程\"); book1.setDescription(\"小试牛刀\"); bookList.add(book1); Book book2 = new Book(); book2.setType(\"计算机\"); book2.setName(\"SpringMVC实战教程\"); book2.setDescription(\"一代宗师\"); bookList.add(book2); Book book3 = new Book(); book3.setType(\"计算机丛书\"); book3.setName(\"SpringMVC实战教程进阶\"); book3.setDescription(\"一代宗师呕心创作\"); bookList.add(book3); return bookList; } } 步骤2：使用PostMan进行测试测试新增 { \"type\":\"计算机丛书\", \"name\":\"SpringMVC终极开发\", \"description\":\"这是一本好书\" } 测试查询 5.4.3 页面访问处理步骤1:拷贝静态页面将所有内容拷贝到项目的webapp目录下 步骤2:访问pages目录下的books.html打开浏览器输入http://localhost/pages/books.html (1)出现错误的原因? SpringMVC拦截了静态资源，根据/pages/books.html去controller找对应的方法，找不到所以会报404的错误。 (2)SpringMVC为什么会拦截静态资源呢? (3)解决方案? SpringMVC需要将静态资源进行放行。 @Configuration public class SpringMvcSupport extends WebMvcConfigurationSupport { //设置静态资源访问过滤，当前类需要设置为配置类，并被扫描加载 @Override protected void addResourceHandlers(ResourceHandlerRegistry registry) { //当访问/pages/????时候，从/pages目录下查找内容 registry.addResourceHandler(\"/pages/**\").addResourceLocations(\"/pages/\"); registry.addResourceHandler(\"/js/**\").addResourceLocations(\"/js/\"); registry.addResourceHandler(\"/css/**\").addResourceLocations(\"/css/\"); registry.addResourceHandler(\"/plugins/**\").addResourceLocations(\"/plugins/\"); } } 该配置类是在config目录下，SpringMVC扫描的是controller包，所以该配置类还未生效，要想生效需要将SpringMvcConfig配置类进行修改 @Configuration @ComponentScan({\"com.itheima.controller\",\"com.itheima.config\"}) @EnableWebMvc public class SpringMvcConfig { } 或者 @Configuration @ComponentScan(\"com.itheima\") @EnableWebMvc public class SpringMvcConfig { } 步骤3:修改books.html页面&lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;!-- 页面meta --&gt; &lt;meta charset=\"utf-8\"&gt; &lt;title&gt;SpringMVC案例&lt;/title&gt; &lt;!-- 引入样式 --&gt; &lt;link rel=\"stylesheet\" href=\"../plugins/elementui/index.css\"&gt; &lt;link rel=\"stylesheet\" href=\"../plugins/font-awesome/css/font-awesome.min.css\"&gt; &lt;link rel=\"stylesheet\" href=\"../css/style.css\"&gt; &lt;/head&gt; &lt;body class=\"hold-transition\"&gt; &lt;div id=\"app\"&gt; &lt;div class=\"content-header\"&gt; &lt;h1&gt;图书管理&lt;/h1&gt; &lt;/div&gt; &lt;div class=\"app-container\"&gt; &lt;div class=\"box\"&gt; &lt;div class=\"filter-container\"&gt; &lt;el-input placeholder=\"图书名称\" style=\"width: 200px;\" class=\"filter-item\"&gt;&lt;/el-input&gt; &lt;el-button class=\"dalfBut\"&gt;查询&lt;/el-button&gt; &lt;el-button type=\"primary\" class=\"butT\" @click=\"openSave()\"&gt;新建&lt;/el-button&gt; &lt;/div&gt; &lt;el-table size=\"small\" current-row-key=\"id\" :data=\"dataList\" stripe highlight-current-row&gt; &lt;el-table-column type=\"index\" align=\"center\" label=\"序号\"&gt;&lt;/el-table-column&gt; &lt;el-table-column prop=\"type\" label=\"图书类别\" align=\"center\"&gt;&lt;/el-table-column&gt; &lt;el-table-column prop=\"name\" label=\"图书名称\" align=\"center\"&gt;&lt;/el-table-column&gt; &lt;el-table-column prop=\"description\" label=\"描述\" align=\"center\"&gt;&lt;/el-table-column&gt; &lt;el-table-column label=\"操作\" align=\"center\"&gt; &lt;template slot-scope=\"scope\"&gt; &lt;el-button type=\"primary\" size=\"mini\"&gt;编辑&lt;/el-button&gt; &lt;el-button size=\"mini\" type=\"danger\"&gt;删除&lt;/el-button&gt; &lt;/template&gt; &lt;/el-table-column&gt; &lt;/el-table&gt; &lt;div class=\"pagination-container\"&gt; &lt;el-pagination class=\"pagiantion\" @current-change=\"handleCurrentChange\" :current-page=\"pagination.currentPage\" :page-size=\"pagination.pageSize\" layout=\"total, prev, pager, next, jumper\" :total=\"pagination.total\"&gt; &lt;/el-pagination&gt; &lt;/div&gt; &lt;!-- 新增标签弹层 --&gt; &lt;div class=\"add-form\"&gt; &lt;el-dialog title=\"新增图书\" :visible.sync=\"dialogFormVisible\"&gt; &lt;el-form ref=\"dataAddForm\" :model=\"formData\" :rules=\"rules\" label-position=\"right\" label-width=\"100px\"&gt; &lt;el-row&gt; &lt;el-col :span=\"12\"&gt; &lt;el-form-item label=\"图书类别\" prop=\"type\"&gt; &lt;el-input v-model=\"formData.type\"/&gt; &lt;/el-form-item&gt; &lt;/el-col&gt; &lt;el-col :span=\"12\"&gt; &lt;el-form-item label=\"图书名称\" prop=\"name\"&gt; &lt;el-input v-model=\"formData.name\"/&gt; &lt;/el-form-item&gt; &lt;/el-col&gt; &lt;/el-row&gt; &lt;el-row&gt; &lt;el-col :span=\"24\"&gt; &lt;el-form-item label=\"描述\"&gt; &lt;el-input v-model=\"formData.description\" type=\"textarea\"&gt;&lt;/el-input&gt; &lt;/el-form-item&gt; &lt;/el-col&gt; &lt;/el-row&gt; &lt;/el-form&gt; &lt;div slot=\"footer\" class=\"dialog-footer\"&gt; &lt;el-button @click=\"dialogFormVisible = false\"&gt;取消&lt;/el-button&gt; &lt;el-button type=\"primary\" @click=\"saveBook()\"&gt;确定&lt;/el-button&gt; &lt;/div&gt; &lt;/el-dialog&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;!-- 引入组件库 --&gt; &lt;script src=\"../js/vue.js\"&gt;&lt;/script&gt; &lt;script src=\"../plugins/elementui/index.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\" src=\"../js/jquery.min.js\"&gt;&lt;/script&gt; &lt;script src=\"../js/axios-0.18.0.js\"&gt;&lt;/script&gt; &lt;script&gt; var vue = new Vue({ el: '#app', data:{ dataList: [],//当前页要展示的分页列表数据 formData: {},//表单数据 dialogFormVisible: false,//增加表单是否可见 dialogFormVisible4Edit:false,//编辑表单是否可见 pagination: {},//分页模型数据，暂时弃用 }, //钩子函数，VUE对象初始化完成后自动执行 created() { this.getAll(); }, methods: { // 重置表单 resetForm() { //清空输入框 this.formData = {}; }, // 弹出添加窗口 openSave() { this.dialogFormVisible = true; this.resetForm(); }, //添加 saveBook () { axios.post(\"/books\",this.formData).then((res)=&gt;{ }); }, //主页列表查询 getAll() { axios.get(\"/books\").then((res)=&gt;{ this.dataList = res.data; }); }, } }) &lt;/script&gt; &lt;/html&gt;","categories":[],"tags":[{"name":"SSMP","slug":"SSMP","permalink":"https://gitee.com/yunyd/tags/SSMP/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://gitee.com/yunyd/tags/SpringMVC/"}],"author":"llllz."},{"title":"Spring复习 -1","slug":"Spring复习  -1","date":"2023-07-21T08:01:03.000Z","updated":"2023-08-25T00:22:54.991Z","comments":true,"path":"posts/df2593a9.html","link":"","permalink":"https://gitee.com/yunyd/posts/df2593a9.html","excerpt":"","text":"Spring复习1.IOC DI1.1 IOC入门案例对于入门案例，我们得先分析思路然后再代码实现， 1.1.1 入门案例思路分析(1)Spring是使用容器来管理bean对象的，那么管什么? 主要管理项目中所使用到的类对象，比如(Service和Dao) (2)如何将被管理的对象告知IOC容器? 使用配置文件 (3)被管理的对象交给IOC容器，要想从容器中获取对象，就先得思考如何获取到IOC容器? Spring框架提供相应的接口 (4)IOC容器得到后，如何从容器中获取bean? 调用Spring框架提供对应接口中的方法 (5)使用Spring导入哪些坐标? 用别人的东西，就需要在pom.xml添加对应的依赖 1.1.2 入门案例代码实现 需求分析:将BookServiceImpl和BookDaoImpl交给Spring管理，并从容器中获取对应的bean对象进行方法调用。 1.创建Maven的java项目 2.pom.xml添加Spring的依赖jar包 3.创建BookService,BookServiceImpl，BookDao和BookDaoImpl四个类 4.resources下添加spring配置文件，并完成bean的配置 5.使用Spring提供的接口完成IOC容器的创建 6.从容器中获取对象进行方法调用 步骤1:创建Maven项目 步骤2:添加Spring的依赖jar包pom.xml &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 步骤3:添加案例中需要的类创建BookService,BookServiceImpl，BookDao和BookDaoImpl四个类 public interface BookDao { public void save(); } public class BookDaoImpl implements BookDao { public void save() { System.out.println(\"book dao save ...\"); } } public interface BookService { public void save(); } public class BookServiceImpl implements BookService { private BookDao bookDao = new BookDaoImpl(); public void save() { System.out.println(\"book service save ...\"); bookDao.save(); } } 步骤4:添加spring配置文件resources下添加spring配置文件applicationContext.xml，并完成bean的配置 步骤5:在配置文件中完成bean的配置&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!--bean标签标示配置bean id属性标示给bean起名字 class属性表示给bean定义类型 --&gt; &lt;bean id=\"bookDao\" class=\"com.itheima.dao.impl.BookDaoImpl\"/&gt; &lt;bean id=\"bookService\" class=\"com.itheima.service.impl.BookServiceImpl\"/&gt; &lt;/beans&gt; ==注意事项：bean定义时id属性在同一个上下文中(配置文件)不能重复== 步骤6:获取IOC容器使用Spring提供的接口完成IOC容器的创建，创建App类，编写main方法 public class App { public static void main(String[] args) { //获取IOC容器 ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); } } 步骤7:从容器中获取对象进行方法调用public class App { public static void main(String[] args) { //获取IOC容器 ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); // BookDao bookDao = (BookDao) ctx.getBean(\"bookDao\"); // bookDao.save(); BookService bookService = (BookService) ctx.getBean(\"bookService\"); bookService.save(); } } 步骤8:运行程序测试结果为： Spring的IOC入门案例已经完成，但是在BookServiceImpl的类中依然存在BookDaoImpl对象的new操作，它们之间的耦合度还是比较高，这块该如何解决，就需要用到下面的DI:依赖注入。 1.2 DI入门案例对于DI的入门案例，我们依然先分析思路然后再代码实现， 1.2.1 入门案例思路分析(1)要想实现依赖注入，必须要基于IOC管理Bean DI的入门案例要依赖于前面IOC的入门案例 (2)Service中使用new形式创建的Dao对象是否保留? 需要删除掉，最终要使用IOC容器中的bean对象 (3)Service中需要的Dao对象如何进入到Service中? 在Service中提供方法，让Spring的IOC容器可以通过该方法传入bean对象 (4)Service与Dao间的关系如何描述? 使用配置文件 1.2.2 入门案例代码实现 需求:基于IOC入门案例，在BookServiceImpl类中删除new对象的方式，使用Spring的DI完成Dao层的注入 1.删除业务层中使用new的方式创建的dao对象 2.在业务层提供BookDao的setter方法 3.在配置文件中添加依赖注入的配置 4.运行程序调用方法 步骤1: 去除代码中的new在BookServiceImpl类中，删除业务层中使用new的方式创建的dao对象 public class BookServiceImpl implements BookService { //删除业务层中使用new的方式创建的dao对象 private BookDao bookDao; public void save() { System.out.println(\"book service save ...\"); bookDao.save(); } } 步骤2:为属性提供setter方法在BookServiceImpl类中,为BookDao提供setter方法 public class BookServiceImpl implements BookService { //删除业务层中使用new的方式创建的dao对象 private BookDao bookDao; public void save() { System.out.println(\"book service save ...\"); bookDao.save(); } //提供对应的set方法 public void setBookDao(BookDao bookDao) { this.bookDao = bookDao; } } 步骤3:修改配置完成注入在配置文件中添加依赖注入的配置 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!--bean标签标示配置bean id属性标示给bean起名字 class属性表示给bean定义类型 --&gt; &lt;bean id=\"bookDao\" class=\"com.itheima.dao.impl.BookDaoImpl\"/&gt; &lt;bean id=\"bookService\" class=\"com.itheima.service.impl.BookServiceImpl\"&gt; &lt;!--配置server与dao的关系--&gt; &lt;!--property标签表示配置当前bean的属性 name属性表示配置哪一个具体的属性 ref属性表示参照哪一个bean --&gt; &lt;property name=\"bookDao\" ref=\"bookDao\"/&gt; &lt;/bean&gt; &lt;/beans&gt; ==注意:配置中的两个bookDao的含义是不一样的== name=”bookDao”中bookDao的作用是让Spring的IOC容器在获取到名称后，将首字母大写，前面加set找对应的setBookDao()方法进行对象注入 ref=”bookDao”中bookDao的作用是让Spring能在IOC容器中找到id为bookDao的Bean对象给bookService进行注入 综上所述，对应关系如下: 步骤4:运行程序运行，测试结果为： 2.IOC相关内容通过前面两个案例，我们已经学习了bean如何定义配置，DI如何定义配置以及容器对象如何获取的内容，接下来主要是把这三块内容展开进行详细的讲解，深入的学习下这三部分的内容，首先是bean基础配置。 2.1 bean基础配置对于bean的配置中，主要会讲解bean基础配置,bean的别名配置,bean的作用范围配置==(重点)==,这三部分内容： 2.1.1 bean基础配置(id与class)对于bean的基础配置，在前面的案例中已经使用过: &lt;bean id=\"\" class=\"\"/&gt; 其中，bean标签的功能、使用方式以及id和class属性的作用，我们通过一张图来描述下 这其中需要大家重点掌握的是:==bean标签的id和class属性的使用==。 思考： class属性能不能写接口如BookDao的类全名呢? 答案肯定是不行，因为接口是没办法创建对象的。 前面提过为bean设置id时，id必须唯一，但是如果由于命名习惯而产生了分歧后，该如何解决? 在解决这个问题之前，我们需要准备下开发环境，对于开发环境我们可以有两种解决方案: 使用前面IOC和DI的案例 重新搭建一个新的案例环境,目的是方便大家查阅代码 搭建的内容和前面的案例是一样的，内容如下： 2.1.2 bean的name属性环境准备好后，接下来就可以在这个环境的基础上来学习下bean的别名配置， 首先来看下别名的配置说明: 步骤1：配置别名打开spring的配置文件applicationContext.xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!--name:为bean指定别名，别名可以有多个，使用逗号，分号，空格进行分隔--&gt; &lt;bean id=\"bookService\" name=\"service service4 bookEbi\" class=\"com.itheima.service.impl.BookServiceImpl\"&gt; &lt;property name=\"bookDao\" ref=\"bookDao\"/&gt; &lt;/bean&gt; &lt;!--scope：为bean设置作用范围，可选值为单例singloton，非单例prototype--&gt; &lt;bean id=\"bookDao\" name=\"dao\" class=\"com.itheima.dao.impl.BookDaoImpl\"/&gt; &lt;/beans&gt; 说明:Ebi全称Enterprise Business Interface，翻译为企业业务接口 步骤2:根据名称容器中获取bean对象public class AppForName { public static void main(String[] args) { ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); //此处根据bean标签的id属性和name属性的任意一个值来获取bean对象 BookService bookService = (BookService) ctx.getBean(\"service4\"); bookService.save(); } } 步骤3:运行程序测试结果为： ==注意事项:== bean依赖注入的ref属性指定bean，必须在容器中存在 如果不存在,则会报错，如下: 这个错误大家需要特别关注下: 获取bean无论是通过id还是name获取，如果无法获取到，将抛出异常==NoSuchBeanDefinitionException== 2.1.3 bean作用范围scope配置关于bean的作用范围是bean属性配置的一个==重点==内容。 看到这个作用范围，我们就得思考bean的作用范围是来控制bean哪块内容的? 我们先来看下bean作用范围的配置属性: 2.1.3.1 验证IOC容器中对象是否为单例验证思路​ 同一个bean获取两次，将对象打印到控制台，看打印出的地址值是否一致。 具体实现 创建一个AppForScope的类，在其main方法中来验证 public class AppForScope { public static void main(String[] args) { ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); BookDao bookDao1 = (BookDao) ctx.getBean(\"bookDao\"); BookDao bookDao2 = (BookDao) ctx.getBean(\"bookDao\"); System.out.println(bookDao1); System.out.println(bookDao2); } } 打印，观察控制台的打印结果 结论:默认情况下，Spring创建的bean对象都是单例的 获取到结论后，问题就来了，那如果我想创建出来非单例的bean对象，该如何实现呢? 2.1.3.2 配置bean为非单例在Spring配置文件中，配置scope属性来实现bean的非单例创建 在Spring的配置文件中，修改&lt;bean&gt;的scope属性 &lt;bean id=\"bookDao\" name=\"dao\" class=\"com.itheima.dao.impl.BookDaoImpl\" scope=\"\"/&gt; 将scope设置为singleton &lt;bean id=\"bookDao\" name=\"dao\" class=\"com.itheima.dao.impl.BookDaoImpl\" scope=\"singleton\"/&gt; 运行AppForScope，打印看结果 将scope设置为prototype &lt;bean id=\"bookDao\" name=\"dao\" class=\"com.itheima.dao.impl.BookDaoImpl\" scope=\"prototype\"/&gt; 运行AppForScope，打印看结果 结论，使用bean的scope属性可以控制bean的创建是否为单例： singleton默认为单例 prototype为非单例 2.1.3.3 scope使用后续思考介绍完scope属性以后，我们来思考几个问题: 为什么bean默认为单例? bean为单例的意思是在Spring的IOC容器中只会有该类的一个对象 bean对象只有一个就避免了对象的频繁创建与销毁，达到了bean对象的复用，性能高 bean在容器中是单例的，会不会产生线程安全问题? 如果对象是有状态对象，即该对象有成员变量可以用来存储数据的， 因为所有请求线程共用一个bean对象，所以会存在线程安全问题。 如果对象是无状态对象，即该对象没有成员变量没有进行数据存储的， 因方法中的局部变量在方法调用完成后会被销毁，所以不会存在线程安全问题。 哪些bean对象适合交给容器进行管理? 表现层对象 业务层对象 数据层对象 工具对象 哪些bean对象不适合交给容器进行管理? 封装实例的域对象，因为会引发线程安全问题，所以不适合。 2.14 bean基础配置小结关于bean的基础配置中，需要大家掌握以下属性: 2.2 bean实例化对象已经能交给Spring的IOC容器来创建了，但是容器是如何来创建对象的呢? 就需要研究下bean的实例化过程，在这块内容中主要解决两部分内容，分别是 bean是如何创建的 实例化bean的三种方式，构造方法,静态工厂和实例工厂 在讲解这三种创建方式之前，我们需要先确认一件事: bean本质上就是对象，对象在new的时候会使用构造方法完成，那创建bean也是使用构造方法完成的。 基于这个知识点出发，我们来验证spring中bean的三种创建方式， 2.2.1 环境准备为了方便大家阅读代码，重新准备个开发环境， 创建一个Maven项目 pom.xml添加依赖 resources下添加spring的配置文件applicationContext.xml 这些步骤和前面的都一致，大家可以快速的拷贝即可，最终项目的结构如下: 2.2.2 构造方法实例化在上述的环境下，我们来研究下Spring中的第一种bean的创建方式构造方法实例化: 步骤1:准备需要被创建的类准备一个BookDao和BookDaoImpl类 public interface BookDao { public void save(); } public class BookDaoImpl implements BookDao { public void save() { System.out.println(\"book dao save ...\"); } } 步骤2:将类配置到Spring容器&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"bookDao\" class=\"com.itheima.dao.impl.BookDaoImpl\"/&gt; &lt;/beans&gt; 步骤3:编写运行程序public class AppForInstanceBook { public static void main(String[] args) { ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); BookDao bookDao = (BookDao) ctx.getBean(\"bookDao\"); bookDao.save(); } } 步骤4:类中提供构造函数测试在BookDaoImpl类中添加一个无参构造函数，并打印一句话，方便观察结果。 public class BookDaoImpl implements BookDao { public BookDaoImpl() { System.out.println(\"book dao constructor is running ....\"); } public void save() { System.out.println(\"book dao save ...\"); } } 运行程序，如果控制台有打印构造函数中的输出，说明Spring容器在创建对象的时候也走的是构造函数 步骤5:将构造函数改成private测试public class BookDaoImpl implements BookDao { private BookDaoImpl() { System.out.println(\"book dao constructor is running ....\"); } public void save() { System.out.println(\"book dao save ...\"); } } 运行程序，能执行成功,说明内部走的依然是构造函数,能访问到类中的私有构造方法,显而易见Spring底层用的是反射 步骤6:构造函数中添加一个参数测试public class BookDaoImpl implements BookDao { private BookDaoImpl(int i) { System.out.println(\"book dao constructor is running ....\"); } public void save() { System.out.println(\"book dao save ...\"); } } 运行程序， 程序会报错，说明Spring底层使用的是类的无参构造方法。 2.2.3 分析Spring的错误信息接下来，我们主要研究下Spring的报错信息来学一学如阅读。 错误信息从下往上依次查看，因为上面的错误大都是对下面错误的一个包装，最核心错误是在最下面 Caused by: java.lang.NoSuchMethodException: com.itheima.dao.impl.BookDaoImpl.&lt;init&gt;() Caused by 翻译为引起，即出现错误的原因 java.lang.NoSuchMethodException:抛出的异常为没有这样的方法异常 com.itheima.dao.impl.BookDaoImpl.&lt;init&gt;():哪个类的哪个方法没有被找到导致的异常，&lt;init&gt;()指定是类的构造方法，即该类的无参构造方法 如果最后一行错误获取不到错误信息，接下来查看第二层: Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.itheima.dao.impl.BookDaoImpl]: No default constructor found; nested exception is java.lang.NoSuchMethodException: com.itheima.dao.impl.BookDaoImpl.&lt;init&gt;() nested:嵌套的意思，后面的异常内容和最底层的异常是一致的 Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.itheima.dao.impl.BookDaoImpl]: No default constructor found; Caused by: 引发 BeanInstantiationException:翻译为bean实例化异常 No default constructor found:没有一个默认的构造函数被发现 看到这其实错误已经比较明显，给大家个练习，把倒数第三层的错误分析下吧: Exception in thread “main” org.springframework.beans.factory.BeanCreationException: Error creating bean with name ‘bookDao’ defined in class path resource [applicationContext.xml]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.itheima.dao.impl.BookDaoImpl]: No default constructor found; nested exception is java.lang.NoSuchMethodException: com.itheima.dao.impl.BookDaoImpl.&lt;init&gt;()。 至此，关于Spring的构造方法实例化就已经学习完了，因为每一个类默认都会提供一个无参构造函数，所以其实真正在使用这种方式的时候，我们什么也不需要做。这也是我们以后比较常用的一种方式。 2.2.4 静态工厂实例化接下来研究Spring中的第二种bean的创建方式静态工厂实例化: 2.2.4.1 工厂方式创建bean在讲这种方式之前，我们需要先回顾一个知识点是使用工厂来创建对象的方式: (1)准备一个OrderDao和OrderDaoImpl类 public interface OrderDao { public void save(); } public class OrderDaoImpl implements OrderDao { public void save() { System.out.println(\"order dao save ...\"); } } (2)创建一个工厂类OrderDaoFactory并提供一个==静态方法== //静态工厂创建对象 public class OrderDaoFactory { public static OrderDao getOrderDao(){ return new OrderDaoImpl(); } } (3)编写AppForInstanceOrder运行类，在类中通过工厂获取对象 public class AppForInstanceOrder { public static void main(String[] args) { //通过静态工厂创建对象 OrderDao orderDao = OrderDaoFactory.getOrderDao(); orderDao.save(); } } (4)运行后，可以查看到结果 如果代码中对象是通过上面的这种方式来创建的，如何将其交给Spring来管理呢? 2.2.4.2 静态工厂实例化这就要用到Spring中的静态工厂实例化的知识了，具体实现步骤为: (1)在spring的配置文件application.properties中添加以下内容: &lt;bean id=\"orderDao\" class=\"com.itheima.factory.OrderDaoFactory\" factory-method=\"getOrderDao\"/&gt; class:工厂类的类全名 factory-mehod:具体工厂类中创建对象的方法名 对应关系如下图: (2)在AppForInstanceOrder运行类，使用从IOC容器中获取bean的方法进行运行测试 public class AppForInstanceOrder { public static void main(String[] args) { ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); OrderDao orderDao = (OrderDao) ctx.getBean(\"orderDao\"); orderDao.save(); } } (3)运行后，可以查看到结果 看到这，可能有人会问了，你这种方式在工厂类中不也是直接new对象的，和我自己直接new没什么太大的区别，而且静态工厂的方式反而更复杂，这种方式的意义是什么? 主要的原因是: 在工厂的静态方法中，我们除了new对象还可以做其他的一些业务操作，这些操作必不可少,如: public class OrderDaoFactory { public static OrderDao getOrderDao(){ System.out.println(\"factory setup....\");//模拟必要的业务操作 return new OrderDaoImpl(); } } 之前new对象的方式就无法添加其他的业务内容，重新运行，查看结果: 介绍完静态工厂实例化后，这种方式一般是用来兼容早期的一些老系统，所以==了解为主==。 2.2.5 实例工厂与FactoryBean接下来继续来研究Spring的第三种bean的创建方式实例工厂实例化: 2.2.3.1 环境准备(1)准备一个UserDao和UserDaoImpl类 public interface UserDao { public void save(); } public class UserDaoImpl implements UserDao { public void save() { System.out.println(\"user dao save ...\"); } } (2)创建一个工厂类OrderDaoFactory并提供一个普通方法，注意此处和静态工厂的工厂类不一样的地方是方法不是静态方法 public class UserDaoFactory { public UserDao getUserDao(){ return new UserDaoImpl(); } } (3)编写AppForInstanceUser运行类，在类中通过工厂获取对象 public class AppForInstanceUser { public static void main(String[] args) { //创建实例工厂对象 UserDaoFactory userDaoFactory = new UserDaoFactory(); //通过实例工厂对象创建对象 UserDao userDao = userDaoFactory.getUserDao(); userDao.save(); } (4)运行后，可以查看到结果 对于上面这种实例工厂的方式如何交给Spring管理呢? 2.2.3.2 实例工厂实例化具体实现步骤为: (1)在spring的配置文件中添加以下内容: &lt;bean id=\"userFactory\" class=\"com.itheima.factory.UserDaoFactory\"/&gt; &lt;bean id=\"userDao\" factory-method=\"getUserDao\" factory-bean=\"userFactory\"/&gt; 实例化工厂运行的顺序是: 创建实例化工厂对象,对应的是第一行配置 调用对象中的方法来创建bean，对应的是第二行配置 factory-bean:工厂的实例对象 factory-method:工厂对象中的具体创建对象的方法名,对应关系如下: factory-mehod:具体工厂类中创建对象的方法名 (2)在AppForInstanceUser运行类，使用从IOC容器中获取bean的方法进行运行测试 public class AppForInstanceUser { public static void main(String[] args) { ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); UserDao userDao = (UserDao) ctx.getBean(\"userDao\"); userDao.save(); } } (3)运行后，可以查看到结果 实例工厂实例化的方式就已经介绍完了，配置的过程还是比较复杂，所以Spring为了简化这种配置方式就提供了一种叫FactoryBean的方式来简化开发。 2.2.3.3 FactoryBean的使用具体的使用步骤为: (1)创建一个UserDaoFactoryBean的类，实现FactoryBean接口，重写接口的方法 public class UserDaoFactoryBean implements FactoryBean&lt;UserDao&gt; { //代替原始实例工厂中创建对象的方法 public UserDao getObject() throws Exception { return new UserDaoImpl(); } //返回所创建类的Class对象 public Class&lt;?&gt; getObjectType() { return UserDao.class; } } (2)在Spring的配置文件中进行配置 &lt;bean id=\"userDao\" class=\"com.itheima.factory.UserDaoFactoryBean\"/&gt; (3)AppForInstanceUser运行类不用做任何修改，直接运行 这种方式在Spring去整合其他框架的时候会被用到，所以这种方式需要大家理解掌握。 查看源码会发现，FactoryBean接口其实会有三个方法，分别是: T getObject() throws Exception; Class&lt;?&gt; getObjectType(); default boolean isSingleton() { return true; } 方法一:getObject()，被重写后，在方法中进行对象的创建并返回 方法二:getObjectType(),被重写后，主要返回的是被创建类的Class对象 方法三:没有被重写，因为它已经给了默认值，从方法名中可以看出其作用是设置对象是否为单例，默认true，从意思上来看，我们猜想默认应该是单例，如何来验证呢? 思路很简单，就是从容器中获取该对象的多个值，打印到控制台，查看是否为同一个对象。 public class AppForInstanceUser { public static void main(String[] args) { ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); UserDao userDao1 = (UserDao) ctx.getBean(\"userDao\"); UserDao userDao2 = (UserDao) ctx.getBean(\"userDao\"); System.out.println(userDao1); System.out.println(userDao2); } } 打印结果，如下: 通过验证，会发现默认是单例，那如果想改成单例具体如何实现? 只需要将isSingleton()方法进行重写，修改返回为false，即可 //FactoryBean创建对象 public class UserDaoFactoryBean implements FactoryBean&lt;UserDao&gt; { //代替原始实例工厂中创建对象的方法 public UserDao getObject() throws Exception { return new UserDaoImpl(); } public Class&lt;?&gt; getObjectType() { return UserDao.class; } public boolean isSingleton() { return false; } } 重新运行AppForInstanceUser，查看结果 从结果中可以看出现在已经是非单例了，但是一般情况下我们都会采用单例，也就是采用默认即可。所以isSingleton()方法一般不需要进行重写。 2.2.6 bean实例化小结通过这一节的学习，需要掌握: (1)bean是如何创建的呢? 构造方法 (2)Spring的IOC实例化对象的三种方式分别是: 构造方法(常用) 静态工厂(了解) 实例工厂(了解) FactoryBean(实用) 这些方式中，重点掌握构造方法和FactoryBean即可。 需要注意的一点是，构造方法在类中默认会提供，但是如果重写了构造方法，默认的就会消失，在使用的过程中需要注意，如果需要重写构造方法，最好把默认的构造方法也重写下。 2.3 bean的生命周期关于bean的相关知识还有最后一个是bean的生命周期,对于生命周期，我们主要围绕着bean生命周期控制来讲解: 首先理解下什么是生命周期? 从创建到消亡的完整过程,例如人从出生到死亡的整个过程就是一个生命周期。 bean生命周期是什么? bean对象从创建到销毁的整体过程。 bean生命周期控制是什么? 在bean创建后到销毁前做一些事情。 现在我们面临的问题是如何在bean的创建之后和销毁之前把我们需要添加的内容添加进去。 2.3.1 环境准备还是老规矩，为了方便大家后期代码的阅读，我们重新搭建下环境: 创建一个Maven项目 pom.xml添加依赖 resources下添加spring的配置文件applicationContext.xml 这些步骤和前面的都一致，大家可以快速的拷贝即可，最终项目的结构如下: (1)项目中添加BookDao、BookDaoImpl、BookService和BookServiceImpl类 public interface BookDao { public void save(); } public class BookDaoImpl implements BookDao { public void save() { System.out.println(\"book dao save ...\"); } } public interface BookService { public void save(); } public class BookServiceImpl implements BookService{ private BookDao bookDao; public void setBookDao(BookDao bookDao) { this.bookDao = bookDao; } public void save() { System.out.println(\"book service save ...\"); bookDao.save(); } } (2)resources下提供spring的配置文件 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"bookDao\" class=\"com.itheima.dao.impl.BookDaoImpl\"/&gt; &lt;/beans&gt; (3)编写AppForLifeCycle运行类，加载Spring的IOC容器，并从中获取对应的bean对象 public class AppForLifeCycle { public static void main( String[] args ) { ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); BookDao bookDao = (BookDao) ctx.getBean(\"bookDao\"); bookDao.save(); } } 2.3.2 生命周期设置接下来，在上面这个环境中来为BookDao添加生命周期的控制方法，具体的控制有两个阶段: bean创建之后，想要添加内容，比如用来初始化需要用到资源 bean销毁之前，想要添加内容，比如用来释放用到的资源 步骤1:添加初始化和销毁方法针对这两个阶段，我们在BooDaoImpl类中分别添加两个方法，==方法名任意== public class BookDaoImpl implements BookDao { public void save() { System.out.println(\"book dao save ...\"); } //表示bean初始化对应的操作 public void init(){ System.out.println(\"init...\"); } //表示bean销毁前对应的操作 public void destory(){ System.out.println(\"destory...\"); } } 步骤2:配置生命周期在配置文件添加配置，如下: &lt;bean id=\"bookDao\" class=\"com.itheima.dao.impl.BookDaoImpl\" init-method=\"init\" destroy-method=\"destory\"/&gt; 步骤3:运行程序运行AppForLifeCycle打印结果为: 从结果中可以看出，init方法执行了，但是destroy方法却未执行，这是为什么呢? Spring的IOC容器是运行在JVM中 运行main方法后,JVM启动,Spring加载配置文件生成IOC容器,从容器获取bean对象，然后调方法执行 main方法执行完后，JVM退出，这个时候IOC容器中的bean还没有来得及销毁就已经结束了 所以没有调用对应的destroy方法 知道了出现问题的原因，具体该如何解决呢? 2.3.3 close关闭容器 ApplicationContext中没有close方法 需要将ApplicationContext更换成ClassPathXmlApplicationContext ClassPathXmlApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); 调用ctx的close()方法 ctx.close(); 运行程序，就能执行destroy方法的内容 2.3.4 注册钩子关闭容器 在容器未关闭之前，提前设置好回调函数，让JVM在退出之前回调此函数来关闭容器 调用ctx的registerShutdownHook()方法 ctx.registerShutdownHook(); **注意:**registerShutdownHook在ApplicationContext中也没有 运行后，查询打印结果 两种方式介绍完后，close和registerShutdownHook选哪个? 相同点:这两种都能用来关闭容器 不同点:close()是在调用的时候关闭，registerShutdownHook()是在JVM退出前调用关闭。 分析上面的实现过程，会发现添加初始化和销毁方法，即需要编码也需要配置，实现起来步骤比较多也比较乱。 Spring提供了两个接口来完成生命周期的控制，好处是可以不用再进行配置init-method和destroy-method 接下来在BookServiceImpl完成这两个接口的使用: 修改BookServiceImpl类，添加两个接口InitializingBean， DisposableBean并实现接口中的两个方法afterPropertiesSet和destroy public class BookServiceImpl implements BookService, InitializingBean, DisposableBean { private BookDao bookDao; public void setBookDao(BookDao bookDao) { this.bookDao = bookDao; } public void save() { System.out.println(\"book service save ...\"); bookDao.save(); } public void destroy() throws Exception { System.out.println(\"service destroy\"); } public void afterPropertiesSet() throws Exception { System.out.println(\"service init\"); } } 重新运行AppForLifeCycle类， 那第二种方式的实现，我们也介绍完了。 小细节 对于InitializingBean接口中的afterPropertiesSet方法，翻译过来为属性设置之后。 对于BookServiceImpl来说，bookDao是它的一个属性 setBookDao方法是Spring的IOC容器为其注入属性的方法 思考:afterPropertiesSet和setBookDao谁先执行? 从方法名分析，猜想应该是setBookDao方法先执行 验证思路，在setBookDao方法中添加一句话 public void setBookDao(BookDao bookDao) { System.out.println(\"set .....\"); this.bookDao = bookDao; } 重新运行AppForLifeCycle，打印结果如下: 验证的结果和我们猜想的结果是一致的，所以初始化方法会在类中属性设置之后执行。 2.3.5 bean生命周期小结(1)关于Spring中对bean生命周期控制提供了两种方式: 在配置文件中的bean标签中添加init-method和destroy-method属性 类实现InitializingBean与DisposableBean接口，这种方式了解下即可。 (2)对于bean的生命周期控制在bean的整个生命周期中所处的位置如下: 初始化容器 1.创建对象(内存分配) 2.执行构造方法 3.执行属性注入(set操作) ==4.执行bean初始化方法== 使用bean 1.执行业务操作 关闭/销毁容器 ==1.执行bean销毁方法== (3)关闭容器的两种方式: ConfigurableApplicationContext是ApplicationContext的子类 close()方法 registerShutdownHook()方法 3.DI相关内容前面我们已经完成了bean相关操作的讲解，接下来就进入第二个大的模块DI依赖注入，首先来介绍下Spring中有哪些注入方式? 我们先来思考 向一个类中传递数据的方式有几种? 普通方法(set方法) 构造方法 依赖注入描述了在容器中建立bean与bean之间的依赖关系的过程，如果bean运行需要的是数字或字符串呢? 引用类型 简单类型(基本数据类型与String) Spring就是基于上面这些知识点，为我们提供了两种注入方式，分别是: setter注入 简单类型 ==引用类型== 构造器注入 简单类型 引用类型 依赖注入的方式已经介绍完，接下来挨个学习下: 3.1 setter注入 对于setter方式注入引用类型的方式之前已经学习过，快速回顾下: 在bean中定义引用类型属性，并提供可访问的==set==方法 public class BookServiceImpl implements BookService { private BookDao bookDao; public void setBookDao(BookDao bookDao) { this.bookDao = bookDao; } } 配置中使用==property==标签==ref==属性注入引用类型对象 &lt;bean id=\"bookService\" class=\"com.itheima.service.impl.BookServiceImpl\"&gt; &lt;property name=\"bookDao\" ref=\"bookDao\"/&gt; &lt;/bean&gt; &lt;bean id=\"bookDao\" class=\"com.itheima.dao.imipl.BookDaoImpl\"/&gt; 3.1.1 环境准备为了更好的学习下面内容，我们依旧准备一个新环境: 创建一个Maven项目 pom.xml添加依赖 resources下添加spring的配置文件 这些步骤和前面的都一致，大家可以快速的拷贝即可，最终项目的结构如下: (1)项目中添加BookDao、BookDaoImpl、UserDao、UserDaoImpl、BookService和BookServiceImpl类 public interface BookDao { public void save(); } public class BookDaoImpl implements BookDao { public void save() { System.out.println(\"book dao save ...\"); } } public interface UserDao { public void save(); } public class UserDaoImpl implements UserDao { public void save() { System.out.println(\"user dao save ...\"); } } public interface BookService { public void save(); } public class BookServiceImpl implements BookService{ private BookDao bookDao; public void setBookDao(BookDao bookDao) { this.bookDao = bookDao; } public void save() { System.out.println(\"book service save ...\"); bookDao.save(); } } (2)resources下提供spring的配置文件 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"bookDao\" class=\"com.itheima.dao.impl.BookDaoImpl\"/&gt; &lt;bean id=\"bookService\" class=\"com.itheima.service.impl.BookServiceImpl\"&gt; &lt;property name=\"bookDao\" ref=\"bookDao\"/&gt; &lt;/bean&gt; &lt;/beans&gt; (3)编写AppForDISet运行类，加载Spring的IOC容器，并从中获取对应的bean对象 public class AppForDISet { public static void main( String[] args ) { ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); BookService bookService = (BookService) ctx.getBean(\"bookService\"); bookService.save(); } } 接下来，在上面这个环境中来完成setter注入的学习: 3.1.2 注入引用数据类型 需求:在bookServiceImpl对象中注入userDao 1.在BookServiceImpl中声明userDao属性 2.为userDao属性提供setter方法 3.在配置文件中使用property标签注入 步骤1:声明属性并提供setter方法在BookServiceImpl中声明userDao属性，并提供setter方法 public class BookServiceImpl implements BookService{ private BookDao bookDao; private UserDao userDao; public void setUserDao(UserDao userDao) { this.userDao = userDao; } public void setBookDao(BookDao bookDao) { this.bookDao = bookDao; } public void save() { System.out.println(\"book service save ...\"); bookDao.save(); userDao.save(); } } 步骤2:配置文件中进行注入配置在applicationContext.xml配置文件中使用property标签注入 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"bookDao\" class=\"com.itheima.dao.impl.BookDaoImpl\"/&gt; &lt;bean id=\"userDao\" class=\"com.itheima.dao.impl.UserDaoImpl\"/&gt; &lt;bean id=\"bookService\" class=\"com.itheima.service.impl.BookServiceImpl\"&gt; &lt;property name=\"bookDao\" ref=\"bookDao\"/&gt; &lt;property name=\"userDao\" ref=\"userDao\"/&gt; &lt;/bean&gt; &lt;/beans&gt; 步骤3:运行程序运行AppForDISet类，查看结果，说明userDao已经成功注入。 3.1.3 注入简单数据类型 需求：给BookDaoImpl注入一些简单数据类型的数据 参考引用数据类型的注入，我们可以推出具体的步骤为: 1.在BookDaoImpl类中声明对应的简单数据类型的属性 2.为这些属性提供对应的setter方法 3.在applicationContext.xml中配置 思考: 引用类型使用的是&lt;property name=\"\" ref=\"\"/&gt;,简单数据类型还是使用ref么? ref是指向Spring的IOC容器中的另一个bean对象的，对于简单数据类型，没有对应的bean对象，该如何配置? 步骤1:声明属性并提供setter方法在BookDaoImpl类中声明对应的简单数据类型的属性,并提供对应的setter方法 public class BookDaoImpl implements BookDao { private String databaseName; private int connectionNum; public void setConnectionNum(int connectionNum) { this.connectionNum = connectionNum; } public void setDatabaseName(String databaseName) { this.databaseName = databaseName; } public void save() { System.out.println(\"book dao save ...\"+databaseName+\",\"+connectionNum); } } 步骤2:配置文件中进行注入配置在applicationContext.xml配置文件中使用property标签注入 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"bookDao\" class=\"com.itheima.dao.impl.BookDaoImpl\"&gt; &lt;property name=\"databaseName\" value=\"mysql\"/&gt; &lt;property name=\"connectionNum\" value=\"10\"/&gt; &lt;/bean&gt; &lt;bean id=\"userDao\" class=\"com.itheima.dao.impl.UserDaoImpl\"/&gt; &lt;bean id=\"bookService\" class=\"com.itheima.service.impl.BookServiceImpl\"&gt; &lt;property name=\"bookDao\" ref=\"bookDao\"/&gt; &lt;property name=\"userDao\" ref=\"userDao\"/&gt; &lt;/bean&gt; &lt;/beans&gt; 说明: value:后面跟的是简单数据类型，对于参数类型，Spring在注入的时候会自动转换，但是不能写成 &lt;property name=\"connectionNum\" value=\"abc\"/&gt; 这样的话，spring在将abc转换成int类型的时候就会报错。 步骤3:运行程序运行AppForDISet类，查看结果，说明userDao已经成功注入。 **注意:**两个property注入标签的顺序可以任意。 对于setter注入方式的基本使用就已经介绍完了， 对于引用数据类型使用的是&lt;property name=\"\" ref=\"\"/&gt; 对于简单数据类型使用的是&lt;property name=\"\" value=\"\"/&gt; 3.2 构造器注入3.2.1 环境准备构造器注入也就是构造方法注入，学习之前，还是先准备下环境: 创建一个Maven项目 pom.xml添加依赖 resources下添加spring的配置文件 这些步骤和前面的都一致，大家可以快速的拷贝即可，最终项目的结构如下: (1)项目中添加BookDao、BookDaoImpl、UserDao、UserDaoImpl、BookService和BookServiceImpl类 public interface BookDao { public void save(); } public class BookDaoImpl implements BookDao { private String databaseName; private int connectionNum; public void save() { System.out.println(\"book dao save ...\"); } } public interface UserDao { public void save(); } public class UserDaoImpl implements UserDao { public void save() { System.out.println(\"user dao save ...\"); } } public interface BookService { public void save(); } public class BookServiceImpl implements BookService{ private BookDao bookDao; public void setBookDao(BookDao bookDao) { this.bookDao = bookDao; } public void save() { System.out.println(\"book service save ...\"); bookDao.save(); } } (2)resources下提供spring的配置文件 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"bookDao\" class=\"com.itheima.dao.impl.BookDaoImpl\"/&gt; &lt;bean id=\"bookService\" class=\"com.itheima.service.impl.BookServiceImpl\"&gt; &lt;property name=\"bookDao\" ref=\"bookDao\"/&gt; &lt;/bean&gt; &lt;/beans&gt; (3)编写AppForDIConstructor运行类，加载Spring的IOC容器，并从中获取对应的bean对象 public class AppForDIConstructor { public static void main( String[] args ) { ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); BookService bookService = (BookService) ctx.getBean(\"bookService\"); bookService.save(); } } 3.2.2 构造器注入引用数据类型接下来，在上面这个环境中来完成构造器注入的学习: 需求：将BookServiceImpl类中的bookDao修改成使用构造器的方式注入。 1.将bookDao的setter方法删除掉 2.添加带有bookDao参数的构造方法 3.在applicationContext.xml中配置 步骤1:删除setter方法并提供构造方法在BookServiceImpl类中将bookDao的setter方法删除掉,并添加带有bookDao参数的构造方法 public class BookServiceImpl implements BookService{ private BookDao bookDao; public BookServiceImpl(BookDao bookDao) { this.bookDao = bookDao; } public void save() { System.out.println(\"book service save ...\"); bookDao.save(); } } 步骤2:配置文件中进行配置构造方式注入在applicationContext.xml中配置 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"bookDao\" class=\"com.itheima.dao.impl.BookDaoImpl\"/&gt; &lt;bean id=\"bookService\" class=\"com.itheima.service.impl.BookServiceImpl\"&gt; &lt;constructor-arg name=\"bookDao\" ref=\"bookDao\"/&gt; &lt;/bean&gt; &lt;/beans&gt; 说明: 标签中 name属性对应的值为构造函数中方法形参的参数名，必须要保持一致。 ref属性指向的是spring的IOC容器中其他bean对象。 步骤3：运行程序运行AppForDIConstructor类，查看结果，说明bookDao已经成功注入。 3.2.3 构造器注入多个引用数据类型 需求:在BookServiceImpl使用构造函数注入多个引用数据类型，比如userDao 1.声明userDao属性 2.生成一个带有bookDao和userDao参数的构造函数 3.在applicationContext.xml中配置注入 步骤1:提供多个属性的构造函数在BookServiceImpl声明userDao并提供多个参数的构造函数 public class BookServiceImpl implements BookService{ private BookDao bookDao; private UserDao userDao; public BookServiceImpl(BookDao bookDao,UserDao userDao) { this.bookDao = bookDao; this.userDao = userDao; } public void save() { System.out.println(\"book service save ...\"); bookDao.save(); userDao.save(); } } 步骤2:配置文件中配置多参数注入 在applicationContext.xml中配置注入 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"bookDao\" class=\"com.itheima.dao.impl.BookDaoImpl\"/&gt; &lt;bean id=\"userDao\" class=\"com.itheima.dao.impl.UserDaoImpl\"/&gt; &lt;bean id=\"bookService\" class=\"com.itheima.service.impl.BookServiceImpl\"&gt; &lt;constructor-arg name=\"bookDao\" ref=\"bookDao\"/&gt; &lt;constructor-arg name=\"userDao\" ref=\"userDao\"/&gt; &lt;/bean&gt; &lt;/beans&gt; **说明:**这两个&lt;contructor-arg&gt;的配置顺序可以任意 步骤3:运行程序运行AppForDIConstructor类，查看结果，说明userDao已经成功注入。 3.2.4 构造器注入多个简单数据类型 需求:在BookDaoImpl中，使用构造函数注入databaseName和connectionNum两个参数。 参考引用数据类型的注入，我们可以推出具体的步骤为: 1.提供一个包含这两个参数的构造方法 2.在applicationContext.xml中进行注入配置 步骤1:添加多个简单属性并提供构造方法修改BookDaoImpl类，添加构造方法 public class BookDaoImpl implements BookDao { private String databaseName; private int connectionNum; public BookDaoImpl(String databaseName, int connectionNum) { this.databaseName = databaseName; this.connectionNum = connectionNum; } public void save() { System.out.println(\"book dao save ...\"+databaseName+\",\"+connectionNum); } } 步骤2:配置完成多个属性构造器注入在applicationContext.xml中进行注入配置 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"bookDao\" class=\"com.itheima.dao.impl.BookDaoImpl\"&gt; &lt;constructor-arg name=\"databaseName\" value=\"mysql\"/&gt; &lt;constructor-arg name=\"connectionNum\" value=\"666\"/&gt; &lt;/bean&gt; &lt;bean id=\"userDao\" class=\"com.itheima.dao.impl.UserDaoImpl\"/&gt; &lt;bean id=\"bookService\" class=\"com.itheima.service.impl.BookServiceImpl\"&gt; &lt;constructor-arg name=\"bookDao\" ref=\"bookDao\"/&gt; &lt;constructor-arg name=\"userDao\" ref=\"userDao\"/&gt; &lt;/bean&gt; &lt;/beans&gt; **说明:**这两个&lt;contructor-arg&gt;的配置顺序可以任意 步骤3:运行程序运行AppForDIConstructor类，查看结果 上面已经完成了构造函数注入的基本使用，但是会存在一些问题: 当构造函数中方法的参数名发生变化后，配置文件中的name属性也需要跟着变 这两块存在紧耦合，具体该如何解决? 在解决这个问题之前，需要提前说明的是，这个参数名发生变化的情况并不多，所以上面的还是比较主流的配置方式，下面介绍的，大家都以了解为主。 方式一:删除name属性，添加type属性，按照类型注入 &lt;bean id=\"bookDao\" class=\"com.itheima.dao.impl.BookDaoImpl\"&gt; &lt;constructor-arg type=\"int\" value=\"10\"/&gt; &lt;constructor-arg type=\"java.lang.String\" value=\"mysql\"/&gt; &lt;/bean&gt; 这种方式可以解决构造函数形参名发生变化带来的耦合问题 但是如果构造方法参数中有类型相同的参数，这种方式就不太好实现了 方式二:删除type属性，添加index属性，按照索引下标注入，下标从0开始 &lt;bean id=\"bookDao\" class=\"com.itheima.dao.impl.BookDaoImpl\"&gt; &lt;constructor-arg index=\"1\" value=\"100\"/&gt; &lt;constructor-arg index=\"0\" value=\"mysql\"/&gt; &lt;/bean&gt; 这种方式可以解决参数类型重复问题 但是如果构造方法参数顺序发生变化后，这种方式又带来了耦合问题 介绍完两种参数的注入方式，具体我们该如何选择呢? 强制依赖使用构造器进行，使用setter注入有概率不进行注入导致null对象出现 强制依赖指对象在创建的过程中必须要注入指定的参数 可选依赖使用setter注入进行，灵活性强 可选依赖指对象在创建过程中注入的参数可有可无 Spring框架倡导使用构造器，第三方框架内部大多数采用构造器注入的形式进行数据初始化，相对严谨 如果有必要可以两者同时使用，使用构造器注入完成强制依赖的注入，使用setter注入完成可选依赖的注入 实际开发过程中还要根据实际情况分析，如果受控对象没有提供setter方法就必须使用构造器注入 ==自己开发的模块推荐使用setter注入== 这节中主要讲解的是Spring的依赖注入的实现方式: setter注入 简单数据类型 &lt;bean ...&gt; &lt;property name=\"\" value=\"\"/&gt; &lt;/bean&gt; 引用数据类型 &lt;bean ...&gt; &lt;property name=\"\" ref=\"\"/&gt; &lt;/bean&gt; 构造器注入 简单数据类型 &lt;bean ...&gt; &lt;constructor-arg name=\"\" index=\"\" type=\"\" value=\"\"/&gt; &lt;/bean&gt; 引用数据类型 &lt;bean ...&gt; &lt;constructor-arg name=\"\" index=\"\" type=\"\" ref=\"\"/&gt; &lt;/bean&gt; 依赖注入的方式选择上 建议使用setter注入 第三方技术根据情况选择 3.3 自动配置前面花了大量的时间把Spring的注入去学习了下，总结起来就一个字==麻烦==。 问:麻烦在哪? 答:配置文件的编写配置上。 问:有更简单方式么? 答:有，自动配置 什么是自动配置以及如何实现自动配置，就是接下来要学习的内容： 3.3.1 什么是依赖自动装配? IoC容器根据bean所依赖的资源在容器中自动查找并注入到bean中的过程称为自动装配 3.3.2 自动装配方式有哪些? ==按类型（常用）== 按名称 按构造方法 不启用自动装配 3.3.3 准备下案例环境 创建一个Maven项目 pom.xml添加依赖 resources下添加spring的配置文件 这些步骤和前面的都一致，大家可以快速的拷贝即可，最终项目的结构如下: (1)项目中添加BookDao、BookDaoImpl、BookService和BookServiceImpl类 public interface BookDao { public void save(); } public class BookDaoImpl implements BookDao { private String databaseName; private int connectionNum; public void save() { System.out.println(\"book dao save ...\"); } } public interface BookService { public void save(); } public class BookServiceImpl implements BookService{ private BookDao bookDao; public void setBookDao(BookDao bookDao) { this.bookDao = bookDao; } public void save() { System.out.println(\"book service save ...\"); bookDao.save(); } } (2)resources下提供spring的配置文件 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"bookDao\" class=\"com.itheima.dao.impl.BookDaoImpl\"/&gt; &lt;bean id=\"bookService\" class=\"com.itheima.service.impl.BookServiceImpl\"&gt; &lt;property name=\"bookDao\" ref=\"bookDao\"/&gt; &lt;/bean&gt; &lt;/beans&gt; (3)编写AppForAutoware运行类，加载Spring的IOC容器，并从中获取对应的bean对象 public class AppForAutoware { public static void main( String[] args ) { ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); BookService bookService = (BookService) ctx.getBean(\"bookService\"); bookService.save(); } } 3.3.4 完成自动装配的配置接下来，在上面这个环境中来完成自动装配的学习: 自动装配只需要修改applicationContext.xml配置文件即可: (1)将&lt;property&gt;标签删除 (2)在&lt;bean&gt;标签中添加autowire属性 首先来实现按照类型注入的配置 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean class=\"com.itheima.dao.impl.BookDaoImpl\"/&gt; &lt;!--autowire属性：开启自动装配，通常使用按类型装配--&gt; &lt;bean id=\"bookService\" class=\"com.itheima.service.impl.BookServiceImpl\" autowire=\"byType\"/&gt; &lt;/beans&gt; ==注意事项:== 需要注入属性的类中对应属性的setter方法不能省略 被注入的对象必须要被Spring的IOC容器管理 按照类型在Spring的IOC容器中如果找到多个对象，会报NoUniqueBeanDefinitionException 一个类型在IOC中有多个对象，还想要注入成功，这个时候就需要按照名称注入，配置方式为: &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean class=\"com.itheima.dao.impl.BookDaoImpl\"/&gt; &lt;!--autowire属性：开启自动装配，通常使用按类型装配--&gt; &lt;bean id=\"bookService\" class=\"com.itheima.service.impl.BookServiceImpl\" autowire=\"byName\"/&gt; &lt;/beans&gt; ==注意事项:== 按照名称注入中的名称指的是什么? bookDao是private修饰的，外部类无法直接方法 外部类只能通过属性的set方法进行访问 对外部类来说，setBookDao方法名，去掉set后首字母小写是其属性名 为什么是去掉set首字母小写? 这个规则是set方法生成的默认规则，set方法的生成是把属性名首字母大写前面加set形成的方法名 所以按照名称注入，其实是和对应的set方法有关，但是如果按照标准起名称，属性名和set对应的名是一致的 如果按照名称去找对应的bean对象，找不到则注入Null 当某一个类型在IOC容器中有多个对象，按照名称注入只找其指定名称对应的bean对象，不会报错 两种方式介绍完后，以后用的更多的是==按照类型==注入。 最后对于依赖注入，需要注意一些其他的配置特征: 自动装配用于引用类型依赖注入，不能对简单类型进行操作 使用按类型装配时（byType）必须保障容器中相同类型的bean唯一，推荐使用 使用按名称装配时（byName）必须保障容器中具有指定名称的bean，因变量名与配置耦合，不推荐使用 自动装配优先级低于setter注入与构造器注入，同时出现时自动装配配置失效 3.4 集合注入前面我们已经能完成引入数据类型和简单数据类型的注入，但是还有一种数据类型==集合==，集合中既可以装简单数据类型也可以装引用数据类型，对于集合，在Spring中该如何注入呢? 先来回顾下，常见的集合类型有哪些? 数组 List Set Map Properties 针对不同的集合类型，该如何实现注入呢? 3.4.1 环境准备 创建一个Maven项目 pom.xml添加依赖 resources下添加spring的配置文件applicationContext.xml 这些步骤和前面的都一致，大家可以快速的拷贝即可，最终项目的结构如下: (1)项目中添加添加BookDao、BookDaoImpl类 public interface BookDao { public void save(); } public class BookDaoImpl implements BookDao { private int[] array; private List&lt;String&gt; list; private Set&lt;String&gt; set; private Map&lt;String,String&gt; map; private Properties properties; public void save() { System.out.println(\"book dao save ...\"); System.out.println(\"遍历数组:\" + Arrays.toString(array)); System.out.println(\"遍历List\" + list); System.out.println(\"遍历Set\" + set); System.out.println(\"遍历Map\" + map); System.out.println(\"遍历Properties\" + properties); } //setter....方法省略，自己使用工具生成 } (2)resources下提供spring的配置文件，applicationContext.xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"bookDao\" class=\"com.itheima.dao.impl.BookDaoImpl\"/&gt; &lt;/beans&gt; (3)编写AppForDICollection运行类，加载Spring的IOC容器，并从中获取对应的bean对象 public class AppForDICollection { public static void main( String[] args ) { ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); BookDao bookDao = (BookDao) ctx.getBean(\"bookDao\"); bookDao.save(); } } 接下来，在上面这个环境中来完成集合注入的学习: 下面的所以配置方式，都是在bookDao的bean标签中使用进行注入 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"bookDao\" class=\"com.itheima.dao.impl.BookDaoImpl\"&gt; &lt;/bean&gt; &lt;/beans&gt; 3.4.2 注入数组类型数据&lt;property name=\"array\"&gt; &lt;array&gt; &lt;value&gt;100&lt;/value&gt; &lt;value&gt;200&lt;/value&gt; &lt;value&gt;300&lt;/value&gt; &lt;/array&gt; &lt;/property&gt; 3.4.3 注入List类型数据&lt;property name=\"list\"&gt; &lt;list&gt; &lt;value&gt;itcast&lt;/value&gt; &lt;value&gt;itheima&lt;/value&gt; &lt;value&gt;boxuegu&lt;/value&gt; &lt;value&gt;chuanzhihui&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; 3.4.4 注入Set类型数据&lt;property name=\"set\"&gt; &lt;set&gt; &lt;value&gt;itcast&lt;/value&gt; &lt;value&gt;itheima&lt;/value&gt; &lt;value&gt;boxuegu&lt;/value&gt; &lt;value&gt;boxuegu&lt;/value&gt; &lt;/set&gt; &lt;/property&gt; 3.4.5 注入Map类型数据&lt;property name=\"map\"&gt; &lt;map&gt; &lt;entry key=\"country\" value=\"china\"/&gt; &lt;entry key=\"province\" value=\"henan\"/&gt; &lt;entry key=\"city\" value=\"kaifeng\"/&gt; &lt;/map&gt; &lt;/property&gt; 3.4.6 注入Properties类型数据&lt;property name=\"properties\"&gt; &lt;props&gt; &lt;prop key=\"country\"&gt;china&lt;/prop&gt; &lt;prop key=\"province\"&gt;henan&lt;/prop&gt; &lt;prop key=\"city\"&gt;kaifeng&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; 配置完成后，运行下看结果: 说明： property标签表示setter方式注入，构造方式注入constructor-arg标签内部也可以写&lt;array&gt;、&lt;list&gt;、&lt;set&gt;、&lt;map&gt;、&lt;props&gt;标签 List的底层也是通过数组实现的，所以&lt;list&gt;和&lt;array&gt;标签是可以混用 集合中要添加引用类型，只需要把&lt;value&gt;标签改成&lt;ref&gt;标签，这种方式用的比较少","categories":[],"tags":[{"name":"SSMP","slug":"SSMP","permalink":"https://gitee.com/yunyd/tags/SSMP/"},{"name":"Spring","slug":"Spring","permalink":"https://gitee.com/yunyd/tags/Spring/"}],"author":"llllz."}],"categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://gitee.com/yunyd/tags/Docker/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://gitee.com/yunyd/tags/SpringCloud/"},{"name":"Gateway","slug":"Gateway","permalink":"https://gitee.com/yunyd/tags/Gateway/"},{"name":"Feign","slug":"Feign","permalink":"https://gitee.com/yunyd/tags/Feign/"},{"name":"Nacos","slug":"Nacos","permalink":"https://gitee.com/yunyd/tags/Nacos/"},{"name":"Eureka","slug":"Eureka","permalink":"https://gitee.com/yunyd/tags/Eureka/"},{"name":"Dubbo","slug":"Dubbo","permalink":"https://gitee.com/yunyd/tags/Dubbo/"},{"name":"Redis","slug":"Redis","permalink":"https://gitee.com/yunyd/tags/Redis/"},{"name":"JUC并发编程","slug":"JUC并发编程","permalink":"https://gitee.com/yunyd/tags/JUC%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"MQ","slug":"MQ","permalink":"https://gitee.com/yunyd/tags/MQ/"},{"name":"Maven","slug":"Maven","permalink":"https://gitee.com/yunyd/tags/Maven/"},{"name":"Git","slug":"Git","permalink":"https://gitee.com/yunyd/tags/Git/"},{"name":"项目","slug":"项目","permalink":"https://gitee.com/yunyd/tags/%E9%A1%B9%E7%9B%AE/"},{"name":"MyBatis-Plus","slug":"MyBatis-Plus","permalink":"https://gitee.com/yunyd/tags/MyBatis-Plus/"},{"name":"SSMP","slug":"SSMP","permalink":"https://gitee.com/yunyd/tags/SSMP/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://gitee.com/yunyd/tags/SpringBoot/"},{"name":"MyBatis","slug":"MyBatis","permalink":"https://gitee.com/yunyd/tags/MyBatis/"},{"name":"Spring","slug":"Spring","permalink":"https://gitee.com/yunyd/tags/Spring/"},{"name":"Linux","slug":"Linux","permalink":"https://gitee.com/yunyd/tags/Linux/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://gitee.com/yunyd/tags/SpringMVC/"}]}